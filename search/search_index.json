{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#flyvis-documentation","title":"Flyvis Documentation","text":"<p>A connectome-constrained deep mechanistic network (DMN) model of the fruit fly visual system in PyTorch.</p> <ul> <li>Explore connectome-constrained models of the fruit fly visual system.</li> <li>Generate and test hypotheses about neural computations.</li> <li>Try pretrained models on your data.</li> <li>Develop custom models using our framework.</li> </ul> <p>Flyvis is our official implementation of Lappalainen et al., \u201cConnectome-constrained networks predict neural activity across the fly visual system.\u201d Nature (2024).</p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#tutorials","title":"Tutorials","text":"<ol> <li>Explore the Connectome: Learn about the structure of the fly visual system connectome.</li> <li>Train the Network: Understand how to train the network on an optic flow task.</li> <li>Flash Responses: Explore how the model responses to flash stimuli.</li> <li>Moving Edge Responses: Analyze the model\u2019s responses to moving edge stimuli.</li> <li>Ensemble Clustering: Learn about clustering ensembles of models.</li> <li>Maximally Excitatory Stimuli: Discover how to find stimuli that maximally excite neurons.</li> <li>Custom Stimuli: Learn how to provide your own custom stimuli to the model.</li> </ol>"},{"location":"#main-results","title":"Main Results","text":"<p>These notebooks show the main results of the paper:</p> <ol> <li>Fig. 1: Connectome-constrained and task-optimized models of the fly visual system.</li> <li>Fig. 2: Ensembles of DMNs predict tuning properties.</li> <li>Fig. 3: Cluster analysis of DMN ensembles enables hypothesis generation and suggests experimental tests.</li> <li>Fig. 4: Task-optimal DMNs largely recapitulate known mechanisms of motion computation.</li> </ol>"},{"location":"#usage-guide","title":"Usage Guide","text":""},{"location":"#quickstart-with-google-colab","title":"Quickstart with Google Colab","text":"<p>Try the models and code inside our Google Colab notebooks for a quickstart.</p> <ul> <li>Explore the connectome</li> <li>Optic flow task</li> <li>Flash responses</li> <li>Moving edge responses</li> <li>Umap and clustering</li> <li>Maximally excitatory stimuli</li> <li>Provide custom stimuli</li> </ul>"},{"location":"#local-installation","title":"Local Installation","text":"<p>See install.md for details on how to install the package and download the pretrained models.</p>"},{"location":"#api-reference","title":"API Reference","text":"<p>For detailed information about flyvis\u2019 components and functions, please refer to our API Reference section. This includes documentation for things like</p> <ul> <li>Core components like Connectomes, Network, NetworkView, EnsembleView</li> <li>Analysis tools for flash responses, moving stimuli, optimal stimuli generation, ensemble clustering</li> <li>Command line tools for training, validation, and analysis</li> </ul>"},{"location":"#command-line-interface","title":"Command Line Interface","text":"<p>For running experiments and analysis pipelines, check out our Command Line Interface documentation. This provides tools for training models, running analysis, and managing experiments on compute clusters.</p>"},{"location":"#related-projects","title":"Related Projects","text":"<p>Projects using or building upon flyvis:</p> <ul> <li>NeuroMechFly: A neuromechanical model of the adult fruit fly that integrates our visual system model for sensory processing.</li> </ul>"},{"location":"#citation","title":"Citation","text":"<pre><code>@article{lappalainen2024connectome,\n    title = {Connectome-constrained networks predict neural activity across the fly visual system},\n    issn = {1476-4687},\n    url = {https://doi.org/10.1038/s41586-024-07939-3},\n    doi = {10.1038/s41586-024-07939-3},\n    journal = {Nature},\n    author = {Lappalainen, Janne K. and Tschopp, Fabian D. and Prakhya, Sridhama and McGill, Mason and Nern, Aljoscha and Shinomiya, Kazunori and Takemura, Shin-ya and Gruntman, Eyal and Macke, Jakob H. and Turaga, Srinivas C.},\n    month = sep,\n    year = {2024},\n}\n</code></pre> <p>If you have any questions or encounter any issues, please check our FAQ or Contributing pages for more information.</p>"},{"location":"acknowledgements/","title":"Acknowledgements","text":"<p><code>flyvision</code> is developed at the Macke Lab at the University of T\u00fcbingen and at the Turaga Lab at Janelia Research Campus.</p>"},{"location":"acknowledgements/#paper","title":"Paper","text":"<p>Acknowledgements for the scientific content can be found in the paper.</p> <p>Lappalainen J.K., Tschopp F.D., Prakhya S., McGill M., Nern A., Shinomiya K., Takemura S., Gruntman E., Macke J.H., Turaga S.C., Connectome-constrained networks predict neural activity across the fly visual system. Nature 1\u20139 (2024).</p>"},{"location":"acknowledgements/#funding","title":"Funding","text":"<p>This project was supported by the HHMI. J.K.L. and J.H.M. were supported by the German Research Foundation (DFG) through Germany\u2019s Excellence Strategy (EXC-Number 2064/1, Project number 390727645), the German Federal Ministry of Education and Research (BMBF; T\u00fcbingen AI Center, FKZ: 01IS18039A) and the European Union (ERC, DeepCoMechTome, 101089288).</p>"},{"location":"acknowledgements/#credits-to-colleagues","title":"Credits to colleagues","text":"<p>We extend credits to Jan Funke for an early discussion on the IO code. Roman Vaxenburg for the function <code>is_inside_hex</code> for more fine-grained control over stimulus rendering. The whole new flyvis team at the Macke Lab for supporting the code cleanup and filling in tutorial notebooks. Gert-Jan Both for general feedback and for pointing towards xarray and joblib for pruning of labeled tensor code and custom caching.</p>"},{"location":"acknowledgements/#disclaimer-on-the-usage-of-ai","title":"Disclaimer on the usage of AI","text":"<p>The majority of the code in <code>flyvision</code> is based on code that we wrote before the widespread use of AI in scientific software development. Since our preprint was realeased in early 2023, we used AI in the last months to help us with in depth documentation. We tested the code to the best of our ability, but it might still contain errors. Please help us improve the code by opening an issue on Github.</p>"},{"location":"acknowledgements/#credits-to-open-source-software","title":"Credits to open source software","text":"<p>PyTorch, NumPy, xarray, matplotlib,umap-learn, pandas, scikit-learn, scipy, omegaconf, hydra, networkx, toolz, joblib</p>"},{"location":"acknowledgements/#mit-license","title":"MIT License","text":"<p>Copyright \u00a9 2023 Janne K. Lappalainen, Fabian D. Tschopp, Mason McGill, Jakob H. Macke, Srinivas C. Turaga</p>"},{"location":"contribute/","title":"Contributing","text":"<p>Please submit an issue on GitHub for any suggestions for improving the code, bug reports, or questions. We will attend to issues and pull requests as time allows and appreciate any feedback! To get involved, please read the developer guide.</p>"},{"location":"contribute/#developer-guide","title":"Developer Guide","text":""},{"location":"contribute/#project-setup","title":"Project Setup","text":"<p>This project uses Python and is built with setuptools. It requires Python 3.6 or higher.</p>"},{"location":"contribute/#installation","title":"Installation","text":"<p>To set up the development environment:</p> <ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/turagalab/flyvis.git\ncd flyvision\n</code></pre></p> </li> <li> <p>Create and activate a virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate\n</code></pre></p> </li> <li> <p>Install the package with development dependencies:    <pre><code>pip install -e \".[dev]\"\n</code></pre></p> </li> </ol>"},{"location":"contribute/#development-tools","title":"Development Tools","text":""},{"location":"contribute/#code-formatting-and-linting","title":"Code Formatting and Linting","text":"<p>We use the following tools for code quality:</p> <ul> <li>Ruff: For linting and code formatting. Configuration is in <code>pyproject.toml</code>.</li> <li>Pre-commit: To run checks before committing.</li> </ul> <p>To set up pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"contribute/#testing","title":"Testing","text":"<p>We use pytest for testing. Run tests with:</p> <pre><code>pytest\n</code></pre> <p>Pytest configuration is in <code>pyproject.toml</code>. Notable markers: - <code>slow</code>: For time-consuming tests - <code>gpu</code>: For tests requiring a GPU - <code>require_large_download</code>: For tests needing large data downloads - <code>require_download</code>: For tests needing data downloads</p> <p>To run tests excluding certain markers:</p> <pre><code>pytest -m \"not slow and not gpu and not require_large_download and not require_download\"\n</code></pre>"},{"location":"contribute/#documentation","title":"Documentation","text":"<p>Documentation is built using MkDocs. To build and serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>To build the documentation:</p>"},{"location":"contribute/#dependency-management","title":"Dependency Management","text":"<ul> <li>Main dependencies are listed in <code>pyproject.toml</code> under <code>[project.dependencies]</code>.</li> <li>Development dependencies are under <code>[project.optional-dependencies.dev]</code>.</li> <li>Documentation dependencies are under <code>[project.optional-dependencies.docs]</code>.</li> </ul> <p>To install all dependencies including development and documentation:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre>"},{"location":"contribute/#version-management","title":"Version Management","text":"<p>This project uses <code>setuptools_scm</code> for versioning. The version is automatically derived from git tags.</p>"},{"location":"contribute/#project-structure","title":"Project Structure","text":"<ul> <li><code>flyvision/</code>: Main package directory</li> <li><code>tests/</code>: Test files</li> <li><code>docs/</code>: Documentation files</li> <li><code>examples/</code>: Example scripts and notebooks</li> <li><code>scripts/</code>: Utility scripts</li> <li><code>config/</code>: Configuration files</li> <li><code>data/</code>: Data files</li> </ul>"},{"location":"contribute/#contribution-guidelines","title":"Contribution Guidelines","text":"<ol> <li>Fork the repository and create your branch from <code>main</code>.</li> <li>Ensure the test suite passes by running <code>pytest</code>.</li> <li>Make sure your code follows the project\u2019s style guide (enforced by Ruff).</li> <li>Update documentation as necessary.</li> <li>Create a pull request with a clear description of your changes.</li> </ol>"},{"location":"contribute/#additional-notes","title":"Additional Notes","text":"<ul> <li>The project includes optional dependencies for development, documentation, and examples. Install them as needed.</li> </ul> <p>For any questions or issues, please open an issue on the project\u2019s GitHub repository.</p>"},{"location":"faq/","title":"Frequently asked questions","text":"<p>We have not created a formal FAQ yet. Please submit an issue on GitHub for any questions.</p>"},{"location":"install/","title":"Install","text":""},{"location":"install/#local-installation","title":"Local installation","text":"<p>Note: <code>flyvis</code> is only tested on Linux.</p>"},{"location":"install/#create-virtual-environment","title":"Create virtual environment","text":""},{"location":"install/#option-1-using-conda-recommended","title":"Option 1: Using conda (recommended)","text":"<ol> <li>Create a new conda environment: <code>conda create --name flyvision python=3.9 -y</code></li> <li>Activate the new conda environment: <code>conda activate flyvision</code></li> </ol>"},{"location":"install/#option-2-using-venv","title":"Option 2: Using venv","text":"<ol> <li>Create a new virtual environment: <code>python -m venv flyvision_env</code></li> <li>Activate the virtual environment: <code>source flyvision_env/bin/activate</code></li> </ol>"},{"location":"install/#clone-repo-and-install","title":"Clone repo and install","text":"<ol> <li>Clone the repository: <code>git clone https://github.com/TuragaLab/flyvis.git</code></li> <li>Navigate to the repo: <code>cd flyvis</code></li> <li>Install in developer mode: <code>pip install -e .</code></li> </ol> <p>For development, documentation, or to run examples, you can install additional dependencies: - For development: <code>pip install -e \".[dev]\"</code> - For documentation: <code>pip install -e \".[docs]\"</code> - For examples: <code>pip install -e \".[example]\"</code></p> <p>Note: We make flyvision available on pypi soon to simplify the installation process.</p>"},{"location":"install/#download-pretrained-models","title":"Download pretrained models","text":"<p>After installation, download the pretrained models by running:</p> <pre><code>flyvis download-pretrained\n</code></pre> <p>Make sure to run this command from your active flyvision environment.</p>"},{"location":"install/#set-environment-variables","title":"Set environment variables","text":"<p><code>flyvis</code> uses environment variables for configuration. These can be set using a <code>.env</code> file or manually.</p>"},{"location":"install/#option-1-using-env-file","title":"Option 1: Using .env file","text":"<p>Create a <code>.env</code> file in one of these locations (in order of precedence):</p> <ol> <li>Your current working directory (where you run your scripts)</li> <li>The root directory of your project</li> <li>Any parent directory of your working directory</li> </ol> <p>Example <code>.env</code> file contents: <pre><code># Set your preferred data directory (default: './data' relative to package directory)\nFLYVIS_ROOT_DIR='path/to/your/data'\n</code></pre></p>"},{"location":"install/#option-2-setting-environment-variables-manually","title":"Option 2: Setting environment variables manually","text":"<p>You can also set the environment variables directly in your shell:</p> <pre><code>export FLYVIS_ROOT_DIR='path/to/your/data'\n</code></pre> <p>Note: The data directory is where <code>flyvis</code> will store downloaded models, cached data, and other files. If <code>FLYVIS_ROOT_DIR</code> is not set, it defaults to a <code>data</code> folder in the package directory.</p>"},{"location":"release/","title":"Release Process","text":""},{"location":"release/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Ensure all tests pass: <pre><code>pytest\n</code></pre></p> </li> <li> <p>Update and verify the documentation: Follow the instructions in the readme to update and verify the documentation. The deployment to github can be done last or via workflow.</p> </li> <li> <p>Install required tools: <pre><code>python -m pip install build twine\n</code></pre></p> </li> </ol>"},{"location":"release/#release-steps","title":"Release Steps","text":"<ol> <li>Test PyPi before committing (optional)</li> </ol> <p>One can create the wheel and upload it to Test PyPi before committing to develop the package. This can be useful to test if the installation will work before commiting to a version number and push to the remote repository. However, the wheels that are uploaded to Test PyPi cannot be deleted so one should probably do this sparingly and not use version numbers one wants to reserve for the actual release.</p>"},{"location":"release/#upload-to-test-pypi","title":"Upload to Test PyPi","text":"<pre><code># Clean previous builds\nrm -rf dist/\n\n# Set version temporarily for this session manually (change version number)\nexport SETUPTOOLS_SCM_PRETEND_VERSION=0.0.0.dev7\n\n# Now build and test\npython -m build\n\n# Upload to Test PyPI first\npython -m twine upload --repository testpypi dist/*\n</code></pre>"},{"location":"release/#test-installation","title":"Test Installation","text":"<p>In a clean environment, run these sporadic tests to verify the installation: <pre><code># Install in clean environment to test (change version number)\npython -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ flyvis==0.0.0.dev7\n\n# Test installation\nflyvis download-pretrained\nflyvis train --help\nflyvis train-single --help\npython -c \"from flyvis import Network; n = Network()\"\npython -c \"from flyvis import EnsembleView; e = EnsembleView('flow/0000')\"\n\n\n# Test custom configuration\nflyvis init-config\n# Add custom_syn_strength.yaml to flyvis_config/network/edge_config/syn_strength/\ncat &gt; flyvis_config/network/edge_config/syn_strength/custom_syn_strength.yaml &lt;&lt; 'EOL'\ndefaults:\n  - /network/edge_config/syn_strength/syn_strength@_here_\n  - _self_\n\nscale: 1.0\nEOL\n# Run training and check if custom config is loaded correctly\nflyvis train-single --config-dir $(pwd)/flyvis_config network/edge_config/syn_strength=custom_syn_strength ensemble_and_network_id=0 task_name=flow delete_if_exists=true 2&gt;&amp;1 | while read line; do\n    echo \"$line\"\n    if [[ \"$line\" == *\"'syn_strength': {'type': 'SynapseCountScaling'\"* &amp;&amp; \"$line\" == *\"'scale': 1.0\"* ]]; then\n        echo \"Found custom scale parameter in config!\"\n        pkill -P $$\n        break\n    fi\ndone\n# Delete custom config\nrm -rf flyvis_config\n\n# Delete installation and downloaded models\npip uninstall flyvis -y\n\n# When done testing, unset it\nunset SETUPTOOLS_SCM_PRETEND_VERSION\n</code></pre></p>"},{"location":"release/#commit-changes","title":"Commit Changes","text":"<p>Commit all open changes to the repository.</p>"},{"location":"release/#update-changelog","title":"Update Changelog","text":"<ul> <li>Append entry in <code>CHANGELOG.md</code> with new version number</li> <li>Include all notable changes under appropriate sections, e.g.,</li> <li>Breaking</li> <li>Features</li> <li>Documentation</li> <li>Infrastructure</li> <li>Distribution</li> <li>Bug Fixes</li> </ul> <pre><code>git add CHANGELOG.md\ngit commit -m \"docs: add changelog for v1.1.2\"\n</code></pre>"},{"location":"release/#create-and-push-tag","title":"Create and Push Tag","text":"<pre><code># Create annotated tag using changelog\ngit tag -a v1.1.2 -F CHANGELOG.md\n\n# Push to both remotes\ngit push origin main\ngit push origin v1.1.2\ngit push public_repo main\ngit push public_repo v1.1.2\n</code></pre>"},{"location":"release/#build-and-upload-to-pypi","title":"Build and Upload to PyPI","text":"<pre><code># Clean previous builds\nrm -rf dist/\n\n# Set version temporarily for this session manually\nexport SETUPTOOLS_SCM_PRETEND_VERSION=1.1.2\n\n# Build package\npython -m build\n\n# Upload to PyPI\npython -m twine upload dist/*\n</code></pre>"},{"location":"release/#create-github-release","title":"Create GitHub Release","text":"<ul> <li>Go to GitHub releases page</li> <li>Create new release using the tag</li> <li>Copy changelog entry into release description</li> </ul>"},{"location":"release/#post-release","title":"Post-release","text":"<ol> <li>Verify package can be installed from PyPI: <pre><code>python -m pip install flyvis\n</code></pre></li> </ol>"},{"location":"release/#check-documentation-is-updated-on-the-documentation-website","title":"Check documentation is updated on the documentation website","text":""},{"location":"release/#version-numbering","title":"Version Numbering","text":"<p>We follow semantic versioning (MAJOR.MINOR.PATCH): - MAJOR: Breaking changes - MINOR: New features (backwards compatible) - PATCH: Bug fixes</p>"},{"location":"release/#notes","title":"Notes","text":"<ul> <li>Always test on Test PyPI before releasing to PyPI</li> <li>Ideally CI checks pass before releasing</li> <li>Keep both origin and public_repo remotes in sync</li> </ul>"},{"location":"examples/01_flyvision_connectome/","title":"Connectome","text":"<p>This notebook illustrates the constructed spatially invariant connectome from local reconstructions that builds the scaffold of the network.</p>"},{"location":"examples/01_flyvision_connectome/#the-connectome-from-average-local-reconstructions","title":"The connectome from average local reconstructions","text":"<pre><code>from flyvis import connectome_file\nfrom flyvis import ConnectomeFromAvgFilters, ConnectomeView\n</code></pre> <pre><code># The ConnectomeFromAvgFilters class compiles the network graph from `data/connectome/fib25-fib19_v2.2.json`.\n# This json-file includes a list of cell types (`nodes`) and average convolutional filters\n# (anatomical receptive fields) (`edges`) that are scattered across a regular hexagonal lattice\n# of 15 column extent and stored on the hierarchical filesystem as h5-files.\nconfig = dict(file=connectome_file.name, extent=15, n_syn_fill=1)\nconnectome = ConnectomeFromAvgFilters(config)\n</code></pre> <pre><code># our network models 45,669 cells represented in this table of nodes\nprint(connectome.nodes.to_df().iloc[0:20].to_markdown())\n</code></pre> <pre><code>|    |   index | role   | type   |   u |   v |\n|---:|--------:|:-------|:-------|----:|----:|\n|  0 |       0 | input  | R1     | -15 |   0 |\n|  1 |       1 | input  | R1     | -15 |   1 |\n|  2 |       2 | input  | R1     | -15 |   2 |\n|  3 |       3 | input  | R1     | -15 |   3 |\n|  4 |       4 | input  | R1     | -15 |   4 |\n|  5 |       5 | input  | R1     | -15 |   5 |\n|  6 |       6 | input  | R1     | -15 |   6 |\n|  7 |       7 | input  | R1     | -15 |   7 |\n|  8 |       8 | input  | R1     | -15 |   8 |\n|  9 |       9 | input  | R1     | -15 |   9 |\n| 10 |      10 | input  | R1     | -15 |  10 |\n| 11 |      11 | input  | R1     | -15 |  11 |\n| 12 |      12 | input  | R1     | -15 |  12 |\n| 13 |      13 | input  | R1     | -15 |  13 |\n| 14 |      14 | input  | R1     | -15 |  14 |\n| 15 |      15 | input  | R1     | -15 |  15 |\n| 16 |      16 | input  | R1     | -14 |  -1 |\n| 17 |      17 | input  | R1     | -14 |   0 |\n| 18 |      18 | input  | R1     | -14 |   1 |\n| 19 |      19 | input  | R1     | -14 |   2 |\n</code></pre> <pre><code># our network models 1,513,231 synapses represented in this table of edges\nprint(connectome.edges.to_df().iloc[0:20].to_markdown())\n</code></pre> <pre><code>|    |   du |   dv |   n_syn |   n_syn_certainty |   sign |   source_index | source_type   |   source_u |   source_v |   target_index | target_type   |   target_u |   target_v |\n|---:|-----:|-----:|--------:|------------------:|-------:|---------------:|:--------------|-----------:|-----------:|---------------:|:--------------|-----------:|-----------:|\n|  0 |    0 |    0 |      40 |           5.85948 |     -1 |              0 | R1            |        -15 |          0 |           5768 | L1            |        -15 |          0 |\n|  1 |    0 |    0 |      40 |           5.85948 |     -1 |              1 | R1            |        -15 |          1 |           5769 | L1            |        -15 |          1 |\n|  2 |    0 |    0 |      40 |           5.85948 |     -1 |              2 | R1            |        -15 |          2 |           5770 | L1            |        -15 |          2 |\n|  3 |    0 |    0 |      40 |           5.85948 |     -1 |              3 | R1            |        -15 |          3 |           5771 | L1            |        -15 |          3 |\n|  4 |    0 |    0 |      40 |           5.85948 |     -1 |              4 | R1            |        -15 |          4 |           5772 | L1            |        -15 |          4 |\n|  5 |    0 |    0 |      40 |           5.85948 |     -1 |              5 | R1            |        -15 |          5 |           5773 | L1            |        -15 |          5 |\n|  6 |    0 |    0 |      40 |           5.85948 |     -1 |              6 | R1            |        -15 |          6 |           5774 | L1            |        -15 |          6 |\n|  7 |    0 |    0 |      40 |           5.85948 |     -1 |              7 | R1            |        -15 |          7 |           5775 | L1            |        -15 |          7 |\n|  8 |    0 |    0 |      40 |           5.85948 |     -1 |              8 | R1            |        -15 |          8 |           5776 | L1            |        -15 |          8 |\n|  9 |    0 |    0 |      40 |           5.85948 |     -1 |              9 | R1            |        -15 |          9 |           5777 | L1            |        -15 |          9 |\n| 10 |    0 |    0 |      40 |           5.85948 |     -1 |             10 | R1            |        -15 |         10 |           5778 | L1            |        -15 |         10 |\n| 11 |    0 |    0 |      40 |           5.85948 |     -1 |             11 | R1            |        -15 |         11 |           5779 | L1            |        -15 |         11 |\n| 12 |    0 |    0 |      40 |           5.85948 |     -1 |             12 | R1            |        -15 |         12 |           5780 | L1            |        -15 |         12 |\n| 13 |    0 |    0 |      40 |           5.85948 |     -1 |             13 | R1            |        -15 |         13 |           5781 | L1            |        -15 |         13 |\n| 14 |    0 |    0 |      40 |           5.85948 |     -1 |             14 | R1            |        -15 |         14 |           5782 | L1            |        -15 |         14 |\n| 15 |    0 |    0 |      40 |           5.85948 |     -1 |             15 | R1            |        -15 |         15 |           5783 | L1            |        -15 |         15 |\n| 16 |    0 |    0 |      40 |           5.85948 |     -1 |             16 | R1            |        -14 |         -1 |           5784 | L1            |        -14 |         -1 |\n| 17 |    0 |    0 |      40 |           5.85948 |     -1 |             17 | R1            |        -14 |          0 |           5785 | L1            |        -14 |          0 |\n| 18 |    0 |    0 |      40 |           5.85948 |     -1 |             18 | R1            |        -14 |          1 |           5786 | L1            |        -14 |          1 |\n| 19 |    0 |    0 |      40 |           5.85948 |     -1 |             19 | R1            |        -14 |          2 |           5787 | L1            |        -14 |          2 |\n</code></pre>"},{"location":"examples/01_flyvision_connectome/#connectivity-between-identified-cell-types","title":"Connectivity between identified cell types","text":"<p>Identified connectivity between 64 cell types, represented by total number of input synapses from all neurons of a given presynaptic cell type to a single postsynaptic of a given cell type. Blue color indicates putative hyperpolarizing inputs, red putative depolarizing inputs as inferred from neurotransmitter and receptor profiling. Size of squares indicates number of input synapses.</p> <pre><code># the ConnectomeView class provides visualizations of the connectome data\nconnectome_view = ConnectomeView(connectome)\n</code></pre> <pre><code>fig = connectome_view.connectivity_matrix(\"n_syn\")\n</code></pre> <p></p>"},{"location":"examples/01_flyvision_connectome/#example-receptive-fields","title":"Example receptive fields","text":"<p>Example of convolutional filter, representing inputs onto cells of the target cell type. Values represent the average number of synapses projecting from presynaptic cells in columns with indicated offset onto the postsynaptic dendrite. Values indicate connection strength derived from electron microscopy data.</p> <pre><code>fig = connectome_view.receptive_fields_grid(\"T4c\")\n</code></pre> <p></p>"},{"location":"examples/01_flyvision_connectome/#example-projective-fields","title":"Example projective fields","text":"<p>Example of projective fields, representing outputs of a source cell type onto target cells. Values represent the average number of synapses projecting from the presynaptic cell onto postsynaptic dendrites in columns with indicated offset. Values indicate connection strength derived from electron microscopy data.</p> <pre><code>fig = connectome_view.projective_fields_grid(\"T4c\")\n</code></pre> <p></p>"},{"location":"examples/01_flyvision_connectome/#network-layout","title":"Network layout","text":"<p>Our retinotopic hexagonal lattice network organizes cells of each cell type into visual columns corresponding to photoreceptor locations to capture the crystalline, hexagonal structure of the fly eye. Some cell types are non-columnar, i.e. their cells occur only in every other column\u2014here Lawf1 and Lawf2 cell types\u2014as estimated by our connectome construction algorithm. The edges represent pairs of connected cell types. For the task, we decoded from T-shaped and transmedullary cells (within the black box).</p> <pre><code># cause the layout is spatially periodic it suffices to visualize a few columns\n# to get the gist of the layout which can be controlled using max_extent\nfig = connectome_view.network_layout(max_extent=6)\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/","title":"Optic flow task","text":"<p>This notebook illustrates the optic flow task and how to use it with our pretrained fly visual system model and decoder.</p>"},{"location":"examples/02_flyvision_optic_flow_task/#the-sintel-dataset","title":"The Sintel dataset","text":"<p>We use the Sintel dataset to train our models as described in the paper. More infos about the Sintel dataset can be found on the official Sintel website: http://sintel.is.tue.mpg.de/.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom flyvis.datasets.sintel import MultiTaskSintel\nfrom flyvis.analysis.animations.sintel import SintelSample\n</code></pre> <p>The class <code>MultiTaskSintel</code> loads, preprocesses, renders, and augments the sintel data. It adheres to the pytorch dataset primitive. It provides the interface to the input data and the output data for the flyvis networks. Note: the fly-eye rendering we use here, we introduce in the notebook on creating custom stimuli already.</p> <p>This is the full setting:</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    # Because the fly eye rendering is square\n    # and sintel is wide, we can crop sintel\n    # in width and render three sequences from one.\n    # This allows us to statically augment our dataset\n    # a bit already before we proceed with the random augmentations.\n    # We end up with 3 * 23 sequences.\n    vertical_splits=3,\n    n_frames=19,\n    center_crop_fraction=0.7,\n    dt=1 / 50,\n    augment=True,\n    # From sequences with more than n_frames, we randomly sample the start frame.\n    random_temporal_crop=True,\n    all_frames=False,\n    # We resample movie frames to the effective framerate given by 1/dt\n    resampling=True,\n    # We interpolate the flow arrows to 1/dt.\n    interpolate=True,\n    # We flip with equal probability (using one flip-axis).\n    p_flip=0.5,\n    flip_axes=[0, 1],\n    # We rotate with equal probability (using five fold rotation symmetry of the hex-grid).\n    p_rot=5 / 6,\n    # We randomly adjust contrast and brightness.\n    contrast_std=0.2,\n    brightness_std=0.1,\n    # We add random white noise pixelweise.\n    gaussian_white_noise=0.08,\n    gamma_std=None,\n    _init_cache=True,\n    unittest=False,\n)\n</code></pre> <pre><code>[2024-12-08 19:30:46] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code># The `dataset.arg_df` tracks the sequence index, identity etc.\ndataset.arg_df\n</code></pre> index original_index name original_n_frames 0 0 0 sequence_00_alley_1_split_00 50 1 1 0 sequence_00_alley_1_split_01 50 2 2 0 sequence_00_alley_1_split_02 50 3 3 1 sequence_01_alley_2_split_00 50 4 4 1 sequence_01_alley_2_split_01 50 ... ... ... ... ... 64 64 21 sequence_21_temple_2_split_01 50 65 65 21 sequence_21_temple_2_split_02 50 66 66 22 sequence_22_temple_3_split_00 50 67 67 22 sequence_22_temple_3_split_01 50 68 68 22 sequence_22_temple_3_split_02 50 <p>69 rows \u00d7 4 columns</p>"},{"location":"examples/02_flyvision_optic_flow_task/#single-sample","title":"Single sample","text":"<p>First, let\u2019s chunk this into smaller digestable pieces.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    dt=1 / 24,\n    augment=False,\n)\n</code></pre> <pre><code>[2024-12-08 19:30:51] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <p>The first sample. For the target, the pixel-accurate motion vectors, the color indicates the direction of motion of the respective input pixel. The saturation indicates the magnitude of motion.</p> <pre><code>lum = dataset[0][\"lum\"]\nflow = dataset[0][\"flow\"]\n\nanimation = SintelSample(lum[None], flow[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p> <p>Sintel has more groundtruth annotations. We support depth and flow because we know with some confidence that these are relevant for the fly.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"depth\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    dt=1 / 24,\n    augment=False,\n)\n</code></pre> <pre><code>[2024-12-08 19:30:58] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n[2024-12-08 19:30:58] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code>lum1 = dataset[0][\"lum\"]\ndepth1 = dataset[0][\"depth\"]\n\nanimation = SintelSample(lum1[None], depth1[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#augmenting-the-dataset-step-by-step","title":"Augmenting the dataset step-by-step","text":"<p>We apply rich augmentations to the dataset of naturalistic sequences because the dataset is otherwise relatively small. This might lead to overfitting to, e.g., predicting motion mostly into well-represented directons or of objects of specific contrasts etc. Using rich augmentations, we \u2018ask\u2019 the network to generalize better and invariantly compute motion regardless of direction, contrast, brightness, pixel noise, temporal appearance etc.</p>"},{"location":"examples/02_flyvision_optic_flow_task/#vertical-splits","title":"Vertical splits","text":"<p>First, we split each sequence into three sequences vertically to leverage a wider extent of the video than if we would only render the center. We precompute these renderings.</p> <pre><code>from flyvis.analysis.visualization.plots import quick_hex_scatter\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    dt=1 / 24,\n    augment=False,\n)\n</code></pre> <pre><code>[2024-12-08 19:31:04] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <p>Sintel has 23 movie sequences originally.</p> <pre><code>len(np.unique(dataset.arg_df.original_index))\n</code></pre> <pre><code>23\n</code></pre> <p>Each original sequence is 436 pixel in height times 1024 pixel in width in cartesian coordinates.</p> <pre><code>sequence = dataset.cartesian_sequence(0, vertical_splits=1, center_crop_fraction=1.0)\nprint(sequence.shape)\n</code></pre> <pre><code>(1, 49, 436, 1024)\n</code></pre> <p>With the vertical crops, we end up with 3 * 23 sequences. The <code>dataset.arg_df</code> tracks the sequence index, identity etc.</p> <pre><code>dataset.arg_df\n</code></pre> index original_index name original_n_frames 0 0 0 sequence_00_alley_1_split_00 50 1 1 0 sequence_00_alley_1_split_01 50 2 2 0 sequence_00_alley_1_split_02 50 3 3 1 sequence_01_alley_2_split_00 50 4 4 1 sequence_01_alley_2_split_01 50 ... ... ... ... ... 64 64 21 sequence_21_temple_2_split_01 50 65 65 21 sequence_21_temple_2_split_02 50 66 66 22 sequence_22_temple_3_split_00 50 67 67 22 sequence_22_temple_3_split_01 50 68 68 22 sequence_22_temple_3_split_02 50 <p>69 rows \u00d7 4 columns</p> <pre><code>_ = plt.imshow(sequence[0, 0], cmap=plt.cm.binary_r)\n</code></pre> <p></p> <pre><code>fig, axes = plt.subplots(1, 3)\n_ = quick_hex_scatter(dataset[0]['lum'][0].flatten(), fig=fig, ax=axes[0], cbar=False)\n_ = quick_hex_scatter(dataset[1]['lum'][0].flatten(), fig=fig, ax=axes[1], cbar=False)\n_ = quick_hex_scatter(dataset[2]['lum'][0].flatten(), fig=fig, ax=axes[2], cbar=False)\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#random-temporal-crops","title":"Random temporal crops","text":"<p>We train on 19 frames ~ 792ms movie. Most sequences have 49 frames. To use the whole temporal content, we stochastically sample start and end frame ~ ((1, 19), (2, 20), \u2026, (31, 49)).</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 24,\n    augment=True,\n    random_temporal_crop=True,\n    all_frames=False,\n    resampling=False,\n    interpolate=False,\n    p_flip=0,\n    p_rot=0,\n    contrast_std=None,\n    brightness_std=None,\n    gaussian_white_noise=None,\n)\n</code></pre> <pre><code>[2024-12-08 19:31:14] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code># These two samples from the same original sequence should have stochastically different start and end frames.\nlum1 = dataset[0]['lum']\nlum2 = dataset[0]['lum']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#flips-and-rotations","title":"Flips and rotations","text":"<p>Next, we flip stochastically across 2 axes and or rotate a random number of times around the center. We implement this to be fast to do so at runtime.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 24,\n    augment=True,\n    random_temporal_crop=False,\n    all_frames=False,\n    resampling=False,\n    interpolate=False,\n    p_flip=1 / 2,\n    p_rot=5 / 6,\n    contrast_std=None,\n    brightness_std=None,\n    gaussian_white_noise=None,\n)\n</code></pre> <pre><code>[2024-12-08 19:31:22] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code># These two samples from the same original sequence should have stochastically different orientation.\nlum1 = dataset[0]['lum']\nlum2 = dataset[0]['lum']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\nanimation.animate_in_notebook()\n</code></pre> <p></p> <p>Flow vectors need to be flipped and rotated accordingly.</p> <pre><code># These two samples from the same original sequence should have stochastically different orientation.\ndata = dataset[0]\nlum1 = data['lum']\nflow1 = data['flow']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], flow1[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#further-augmentations","title":"Further augmentations","text":"<p>Besides that, we also augment the input with random contrasts and brightnesses and random gaussian pixel noise, while the motion stays the same. This pretends that the same motion takes place under different illumination conditions and signal to noise ratios.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 24,\n    augment=True,\n    random_temporal_crop=False,\n    all_frames=False,\n    resampling=False,\n    interpolate=False,\n    p_flip=0,\n    p_rot=0,\n    contrast_std=0.2,\n    brightness_std=0.1,\n    gaussian_white_noise=0.08,\n)\n</code></pre> <pre><code>[2024-12-08 19:31:35] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code># These two samples from the same original sequence have\n# stochastically different contrast, brightness and pixel-wise noise.\nlum1 = dataset[0]['lum']\nlum2 = dataset[0]['lum']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], lum2[None], title2=\"input\")\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#framerate-of-the-dataset-and-integration-time-step","title":"Framerate of the dataset and integration time step","text":"<p>The Sintel dataset is originally rendered at 24 frames per second, i.e., one frame every 42ms. The fruit fly neurons are able to respond to temporal differences as fast as 5-20ms. Therefore, we resample every frame multiple times to pretend that the movie was originally sampled at such a faster framerate. For the motion fields, we interpolate flow vectors in time instead of resampling them, which hopefully gives a better learning signal to the network. We have to trade-off speed of the numerical integration and memory consumption during optimization with the simulation accuracy by choosing time steps between 5-20ms. We chose to train networks at the upper bount of 20ms and evaluate them more accurately at 5-10ms.</p> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=3,\n    n_frames=19,\n    dt=1 / 50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>[2024-12-08 19:31:42] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code># Now, every input frame appears twice and target frames are interpolated.\ndata = dataset[0]\nlum1 = data['lum']\nflow1 = data['flow']\n</code></pre> <pre><code>animation = SintelSample(lum1[None], flow1[None])\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#computing-responses-to-the-sintel-data","title":"Computing responses to the Sintel data","text":"<p>Before we get to training a network, we look at a few responses to these type of sequences of individual neurons.</p> <pre><code>from flyvis.network import NetworkView, Network\nfrom flyvis.utils.activity_utils import LayerActivity\n\nfrom flyvis.datasets.sintel import MultiTaskSintel\n</code></pre> <pre><code># new network instance\nnetwork = Network()\n\n# Alternative: uncomment to use a pretrained network\n# network_view = NetworkView(results_dir / \"flow/0000/000\")\n# network = network_view.init_network(network)\n</code></pre> <pre><code>[2024-12-08 19:31:59] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n</code></pre> <pre><code>layer_activity = LayerActivity(None, network.connectome, keepref=True)\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    n_frames=19,\n    dt=1 / 50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>[2024-12-08 19:32:04] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code>stationary_state = network.fade_in_state(1.0, dataset.dt, dataset[0][\"lum\"][[0]])\nresponses = network.simulate(\n    dataset[0][\"lum\"][None], dataset.dt, initial_state=stationary_state\n).cpu()\n</code></pre> <pre><code>plt.figure(figsize=[3, 2])\nlayer_activity.update(responses)\nr = layer_activity.central.T4c.squeeze().numpy()\ntime = np.arange(0, r.shape[0], 1) * dataset.dt\nplt.plot(time, r)\nplt.xlabel(\"time in s\")\nplt.ylabel(\"voltage (a.u.)\")\nplt.title(\"response of central T4c cell\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'response of central T4c cell')\n</code></pre> <p></p>"},{"location":"examples/02_flyvision_optic_flow_task/#decoding-the-task-from-neural-activity","title":"Decoding the task from neural activity","text":"<p>We need to predict the pixel-accurate flow field that Sintel gives us. For that we decode the voltages of a bunch of cell types. The decoder and the network are trained end-to-end. Here an example of a forward pass through the whole pipeline in code.</p> <pre><code>from flyvis.datasets.sintel import MultiTaskSintel\nfrom flyvis.task.decoder import DecoderGAVP\n</code></pre> <pre><code>network = Network()\n</code></pre> <pre><code>[2024-12-08 19:32:15] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n</code></pre> <pre><code>decoder = DecoderGAVP(network.connectome, shape=[8, 2], kernel_size=5)\n</code></pre> <pre><code>[2024-12-08 19:32:20] decoder:282 Initialized decoder with NumberOfParams(free=7427, fixed=0) parameters.\n[2024-12-08 19:32:20] decoder:283 DecoderGAVP(\n  (base): Sequential(\n    (0): Conv2dHexSpace(34, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Softplus(beta=1, threshold=20)\n    (3): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Sequential(\n    (0): Conv2dHexSpace(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (head): Sequential()\n)\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    all_frames=True,\n    dt=1 / 50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>[2024-12-08 19:32:20] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code>data = dataset[0]\nlum = data[\"lum\"]\nflow = data[\"flow\"]\n\nstationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\nresponses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)\n</code></pre> <pre><code>y_pred = decoder(responses)\n</code></pre> <p>We predict motion with an untrained decoder from an untrained network with randomly initialized parameters. We do not expect this to work.</p> <pre><code>animation = SintelSample(lum[None], flow[None], prediction=y_pred.detach().cpu())\nanimation.animate_in_notebook(frames=np.arange(lum.shape[0])[::10])\n</code></pre> <p></p> <pre><code>((y_pred - flow) ** 2).sqrt().mean()\n</code></pre> <pre><code>tensor(0.9877, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#training-network-and-decoder-on-a-single-batch","title":"Training network and decoder on a single batch","text":"<p>We now train the network on a single batch to validate that the pipeline works. We do not expect these networks to generalize their function.</p> <pre><code>from tqdm.notebook import tqdm\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\n\nfrom flyvis.network import Network\nfrom flyvis.task.decoder import DecoderGAVP\n\nfrom flyvis.datasets.sintel import MultiTaskSintel\nfrom flyvis.task.objectives import l2norm, epe\n</code></pre> <pre><code>network = Network()\n</code></pre> <pre><code>[2024-12-08 19:32:37] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n</code></pre> <pre><code>decoder = DecoderGAVP(network.connectome, shape=[8, 2], kernel_size=5)\n</code></pre> <pre><code>[2024-12-08 19:32:42] decoder:282 Initialized decoder with NumberOfParams(free=7427, fixed=0) parameters.\n[2024-12-08 19:32:42] decoder:283 DecoderGAVP(\n  (base): Sequential(\n    (0): Conv2dHexSpace(34, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Softplus(beta=1, threshold=20)\n    (3): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Sequential(\n    (0): Conv2dHexSpace(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (head): Sequential()\n)\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    n_frames=19,\n    dt=1 / 50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>[2024-12-08 19:32:42] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code>t_pre = 0.5\ndt = 1 / 50\nbatch_size = 4\ntrain_loader = DataLoader(dataset, batch_size=batch_size)\n</code></pre> <pre><code>optimizer = Adam((*network.parameters(), *decoder.parameters()), lr=1e-5)\n</code></pre> <pre><code>batch = next(iter(train_loader))\n</code></pre> <pre><code>loss_fn = epe\n</code></pre> <pre><code>epochs = 1000\n\nerrors = []\n\ninitial_state = network.steady_state(t_pre, dt, batch_size)\n\nfor e in tqdm(range(epochs)):\n    lum = batch[\"lum\"]\n    flow = batch[\"flow\"]\n\n    optimizer.zero_grad()\n    network.stimulus.zero()\n    network.stimulus.add_input(lum)\n\n    activity = network(network.stimulus(), dt=1 / 50, state=initial_state)\n    y_pred = decoder(activity)\n\n    batch_error = loss_fn(y_pred, flow)\n    errors.append(batch_error.cpu().item())\n    batch_error.backward()\n    optimizer.step()\n\n    if e % 10 == 0:\n        print(f\"Epoch {e}: {batch_error.item()}\")\n</code></pre> <pre><code>  0%|          | 0/1000 [00:00&lt;?, ?it/s]\n\n\nEpoch 0: 10.636537551879883\nEpoch 10: 10.621147155761719\nEpoch 20: 10.607827186584473\nEpoch 30: 10.599922180175781\nEpoch 40: 10.590510368347168\nEpoch 50: 10.582784652709961\nEpoch 60: 10.57673168182373\nEpoch 70: 10.57288932800293\nEpoch 80: 10.56686019897461\nEpoch 90: 10.563536643981934\nEpoch 100: 10.561113357543945\nEpoch 110: 10.557619094848633\nEpoch 120: 10.553178787231445\nEpoch 130: 10.550191879272461\nEpoch 140: 10.545988082885742\nEpoch 150: 10.545486450195312\nEpoch 160: 10.54134464263916\nEpoch 170: 10.540717124938965\nEpoch 180: 10.537071228027344\nEpoch 190: 10.53472900390625\nEpoch 200: 10.531929016113281\nEpoch 210: 10.529220581054688\nEpoch 220: 10.526920318603516\nEpoch 230: 10.524316787719727\nEpoch 240: 10.522162437438965\nEpoch 250: 10.519787788391113\nEpoch 260: 10.518158912658691\nEpoch 270: 10.516519546508789\nEpoch 280: 10.513129234313965\nEpoch 290: 10.511229515075684\nEpoch 300: 10.509740829467773\nEpoch 310: 10.506508827209473\nEpoch 320: 10.505179405212402\nEpoch 330: 10.502842903137207\nEpoch 340: 10.5007963180542\nEpoch 350: 10.497834205627441\nEpoch 360: 10.496322631835938\nEpoch 370: 10.495060920715332\nEpoch 380: 10.493014335632324\nEpoch 390: 10.491446495056152\nEpoch 400: 10.48892879486084\nEpoch 410: 10.489540100097656\nEpoch 420: 10.485395431518555\nEpoch 430: 10.483999252319336\nEpoch 440: 10.481637954711914\nEpoch 450: 10.47884464263916\nEpoch 460: 10.478631019592285\nEpoch 470: 10.476183891296387\nEpoch 480: 10.475756645202637\nEpoch 490: 10.473572731018066\nEpoch 500: 10.471808433532715\nEpoch 510: 10.471207618713379\nEpoch 520: 10.468792915344238\nEpoch 530: 10.466946601867676\nEpoch 540: 10.465457916259766\nEpoch 550: 10.462742805480957\nEpoch 560: 10.462434768676758\nEpoch 570: 10.460104942321777\nEpoch 580: 10.457630157470703\nEpoch 590: 10.456503868103027\nEpoch 600: 10.454134941101074\nEpoch 610: 10.453128814697266\nEpoch 620: 10.450531959533691\nEpoch 630: 10.448619842529297\nEpoch 640: 10.446551322937012\nEpoch 650: 10.444059371948242\nEpoch 660: 10.44367504119873\nEpoch 670: 10.437813758850098\nEpoch 680: 10.437586784362793\nEpoch 690: 10.436905860900879\nEpoch 700: 10.432501792907715\nEpoch 710: 10.430790901184082\nEpoch 720: 10.428460121154785\nEpoch 730: 10.423649787902832\nEpoch 740: 10.42512321472168\nEpoch 750: 10.422974586486816\nEpoch 760: 10.418354034423828\nEpoch 770: 10.41611099243164\nEpoch 780: 10.413171768188477\nEpoch 790: 10.408281326293945\nEpoch 800: 10.405777931213379\nEpoch 810: 10.401845932006836\nEpoch 820: 10.395087242126465\nEpoch 830: 10.390754699707031\nEpoch 840: 10.386748313903809\nEpoch 850: 10.381792068481445\nEpoch 860: 10.376413345336914\nEpoch 870: 10.371747016906738\nEpoch 880: 10.367315292358398\nEpoch 890: 10.363433837890625\nEpoch 900: 10.357799530029297\nEpoch 910: 10.35655403137207\nEpoch 920: 10.350890159606934\nEpoch 930: 10.347064971923828\nEpoch 940: 10.342965126037598\nEpoch 950: 10.339473724365234\nEpoch 960: 10.334851264953613\nEpoch 970: 10.330768585205078\nEpoch 980: 10.325502395629883\nEpoch 990: 10.32119369506836\n</code></pre> <pre><code>plt.plot(errors)\n</code></pre> <pre><code>[&lt;matplotlib.lines.Line2D at 0x7f0b0d0730a0&gt;]\n</code></pre> <p></p> <p>We expect that the prediction from this overfitted network on the sample it was trained on is ok.</p> <pre><code>data = dataset[0]\nlum = data[\"lum\"]\nflow = data[\"flow\"]\n\nstationary_state = network.fade_in_state(1.0, dataset.dt, lum[[0]])\nresponses = network.simulate(lum[None], dataset.dt, initial_state=stationary_state)\n</code></pre> <pre><code>y_pred = decoder(responses)\n</code></pre> <pre><code>animation = SintelSample(lum[None], flow[None], prediction=y_pred.detach().cpu())\nanimation.animate_in_notebook()\n</code></pre> <p></p> <pre><code>((y_pred - flow) ** 2).sqrt().mean()\n</code></pre> <pre><code>tensor(0.7563, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#evaluating-trained-networks","title":"Evaluating trained networks","text":"<pre><code>from flyvis import results_dir\nfrom flyvis.network import NetworkView\nfrom flyvis.utils.activity_utils import LayerActivity\n\nfrom flyvis.datasets.sintel import MultiTaskSintel\nfrom flyvis.task.decoder import DecoderGAVP\n</code></pre> <pre><code># we load the best task-performing model from the presorted ensemble\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-12-08 19:34:48] network_view:122 Initialized network view at ../flyvis/data/results/flow/0000/000\n</code></pre> <pre><code>network = network_view.init_network()\n</code></pre> <pre><code>[2024-12-08 19:34:56] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-12-08 19:34:56] chkpt_utils:36 Recovered network state.\n</code></pre> <pre><code>network_view.dir.config.task.decoder\n</code></pre> <pre><code>Namespace(\n  flow = Namespace(\n    type = 'DecoderGAVP',\n    shape = [8, 2],\n    kernel_size = 5,\n    const_weight = 0.001,\n    n_out_features = None,\n    p_dropout = 0.5\n  )\n)\n</code></pre> <pre><code>decoder = network_view.init_decoder()[\"flow\"]\n</code></pre> <pre><code>[2024-12-08 19:35:01] decoder:282 Initialized decoder with NumberOfParams(free=7427, fixed=0) parameters.\n[2024-12-08 19:35:01] decoder:283 DecoderGAVP(\n  (base): Sequential(\n    (0): Conv2dHexSpace(34, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Softplus(beta=1, threshold=20)\n    (3): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Sequential(\n    (0): Conv2dHexSpace(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (head): Sequential()\n)\n[2024-12-08 19:35:01] chkpt_utils:65 Recovered flow decoder state.\n</code></pre> <pre><code>dataset = MultiTaskSintel(\n    tasks=[\"flow\"],\n    boxfilter=dict(extent=15, kernel_size=13),\n    vertical_splits=1,\n    all_frames=False,\n    n_frames=19,\n    dt=1 / 50,\n    augment=False,\n    resampling=True,\n    interpolate=True,\n)\n</code></pre> <pre><code>[2024-12-08 19:35:01] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code>data = [dataset[i] for i in range(4)]\nlum = torch.stack([d[\"lum\"] for d in data])\nflow = torch.stack([d[\"flow\"] for d in data])\n\nstationary_state = network.fade_in_state(1.0, dataset.dt, lum[:, 0])\nresponses = network.simulate(lum, dataset.dt, initial_state=stationary_state)\n</code></pre> <pre><code>y_pred = decoder(responses)\n</code></pre> <p>We expect this network to generalize across sequences. This network sees motion into all directions.</p> <pre><code>animation = SintelSample(lum, flow, prediction=y_pred.detach().cpu())\nanimation.animate_in_notebook()\n</code></pre> <p></p> <p>We expect the accuracy is not as good as the overfitted example because this network generalized across the whole-dataset.</p> <pre><code>((y_pred - flow) ** 2).sqrt().mean()\n</code></pre> <pre><code>tensor(6.4274, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n</code></pre>"},{"location":"examples/02_flyvision_optic_flow_task/#evaluating-ensembles","title":"Evaluating ensembles","text":"<p>Last, we evaluated the task error of the 50 trained networks on a held out set of sequences. We evaluated the task error across all checkpoints during training and show the minimal one in the histrogram below. This checkpoint we analyse with respect to it\u2019s tuning predictions as shown in the next notebooks.</p> <pre><code>from flyvis import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:35:21] ensemble:166 Loaded 50 networks.\n</code></pre> <pre><code>ensemble.task_error_histogram()\n</code></pre> <pre><code>(&lt;Figure size 300x300 with 1 Axes&gt;,\n &lt;Axes: xlabel='task error', ylabel='number models'&gt;)\n</code></pre> <p></p>"},{"location":"examples/03_flyvision_flash_responses/","title":"Flash responses","text":"<p>This notebook introduces flash responses and the flash response index (FRI).</p> <p>The FRI measures whether a cell depolarizes to bright or to dark increments in a visual input.</p>"},{"location":"examples/03_flyvision_flash_responses/#flash-stimuli","title":"Flash stimuli","text":"<p>To elicit flash responses, experimenters show a flashing dot to the subject in the center of their field of view. We generate and render these stimuli with the <code>Flashes</code> dataset.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n\nfrom flyvis.analysis.animations.hexscatter import HexScatter\nfrom flyvis.datasets.flashes import Flashes\n</code></pre> <pre><code># initialize dataset\ndataset = Flashes(\n    dynamic_range=[0, 1],  # min and max pixel intensity values, must be in range [0, 1]\n    t_stim=1.0,  # duration of flash\n    t_pre=1.0,  # duration of period between flashes\n    dt=1 / 200,  # temporal resolution of rendered video\n    radius=[-1, 6],  # radius of flashing dot. -1 fills entire field of view\n    alternations=(0, 1, 0),  # flashing pattern, off - on - off\n)\n</code></pre> <pre><code># view stimulus parameters\ndataset.arg_df\n# the dataset has four samples, one corresponding to each row\n</code></pre> baseline intensity radius 0 0.5 0 -1 1 0.5 0 6 2 0.5 1 -1 3 0.5 1 6 <pre><code># visualize single sample\nanimation = HexScatter(\n    dataset[3][None, ::50, None], vmin=0, vmax=1\n)  # intensity=1, radius=6\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/03_flyvision_flash_responses/#network-flash-response","title":"Network flash response","text":"<p>Now that we have generated the stimulus, we can use it to drive a trained connectome-constrained network.</p> <pre><code>from flyvis import results_dir\nfrom flyvis import NetworkView\n\n# model are already sorted by task error\n# we take the best task-performing model from the pre-sorted ensemble\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-12-08 19:35:35] network_view:122 Initialized network view at ../flyvis/data/results/flow/0000/000\n</code></pre> <pre><code>stims_and_resps = network_view.flash_responses(dataset=dataset)\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/577e21fdb69e8a7bf543369fa02dc2aa/output.h5\n</code></pre> <pre><code>stims_and_resps['responses'].custom.where(cell_type=\"L1\", radius=6).custom.plot_traces(\n    x='time'\n)\nfig = plt.gcf()\nfig.axes[-1].set_title(\"L1 flash responses\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'L1 flash responses')\n</code></pre> <p></p>"},{"location":"examples/03_flyvision_flash_responses/#flash-response-index-fri","title":"Flash response index (FRI)","text":"<p>The flash response index (FRI) is a measure of the strength of contrast tuning of a particular cell. It is computed as the difference between the cell\u2019s peak voltage in response to on-flashes (intensity = 1) and off-flashes (intensity = 0), divided by the sum of those peak values.</p> <p>That is, given a single neuron\u2019s response to on-flashes <code>r_on</code> and off-flashes <code>r_off</code> (both of <code>shape=(T,)</code>), we can compute the flash response index with</p> <pre><code>r_on_max = max(r_on)\nr_off_max = max(r_off)\nfri = (r_on_max - r_off_max) / (r_on_max + r_off_max + 1e-16)\n</code></pre> <p>with the additional <code>1e-16</code> simply for numerical stability. Before this calculation, the response traces are shifted to be non-negative.</p> <p>The flash response index can take on values between \\(-1\\), when the off response is much stronger (or more positive) than the on response, to \\(1\\), when the on response is much stronger (or more positive) than the off response.</p> <p>For the L1 cell plotted before, we can see that it displays a positive response to off flashes and a negative response to on flashes, so we expect a negative flash response index.</p> <pre><code>from flyvis.analysis.flash_responses import flash_response_index\n</code></pre> <pre><code>fris = flash_response_index(stims_and_resps, radius=6)\n</code></pre> <pre><code>fris.custom.where(cell_type=\"L1\")\n</code></pre> <pre>&lt;xarray.DataArray 'responses' (network_id: 1, sample: 1, neuron: 1)&gt;\narray([[[-0.33354023]]], dtype=float32)\nCoordinates:\n    baseline      (sample) float64 0.5\n    radius        (sample) int32 6\n  * neuron        (neuron) int64 8\n    cell_type     (neuron) &lt;U8 'L1'\n    u             (neuron) int32 0\n    v             (neuron) int32 0\n  * network_id    (network_id) int64 0\n    network_name  (network_id) &lt;U13 'flow/0000/000'\n    checkpoints   (network_id) object /groups/turaga/home/lappalainenj/FlyVis...\nDimensions without coordinates: sample</pre>xarray.DataArray'responses'<ul><li>network_id: 1</li><li>sample: 1</li><li>neuron: 1</li></ul><ul><li>-0.3335<pre>array([[[-0.33354023]]], dtype=float32)</pre></li><li>Coordinates: (9)<ul><li>baseline(sample)float640.5<pre>array([0.5])</pre></li><li>radius(sample)int326<pre>array([6], dtype=int32)</pre></li><li>neuron(neuron)int648<pre>array([8])</pre></li><li>cell_type(neuron)&lt;U8'L1'<pre>array(['L1'], dtype='&lt;U8')</pre></li><li>u(neuron)int320<pre>array([0], dtype=int32)</pre></li><li>v(neuron)int320<pre>array([0], dtype=int32)</pre></li><li>network_id(network_id)int640<pre>array([0])</pre></li><li>network_name(network_id)&lt;U13'flow/0000/000'<pre>array(['flow/0000/000'], dtype='&lt;U13')</pre></li><li>checkpoints(network_id)object/groups/turaga/home/lappalainenj...<pre>array([PosixPath('../flyvis/data/results/flow/0000/000/chkpts/chkpt_00000')],\n      dtype=object)</pre></li></ul></li><li>Indexes: (2)<ul><li>neuronPandasIndex<pre>PandasIndex(Index([8], dtype='int64', name='neuron'))</pre></li><li>network_idPandasIndex<pre>PandasIndex(Index([0], dtype='int64', name='network_id'))</pre></li></ul></li><li>Attributes: (0)</li></ul>"},{"location":"examples/03_flyvision_flash_responses/#fri-correlation","title":"FRI correlation","text":"<p>Since the tuning of some cell types have been determined experimentally, we can then compare our model to experimental findings by computing the correlation between the model FRIs for known cell types with their expected tuning.</p> <pre><code>from flyvis.analysis.flash_responses import fri_correlation_to_known\nfrom flyvis.utils.groundtruth_utils import polarity\n</code></pre> <pre><code>fri_corr = fri_correlation_to_known(fris)\n</code></pre> <pre><code># manually extract model and true FRIs for plotting\nknown_cell_types = [k for k, v in polarity.items() if v != 0]\nmodel_fris = [fris.custom.where(cell_type=k).item() for k in known_cell_types]\ntrue_fris = [polarity[k] for k in known_cell_types]\n# plot\nplt.figure(figsize=[2, 1])\nplt.scatter(model_fris, true_fris, color=\"k\", s=10)\nplt.xlabel(\"predicted FRI\")\nplt.ylabel(\"putative FRI (true tuning)\")\nplt.axvline(0, linestyle=\"--\", color=\"black\")\nplt.axhline(0, linestyle=\"--\", color=\"black\")\n\nplt.axhspan(0, 2, 0, 0.5, color=\"red\", zorder=-10)\nplt.axhspan(0, 2, 0.5, 1.0, color=\"green\", zorder=-10)\nplt.axhspan(-2, 0, 0, 0.5, color=\"green\", zorder=-10)\nplt.axhspan(-2, 0, 0.5, 1.0, color=\"red\", zorder=-10)\n\nplt.xlim(-1.05, 1.05)\nplt.ylim(-2, 2)\nplt.title(f\"Correlation = {fri_corr[0].item():.2g}\")\nplt.yticks([-1, 1], [\"OFF\", \"ON\"])\nplt.show()\n</code></pre> <p></p> <p>As we can see, for all except two cell types, the model correctly predicts the cell\u2019s tuning (positive or negative).</p>"},{"location":"examples/03_flyvision_flash_responses/#ensemble-responses","title":"Ensemble responses","text":"<p>Now we can compare tuning properties across an ensemble of trained models. First we need to again simulate the network responses.</p> <pre><code>from flyvis import EnsembleView\n\nensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:35:48] ensemble:166 Loaded 50 networks.\n</code></pre> <pre><code>stims_and_resps = ensemble.flash_responses(dataset=dataset)\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/577e21fdb69e8a7bf543369fa02dc2aa/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8178c987bed4870114f3fff7641e7fae/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6acc3ac28e719cae7b1941fdbf745ab6/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b412c4c9ca2a95b27e65a2e50d42467d/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ac57e619046e24281f445a44d7971446/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e4650b12c1890800d286ae37d82e990c/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3580bbda204c6a944ab487961449980a/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5bd06309206c3af6ea63081c6620dd7f/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2ca6d7dd6fac47ce1d9c20622aa9baa0/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/621b6b656522cf71a08cd90c6c0c22a6/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c56af9a9cb35884a5e8a9d57860e10a5/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a9a351801f031be69ad21337bc59491d/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dc90a0ed6d3c079759d3dca82a500f8b/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6bff6ea67b238e22c033d1c9107da4a6/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/714cf5fb6547c174a9cf12dd0c4d9c4a/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/87f91506377402b143bca71242338878/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6dbcfa5a1500fe2215f8c372f7965f9d/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8a3e01e182e95afb8086ce8312c3aae/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3df0054a9e6288e7ceebc44ca0cc150c/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b8267dc6a04c5b6452a8bb4f16e5f864/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b05580c4a06f52ca68750ae48243bdcf/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4fdad6dccb95c52283be2e6f3552160a/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/01a78b0fc40d1bbb5b97cf53acc4d79f/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/35960eff6595e3cd689342be976b55b1/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e4b37991b40bceb01e52716e3e7430ec/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/73a817d9ad0b43111958b5a47a33b4db/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/43e8f4160ce5e34dc66de0d0e2189c75/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7dd89e45192fc0f9009d517b26181a34/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/993b1c46dcab73a9a69db97df9b15b58/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7baf1b5e44cc288bf0eec9fd2bef0914/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ca2cc9cda33bafe20d299585a1bb9250/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/27ef293e91e426b4ea4863c4af96c84e/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ef722b88b9c552a24723b239c40cb32e/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/73c8806a81790837b8e9f4e1fdf3ed8f/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8a29da576a51ed5019f254d70ef31191/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4df04fd638d8ddb225827f6b8e6800cd/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d62909642e8c53dbe844254159f11cb8/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/130e30d134c22b2ff5fcff2f5cc483a4/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/19751f014bb6724279b3f1fb5781d5b5/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6cd2f96e5432702b88b035974712b112/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2a84305bd8a3200b9de9afa7307584ea/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/15db34e9f4ffa60d0640331f3d4d8901/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8142be9881dc59b8d2da22cfda494945/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4f229a718e9645f7dcd9881ffc5b2cb4/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/987c2e4d0491717628df778a90d9136d/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3d65a4eb48ee4aca0e63cf9aa6f91e67/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bdf3f3ff96e3072ff583208161f96954/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2b12d12f049d298f61af1eadfdf47759/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3868fd82450e9075e2a42d5bde8256e0/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b63cff33f9f4d9d61adc6e2920d237f5/output.h5\n</code></pre>"},{"location":"examples/03_flyvision_flash_responses/#response-traces","title":"Response traces","text":"<p>We can once again plot response traces for a single cell type. We subtract the initial value of each trace to center the data before plotting, as the network neuron activities are in arbitrary units.</p> <pre><code>centered = (\n    stims_and_resps['responses']\n    - stims_and_resps['responses'].custom.where(time=0.0).values\n)\n</code></pre> <pre><code>centered.sel(network_id=ensemble.argsort()[:10]).custom.where(\n    cell_type=\"L1\", radius=6, intensity=1\n).custom.plot_traces(x='time', plot_kwargs=dict(color='orange', linewidth=0.5))\nax = plt.gca()\ncentered.sel(network_id=ensemble.argsort()[:10]).custom.where(\n    cell_type=\"L1\", radius=6, intensity=0\n).custom.plot_traces(x='time', plot_kwargs=dict(ax=ax, color='blue', linewidth=0.5))\nax.set_title(\"L1 flash responses\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'L1 flash responses')\n</code></pre> <p></p> <p>Though the scaling varies, all networks predict depolarization to OFF-flashes for L1.</p>"},{"location":"examples/03_flyvision_flash_responses/#flash-response-index-fri_1","title":"Flash response index (FRI)","text":"<p>We can also compute flash response indices for each network in the ensemble.</p> <pre><code># get FRI for L1 cell\n\nfri_l1 = (\n    flash_response_index(stims_and_resps, radius=6)\n    .sel(network_id=ensemble.argsort()[:10])\n    .custom.where(cell_type=\"L1\")\n)\nprint(fri_l1.squeeze().values)\n</code></pre> <pre><code>[-0.33354023 -0.28763247 -0.32586816 -0.20794408 -0.3334335  -0.32148358\n -0.3565678  -0.33286062 -0.1327389  -0.16595899]\n</code></pre> <p>All models recover similar flash response indices for this cell type. We can also plot the distribution of FRIs per cell type across the ensemble.</p> <pre><code>with ensemble.select_items(ensemble.argsort()[:10]):\n    ensemble.flash_response_index()\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d9d302eebb41d955bb76dcf9d6ce623a/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13f5d9136003d68fa860867f0ed89c64/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6ec38263ed72b3a302f55bd519d68643/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/048c1466b844b8be367b875fab782256/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ca0abb0d8af62ceb2b9ad8b3d991eb06/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ecc4b64ad753e775719a388d36fec0d5/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8420baf27ddfbc229fec85b8f120585/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cdc3f7c2ec749662cacbbdcfab68b20c/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/561c8275f604bf5964ebd8efa2ab0838/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/da9d8f4c595528a025e132eafd136811/output.h5\n</code></pre> <p></p>"},{"location":"examples/03_flyvision_flash_responses/#fri-correlation_1","title":"FRI correlation","text":"<p>Lastly, we look at the correlations to ground-truth tuning across the ensemble.</p> <pre><code>from flyvis.analysis.flash_responses import flash_response_index\n</code></pre> <pre><code>fris = flash_response_index(stims_and_resps, radius=6)\n</code></pre> <pre><code>from flyvis.analysis.visualization.plots import violin_groups\n\n# compute correlation\nfri_corr = fri_correlation_to_known(fris)\n\nfig, ax, *_ = violin_groups(\n    np.array(fri_corr)[None, None, :].squeeze(-1),\n    ylabel=\"FRI correlation\",\n    figsize=(2, 2),\n    xlim=(0, 1),\n    xticklabels=[],\n    colors=[plt.get_cmap(\"Pastel1\")(0.0)],\n    scatter_edge_color=\"gray\",\n    scatter_radius=10,\n)\n</code></pre> <p></p> <p>Models in general have very good match to known single-neuron tuning properties, with median correlation around 0.8.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/","title":"Moving edge responses","text":"<p>This notebook introduces moving edge responses and the direction selectivity index (DSI). The DSI measures motion selectivity of cells to visual input.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#moving-edge-stimuli","title":"Moving edge stimuli","text":"<p>To elicit moving edge responses and characterise the motion selectivity of neurons, experimenters show an ON or OFF edge moving in different cardinal directions. We generate and render these stimuli with the <code>MovingEdge</code> dataset.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n\nfrom flyvis.datasets.moving_bar import MovingEdge\nfrom flyvis.analysis.animations.hexscatter import HexScatter\n</code></pre> <pre><code># initialize dataset\n# make the dataset\ndataset = MovingEdge(\n    offsets=[-10, 11],  # offset of bar from center in 1 * radians(2.25) led size\n    intensities=[0, 1],  # intensity of bar\n    speeds=[19],  # speed of bar in 1 * radians(5.8) / s\n    height=80,  # height of moving bar in 1 * radians(2.25) led size\n    post_pad_mode=\"continue\",  # for post-stimulus period, continue with the last frame of the stimulus\n    t_pre=1.0,  # duration of pre-stimulus period\n    t_post=1.0,  # duration of post-stimulus period\n    dt=1 / 200,  # temporal resolution of rendered video\n    angles=list(np.arange(0, 360, 30)),  # motion direction (orthogonal to edge)\n)\n</code></pre> <pre><code># view stimulus parameters\ndataset.arg_df\n# the dataset has four samples, one corresponding to each row\n</code></pre> angle width intensity t_stim speed 0 0 80 0 0.428766 19 1 0 80 1 0.428766 19 2 30 80 0 0.428766 19 3 30 80 1 0.428766 19 4 60 80 0 0.428766 19 5 60 80 1 0.428766 19 6 90 80 0 0.428766 19 7 90 80 1 0.428766 19 8 120 80 0 0.428766 19 9 120 80 1 0.428766 19 10 150 80 0 0.428766 19 11 150 80 1 0.428766 19 12 180 80 0 0.428766 19 13 180 80 1 0.428766 19 14 210 80 0 0.428766 19 15 210 80 1 0.428766 19 16 240 80 0 0.428766 19 17 240 80 1 0.428766 19 18 270 80 0 0.428766 19 19 270 80 1 0.428766 19 20 300 80 0 0.428766 19 21 300 80 1 0.428766 19 22 330 80 0 0.428766 19 23 330 80 1 0.428766 19 <pre><code># visualize single sample\n# %#matplotlib notebook\nanimation = HexScatter(\n    dataset[3][None, ::25, None], vmin=0, vmax=1\n)  # intensity=1, radius=6\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#moving-edge-response","title":"Moving edge response","text":"<p>Now that we have generated the stimulus, we can use it to drive a trained connectome-constrained network.</p> <pre><code>from flyvis import results_dir\nfrom flyvis.network import NetworkView\n\n# model are already sorted by task error\n# we take the best task-performing model from the pre-sorted ensemble\nnetwork_view = NetworkView(results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-12-08 19:36:19] network_view:122 Initialized network view at ../flyvis/data/results/flow/0000/000\n</code></pre> <pre><code>stims_and_resps = network_view.moving_edge_responses(dataset)\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8aa5ae3c0c09b91f372ef03516814bd1/output.h5\n</code></pre> <p>We\u2019ve now computed network moving edge responses for all cells in the network.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#response-traces","title":"Response traces","text":"<p>We can plot single-cell response traces with <code>stims_and_resps['responses'].custom.plot_traces()</code>. Here, we plot responses of T4c cells to edges with intensity 1 (ON edges).</p> <pre><code>stims_and_resps[\"responses\"].custom.where(\n    cell_type=\"T4c\", intensity=1, time=\"&gt;-0.5,&lt;1.0\"\n).custom.plot_traces(x=\"time\", legend_labels=[\"angle\"])\nax = plt.gca()\nax.set_title(\"T4c responses to moving edge\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'T4c responses to moving edge')\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#direction-selectivity-index-dsi","title":"Direction selectivity index (DSI)","text":"<p>The Direction Selectivity Index (DSI) quantifies a cell\u2019s preference for stimuli moving in a particular direction.</p> <p>The DSI is derived from the following steps: 1. Obtain the neuron\u2019s peak responses to stimuli moving in different directions \\(\\theta\\) and at different speeds \\(S\\). 2. Rectify these peak responses to ensure they are non-negative. 3. Compute the DSI using the equation:</p> \\[ DSI_{t_i}(I) = \\frac{1}{\\lvert S \\rvert} \\sum_{S \\in S} \\left\\lvert \\frac{\\sum_{\\theta \\in \\Theta} r^{peak}_{t_{central}}(I, S, \\theta) e^{i\\theta}}{\\max_{I \\in I} \\left\\lvert \\sum_{\\theta \\in \\Theta} r^{peak}_{t_{central}}(I, S, \\theta) \\right\\rvert} \\right\\rvert \\] <p>Where: - \\(DSI_{t_i}(I)\\) is the Direction Selectivity Index for cell type \\(t_i\\) at stimulus intensity \\(I\\). - \\(\\lvert S \\rvert\\) is the number of different speeds at which stimuli are moved. - \\(r^{peak}_{t_{central}}(I, S, \\theta)\\) represents the rectified peak response of the central cell in hexagonal space of a cell type, for a given stimulus intensity \\(I\\), speed \\(S\\), and direction \\(\\theta\\). - \\(\\theta\\) is varied across all tested directions \\(\\Theta\\). - \\(e^{i\\theta}\\) introduces the directional component by weighting the response by the complex exponential of the angle of movement. - The denominator normalizes the responses, ensuring that DSI values range from 0 to 1.</p> <p>The DSI values range from 0 to 1. A DSI of 0 indicates no directional preference, while a DSI of 1 indicates a strong preference for a specific direction.</p> <p>For the T4c cell plotted before, we can see that it preferentially responds to ON edges moving at an angle of 60 degrees, so we expect to see a large DSI.</p> <p>We compute the DSI with <code>flyvis.analysis.direction_selectivity_index</code>.</p> <pre><code>from flyvis.analysis.moving_bar_responses import direction_selectivity_index\n</code></pre> <pre><code># get DSI for T4c cell\ndsis = direction_selectivity_index(stims_and_resps)\nprint(f\"T4c DSI: {dsis.custom.where(cell_type='T4c', intensity=1).item():.2f}\")\n</code></pre> <pre><code>T4c DSI: 0.63\n</code></pre> <p>We compute the preferred direction of the cell with <code>flyvis.analysis.preferred_direction</code> (this is the direction that the tuning lobe points towards). We would expect the preferred direction to be around 60 degrees based on the response traces.</p> <pre><code>from flyvis.analysis.moving_bar_responses import preferred_direction\n</code></pre> <pre><code>pds = preferred_direction(stims_and_resps)\nprint(\n    f\"T4c preferred direction: {pds.custom.where(cell_type='T4c', intensity=1).item() / np.pi * 180:.2f} degrees\"\n)\n</code></pre> <pre><code>T4c preferred direction: 56.24 degrees\n</code></pre> <p>We can also inspect the direction selecity of a cell type visually, by plotting the angular tuning with <code>plot_angular_tuning</code>.</p> <p>Here we see clearly how the cell is tuned to stimuli moving at a 60 degree angle.</p> <pre><code>from flyvis.analysis.moving_bar_responses import plot_angular_tuning\n</code></pre> <pre><code>plot_angular_tuning(stims_and_resps, cell_type=\"T4c\", intensity=1)\n</code></pre> <pre><code>(&lt;Figure size 300x300 with 1 Axes&gt;, &lt;PolarAxes: &gt;)\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#dsi-and-tuning-curve-correlation","title":"DSI  and tuning curve correlation","text":"<p>With the <code>dsi()</code> function we can also compute DSIs for every cell type at once. Since the selectivity of some cell types have been determined experimentally, we can then compare our model to experimental findings by computing the correlation between the model DSIs for known cell types with their expected motion selectivity.</p> <pre><code>from flyvis.analysis.moving_bar_responses import dsi_correlation_to_known\n</code></pre> <pre><code>dsi_corr = dsi_correlation_to_known(direction_selectivity_index(stims_and_resps)).median()\n</code></pre> <pre><code>print(f\"DSI correlation = {dsi_corr.item(): .2f}\")\n</code></pre> <pre><code>DSI correlation =  0.89\n</code></pre> <p>Further, for certain cell types, their actual tuning curves have also been measured experimentally, so we can correlate our model cell\u2019s tuning to the true values. For T4c, the cell is known to tune to stimuli moving at 90 degrees, so the correlation should be relatively high.</p> <pre><code>from flyvis.analysis.moving_bar_responses import correlation_to_known_tuning_curves\n</code></pre> <pre><code>corrs = correlation_to_known_tuning_curves(stims_and_resps)\n</code></pre> <pre><code>print(\n    f\"T4c tuning curve correlation = {corrs.custom.where(cell_type='T4c', intensity=1).squeeze().item():.2f}\"\n)\n</code></pre> <pre><code>T4c tuning curve correlation = 0.54\n</code></pre> <p>In fact, tuning curves for all T4 and T5 cells have been measured, so we can compute the correlation for all 8 cell types.</p> <pre><code>t4_corrs = corrs.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1)\nt5_corrs = corrs.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0)\n</code></pre> <pre><code>print(\n    f\"T4 tuning curve correlations: {t4_corrs.cell_type.values}\\n{t4_corrs.squeeze().values}\"\n)\n</code></pre> <pre><code>T4 tuning curve correlations: ['T4a' 'T4b' 'T4c' 'T4d']\n[0.93699976 0.71944945 0.53721791 0.85661054]\n</code></pre> <pre><code>print(\n    f\"T5 tuning curve correlations: {t5_corrs.cell_type.values}\\n{t5_corrs.squeeze().values}\"\n)\n</code></pre> <pre><code>T5 tuning curve correlations: ['T5a' 'T5b' 'T5c' 'T5d']\n[0.84125431 0.90320938 0.94956469 0.90100506]\n</code></pre> <p>So, the model yields accurate predictions for all T4 and T5 cell types.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#ensemble-responses","title":"Ensemble responses","text":"<p>Now we can compare motion selectivity properties across an ensemble of trained models. First we need to again simulate the network responses.</p> <pre><code>from flyvis import EnsembleView\n\nensemble = EnsembleView(results_dir / \"flow/0000\")\n# choose best 10\nensemble = ensemble[ensemble.argsort()[:10]]\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:36:33] ensemble:166 Loaded 50 networks.\n\n\n\nLoading ensemble:   0%|          | 0/10 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:36:37] ensemble:166 Loaded 10 networks.\n</code></pre> <pre><code>%%capture\nstims_and_resps = ensemble.moving_edge_responses(dataset=dataset)\n</code></pre>"},{"location":"examples/04_flyvision_moving_edge_responses/#response-traces_1","title":"Response traces","text":"<p>We can once again plot response traces for a single cell type.</p> <p>We subtract the initial value of each trace and divide by the max as the network neuron activities are in arbitrary units.</p> <p>We plot only T4c responses to ON edges moving at a 90-degree angle.</p> <pre><code>responses = (\n    stims_and_resps[\"responses\"]\n    - stims_and_resps[\"responses\"].custom.where(time=0).values\n)\n</code></pre> <pre><code>responses = responses / np.abs(responses).max((\"sample\", \"frame\"))\n</code></pre> <pre><code>responses.custom.where(\n    cell_type=\"T4c\",\n    intensity=1,\n    time=\"&gt;-0.5,&lt;1.0\",\n    angle=90,\n).custom.plot_traces(\n    x=\"time\", plot_kwargs=dict(color=\"tab:blue\"), legend_labels=[\"network_id\"]\n)\n</code></pre> <pre><code>&lt;Axes: xlabel='time', ylabel='responses'&gt;\n</code></pre> <p></p> <p>Though for most networks T4c responses are correctly predicted to the stimuli, there are some networks in the ensemble with different responses.</p>"},{"location":"examples/04_flyvision_moving_edge_responses/#direction-selectivity-index-dsi_1","title":"Direction selectivity index (DSI)","text":"<p>We can also compute direction selectivity indices for each network in the ensemble.</p> <pre><code>dsis = direction_selectivity_index(stims_and_resps)\n</code></pre> <pre><code>dsis.custom.where(cell_type=\"T4c\", intensity=1).plot.hist()\nax = plt.gca()\nax.set_title(\"T4c DSI distribution\")\nax.set_ylabel(\"Number of networks\")\n</code></pre> <pre><code>Text(0, 0.5, 'Number of networks')\n</code></pre> <p></p> <p>Most networks in this group recover some direction selectivity for T4c. We can also plot the distribution of DSIs per cell type for both ON and OFF-edge stimuli across the ensemble.</p> <pre><code>from flyvis.analysis.moving_bar_responses import dsi_violins_on_and_off\n\nfig, ax = dsi_violins_on_and_off(\n    dsis,\n    dsis.cell_type,\n    bold_output_type_labels=True,\n    output_cell_types=ensemble[ensemble.names[0]]\n    .connectome.output_cell_types[:]\n    .astype(str),\n    figsize=[10, 1.2],\n    color_known_types=True,\n    fontsize=6,\n    scatter_best_index=0,\n    scatter_best_color=plt.get_cmap(\"Blues\")(1.0),\n)\n</code></pre> <p></p>"},{"location":"examples/04_flyvision_moving_edge_responses/#dsi-correlation","title":"DSI correlation","text":"<p>Lastly, we look at the correlations to ground-truth DSIs and tuning curves across the ensemble. This provides us with a high-level understanding of the accuracy of known motion tuning predictions.</p> <pre><code>dsi_corr = dsi_correlation_to_known(direction_selectivity_index(stims_and_resps))\n</code></pre> <pre><code>tuning_corrs = correlation_to_known_tuning_curves(stims_and_resps)\n</code></pre> <pre><code>t4_corrs = (\n    tuning_corrs.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1)\n    .median(\"neuron\")\n    .squeeze()\n)\nt5_corrs = (\n    tuning_corrs.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0)\n    .median(\"neuron\")\n    .squeeze()\n)\n</code></pre> <pre><code>dsi_corr.shape, t4_corrs.shape, t5_corrs.shape\n</code></pre> <pre><code>((10,), (10,), (10,))\n</code></pre> <pre><code>from flyvis.analysis.visualization.plots import violin_groups\n\nfig, ax, *_ = violin_groups(\n    np.stack([dsi_corr.values, t4_corrs.values, t5_corrs.values], axis=0)[:, None, :],\n    [\"DSI\", \"T4 tuning\", \"T5 tuning\"],\n    ylabel=\"correlation\",\n    figsize=(1.8, 1.5),\n    ylim=(-1, 1),\n    colors=[\n        plt.get_cmap(\"Dark2\")(0.125),\n        plt.get_cmap(\"Dark2\")(0),\n        plt.get_cmap(\"Dark2\")(0.25),\n    ],\n    color_by=\"experiments\",\n    scatter_edge_color=\"gray\",\n    scatter_radius=5,\n    violin_alpha=0.8,\n)\n</code></pre> <p></p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/","title":"Cluster analysis based on naturalistic stimuli responses","text":"<p>This notebook illustrates how to cluster the models of an ensemble after nonlinear dimensionality reduction on their predicted responses to naturalistic stimuli. This can be done for any cell type. Here we provide a detailed example focusing on clustering based on T4c responses.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#naturalistic-stimuli-dataset-sintel","title":"Naturalistic stimuli dataset (Sintel)","text":"<p>We load the dataset with our custom augmentations. The dataset contains movie sequences from the publicly available computer-animated movie Sintel rendered to the hexagonal lattice structure of the fly eye. For a more detailed introduction to the dataset class and parameters see the notebook on the optic flow task.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n\nimport flyvis\nfrom flyvis.datasets.sintel import AugmentedSintel\nfrom flyvis.analysis.animations import HexScatter\n</code></pre> <pre><code>dt = 1 / 100  # can be changed for other temporal resolutions\ndataset = AugmentedSintel(\n    tasks=[\"lum\"],\n    interpolate=False,\n    boxfilter={'extent': 15, 'kernel_size': 13},\n    temporal_split=True,\n    dt=dt,\n)\n</code></pre> <pre><code>[2024-12-08 19:36:52] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <pre><code># view stimulus parameters\ndataset.arg_df\n</code></pre> name original_index vertical_split_index temporal_split_index frames flip_ax n_rot 0 sequence_00_alley_1_split_00 0 0 0 19 0 0 1 sequence_00_alley_1_split_00 0 0 0 19 0 1 2 sequence_00_alley_1_split_00 0 0 0 19 0 2 3 sequence_00_alley_1_split_00 0 0 0 19 0 3 4 sequence_00_alley_1_split_00 0 0 0 19 0 4 ... ... ... ... ... ... ... ... 2263 sequence_22_temple_3_split_02 22 68 188 19 1 1 2264 sequence_22_temple_3_split_02 22 68 188 19 1 2 2265 sequence_22_temple_3_split_02 22 68 188 19 1 3 2266 sequence_22_temple_3_split_02 22 68 188 19 1 4 2267 sequence_22_temple_3_split_02 22 68 188 19 1 5 <p>2268 rows \u00d7 7 columns</p> <pre><code>sequence = dataset[0][\"lum\"]\n</code></pre> <pre><code># one sequence contains 80 frames with 721 hexals each\nsequence.shape\n</code></pre> <pre><code>torch.Size([80, 1, 721])\n</code></pre> <pre><code>animation = HexScatter(sequence[None], vmin=0, vmax=1)\nanimation.animate_in_notebook(frames=np.arange(5))\n</code></pre> <p></p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#ensemble-responses-to-naturalistic-sequences","title":"Ensemble responses to naturalistic sequences","text":"<p>We compute the responses of all models in the stored ensemble to the augmented Sintel dataset.</p> <pre><code># We load the ensemble trained on the optic flow task\nensemble = flyvis.EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:37:13] ensemble:166 Loaded 50 networks.\n</code></pre> <p>We use <code>ensemble.naturalistic_stimuli_responses</code> to return responses of all networks within the ensemble.</p> <pre><code># alternatively, specify indices of sequences to load\n# stims_and_resps = ensemble.naturalistic_stimuli_responses(indices=np.arange(5))\n# or load all sequences\nstims_and_resps = ensemble.naturalistic_stimuli_responses()\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/86b080e815ea9ec928a380df83961c32/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b59b4553d26177882434e7a38fcb1f36/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34edb9af3c92827b50340e6903d4f04c/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6d4092c24a8f5e5ea8a651c5d62a4cb1/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f60dd61be87e6f68b35174932ea805a3/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f680e802d1c70a1263dd82076bf33a36/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/04b4c82e6a1f299e0a95ce53517d4da6/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/56af0790abaf8e03689c4950c6dea1b6/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fe446c2e81fb5c187996c349bf81fc75/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/39a60bf26ca578c6f8a61ade8fc76594/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bd1d5ba31d334757b630351b33f3c7c8/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/78fbe4ae4959a666c6937dd423b9020b/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e4b5a3ca0a903bbb40acb438b1f79e9c/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34543762cd47e40c949ca970749e77e3/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2801e68f00e754372714a56be09caf9f/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/42f01aafe2d1710ab594ae807a362bd9/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b94b14adb8899e4eccc118660ea958c7/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9410fc09859bbade170b51880731dea9/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/544420c7e8246afcd778ee0b353106db/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8dacb927f956aa97478480571577228d/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/531b4dc891cbcd37ac5f86738293c135/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/03684bc5f57d843f1716241f9a0fae72/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b990cd15cf042aa0355aa481aa7d6b41/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/91cfee0552809c386b0a3e8eb754e6d6/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/301b1b68961db10e21d4f7bcf56c9906/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fb26a6ba42c0925fa1021919378d8e27/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/99a1c6ed825f339bda0b78dfbe6d96d3/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9b18d2b42700af7481eccf2d6fa67589/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/528ab0ad496af746d023a6ba873ee0dc/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/df9a3ba79ce02c718ae39f1b691c2074/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/680207b961d14356a08d7e7e4749e59f/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/407f839a987942f6e2856df581147e43/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dfd4875c806ccd1307ff6d7e804e1edf/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/22cd80bc7c98d11c5065ad66d38157b6/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b6e433dcae4b37f7e59b29319839fc50/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/31e5ac10422aa1e1ebabb64c7b173e3c/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4e94417495f0a61657c87c57fc87a1f0/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7f6e7c8a72d475d81acf839a74db4b38/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/03f4135c61293835075130d011bd5d18/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/448f5e3d0b9ad7043ab9d4c22f91dd34/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3e6c91f652149ed9c014bff467b93d6a/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/69572eb846355916126a1c8cfef5274f/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f61388fda823e11dcc52a930c1ef3e93/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dea992edd01893cbdf4d5b27de0d49ad/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e81fe1e9587b7a4d7a1b5a4ebfd3c6c2/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5a1a4580bf311568a60974671660c5c8/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/64f5f362d0a819dcf5666b901342c2c0/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/185b9cebe11b9efe2a625627cb848cba/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1f72e3f57bfa4c1ddb6a6eee76cd02d4/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5afe04583aca5c1f5a960427a81ae439/output.h5\n</code></pre> <pre><code># recommended to only run with precomputed responses using the pipeline manager script,\n# see example_submissions.sh in the repository\n# norm = ensemble.responses_norm()\n# responses = stims_and_resps[\"responses\"] / (norm + 1e-6)\nresponses = stims_and_resps[\"responses\"]\n</code></pre> <pre><code>responses.custom.where(cell_type=\"T4c\", u=0, v=0, sample=0).custom.plot_traces(\n    x=\"time\", plot_kwargs=dict(color=\"tab:blue\", add_legend=False)\n)\nax = plt.gca()\nax.set_title(\"T4c responses to naturalistic stimuli\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'T4c responses to naturalistic stimuli')\n</code></pre> <p></p> <p>We see that the across models of the ensemble the predictions for T4c vary. Our goal is to understand the underlying structure in those variations.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#nonlinear-dimensionality-reduction-umap-and-gaussian-mixtures","title":"Nonlinear dimensionality reduction (UMAP) and Gaussian Mixtures","text":"<pre><code>from flyvis.analysis.clustering import EnsembleEmbedding, get_cluster_to_indices\nfrom flyvis.utils.activity_utils import CentralActivity\n</code></pre> <pre><code># specify parameters for umap embedding\n\nembedding_kwargs = {\n    \"min_dist\": 0.105,\n    \"spread\": 9.0,\n    \"n_neighbors\": 5,\n    \"random_state\": 42,\n    \"n_epochs\": 1500,\n}\n</code></pre> <p>We compute the UMAP embedding of the ensemble based on the T4c responses of the single models to the single sequence for illustration.</p> <pre><code>central_responses = CentralActivity(responses.values, connectome=ensemble.connectome)\n</code></pre> <pre><code>embedding = EnsembleEmbedding(central_responses)\nt4c_embedding = embedding(\"T4c\", embedding_kwargs=embedding_kwargs)\n</code></pre> <pre><code>[2024-12-08 19:37:34] clustering:482 reshaped X from (50, 2268, 80) to (50, 181440)\n/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/umap/umap_.py:1356: RuntimeWarning: divide by zero encountered in power\n  return 1.0 / (1.0 + a * x ** (2 * b))\n</code></pre> <pre><code>task_error = ensemble.task_error()\n</code></pre> <pre><code>embeddingplot = t4c_embedding.plot(colors=task_error.colors)\n</code></pre> <p></p> <p>Each of these scatterpoints in 2d represents a single time series plotted above.</p> <p>We fit a Gaussian Mixture of 2 to 5 components to this embedding to label the clusters. We select the final number of Gaussian Mixture components that minimize the Bayesian Information Criterion (BIC).</p> <pre><code># specifiy parameters for Gaussian Mixture\n\ngm_kwargs = {\n    \"range_n_clusters\": [1, 2, 3, 4, 5],\n    \"n_init\": 100,\n    \"max_iter\": 1000,\n    \"random_state\": 42,\n    \"tol\": 0.001,\n}\n</code></pre> <pre><code>gm_clustering = t4c_embedding.cluster.gaussian_mixture(**gm_kwargs)\n</code></pre> <pre><code>embeddingplot = gm_clustering.plot(task_error=task_error.values, colors=task_error.colors)\n</code></pre> <p></p> <p>We can use the labels to disambiguate the time series data that we plotted above. We expect that these labels aggregate similar time series together and different time series separately.</p> <pre><code>import matplotlib.colors as mcolors\n</code></pre> <pre><code>cluster_to_indices = get_cluster_to_indices(\n    embeddingplot.cluster.embedding.mask,\n    embeddingplot.cluster.labels,\n    ensemble.task_error(),\n)\n</code></pre> <pre><code>fig, axes = plt.subplots(1, len(cluster_to_indices), figsize=(6, 2))\ncolors = {i: color for i, color in enumerate(mcolors.TABLEAU_COLORS.values())}\nfor cluster_id, indices in cluster_to_indices.items():\n    responses.sel(network_id=indices, sample=[0]).custom.where(\n        cell_type=\"T4c\"\n    ).custom.plot_traces(\n        x=\"time\",\n        plot_kwargs=dict(color=colors[cluster_id], add_legend=False, ax=axes[cluster_id]),\n    )\n    axes[cluster_id].set_title(f\"Cluster {cluster_id + 1}\")\nplt.subplots_adjust(wspace=0.3)\n</code></pre> <p></p> <p>The clustering has led us to three qualitatively distinct predictions from the ensemble for this cell and sequence. This is a first lead for an underlying structure in these predictions. We will get an even better estimate once we use more sequences for the clustering.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#using-the-clustering-to-discover-tuning-predictions-in-responses-to-simple-stimuli","title":"Using the clustering to discover tuning predictions in responses to simple stimuli","text":"<p>We expect that the clustering based on naturalistic stimuli will also disambiguate the different tuning predictions from different models for simple stimuli.</p> <pre><code>cluster_to_indices = get_cluster_to_indices(\n    embeddingplot.cluster.embedding.mask,\n    embeddingplot.cluster.labels,\n    ensemble.task_error(),\n)\n</code></pre> <pre><code># define different colormaps for clusters\ncluster_colors = {}\nCMAPS = [\"Blues_r\", \"Reds_r\", \"Greens_r\", \"Oranges_r\", \"Purples_r\"]\n\nfor cluster_id in cluster_to_indices:\n    cluster_colors[cluster_id] = ensemble.task_error(cmap=CMAPS[cluster_id]).colors\n</code></pre>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#clustered-voltage-responses-to-moving-edges","title":"Clustered voltage responses to moving edges","text":"<pre><code>from flyvis.analysis.moving_bar_responses import plot_angular_tuning\nfrom flyvis.analysis.visualization import plt_utils\nfrom flyvis.utils.color_utils import color_to_cmap\n</code></pre> <pre><code>stims_and_resps_moving_edge = ensemble.moving_edge_responses()\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e236e47b9a57dc6d7b692906aca84495/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2a1519d1c3b8bf0d0776e8ff2618353d/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/787654b3c56e4015939e72adfa768448/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d4697cbfdcda0d4b910d26a3f48a2dd/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/546ffb3b9036631dbb8bc4f2d8c3639f/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3fd5d79c2106974104a0362fd7e725a9/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2ed32905ad23f346996a76987694ac26/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13a800f25b57556abf12f6548482733b/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c965f6ca1b4766760aff06bb066dcc4b/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/829fa2f59d755e13c7c04fd5a1a579bc/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/466b4cd31001f19423c507e2f3773c41/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d71a4899b11135e9e39f192e82f06e0/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ba1826533e24098d930150b0168b01cf/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6662e8bb61523d17742c9dd11aa62eeb/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cc480f1ea566ea82bfd19fcdf78cc27e/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8bd5ed52daae786768e228fb58cd3210/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9db907610103a5d3087f87ca0c71a079/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a12d63acadac2a74de55632d4cbabfe6/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2f9340bb144de1c040c6f2a9b58a8376/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e54f818c033f10227d1c003fc779b0c6/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab7e02a752bf6ee954804773846aa1d7/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f5d6259ad9e757467b9ad037056132b8/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/968df97051a8ce2c4cf1a05f4b19359b/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f89eb2dfe2edd056df6f20260a22445/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f08ba3ff4e47076a25f868011998fae/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5d8879e61a3f98f4f81ff3cc31f67f3c/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8ed3248070002d27bd42b83e49e1eb2/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0efca814750b326442bb2057c2a3141d/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/875bc3ea335ae2f70612495aa9a753c4/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/383a5857257bc8be754e28b37b2e4e79/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab8a858f91290a52306a0bb6f9545ed5/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1481eb1faa2b00dcc79036a1bf9f3b9b/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ac160912a60ac748329b349c16ba207f/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/660978a75b531be9c285d84986160ca6/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fa00c670234802d529e1981655483861/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1ae43649496d389d88bc56ca7ccaa383/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d50ab62a3869886437176a4ecf124d75/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/37238a6c41451b197bc11f3c37aef4f2/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9cfa9e971c84bc253c53fbfea3c7ebe6/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/95010c81b682cb979ff3b4f2a6aa6576/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fc266127c935e1835cf20757d3fe581c/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1e5972877c3873b7a1aac86a2f4bba75/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b6af0cb714a199fda52a11619981cb0d/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8292e9a29c31b23123bfa531f9b24d9b/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8b0eda1e0717ec0690d6766e688dace7/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c95394b9922b11a072e992c8d4e2feb5/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/439ba05c490dac452c5aa3fafed9fe9f/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c6894caf2471e76e06aa04f0073d8af5/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3c149c1b1c09ff2c958605cf994742a2/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ae15b6627cbbd1ce3802b4b74fc69e66/output.h5\n</code></pre> <pre><code># invariant to different magnitudes of responses, only to assess direction tuning\nstims_and_resps_moving_edge[\"responses\"] /= np.abs(\n    stims_and_resps_moving_edge[\"responses\"]\n).max(dim=(\"sample\", \"frame\"))\n\n# relative to the norm of the responses to naturalistic stimuli (used for averaging)\n# stims_and_resps_moving_edge['responses'] /= (norm + 1e-6)\n</code></pre> <pre><code>fig, axes = plt.subplots(1, len(cluster_to_indices), figsize=(6, 2))\ncolors = {i: color for i, color in enumerate(mcolors.TABLEAU_COLORS.values())}\nfor cluster_id, indices in cluster_to_indices.items():\n    stims_and_resps_moving_edge['responses'].sel(network_id=indices).custom.where(\n        cell_type=\"T4c\", intensity=1, speed=19, angle=90\n    ).custom.plot_traces(\n        x=\"time\",\n        plot_kwargs=dict(color=colors[cluster_id], add_legend=False, ax=axes[cluster_id]),\n    )\n    axes[cluster_id].set_title(f\"Cluster {cluster_id + 1}\")\nplt.subplots_adjust(wspace=0.3)\n</code></pre> <pre><code>plot_angular_tuning(\n    stims_and_resps_moving_edge,\n    \"T4c\",\n    intensity=1,\n)\n</code></pre> <pre><code>(&lt;Figure size 300x300 with 1 Axes&gt;, &lt;PolarAxes: &gt;)\n</code></pre> <pre><code>tabcolors = list(mcolors.TABLEAU_COLORS.values())\ncolors = [\n    ensemble.task_error(cmap=color_to_cmap(tabcolors[cluster_id]).reversed()).colors[\n        indices\n    ]\n    for cluster_id, indices in cluster_to_indices.items()\n]\nfig, axes = plt.subplots(\n    1, len(cluster_to_indices), subplot_kw={\"projection\": \"polar\"}, figsize=[2, 1]\n)\nfor cluster_id, indices in cluster_to_indices.items():\n    plot_angular_tuning(\n        stims_and_resps_moving_edge.sel(network_id=indices),\n        \"T4c\",\n        intensity=1,\n        colors=colors[cluster_id],\n        zorder=ensemble.zorder()[indices],\n        groundtruth=True if cluster_id == 0 else False,\n        fig=fig,\n        ax=axes[cluster_id],\n    )\n    plt_utils.add_cluster_marker(\n        fig, axes[cluster_id], marker=plt_utils.get_marker(cluster_id)\n    )\n    axes[cluster_id].set_title(f\"Cluster {cluster_id + 1}\")\nplt.subplots_adjust(wspace=0.5)\n</code></pre> <p>As we can see here, the models predict clustered neural responses.</p>"},{"location":"examples/05_flyvision_umap_and_clustering_models/#load-precomputed-umap-and-clustering","title":"Load precomputed umap and clustering","text":"<p>Due to the computational requirement of recording and embedding all responses and for consistency we also show how to use the precomputed embeddings and clusterings from the paper.</p> <pre><code>cell_type = \"T4c\"\nclustering = ensemble.clustering(cell_type)\n</code></pre> <pre><code>[2024-12-08 19:38:15] clustering:835 Loaded T4c embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n</code></pre> <pre><code>task_error = ensemble.task_error()\n</code></pre> <pre><code>embeddingplot = clustering.plot(task_error=task_error.values, colors=task_error.colors)\n</code></pre> <p></p> <p>With this embedding and clustering one can proceed in the same way as above to plot the tunings.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/","title":"Maximally excitatory stimuli from trained models","text":"<p>This notebook illustrates how to compute the stimuli that maximally excite a specific neuron.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#optimal-naturalistic-stimuli","title":"Optimal naturalistic stimuli","text":"<p>We first find the optimal naturalistic stimuli. To do that, we simulate the responses of the network (including the neuron of interest) to all stimuli from a fixed dataset of stimuli. The optimal, or here maximally exctitatory naturalistic stimulus to be precise, is the stimulus for which the response of the chosen neuron is maximal. Finding this is simple and does not require numerical optimization with gradients. We find the stimulus per cell type based on its cell in the central column. At least in our coarse model, the offset version of this stimulus would also maximally excite the equivalently offset neighboring cells of the same type.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n\nfrom flyvis import NetworkView\nfrom flyvis.datasets.sintel import AugmentedSintel\nfrom flyvis.analysis.optimal_stimuli import (\n    FindOptimalStimuli,\n    GenerateOptimalStimuli,\n    plot_stim_response,\n)\n</code></pre> <pre><code># let's load the dataset and the pretrained network\ndataset = AugmentedSintel(tasks=[\"lum\"], temporal_split=True)\nnetwork_view = NetworkView(\"flow/0000/000\")\n</code></pre> <pre><code>[2024-12-08 19:38:27] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n[2024-12-08 19:38:33] network_view:122 Initialized network view at ../flyvis/data/results/flow/0000/000\n</code></pre> <pre><code>findoptstim = FindOptimalStimuli(network_view, dataset)\n</code></pre> <pre><code>[2024-12-08 19:38:41] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-12-08 19:38:41] chkpt_utils:36 Recovered network state.\n</code></pre> <p>For the T4c neuron, we would expect that the maximally excitatory stimulus is an ON-edge moving upward.</p> <pre><code>optstim = network_view.optimal_stimulus_responses(\"T4c\")\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_optimal_stimulus_responses/ea86aff181a9f399fbee084d9288d046/output.h5\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(\n    optstim.stimulus.stimulus,\n    optstim.stimulus.response,\n    1 / 100,\n    *network_view.connectome_view.get_uv(\"T4c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <p></p> <p>We see that the the stimulus indeed contains an ON-edge component moving upward and this is the portion of the stimulus that T4c cells respond most to. What\u2019s unclear is whether the other parts of the stimulus have an influence on the response.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#regularized-optimal-stimuli","title":"Regularized optimal stimuli","text":"<p>We can regularize the optimal stimuli with the objective to keep the response of the cell intact while bringing the stimulus pixels to a neutral grey value.</p> <pre><code>stim_resp_plot = plot_stim_response(\n    optstim.regularized_stimulus,\n    optstim.response,\n    1 / 100,\n    *network_view.connectome_view.get_uv(\"T4c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <p></p> <p>This looks remarkably different! Now only a central black portion follow by the ON-edge moving upward remains in the stimulus. Let\u2019s make sure that the central cell response is really the same as before! This is the entire time trace.</p> <pre><code>fig = plt.figure(figsize=[2, 1])\ntime = np.arange(len(optstim.central_target_response)) / 100\nplt.plot(time, optstim.central_target_response)\nplt.plot(time, optstim.central_predicted_response)\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"response\")\n</code></pre> <pre><code>Text(0, 0.5, 'response')\n</code></pre> <p></p> <p>This looks quite similar! One can play with the regularization parameters of the function <code>regularized_optimal_stimuli</code> to tune this.</p>"},{"location":"examples/06_flyvision_maximally_excitatory_stimuli/#generate-artificial-optimal-stimuli-from-scratch","title":"Generate artificial optimal stimuli from scratch","text":"<p>If one is able to optimize the naturalistic stimulus with the gradient, why don\u2019t we use the gradient to generate an optimal stimulus from scratch (or rather random noise). We do that in the following. Again for T4c, we would expect that it would have some sort of ON-edge moving upwards.</p> <pre><code>genoptstim = GenerateOptimalStimuli(network_view)\n</code></pre> <pre><code>[2024-12-08 19:38:54] chkpt_utils:36 Recovered network state.\n</code></pre> <pre><code>artoptstim = genoptstim.artificial_optimal_stimuli(\"T4c\", t_stim=0.8)\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(\n    artoptstim.stimulus,\n    artoptstim.response,\n    1 / 100,\n    *network_view.connectome_view.get_uv(\"T4c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <p></p> <p>Wow! This stimulus is contains very similar components to the one before and is much more saturated! It also contains new ON-components already from the beginning!</p> <p>Last, let\u2019s compare which stimulus excited the neuron the most.</p> <pre><code>fig = plt.figure(figsize=[2, 1])\ntime = np.arange(len(optstim.central_target_response)) / 100\nplt.plot(time, optstim.central_target_response, label='naturalistic')\nplt.plot(time, optstim.central_predicted_response, label='regularized naturalistic')\nplt.plot(\n    time,\n    artoptstim.response[:, :, artoptstim.response.shape[-1] // 2].flatten(),\n    label='artificial',\n)\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"response\")\nplt.legend()\n</code></pre> <pre><code>&lt;matplotlib.legend.Legend at 0x7f12bafb8130&gt;\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/","title":"Providing custom stimuli","text":"<p>Follow this notebook to learn how to use our models for generating hypothesis about neural computations with custom stimuli.</p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#example-dataset","title":"Example dataset","text":"<p>We take the public Moving MNIST sequence dataset as an example for a custom stimulus dataset. Moving MNIST consists of short grey-scale videos of numbers from 1-10 which move in arbitrary directions. The dataset entails 10,000 sequences of 20 frames each. Individual frames are 64x64 pixels in height and width.</p> <pre><code>import torch\nimport numpy as np\n\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\n\nimport flyvis\nfrom flyvis.utils.dataset_utils import load_moving_mnist\nfrom flyvis.analysis import animations\n</code></pre> <pre><code>sequences = load_moving_mnist()\n</code></pre> <pre><code># the whole dataset has dims (n_sequences, n_frames, height, width)\nsequences.shape\n</code></pre> <pre><code>(10000, 20, 64, 64)\n</code></pre> <pre><code>animation = animations.Imshow(sequences, cmap=plt.cm.binary_r)\nanimation.animate_in_notebook(samples=[0, 1, 2])\n</code></pre> <p></p> <p>Alternative: for an alternative dataset that is generated at runtime and does not require a download try <code>random_walk_of_blocks</code>. As a simple drop-in replacement, this requires to replace <code>load_moving_mnist</code> with <code>random_walk_of_blocks</code> across the notebook.</p> <pre><code>from flyvis.utils.dataset_utils import random_walk_of_blocks\n</code></pre> <pre><code>sequences = random_walk_of_blocks()\n</code></pre> <pre><code>animation = animations.Imshow(sequences, cmap=plt.cm.binary_r)\nanimation.animate_in_notebook(samples=[0, 1, 2])\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#boxeye-rendering","title":"BoxEye rendering","text":""},{"location":"examples/07_flyvision_providing_custom_stimuli/#rendering-cartesian-images-to-hexagonal-lattice","title":"Rendering cartesian images to hexagonal lattice","text":"<p>We translate cartesian frames into receptor activations by placing simulated photoreceptors in a two-dimensional hexagonal array in pixel space (blue dots below), 31 columns across resulting in 721 columns in total, spaced 13 pixels apart. The transduced luminance at each photoreceptor is the greyscale mean value in the 13\u00d713-pixel region surrounding it (black boxes).</p> <pre><code>import flyvis\nfrom flyvis.datasets.rendering import BoxEye\n</code></pre> <pre><code>receptors = BoxEye(extent=15, kernel_size=13)\n</code></pre> <pre><code>fig = receptors.illustrate()\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#render-a-single-frame","title":"Render a single frame","text":"<p>To illustrate, this is what rendering a single frame looks like.</p> <pre><code>import torch\nimport numpy as np\n\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.dpi'] = 200\n\nimport flyvis\nfrom flyvis.utils.dataset_utils import load_moving_mnist\nfrom flyvis.analysis.visualization import plt_utils, plots\n</code></pre> <pre><code>sequences = load_moving_mnist()\n</code></pre> <pre><code>fig, ax = plt_utils.init_plot(figsize=[1, 1], fontsize=5)\nax = plt_utils.rm_spines(ax)\nax.imshow(sequences[0, 0], cmap=plt.cm.binary_r)\n_ = ax.set_title('example frame', fontsize=5)\n</code></pre> <p></p> <pre><code>single_frame = sequences[0, 0]\n\n# the rendering uses pytorch native Conv2d module so it can be executed on GPU and fast\n# we first move the frame to GPU\nsingle_frame = torch.tensor(single_frame, device=flyvis.device).float()\n\n# because the inputs to the receptors instance must have four dimensions (samples, frames, height, width),\n# we create two empty dimensions for samples and frames\nsingle_frame = single_frame[None, None]\n</code></pre> <pre><code># to render the single frame we simply call the instance\n# this automatically rescales the frame to match the receptor layout as illustrated above\n# and then places the average pixel value of the 13x13 boxes at the receptor positions\nreceptors = BoxEye()\nrendered = receptors(single_frame)\n</code></pre> <pre><code>/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n</code></pre> <pre><code># the 721 receptor coordinates are implicitly given in the last dimension\n# they correspond to sorted hexagonal coordinates (u-coordinate, v-coordinate, value)\nrendered.shape\n</code></pre> <pre><code>torch.Size([1, 1, 1, 721])\n</code></pre> <pre><code># the rendered frame is a slightly blurred version of the example\nfig, ax, _ = plots.quick_hex_scatter(\n    rendered.squeeze(), vmin=0, vmax=1, cbar_x_offset=0, fontsize=5\n)\n_ = ax.set_title(\"example frame rendered\", fontsize=5)\n</code></pre> <p></p> <pre><code># Disclaimer: thinking in hex coordinates can be unfamiliar.\n# Therefore, we circumvent dealing with them explicitly.\n# Still - to understand how the above plot infers the pixel-plane coordinates\n# from the implicit hexagonal coordinates, you can inspect the following code.\n</code></pre> <pre><code># # we can explicitly create sorted hex-coordinates from the integer radius of the hexagonal grid\n# # for a regular hexagonal lattice, the radius is uniquely determined from the number of hexagons\n\n# radius = flyvis.utils.hex_utils.get_hextent(rendered.shape[-1])\n\n# # here we create integer u, v coordinates, and we stick to the same function and convention\n# # everywhere in the code\n# u, v = flyvis.utils.hex_utils.get_hex_coords(radius)\n\n# # we transform them to pixel coordinates using our convention\n# x, y = flyvis.utils.hex_utils.hex_to_pixel(u, v)\n\n# # and can just scatter them to be back at the photoreceptor layout\n# fig, ax = plt_utils.init_plot(figsize=[2, 2], fontsize=5)\n# ax.scatter(x, y, s=0.5)\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#render-a-whole-dataset-to-disk","title":"Render a whole dataset to disk","text":"<p>We save rendered sequences to disk to retrieve them faster at runtime.</p> <p>We will use our library datamate here because it provides a powerful interface for writing and reading arrayfiles.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\n\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvis\nfrom flyvis.utils.dataset_utils import load_moving_mnist\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvis import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = BoxEye(extent=config.extent, kernel_size=config.kernel_size)\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(range(sequences.shape[0]))\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument\nmoving_mnist_rendered = RenderedData(\n    dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3])\n)\n</code></pre> <pre><code># this is how we can retrieve the sequences from the disk into memory\nrendered_sequences = moving_mnist_rendered.sequences[:]\n</code></pre> <pre><code>rendered_sequences.shape\n</code></pre> <pre><code>(4, 20, 1, 721)\n</code></pre> <pre><code>animation = animations.HexScatter(rendered_sequences, vmin=0, vmax=1)\nanimation.animate_in_notebook()\n</code></pre> <p></p> <pre><code># Note, to delete a Directory, e.g. to change the __init__ and reinstantiate,\n# run moving_mnist_rendered.rmtree(\"y\").\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#create-a-sequence-dataset","title":"Create a sequence dataset","text":"<p>Next we create a Pytorch dataset for loading the sequences.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\n\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvis\nfrom flyvis.utils.dataset_utils import load_moving_mnist\nfrom flyvis.datasets.datasets import SequenceDataset\nfrom flyvis.analysis import animations\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvis import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = BoxEye(extent=config.extent, kernel_size=config.kernel_size)\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(range(sequences.shape[0]))\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#create-a-custom-dataset","title":"Create a custom dataset","text":"<p>We create a generic interface for custom datasets to make dataloading consistent\u2014this interface can tell the sampler what the framerate, the integration time steps, durations for pre-, and post grey-scale stimulation, and the number of sequences are.</p> <p>In this case, we inherit a SequenceDataset, that also obeys (and extends) the interface of Pytorch\u2019s Dataset.</p> <pre><code>import pandas as pd\n</code></pre> <pre><code>class CustomStimuli(SequenceDataset):\n    # implementing the SequenceDataset interface\n    dt = 1 / 100\n    original_framerate = 24\n    t_pre = 0.5\n    t_post = 0.5\n    n_sequences = None\n    augment = False\n\n    def __init__(self, rendered_data_config: dict):\n        self.dir = RenderedData(rendered_data_config)\n        self.sequences = torch.tensor(self.dir.sequences[:])\n        self.n_sequences = self.sequences.shape[0]\n        self.arg_df = pd.DataFrame({\"sequence_idx\": np.arange(self.n_sequences)})\n\n    def get_item(self, key):\n        sequence = self.sequences[key]\n        # to match the framerate to the integration time dt, we can resample frames\n        # from these indices. note, when dt = 1/framerate, this will return the exact sequence\n        resample = self.get_temporal_sample_indices(sequence.shape[0], sequence.shape[0])\n        return sequence[resample]\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument\ndata = CustomStimuli(dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3]))\n</code></pre> <pre><code>animation = animations.HexScatter(data[0][None], vmin=0, vmax=1)\nanimation.animate_in_notebook()\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#compute-model-responses-to-custom-stimuli","title":"Compute model responses to custom stimuli","text":"<p>Now, we can compute model responses across individual models or the whole ensemble to our custom stimulus.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\n\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvis\nfrom flyvis.utils.dataset_utils import load_moving_mnist\nfrom flyvis.datasets.datasets import SequenceDataset\nfrom flyvis.utils.activity_utils import LayerActivity\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvis import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = BoxEye(extent=config.extent, kernel_size=config.kernel_size)\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(range(sequences.shape[0]))\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre> <pre><code>class CustomStimuli(SequenceDataset):\n    # implementing the SequenceDataset interface\n    dt = 1 / 100\n    framerate = 24\n    t_pre = 0.5\n    t_post = 0.5\n    n_sequences = None\n    augment = False\n\n    def __init__(self, rendered_data_config: dict):\n        self.dir = RenderedData(rendered_data_config)\n        self.sequences = torch.tensor(self.dir.sequences[:])\n        self.n_sequences = self.sequences.shape[0]\n        self.arg_df = pd.DataFrame({\"sequence_idx\": np.arange(self.n_sequences)})\n\n    def get_item(self, key):\n        sequence = self.sequences[key]\n        # to match the framerate to the integration time dt, we can resample frames\n        # from these indices. note, when dt = 1/framerate, this will return the exact sequence\n        resample = self.get_temporal_sample_indices(sequence.shape[0], sequence.shape[0])\n        return sequence[resample]\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument\ndata = CustomStimuli(dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3]))\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#select-a-pretrained-network","title":"Select a pretrained network","text":"<p>To select a network from the ensemble of 50 pretrained networks, let\u2019s see what our options are.</p> <p>Paths to pretrained models from the ensemble end with four digit numbers which are sorted by task error (0-49 from best to worst).</p> <pre><code>sorted([\n    p.relative_to(flyvis.results_dir)\n    for p in (flyvis.results_dir / \"flow/0000\").iterdir()\n    if p.name.isnumeric()\n])\n</code></pre> <pre><code>[PosixPath('flow/0000/000'),\n PosixPath('flow/0000/001'),\n PosixPath('flow/0000/002'),\n PosixPath('flow/0000/003'),\n PosixPath('flow/0000/004'),\n PosixPath('flow/0000/005'),\n PosixPath('flow/0000/006'),\n PosixPath('flow/0000/007'),\n PosixPath('flow/0000/008'),\n PosixPath('flow/0000/009'),\n PosixPath('flow/0000/010'),\n PosixPath('flow/0000/011'),\n PosixPath('flow/0000/012'),\n PosixPath('flow/0000/013'),\n PosixPath('flow/0000/014'),\n PosixPath('flow/0000/015'),\n PosixPath('flow/0000/016'),\n PosixPath('flow/0000/017'),\n PosixPath('flow/0000/018'),\n PosixPath('flow/0000/019'),\n PosixPath('flow/0000/020'),\n PosixPath('flow/0000/021'),\n PosixPath('flow/0000/022'),\n PosixPath('flow/0000/023'),\n PosixPath('flow/0000/024'),\n PosixPath('flow/0000/025'),\n PosixPath('flow/0000/026'),\n PosixPath('flow/0000/027'),\n PosixPath('flow/0000/028'),\n PosixPath('flow/0000/029'),\n PosixPath('flow/0000/030'),\n PosixPath('flow/0000/031'),\n PosixPath('flow/0000/032'),\n PosixPath('flow/0000/033'),\n PosixPath('flow/0000/034'),\n PosixPath('flow/0000/035'),\n PosixPath('flow/0000/036'),\n PosixPath('flow/0000/037'),\n PosixPath('flow/0000/038'),\n PosixPath('flow/0000/039'),\n PosixPath('flow/0000/040'),\n PosixPath('flow/0000/041'),\n PosixPath('flow/0000/042'),\n PosixPath('flow/0000/043'),\n PosixPath('flow/0000/044'),\n PosixPath('flow/0000/045'),\n PosixPath('flow/0000/046'),\n PosixPath('flow/0000/047'),\n PosixPath('flow/0000/048'),\n PosixPath('flow/0000/049')]\n</code></pre> <p>We use the <code>NetworkView</code> class to point to a model. This object can implement plots plus methods to initialize network, stimuli etc.</p> <pre><code>network_view = flyvis.NetworkView(flyvis.results_dir / \"flow/0000/000\")\n</code></pre> <pre><code>[2024-12-08 19:40:21] network_view:122 Initialized network view at ../flyvis/data/results/flow/0000/000\n</code></pre> <pre><code># to load the Pytorch module with pretrained parameters\nnetwork = network_view.init_network()\n</code></pre> <pre><code>[2024-12-08 19:40:30] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-12-08 19:40:30] chkpt_utils:36 Recovered network state.\n</code></pre> <pre><code>movie_input = data[0]\n</code></pre> <pre><code>movie_input.shape\n</code></pre> <pre><code>torch.Size([20, 1, 721])\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#compute-a-stationary-state","title":"Compute a stationary state","text":"<p>We initialize the network at a stationary state, to remove transient responses due to stimulus onset from functional stimulus responses like motion detection. The network provides two methods for stationary state computation <code>network.fade_in_state</code> and <code>network.steady_state</code>. We use <code>fade_in_state</code> here, which slowly ramps up the intensity of the first frame in the sequence to compute a stationary state that minimizes the transient response. The method <code>steady_state</code> computes a sequence-independent stationary state by providing a whole-field grey-scale stimulus at medium intensity (but it does not get rid of a transient response).</p> <pre><code>stationary_state = network.fade_in_state(1.0, data.dt, movie_input[[0]])\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#obtain-network-responses","title":"Obtain network responses","text":"<p>A convenient way to obtain network responses is to call <code>network.simulate</code> which calls the forward function of the Pytorch module without tracking gradients (plus it provides a simpler interface than <code>network.forward</code> because it already maps stimulus to receptors using the <code>network.stimulus</code> attribute).</p> <pre><code># For analysis, we move the returned tensor to cpu.\nresponses = network.simulate(\n    movie_input[None], data.dt, initial_state=stationary_state\n).cpu()\n</code></pre> <pre><code>responses.shape\n</code></pre> <pre><code>torch.Size([1, 20, 45669])\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#visualize-responses-of-specific-cells","title":"Visualize responses of specific cells","text":"<p><code>LayerActivity</code> is an interface to the response tensor of 45k cells that allows dict- and attribute-style access to the responses of individual cell types and to the responses of their central cells.</p> <pre><code>responses = LayerActivity(responses, network.connectome, keepref=True)\n</code></pre> <pre><code>cell_type = \"T4c\"\n</code></pre> <p>The stimulus on the left, and the response on the right described by passive point neuron voltage dynamics. Cells depolarize (red) and hyperpolarize (blue) in response to the stimulus. A single \u201chexal\u201d corresponds to one neuron of the cell type.</p> <pre><code>anim = animations.StimulusResponse(movie_input[None], responses[cell_type][:, :, None])\nanim.animate_in_notebook(frames=np.arange(anim.frames)[::2])\n</code></pre> <p></p> <p>Often, we are interested in a canonical response of a specific cell type to a specific stimulus to generate hypotheses for their role in a computation. In our model, we can take the central cell as a proxy for all cells of the given type, because cells share their parameters and in- and output connections. I.e. the responses of all cells of a given type would be the same (not taking boundary effects into account) when the same stimulus would cross their identical but spatially offset receptive field in the same way.</p> <pre><code>n_frames = movie_input.shape[0]\ntime = np.arange(0, n_frames * data.dt, data.dt)\n</code></pre> <pre><code>fig, ax = plt_utils.init_plot([2, 2], fontsize=5)\nax.plot(time, responses.central[cell_type].squeeze())\nax.set_xlabel(\"time in s\", fontsize=5)\nax.set_ylabel(\"central response (a.u.)\", fontsize=5)\n</code></pre> <pre><code>Text(0, 0.5, 'central response (a.u.)')\n</code></pre> <p></p>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#compute-responses-over-the-whole-ensemble","title":"Compute responses over the whole ensemble","text":"<p>In addition to looking at individual models, we next compute responses across the whole ensemble at once to look at them jointly.</p> <pre><code>from typing import List\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\n\nnp.random.seed(42)\nimport matplotlib.pyplot as plt\n\nplt.rcParams['figure.dpi'] = 200\n\nfrom pathlib import Path\nfrom datamate import root, Directory\n\nimport flyvis\nfrom flyvis.utils.dataset_utils import load_moving_mnist\nfrom flyvis.datasets.datasets import SequenceDataset\nfrom flyvis.utils.activity_utils import LayerActivity\nfrom flyvis import EnsembleView\n</code></pre> <pre><code># the Directory class is a smart pointer to a specific directory\n# on the filesystem\n\n# directory to store the rendered stimuli\nfrom flyvis import renderings_dir\n\n\n# root tells where the Directory-tree starts\n@root(renderings_dir)\nclass RenderedData(Directory):\n    class Config(dict):\n        extent: int  # radius, in number of receptors of the hexagonal array.\n        kernel_size: int  # photon collection radius, in pixels.\n        subset_idx: List[int]  # if specified, subset of sequences to render\n\n    def __init__(self, config: Config):\n        # here comes the preprocessing and rendering as above or similar -- depending on the dataset etc.\n        # this code will be executed automatically once for each unique configuration to store preprocessed\n        # data on disk and later simply provide a reference to it.\n        sequences = load_moving_mnist()\n\n        # we use the configuration to control the settings under which we render the stimuli\n        receptors = BoxEye(extent=config.extent, kernel_size=config.kernel_size)\n\n        # for memory-friendly rendering we can loop over individual sequences\n        # and subsets of the dataset\n        rendered_sequences = []\n        subset_idx = getattr(config, \"subset_idx\", []) or list(range(sequences.shape[0]))\n        with tqdm(total=len(subset_idx)) as pbar:\n            for index in subset_idx:\n                rendered_sequences.append(receptors(sequences[[index]]).cpu().numpy())\n                pbar.update()\n\n        # to join individual sequences along their first dimension\n        # to obtain (n_sequences, n_frames, 1, receptors.hexals)\n        rendered_sequences = np.concatenate(rendered_sequences, axis=0)\n\n        # the __setattr__ method of the Directory class saves sequences to self.path/\"sequences.h5\"\n        # that can be later retrieved using self.sequences[:]\n        self.sequences = rendered_sequences\n</code></pre> <pre><code>class CustomStimuli(SequenceDataset):\n    # implementing the SequenceDataset interface\n    dt = 1 / 100\n    framerate = 24\n    t_pre = 0.5\n    t_post = 0.5\n    n_sequences = None\n    augment = False\n\n    def __init__(self, rendered_data_config: dict):\n        self.dir = RenderedData(rendered_data_config)\n        self.sequences = torch.tensor(self.dir.sequences[:])\n        self.n_sequences = self.sequences.shape[0]\n        self.arg_df = pd.DataFrame({\"sequence_idx\": np.arange(self.n_sequences)})\n\n    def get_item(self, key):\n        sequence = self.sequences[key]\n        # to match the framerate to the integration time dt, we can resample frames\n        # from these indices. note, when dt = 1/framerate, this will return the exact sequence\n        resample = self.get_temporal_sample_indices(sequence.shape[0], sequence.shape[0])\n        return sequence[resample]\n</code></pre> <pre><code># note, to render the whole dataset provide an empty list for `subset_idx` or delete the key word argument\ndata = CustomStimuli(dict(extent=15, kernel_size=13, subset_idx=[0, 1, 2, 3]))\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#select-the-pretrained-ensemble","title":"Select the pretrained ensemble","text":"<p>Similar to the <code>NetworkView</code> object, the <code>EnsembleView</code> object points to an ensemble and implements plots plus methods to initialize networks, stimuli etc. This object provides dict- and attribute-style access to individual <code>NetworkView</code> instances.</p> <pre><code>ensemble = EnsembleView(flyvis.results_dir / \"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:40:51] ensemble:166 Loaded 50 networks.\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#simulate-responses-for-each-network","title":"Simulate responses for each network","text":"<pre><code>movie_input = data[0]\n</code></pre> <p><code>ensemble.simulate</code> provides an efficient method to return responses of all networks within the ensemble.</p> <pre><code># ensemble.simulate returns an iterator over `network.simulate` for each network.\n# we exhaust it and stack responses from all models in the first dimension\nresponses = np.array(list(ensemble.simulate(movie_input[None], data.dt, fade_in=True)))\n</code></pre> <pre><code>Simulating network:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:40:59] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-12-08 19:40:59] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:00] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:00] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:00] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:00] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:00] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:00] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:01] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:01] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:01] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:01] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:01] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:01] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:02] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:02] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:02] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:02] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:02] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:02] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:03] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:03] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:03] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:03] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:03] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:03] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:04] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:04] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:04] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:04] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:04] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:04] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:05] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:05] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:05] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:05] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:05] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:05] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:06] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:06] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:06] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:06] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:06] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:06] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:07] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:07] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:07] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:07] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:07] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:07] chkpt_utils:36 Recovered network state.\n[2024-12-08 19:41:08] chkpt_utils:36 Recovered network state.\n</code></pre> <pre><code># dims are (n_models, n_sequences, n_frames, n_cells)\nresponses.shape\n</code></pre> <pre><code>(50, 1, 20, 45669)\n</code></pre>"},{"location":"examples/07_flyvision_providing_custom_stimuli/#visualize-responses-of-specific-cells-across-the-ensemble","title":"Visualize responses of specific cells across the ensemble","text":"<pre><code>responses = LayerActivity(responses, ensemble[0].connectome, keepref=True)\n</code></pre> <p>We look at responses of all cells of a specific cell-type in the hexagonal lattice.</p> <pre><code>cell_type = \"T4c\"\n\n# (n_models, n_sequences, n_frames, n_hexals)\nresponses[cell_type].shape\n</code></pre> <pre><code>(50, 1, 20, 721)\n</code></pre> <p>We can look at all model responses in succession to see how the stimulus causes depolarization and hyperpolarization in the cells. To speed this up a bit, we specify <code>frames</code> to look at every tenth frame.</p> <pre><code>anim = animations.StimulusResponse(movie_input[None], responses[cell_type][:, 0, :, None])\n# these are now just the first 5 models for illustration\nmodel_index = [0, 1, 2, 3, 4]\nanim.animate_in_notebook(samples=model_index, frames=np.arange(anim.frames)[::10])\n</code></pre> <p></p> <p>Or look at responses in multiple models jointly. Disclaimer: including more axes slows down the animation.</p> <pre><code>cell_type_responses = responses[cell_type]\nmodel_idx = [0, 1, 2, 3, 4]\nanim = animations.StimulusResponse(\n    movie_input[None], [cell_type_responses[i][None, 0, :, None] for i in model_idx]\n)\nanim.animate_in_notebook(frames=np.arange(anim.frames)[::10])\n</code></pre> <p></p> <p>Let\u2019s look at how the whole ensemble characterizes the central cell responses.</p> <pre><code>central_responses = responses.central\n</code></pre> <pre><code>n_frames = movie_input.shape[0]\ntime = np.arange(0, n_frames * data.dt, data.dt)\n</code></pre> <pre><code>colors = ensemble.task_error().colors\n</code></pre> <pre><code>fig, ax = plt_utils.init_plot([2, 2], fontsize=5)\nfor model_id, response in enumerate(central_responses[cell_type]):\n    ax.plot(time, response.squeeze(), c=colors[model_id], zorder=len(ensemble) - model_id)\nax.set_xlabel(\"time in s\", fontsize=5)\nax.set_ylabel(\"response (a.u.)\", fontsize=5)\nax.set_title(f\"{cell_type} responses across the ensemble\", fontsize=5)\n</code></pre> <pre><code>Text(0.5, 1.0, 'T4c responses across the ensemble')\n</code></pre> <p></p> <p>From the above plot it seems like different models generate different predictions for the cell type function and its hard to tell them apart. Therefore, we clustered the models such that we can separate the above responses by functional cluster for a specific cell type. Note, clusters are stored as dictionaries in which the key is the cluster identity and their values are the indices to the corresponding models.</p> <pre><code>cluster_indices = ensemble.cluster_indices(cell_type)\n</code></pre> <pre><code>[2024-12-08 19:41:26] clustering:835 Loaded T4c embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n</code></pre> <pre><code>for cluster_id, model_idx in cluster_indices.items():\n    fig, ax = plt_utils.init_plot([2, 2], fontsize=5)\n    for model_id in model_idx:\n        response = responses.central[cell_type][model_id]\n        ax.plot(\n            time, response.squeeze(), c=colors[model_id], zorder=len(ensemble) - model_id\n        )\n    ax.set_xlabel(\"time in s\", fontsize=5)\n    ax.set_ylabel(\"response (a.u.)\", fontsize=5)\n    ax.set_title(f\"{cell_type} responses across cluster {cluster_id + 1}\", fontsize=5)\n    plt.show()\n</code></pre> <p></p> <p></p> <p></p> <p>For T4c, we know that the first set of models is upwards tuning and the second is downwards tuning (Fig.4c) \u2013 lets try to observe differences in their responses.</p> <p>We choose the best upwards tuning model and the best downwards tuning model to compare.</p> <p>We can notice that the spatial location of hyperpolarization and depolarization is switched vertically between both models.</p> <pre><code>cell_type = \"T4c\"\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(cell_type)\n</code></pre> <pre><code>anim = animations.StimulusResponse(\n    movie_input[None],\n    [\n        responses[cell_type][[cluster_indices[0][0]], 0][:, :, None],\n        responses[cell_type][[cluster_indices[1][0]], 0][:, :, None],\n    ],\n)\nanim.animate_in_notebook(frames=np.arange(anim.frames)[::5])\n</code></pre> <p></p>"},{"location":"examples/__main__/","title":"main","text":"<p>Main notebook containing relevant analysis steps, run for each ensemble.</p> <p>The script `notebook_per_ensemble.py\u2019 automatically copies this notebook to an ensemble directory and executes it for newly trained ensembles using papermill.</p> <p>Warning: You can loose your work! Don\u2019t edit automatically created copies of this notebook within an ensemble directory. Those will be overwritten at a rerun. Create a copy instead.</p> <p>Warning: This notebook is not intended for standalone use. It is automatically copied to an ensemble directory and executed for newly trained ensembles using papermill. Adapt mindfully.</p> <pre><code>import logging\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom flyvis import EnsembleView\nfrom flyvis.analysis.moving_bar_responses import plot_angular_tuning\nfrom flyvis.analysis.visualization.plt_utils import add_cluster_marker, get_marker\n\nlogging.disable()\n\n\nmpl.rcParams[\"figure.dpi\"] = 300\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code>ensemble_name = \"flow/0001\"  # type: str\n</code></pre> <pre><code>validation_subdir = \"validation\"\nloss_file_name = \"epe\"\n</code></pre> <pre><code>ensemble = EnsembleView(\n    ensemble_name,\n    best_checkpoint_fn_kwargs={\n        \"validation_subdir\": validation_subdir,\n        \"loss_file_name\": loss_file_name,\n    },\n)\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n</code></pre> <pre><code>print(f\"Description of experiment: {getattr(ensemble[0].dir.config, 'description', '')}\")\n</code></pre> <pre><code>Description of experiment: ???\n</code></pre>"},{"location":"examples/__main__/#task-performance","title":"Task performance","text":""},{"location":"examples/__main__/#training-and-validation-losses","title":"Training and validation losses","text":"<pre><code>fig, ax = ensemble.training_loss()\n</code></pre> <pre><code>fig, ax = ensemble.validation_loss()\n</code></pre> <pre><code>fig, ax = ensemble.task_error_histogram()\n</code></pre>"},{"location":"examples/__main__/#learned-parameter-marginals","title":"Learned parameter marginals","text":"<pre><code>fig, axes = ensemble.node_parameters(\"bias\")\n</code></pre> <pre><code>fig, axes = ensemble.node_parameters(\"time_const\")\n</code></pre> <pre><code>fig, axes = ensemble.edge_parameters(\"syn_strength\")\n</code></pre>"},{"location":"examples/__main__/#dead-or-alive","title":"Dead or alive","text":"<pre><code>fig, ax, cbar, matrix = ensemble.dead_or_alive()\n</code></pre> <pre><code>../flyvis/data/results/flow/0001/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c0441561bbbb0ee371d1a28cef8a9505/output.h5\n../flyvis/data/results/flow/0001/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3e8e02604549aa7ac2c8df17f4736770/output.h5\n../flyvis/data/results/flow/0001/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/98f91049ef85d431968d03de9fcfbba9/output.h5\n../flyvis/data/results/flow/0001/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/66cdfd526f6afe4bd5b7326cebfa3bd6/output.h5\n../flyvis/data/results/flow/0001/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6558fab1e383da5dc4b0ea33f2693a42/output.h5\n../flyvis/data/results/flow/0001/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b4429ce21a0c1a12b19fa17757e57137/output.h5\n../flyvis/data/results/flow/0001/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a2e9fc84d3d5a97a6893e6975a5ba335/output.h5\n../flyvis/data/results/flow/0001/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e5e9fbae703c6b372769c120e12988a8/output.h5\n../flyvis/data/results/flow/0001/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3cb42587f6883813dda4243f35a9073b/output.h5\n../flyvis/data/results/flow/0001/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f312a212e34dac86e0b15bc88bdb60a4/output.h5\n../flyvis/data/results/flow/0001/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/00f2e1f02335a1acceca5d266994fee2/output.h5\n../flyvis/data/results/flow/0001/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7cd7d1816e75955785d49c3aefbcbb8f/output.h5\n../flyvis/data/results/flow/0001/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5677b21f148bfb90d466b18a93739783/output.h5\n../flyvis/data/results/flow/0001/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5682a51171b64f281bc2f771acb92527/output.h5\n../flyvis/data/results/flow/0001/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2d59c5edfa52c27d2c508d6dd5c968d7/output.h5\n../flyvis/data/results/flow/0001/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/583017a23212926b4d633414a80aac22/output.h5\n../flyvis/data/results/flow/0001/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0d5bde0d357138a1a8c824d22b2b4815/output.h5\n../flyvis/data/results/flow/0001/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/79643dad23598927268ec5da4006a9ae/output.h5\n../flyvis/data/results/flow/0001/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0e419a5cbe883b2a57c5e696ec75b93d/output.h5\n../flyvis/data/results/flow/0001/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/aa404b0e4c76831d9c7b0095fcd31d9d/output.h5\n../flyvis/data/results/flow/0001/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/514075420e3c6875df93555dcfe603a8/output.h5\n../flyvis/data/results/flow/0001/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bfb4f4c4ac1817690098803eded2d660/output.h5\n../flyvis/data/results/flow/0001/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/def38e411152b6cfc3d051d22428c111/output.h5\n../flyvis/data/results/flow/0001/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9bbb3f924f67943fc6e9664ef7c7468b/output.h5\n../flyvis/data/results/flow/0001/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6e0ef3870bc16ed50f2d5db4a985a716/output.h5\n../flyvis/data/results/flow/0001/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/132446834d4813ae6d78f920ca2aa96b/output.h5\n../flyvis/data/results/flow/0001/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5f1579e6b3a5869a7fa57f18db00c58e/output.h5\n../flyvis/data/results/flow/0001/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/14070269cb74ae4ada1b0f387f253d8b/output.h5\n../flyvis/data/results/flow/0001/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/404f5ac8bf3dd944bb8fc39ef7c49237/output.h5\n../flyvis/data/results/flow/0001/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/59f53ef9a626524cec2e175bb16c410d/output.h5\n../flyvis/data/results/flow/0001/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/becc3e5be49b4806e9b6a40e2842ea47/output.h5\n../flyvis/data/results/flow/0001/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9259f4d62ac65c92f68981e7a5708bc0/output.h5\n../flyvis/data/results/flow/0001/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/29dfdfe0fefebe7ee59bdc206a230272/output.h5\n../flyvis/data/results/flow/0001/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a864d3a5ba9aa8ef3ddf81dd41668701/output.h5\n../flyvis/data/results/flow/0001/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b980b34213625a4de40335c67d03af8b/output.h5\n../flyvis/data/results/flow/0001/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e5bc8053729138a156ff196c6ffb404a/output.h5\n../flyvis/data/results/flow/0001/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/687e177333f1e4a140c2794bb275b638/output.h5\n../flyvis/data/results/flow/0001/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4441374e363c61ea92f93ea52095192a/output.h5\n../flyvis/data/results/flow/0001/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/99f4dec81e74368481aecc7a1b14be6f/output.h5\n../flyvis/data/results/flow/0001/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d888e60f3428f5ef1216549a8f03805b/output.h5\n../flyvis/data/results/flow/0001/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/452af539922790584eea7937d0ab901d/output.h5\n../flyvis/data/results/flow/0001/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/95bc621f4049f6dd342af751a3c0d8f5/output.h5\n../flyvis/data/results/flow/0001/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/08b69eb513cf7ba0c31144f695db10dd/output.h5\n../flyvis/data/results/flow/0001/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/75099cd5bb501f1eeb3a49bd13ed6ab7/output.h5\n../flyvis/data/results/flow/0001/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d4db856e71a4ee221babd6664a4d089e/output.h5\n../flyvis/data/results/flow/0001/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4c2f807a64caa503fd6317434800d8fa/output.h5\n../flyvis/data/results/flow/0001/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/80bef81e3ce7e4742a7c5403df2d4969/output.h5\n../flyvis/data/results/flow/0001/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4f3d6a88a2ef428b6066fa8e39818707/output.h5\n../flyvis/data/results/flow/0001/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3807f5bb85f011ecc8f4a695037f70de/output.h5\n../flyvis/data/results/flow/0001/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f3c5168fee7bcb1a7ba1653d8d896ce3/output.h5\n</code></pre>"},{"location":"examples/__main__/#contrast-selectivity-and-flash-response-indices-fri","title":"Contrast selectivity and flash response indices (FRI)","text":""},{"location":"examples/__main__/#20-best-task-performing-models","title":"20% best task-performing models","text":"<pre><code>with ensemble.ratio(best=0.2):\n    ensemble.flash_response_index()\n</code></pre> <pre><code>../flyvis/data/results/flow/0001/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bd4c65a392d06dcdffb007b5a81e2a72/output.h5\n../flyvis/data/results/flow/0001/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3bf428204710a3cd4d506ebd22221b69/output.h5\n../flyvis/data/results/flow/0001/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/44f153e96335390c137630fe676c25af/output.h5\n../flyvis/data/results/flow/0001/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b7d43430908f0ebbe09a36ce2cadd3b6/output.h5\n../flyvis/data/results/flow/0001/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bec5e5065969242f2c609a915e7c8e4e/output.h5\n../flyvis/data/results/flow/0001/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9c070ae30dde5fae9f0667e81add549a/output.h5\n../flyvis/data/results/flow/0001/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c5e319c7d288f6d3a74ad66b98ee8b28/output.h5\n../flyvis/data/results/flow/0001/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/511eb784ee629c003f4bbc334268f798/output.h5\n../flyvis/data/results/flow/0001/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13a439e203e38b115205b38a1601f840/output.h5\n../flyvis/data/results/flow/0001/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/928af923ab47d566f61e0c0937238164/output.h5\n</code></pre>"},{"location":"examples/__main__/#100-models","title":"100% models","text":"<pre><code>fig, ax = ensemble.flash_response_index()\n</code></pre> <pre><code>../flyvis/data/results/flow/0001/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9c8ed3f297a6bbe6681923cca44fef08/output.h5\n../flyvis/data/results/flow/0001/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fcdb5947ee72b22747f4bd39d3f27c8b/output.h5\n../flyvis/data/results/flow/0001/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e1cda7457bdc14c633ea3651dd30e20d/output.h5\n../flyvis/data/results/flow/0001/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ae98506a9f5b3c60f1f69dee760960a0/output.h5\n../flyvis/data/results/flow/0001/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fc9fa31f1878f051e90891ac9aa734e3/output.h5\n../flyvis/data/results/flow/0001/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/164c4e901ed946dfcaf6b22b78354e8a/output.h5\n../flyvis/data/results/flow/0001/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/60956ba0614f4259110004adf6bfb0c3/output.h5\n../flyvis/data/results/flow/0001/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13a439e203e38b115205b38a1601f840/output.h5\n../flyvis/data/results/flow/0001/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/315a60dbafac7a826614bca39463925b/output.h5\n../flyvis/data/results/flow/0001/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/21c47b51d1a1af74ea8d03d94ff50022/output.h5\n../flyvis/data/results/flow/0001/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/44f153e96335390c137630fe676c25af/output.h5\n../flyvis/data/results/flow/0001/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0ab3c7906d8a0ac182b9373312fdfe34/output.h5\n../flyvis/data/results/flow/0001/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f8d32478be81dc5f2d96ca0fe57f463a/output.h5\n../flyvis/data/results/flow/0001/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1fd69989a081236837070e64ed912125/output.h5\n../flyvis/data/results/flow/0001/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c5e319c7d288f6d3a74ad66b98ee8b28/output.h5\n../flyvis/data/results/flow/0001/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2c9323b2e17dcb0fac7dd88908ed3ef3/output.h5\n../flyvis/data/results/flow/0001/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6c00cd901eccd5a786843b43a26a2008/output.h5\n../flyvis/data/results/flow/0001/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/df76a450d74c71a5175d2b2e835c41b9/output.h5\n../flyvis/data/results/flow/0001/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fb7c8db108277f0d49794c9757b79bdc/output.h5\n../flyvis/data/results/flow/0001/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/73d5fb8944cd39dc5306832069f1eb53/output.h5\n../flyvis/data/results/flow/0001/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ae0b6d9415adddaedf3dc4de60f08e13/output.h5\n../flyvis/data/results/flow/0001/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c398d4ff5336e245b911f1435e53d697/output.h5\n../flyvis/data/results/flow/0001/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d8fd7501128eaa34c01cb2a251bf827f/output.h5\n../flyvis/data/results/flow/0001/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e9b2bd568ba1cd51e3c59f5494cca039/output.h5\n../flyvis/data/results/flow/0001/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cbeca159094bc36f61e150305b4891d3/output.h5\n../flyvis/data/results/flow/0001/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d041a037891c0949cbeba7482f53042f/output.h5\n../flyvis/data/results/flow/0001/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bec5e5065969242f2c609a915e7c8e4e/output.h5\n../flyvis/data/results/flow/0001/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c9c4e95a9049d663c98e511adaecdc50/output.h5\n../flyvis/data/results/flow/0001/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ba732cb31505519c5316acb33c2b69f0/output.h5\n../flyvis/data/results/flow/0001/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b926ff5fe0db9e0b88fcffaf563f9200/output.h5\n../flyvis/data/results/flow/0001/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/26eb198b2755f87b3e01e553216808fa/output.h5\n../flyvis/data/results/flow/0001/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a27d95a6cd94f722342ac35ccab89940/output.h5\n../flyvis/data/results/flow/0001/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a347866cdaa32089c0492747cd443584/output.h5\n../flyvis/data/results/flow/0001/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2fb0d7266c177dcb118c397632c2507c/output.h5\n../flyvis/data/results/flow/0001/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1b4ee7480d1ff450c61088f29a806f2d/output.h5\n../flyvis/data/results/flow/0001/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3bf428204710a3cd4d506ebd22221b69/output.h5\n../flyvis/data/results/flow/0001/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bd4c65a392d06dcdffb007b5a81e2a72/output.h5\n../flyvis/data/results/flow/0001/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7d077bd2149c4fd3a0697c4e1a06bb2d/output.h5\n../flyvis/data/results/flow/0001/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/928af923ab47d566f61e0c0937238164/output.h5\n../flyvis/data/results/flow/0001/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8d5abfbd37b5c844aa18f37ba659f313/output.h5\n../flyvis/data/results/flow/0001/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f109a44bddab0f1734dbdaea56dee2f9/output.h5\n../flyvis/data/results/flow/0001/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/41c4e9939c6add4492ae883eb3a9faea/output.h5\n../flyvis/data/results/flow/0001/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b7d43430908f0ebbe09a36ce2cadd3b6/output.h5\n../flyvis/data/results/flow/0001/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/511eb784ee629c003f4bbc334268f798/output.h5\n../flyvis/data/results/flow/0001/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e8e9b3efa8b66ecd53755a65f0cd8526/output.h5\n../flyvis/data/results/flow/0001/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9c070ae30dde5fae9f0667e81add549a/output.h5\n../flyvis/data/results/flow/0001/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6b31cf47b0633c9bf022f8300bd6060d/output.h5\n../flyvis/data/results/flow/0001/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/608a807e9da24c550996f170b815f687/output.h5\n../flyvis/data/results/flow/0001/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e753ddd0395dcd95355b1774ba487aa0/output.h5\n../flyvis/data/results/flow/0001/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34a6fc6aace38573e70e711bcbb19cfd/output.h5\n</code></pre>"},{"location":"examples/__main__/#motion-selectivity-and-direction-selectivity-index-dsi","title":"Motion selectivity and direction selectivity index (DSI)","text":""},{"location":"examples/__main__/#20-best-task-performing-models_1","title":"20% best task-performing models","text":"<pre><code>with ensemble.ratio(best=0.2):\n    ensemble.direction_selectivity_index()\n</code></pre> <pre><code>../flyvis/data/results/flow/0001/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/57f072f845c6dc08a59fd1d0cda89135/output.h5\n../flyvis/data/results/flow/0001/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fc081508d80348d38c1911ba1542fe43/output.h5\n../flyvis/data/results/flow/0001/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/54edadc37895551e5ac747c282646e72/output.h5\n../flyvis/data/results/flow/0001/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/17803a4182c3768059c1488c99521d91/output.h5\n../flyvis/data/results/flow/0001/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34fb025d28f9f5881f44098fc0130e88/output.h5\n../flyvis/data/results/flow/0001/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/52a28ad06d178c499beb5074af2c934f/output.h5\n../flyvis/data/results/flow/0001/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d89a1143c3313d26ef60aefd7497e7f8/output.h5\n../flyvis/data/results/flow/0001/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/05dd71ddcb7ef28c921a856316e402e2/output.h5\n../flyvis/data/results/flow/0001/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2892c88f39169afc77fdad6acbbeff31/output.h5\n../flyvis/data/results/flow/0001/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d9f3f2040fc33f87520ef5ae1a51163b/output.h5\n</code></pre>"},{"location":"examples/__main__/#100-models_1","title":"100% models","text":"<pre><code>ensemble.direction_selectivity_index()\n</code></pre> <pre><code>../flyvis/data/results/flow/0001/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0c81fe5112956cf9df3d9e2c720a89f8/output.h5\n../flyvis/data/results/flow/0001/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a5effd2f066299c87e27f38bb75c08cf/output.h5\n../flyvis/data/results/flow/0001/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/36cc7566416e98653de0b682fc69b59e/output.h5\n../flyvis/data/results/flow/0001/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34beb6e4231f3beafacb8d73a66f54d5/output.h5\n../flyvis/data/results/flow/0001/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/62ea707693a8ced3ef9e7e4d7307585c/output.h5\n../flyvis/data/results/flow/0001/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7304c3fda3ad8cf3308d2b81e364a4e5/output.h5\n../flyvis/data/results/flow/0001/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2f20844dfb76bb618d9093610482e3eb/output.h5\n../flyvis/data/results/flow/0001/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2892c88f39169afc77fdad6acbbeff31/output.h5\n../flyvis/data/results/flow/0001/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c53f93ab2d9b35eaa8f9a61eac542be2/output.h5\n../flyvis/data/results/flow/0001/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/309b08b5f516a6a83ad1d6b96278dadf/output.h5\n../flyvis/data/results/flow/0001/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/54edadc37895551e5ac747c282646e72/output.h5\n../flyvis/data/results/flow/0001/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4375d2101a1629216ebf8a4e28f62a33/output.h5\n../flyvis/data/results/flow/0001/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/64541cf2bb01f5056f80688fb41f0ba9/output.h5\n../flyvis/data/results/flow/0001/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9bdb7271b2373f6a71926f9be48e82fe/output.h5\n../flyvis/data/results/flow/0001/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d89a1143c3313d26ef60aefd7497e7f8/output.h5\n../flyvis/data/results/flow/0001/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f2d0da658e7d426500cf1b38eb7a989e/output.h5\n../flyvis/data/results/flow/0001/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/307e5f1a53d588f98b26aaa6326b7b58/output.h5\n../flyvis/data/results/flow/0001/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8af2371cd5d822adfed4f8700e61e564/output.h5\n../flyvis/data/results/flow/0001/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/49fe41ece25423d8f0be281b4c629266/output.h5\n../flyvis/data/results/flow/0001/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cf13694a1b22713de7f6006367040072/output.h5\n../flyvis/data/results/flow/0001/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4c260755e7a480630ed0ad0c522266c6/output.h5\n../flyvis/data/results/flow/0001/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/59e45698e81bd8bc38832f93f20cc0cf/output.h5\n../flyvis/data/results/flow/0001/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/85f61ab5cc999ac2365ebab039463f4d/output.h5\n../flyvis/data/results/flow/0001/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/53f05a3307151650fd0d0c159c1f441e/output.h5\n../flyvis/data/results/flow/0001/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/99aaaa3abfb9bab3734ee84d2fec25d7/output.h5\n../flyvis/data/results/flow/0001/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/521b00ceffe7b4911f7d8dbba8d4c0a0/output.h5\n../flyvis/data/results/flow/0001/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34fb025d28f9f5881f44098fc0130e88/output.h5\n../flyvis/data/results/flow/0001/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e244e4faa471b00a78327c9642d74b63/output.h5\n../flyvis/data/results/flow/0001/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e58bed06839e2e5088f942aacd122253/output.h5\n../flyvis/data/results/flow/0001/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/eb1340b580d31cfe7e8f5d0504fced92/output.h5\n../flyvis/data/results/flow/0001/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8c8d87f138997f67bb2236cfe7a7af1c/output.h5\n../flyvis/data/results/flow/0001/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c28893ee720c5d314d206287de8db394/output.h5\n../flyvis/data/results/flow/0001/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/44a553f28596a7ad2c6eab121dbc642d/output.h5\n../flyvis/data/results/flow/0001/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/afd56b985f39750c735722f4d48973a3/output.h5\n../flyvis/data/results/flow/0001/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e2b717e9cc34da542d4855a45361e160/output.h5\n../flyvis/data/results/flow/0001/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fc081508d80348d38c1911ba1542fe43/output.h5\n../flyvis/data/results/flow/0001/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/57f072f845c6dc08a59fd1d0cda89135/output.h5\n../flyvis/data/results/flow/0001/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a3c1acffbebd6b29e88f40126450b5fd/output.h5\n../flyvis/data/results/flow/0001/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d9f3f2040fc33f87520ef5ae1a51163b/output.h5\n../flyvis/data/results/flow/0001/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/91de8ba393e6ff302174344e0039ea91/output.h5\n../flyvis/data/results/flow/0001/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/71e4dae102c4a0cb1031633e71238782/output.h5\n../flyvis/data/results/flow/0001/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/493a12c74654643b8dad4e13f4846ef5/output.h5\n../flyvis/data/results/flow/0001/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/17803a4182c3768059c1488c99521d91/output.h5\n../flyvis/data/results/flow/0001/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/05dd71ddcb7ef28c921a856316e402e2/output.h5\n../flyvis/data/results/flow/0001/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0760489539bb22c16b9a6660baa94622/output.h5\n../flyvis/data/results/flow/0001/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/52a28ad06d178c499beb5074af2c934f/output.h5\n../flyvis/data/results/flow/0001/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/771343b27d0b38823e732d362742971a/output.h5\n../flyvis/data/results/flow/0001/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e9bcb29e994581187780f04e661472e8/output.h5\n../flyvis/data/results/flow/0001/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e50276c692df98aedda40cad1e50c43d/output.h5\n../flyvis/data/results/flow/0001/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c7e424b1c9aa6ed65a704f02bc0361d7/output.h5\n\n\n\n\n\n(&lt;Figure size 3000x360 with 2 Axes&gt;, array([&lt;Axes: &gt;, &lt;Axes: &gt;], dtype=object))\n</code></pre>"},{"location":"examples/__main__/#clustering-of-models-based-on-responses-to-naturalistic-stimuli","title":"Clustering of models based on responses to naturalistic stimuli","text":""},{"location":"examples/__main__/#t4c","title":"T4c","text":"<pre><code>task_error = ensemble.task_error()\nembeddingplot = ensemble.clustering(\"T4c\").plot(\n    task_error=task_error.values, colors=task_error.colors\n)\n</code></pre> <pre><code>../flyvis/data/results/flow/0001/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c0441561bbbb0ee371d1a28cef8a9505/output.h5\n../flyvis/data/results/flow/0001/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3e8e02604549aa7ac2c8df17f4736770/output.h5\n../flyvis/data/results/flow/0001/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/98f91049ef85d431968d03de9fcfbba9/output.h5\n../flyvis/data/results/flow/0001/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/66cdfd526f6afe4bd5b7326cebfa3bd6/output.h5\n../flyvis/data/results/flow/0001/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6558fab1e383da5dc4b0ea33f2693a42/output.h5\n../flyvis/data/results/flow/0001/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b4429ce21a0c1a12b19fa17757e57137/output.h5\n../flyvis/data/results/flow/0001/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a2e9fc84d3d5a97a6893e6975a5ba335/output.h5\n../flyvis/data/results/flow/0001/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e5e9fbae703c6b372769c120e12988a8/output.h5\n../flyvis/data/results/flow/0001/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3cb42587f6883813dda4243f35a9073b/output.h5\n../flyvis/data/results/flow/0001/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f312a212e34dac86e0b15bc88bdb60a4/output.h5\n../flyvis/data/results/flow/0001/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/00f2e1f02335a1acceca5d266994fee2/output.h5\n../flyvis/data/results/flow/0001/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7cd7d1816e75955785d49c3aefbcbb8f/output.h5\n../flyvis/data/results/flow/0001/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5677b21f148bfb90d466b18a93739783/output.h5\n../flyvis/data/results/flow/0001/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5682a51171b64f281bc2f771acb92527/output.h5\n../flyvis/data/results/flow/0001/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2d59c5edfa52c27d2c508d6dd5c968d7/output.h5\n../flyvis/data/results/flow/0001/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/583017a23212926b4d633414a80aac22/output.h5\n../flyvis/data/results/flow/0001/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0d5bde0d357138a1a8c824d22b2b4815/output.h5\n../flyvis/data/results/flow/0001/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/79643dad23598927268ec5da4006a9ae/output.h5\n../flyvis/data/results/flow/0001/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0e419a5cbe883b2a57c5e696ec75b93d/output.h5\n../flyvis/data/results/flow/0001/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/aa404b0e4c76831d9c7b0095fcd31d9d/output.h5\n../flyvis/data/results/flow/0001/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/514075420e3c6875df93555dcfe603a8/output.h5\n../flyvis/data/results/flow/0001/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bfb4f4c4ac1817690098803eded2d660/output.h5\n../flyvis/data/results/flow/0001/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/def38e411152b6cfc3d051d22428c111/output.h5\n../flyvis/data/results/flow/0001/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9bbb3f924f67943fc6e9664ef7c7468b/output.h5\n../flyvis/data/results/flow/0001/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6e0ef3870bc16ed50f2d5db4a985a716/output.h5\n../flyvis/data/results/flow/0001/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/132446834d4813ae6d78f920ca2aa96b/output.h5\n../flyvis/data/results/flow/0001/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5f1579e6b3a5869a7fa57f18db00c58e/output.h5\n../flyvis/data/results/flow/0001/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/14070269cb74ae4ada1b0f387f253d8b/output.h5\n../flyvis/data/results/flow/0001/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/404f5ac8bf3dd944bb8fc39ef7c49237/output.h5\n../flyvis/data/results/flow/0001/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/59f53ef9a626524cec2e175bb16c410d/output.h5\n../flyvis/data/results/flow/0001/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/becc3e5be49b4806e9b6a40e2842ea47/output.h5\n../flyvis/data/results/flow/0001/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9259f4d62ac65c92f68981e7a5708bc0/output.h5\n../flyvis/data/results/flow/0001/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/29dfdfe0fefebe7ee59bdc206a230272/output.h5\n../flyvis/data/results/flow/0001/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a864d3a5ba9aa8ef3ddf81dd41668701/output.h5\n../flyvis/data/results/flow/0001/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b980b34213625a4de40335c67d03af8b/output.h5\n../flyvis/data/results/flow/0001/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e5bc8053729138a156ff196c6ffb404a/output.h5\n../flyvis/data/results/flow/0001/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/687e177333f1e4a140c2794bb275b638/output.h5\n../flyvis/data/results/flow/0001/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4441374e363c61ea92f93ea52095192a/output.h5\n../flyvis/data/results/flow/0001/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/99f4dec81e74368481aecc7a1b14be6f/output.h5\n../flyvis/data/results/flow/0001/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d888e60f3428f5ef1216549a8f03805b/output.h5\n../flyvis/data/results/flow/0001/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/452af539922790584eea7937d0ab901d/output.h5\n../flyvis/data/results/flow/0001/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/95bc621f4049f6dd342af751a3c0d8f5/output.h5\n../flyvis/data/results/flow/0001/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/08b69eb513cf7ba0c31144f695db10dd/output.h5\n../flyvis/data/results/flow/0001/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/75099cd5bb501f1eeb3a49bd13ed6ab7/output.h5\n../flyvis/data/results/flow/0001/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d4db856e71a4ee221babd6664a4d089e/output.h5\n../flyvis/data/results/flow/0001/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4c2f807a64caa503fd6317434800d8fa/output.h5\n../flyvis/data/results/flow/0001/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/80bef81e3ce7e4742a7c5403df2d4969/output.h5\n../flyvis/data/results/flow/0001/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4f3d6a88a2ef428b6066fa8e39818707/output.h5\n../flyvis/data/results/flow/0001/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3807f5bb85f011ecc8f4a695037f70de/output.h5\n../flyvis/data/results/flow/0001/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f3c5168fee7bcb1a7ba1653d8d896ce3/output.h5\n\n\n/home/lappalainenj@hhmi.org/miniconda3/envs/flyvision/lib/python3.9/site-packages/umap/umap_.py:1356: RuntimeWarning: divide by zero encountered in power\n  return 1.0 / (1.0 + a * x ** (2 * b))\n</code></pre> <pre><code>r = ensemble.moving_edge_responses()\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>colors = ensemble.task_error().colors\n</code></pre> <pre><code>fig, axes = plt.subplots(\n    1, len(cluster_indices), subplot_kw={\"projection\": \"polar\"}, figsize=[2, 1]\n)\nfor cluster_id, indices in cluster_indices.items():\n    plot_angular_tuning(\n        r.sel(network_id=indices),\n        \"T4c\",\n        intensity=1,\n        colors=colors[indices],\n        zorder=ensemble.zorder()[indices],\n        groundtruth=True if cluster_id == 0 else False,\n        fig=fig,\n        ax=axes[cluster_id],\n    )\n    add_cluster_marker(fig, axes[cluster_id], marker=get_marker(cluster_id))\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/__main_per_model__/","title":"main per model","text":"<p>Main notebook containing relevant analysis steps, run for each model.</p> <p>The script `notebook_per_model.py\u2019 automatically copies this notebook to an ensemble directory and executes it for newly trained ensembles using papermill.</p> <p>Warning: You can loose your work! Don\u2019t edit automatically created copies of this notebook within a model directory. Those will be overwritten at a rerun. Create a copy instead.</p> <p>Warning: This notebook is not intended for standalone use. It is automatically copied to an ensemble directory and executed for newly trained models using papermill. Adapt mindfully.</p> <pre><code>import flyvis\n</code></pre> <pre><code>ensemble_and_network_id = \"0000/000\"  # type: str\ntask_name = \"flow\"  # type: str\n</code></pre> <pre><code>network_view = flyvis.NetworkView(f\"{task_name}/{ensemble_and_network_id}\")\n</code></pre> <pre><code>[2024-12-08 19:51:02] network_view:122 Initialized network view at ../flyvis/data/results/flow/0000/000\n</code></pre>"},{"location":"examples/figure_01_fly_visual_system/","title":"Figure 1","text":""},{"location":"examples/figure_01_fly_visual_system/#a","title":"a","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nfrom flyvis import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:41:51] ensemble:166 Loaded 50 networks.\n</code></pre> <pre><code>fig, ax, cbar, matrix = ensemble[0].connectivity_matrix()\n</code></pre>"},{"location":"examples/figure_01_fly_visual_system/#e","title":"e","text":"<pre><code>fig = ensemble[0].receptive_field(\n    source=\"Mi9\",\n    target=\"T4d\",\n    annotate=True,\n    annotate_coords=False,\n    trained=False,\n    n_syn=True,\n    cbar=False,\n    fontsize=6,\n    vmax=14,\n    figsize=[2, 2],\n    title=\"\",\n    max_extent=2,\n    edgewidth=0.2,\n)\n</code></pre>"},{"location":"examples/figure_01_fly_visual_system/#g","title":"g","text":"<pre><code>import matplotlib.pyplot as plt\n\nfrom flyvis.datasets.sintel import MultiTaskSintel\nfrom flyvis.analysis.visualization.plots import hex_scatter, quick_hex_scatter\nfrom flyvis.analysis.visualization.plt_utils import rm_spines\n</code></pre> <pre><code>dataset = MultiTaskSintel(dt=1 / 24)\nsequence = dataset.cartesian_sequence(0, outwidth=436)\n</code></pre> <pre><code>[2024-12-08 19:41:59] sintel_utils:331 Found Sintel at ../flyvis/data/SintelDataSet\n</code></pre> <p>sintel movie</p> <pre><code>for frame in [0, 1, 18]:\n    fig, ax = plt.subplots(figsize=[1, 1])\n    ax.imshow(sequence[1, frame], cmap=plt.cm.binary_r)\n    rm_spines(ax)\n</code></pre> <p></p> <p></p> <p></p> <pre><code>dataset.augment = False\n</code></pre> <pre><code>sequence = dataset[1]\n</code></pre> <p>fly eye rendering</p> <pre><code>for frame in [0, 1, -1]:\n    quick_hex_scatter(sequence[\"lum\"][frame, 0], cbar=False)\n    rm_spines(ax)\n</code></pre> <p></p> <p></p> <p></p> <p>activations</p> <pre><code>from flyvis.connectome import ConnectomeFromAvgFilters\nfrom flyvis.analysis.visualization import plt_utils\nfrom flyvis.analysis.visualization.network_fig import WholeNetworkFigure\nfrom flyvis.utils.color_utils import cell_type_colors\n</code></pre> <pre><code>sequence = dataset[1]\n</code></pre> <pre><code>ctome = ConnectomeFromAvgFilters()\n</code></pre> <pre><code>nodes = ctome.nodes.to_df()\n</code></pre> <pre><code>responses = (\n    ensemble[0]\n    .init_network()\n    .simulate(sequence[\"lum\"][None], dt=1 / 50, as_layer_activity=True)\n)\n</code></pre> <pre><code>[2024-12-08 19:42:18] network:222 Initialized network with NumberOfParams(free=734, fixed=2959) parameters.\n[2024-12-08 19:42:18] chkpt_utils:36 Recovered network state.\n</code></pre> <pre><code>frame = -1\nwnf = WholeNetworkFigure(ctome)\nwnf.init_figure(\n    figsize=(5.250, 1.3125),\n    decoder_box=False,\n    cell_type_labels=False,\n    fontsize=5,\n    add_graph_kwargs={\n        \"constant_edge_width\": 0.2,\n        \"edge_width\": 0.15,  # this scales edges relative to each other\n        \"constant_edge_color\": \"k\",\n        \"edge_alpha\": 0.1,\n        \"nx_kwargs\": {\n            \"min_source_margin\": 0,\n            \"min_target_margin\": 5,\n            \"selfloop_x0\": 0,\n            \"selfloop_y0\": 0,\n            \"selfloop_h_shift\": 0.025,\n            \"selfloop_v_shift\": 0.1275,\n        },\n    },\n    network_layout_axes_kwargs={\n        \"types_per_column\": 4,\n        \"region_spacing\": 1.25,\n        \"wspace\": 0.0,\n    },\n)\n\nfor i, cell_type in enumerate(wnf.layout.keys()):\n    ax = wnf.axes[i]\n    u = nodes[nodes.type == cell_type].u.values\n    v = nodes[nodes.type == cell_type].v.values\n    hex_scatter(\n        u,\n        v,\n        responses[cell_type][0, frame],\n        fig=wnf.fig,\n        ax=ax,\n        label=f\"{cell_type}\",\n        label_color=cell_type_colors[cell_type],\n        cmap=plt.cm.binary_r,\n        cbar=False,\n        fontsize=5,\n        fill=True,\n        labelxy=\"auto\",\n    )\n    (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n    ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n    ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.02))\n</code></pre> <p></p> <p>optic flow</p> <pre><code>from flyvis.analysis.visualization.plots import quick_hex_flow\n</code></pre> <pre><code>sequence = dataset[1]\n</code></pre> <pre><code>for frame in [0, 1, -1]:\n    quick_hex_flow(\n        sequence[\"flow\"][frame],\n        cwheel=False,\n        cwheelradius=0.2,\n        cwheelpos=\"southeast\",\n        cwheellabelpad=-3,\n    )\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"examples/figure_02_simple_stimuli_responses/","title":"Figure 2","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nimport numpy as np\n\nfrom flyvis import EnsembleView\nfrom flyvis.utils import color_utils\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:44:01] ensemble:166 Loaded 50 networks.\n</code></pre>"},{"location":"examples/figure_02_simple_stimuli_responses/#b","title":"b","text":"<pre><code>with ensemble.ratio(best=0.2):\n    fig, ax = ensemble.flash_response_index()\n\nymin, ymax = 0, 1\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [\n    p.get_position()[0] for p in ax.get_xticklabels() if p.get_text() in [\"R1\", \"Tm3\"]\n]\n# to place in between ticks\nxmin -= 1 / 2\nxmax += 1 / 2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.ON_FR, alpha=0.1)\nax.add_patch(rect)\n\nymin, ymax = 0, -1\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [\n    p.get_position()[0] for p in ax.get_xticklabels() if p.get_text() in [\"L1\", \"Tm9\"]\n]\n# to place in between ticks\nxmin -= 1 / 2\nxmax += 1 / 2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.OFF_FR, alpha=0.1)\nax.add_patch(rect)\n\nax.set_title(\"Flash response indices\")\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d9d302eebb41d955bb76dcf9d6ce623a/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13f5d9136003d68fa860867f0ed89c64/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6ec38263ed72b3a302f55bd519d68643/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/048c1466b844b8be367b875fab782256/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ca0abb0d8af62ceb2b9ad8b3d991eb06/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ecc4b64ad753e775719a388d36fec0d5/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8420baf27ddfbc229fec85b8f120585/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cdc3f7c2ec749662cacbbdcfab68b20c/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/561c8275f604bf5964ebd8efa2ab0838/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/da9d8f4c595528a025e132eafd136811/output.h5\n\n\n\n\n\nText(0.5, 1.0, 'Flash response indices')\n</code></pre>"},{"location":"examples/figure_02_simple_stimuli_responses/#c","title":"c","text":"<pre><code>with ensemble.ratio(best=0.2):\n    fig, axes = ensemble.direction_selectivity_index()\n\nymin, ymax = 0, 1\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [\n    p.get_position()[0]\n    for p in axes[1].get_xticklabels()\n    if p.get_text() in [\"T4a\", \"T4d\"]\n]\n# to place in between ticks\nxmin -= 1 / 2\nxmax += 1 / 2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.ON, alpha=0.1)\naxes[0].add_patch(rect)\n\n# to get locations of left most and right most T4 subtype ticks\nxmin, xmax = [\n    p.get_position()[0]\n    for p in axes[1].get_xticklabels()\n    if p.get_text() in [\"T5a\", \"T5d\"]\n]\n# to place in between ticks\nxmin -= 1 / 2\nxmax += 1 / 2\nxy = (xmin, ymin)\nwidth = xmax - xmin\nheight = ymax\nrect = Rectangle(xy, width, height, facecolor=color_utils.OFF, alpha=0.1)\naxes[1].add_patch(rect)\n\nax.set_title(\"Direction selectivity indices\")\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e236e47b9a57dc6d7b692906aca84495/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2a1519d1c3b8bf0d0776e8ff2618353d/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/787654b3c56e4015939e72adfa768448/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d4697cbfdcda0d4b910d26a3f48a2dd/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/546ffb3b9036631dbb8bc4f2d8c3639f/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3fd5d79c2106974104a0362fd7e725a9/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13a800f25b57556abf12f6548482733b/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/829fa2f59d755e13c7c04fd5a1a579bc/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2ed32905ad23f346996a76987694ac26/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6662e8bb61523d17742c9dd11aa62eeb/output.h5\n\n\n\n\n\nText(0.5, 1.0, 'Direction selectivity indices')\n</code></pre>"},{"location":"examples/figure_02_simple_stimuli_responses/#d","title":"d","text":"<pre><code>from flyvis.analysis.flash_responses import (\n    flash_response_index,\n    fri_correlation_to_known,\n)\nfrom flyvis.analysis.moving_bar_responses import (\n    direction_selectivity_index,\n    dsi_correlation_to_known,\n    correlation_to_known_tuning_curves,\n    preferred_direction,\n    angular_distance_to_known,\n)\n</code></pre> <pre><code>with ensemble.ratio(best=0.2):\n    print(ensemble.names)\n    fris = flash_response_index(ensemble.flash_responses(), radius=6)\n    fri_corr = fri_correlation_to_known(fris)\n</code></pre> <pre><code>['flow/0000/000', 'flow/0000/001', 'flow/0000/002', 'flow/0000/003', 'flow/0000/004', 'flow/0000/005', 'flow/0000/007', 'flow/0000/009', 'flow/0000/006', 'flow/0000/013']\n../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d9d302eebb41d955bb76dcf9d6ce623a/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13f5d9136003d68fa860867f0ed89c64/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6ec38263ed72b3a302f55bd519d68643/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/048c1466b844b8be367b875fab782256/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ca0abb0d8af62ceb2b9ad8b3d991eb06/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ecc4b64ad753e775719a388d36fec0d5/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8420baf27ddfbc229fec85b8f120585/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cdc3f7c2ec749662cacbbdcfab68b20c/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/561c8275f604bf5964ebd8efa2ab0838/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/da9d8f4c595528a025e132eafd136811/output.h5\n</code></pre> <pre><code>with ensemble.ratio(best=0.2):\n    stims_and_resps_moving_edges = ensemble.moving_edge_responses()\n\n    # TODO: fix this, does not come out as expected\n    dsi_corr = dsi_correlation_to_known(\n        direction_selectivity_index(stims_and_resps_moving_edges)\n    )\n    tuning_corrs = correlation_to_known_tuning_curves(stims_and_resps_moving_edges)\n    t4_corrs = (\n        tuning_corrs.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1)\n        .median(\"neuron\")\n        .squeeze()\n    )\n    t5_corrs = (\n        tuning_corrs.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0)\n        .median(\"neuron\")\n        .squeeze()\n    )\n</code></pre> <pre><code>pds = preferred_direction(stims_and_resps_moving_edges)\npd_distances = angular_distance_to_known(pds)\n</code></pre> <pre><code>from flyvis.analysis.visualization.plots import violin_groups\n\nfig, ax, *_ = violin_groups(\n    np.stack(\n        [\n            fri_corr.squeeze(),\n            t4_corrs.values,\n            t5_corrs.values,\n            dsi_corr.values,\n        ],\n        axis=0,\n    )[:, None, :],\n    [\"FRI\", \"T4 tuning\", \"T5 tuning\", \"DSI\"],\n    ylabel=\"correlation\",\n    figsize=(1.8, 1.5),\n    ylim=(-1, 1),\n    colors=[\n        plt.get_cmap(\"Dark2\")(0.125),\n        plt.get_cmap(\"Dark2\")(0),\n        plt.get_cmap(\"Dark2\")(0.25),\n        plt.get_cmap(\"Dark2\")(0.375),\n    ],\n    color_by=\"experiments\",\n    scatter_edge_color=\"gray\",\n    scatter_radius=5,\n    violin_alpha=0.8,\n)\n</code></pre> <pre><code>fig, ax, *_ = violin_groups(\n    pd_distances.values.flatten()[None, None, :],\n    [\"PD distance\"],\n    ylabel=\"angular distance\",\n    figsize=(1.8, 1.5),\n    ylim=(-1, 1),\n    colors=[\n        plt.get_cmap(\"Dark2\")(0.5),\n    ],\n    color_by=\"experiments\",\n    scatter_edge_color=\"gray\",\n    scatter_radius=5,\n    violin_alpha=0.8,\n)\nax.set_ylim(\n    np.pi + 0.1,\n    -0.1,\n)\n</code></pre> <pre><code>(3.241592653589793, -0.1)\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/","title":"Figure 3","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nfrom flyvis import EnsembleView\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:44:37] ensemble:166 Loaded 50 networks.\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/#a","title":"a","text":"<pre><code>task_error = ensemble.task_error()\n</code></pre> <pre><code>embedding_and_clustering = ensemble.clustering(\"T4c\")\n</code></pre> <pre><code>[2024-12-08 19:44:39] clustering:835 Loaded T4c embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n</code></pre> <pre><code>embeddingplot = embedding_and_clustering.plot(\n    task_error=task_error.values, colors=task_error.colors\n)\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/#b","title":"b","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom flyvis.analysis.visualization import plt_utils\nfrom flyvis.analysis.moving_bar_responses import plot_angular_tuning\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>r = ensemble.moving_edge_responses()\nr['responses'] /= np.abs(r['responses']).max(dim=('frame', 'sample'))\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e236e47b9a57dc6d7b692906aca84495/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2a1519d1c3b8bf0d0776e8ff2618353d/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/787654b3c56e4015939e72adfa768448/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d4697cbfdcda0d4b910d26a3f48a2dd/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/546ffb3b9036631dbb8bc4f2d8c3639f/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3fd5d79c2106974104a0362fd7e725a9/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2ed32905ad23f346996a76987694ac26/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13a800f25b57556abf12f6548482733b/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c965f6ca1b4766760aff06bb066dcc4b/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/829fa2f59d755e13c7c04fd5a1a579bc/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/466b4cd31001f19423c507e2f3773c41/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d71a4899b11135e9e39f192e82f06e0/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ba1826533e24098d930150b0168b01cf/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6662e8bb61523d17742c9dd11aa62eeb/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cc480f1ea566ea82bfd19fcdf78cc27e/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8bd5ed52daae786768e228fb58cd3210/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9db907610103a5d3087f87ca0c71a079/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a12d63acadac2a74de55632d4cbabfe6/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2f9340bb144de1c040c6f2a9b58a8376/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e54f818c033f10227d1c003fc779b0c6/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab7e02a752bf6ee954804773846aa1d7/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f5d6259ad9e757467b9ad037056132b8/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/968df97051a8ce2c4cf1a05f4b19359b/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f89eb2dfe2edd056df6f20260a22445/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f08ba3ff4e47076a25f868011998fae/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5d8879e61a3f98f4f81ff3cc31f67f3c/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8ed3248070002d27bd42b83e49e1eb2/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0efca814750b326442bb2057c2a3141d/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/875bc3ea335ae2f70612495aa9a753c4/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/383a5857257bc8be754e28b37b2e4e79/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab8a858f91290a52306a0bb6f9545ed5/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1481eb1faa2b00dcc79036a1bf9f3b9b/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ac160912a60ac748329b349c16ba207f/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/660978a75b531be9c285d84986160ca6/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fa00c670234802d529e1981655483861/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1ae43649496d389d88bc56ca7ccaa383/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d50ab62a3869886437176a4ecf124d75/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/37238a6c41451b197bc11f3c37aef4f2/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9cfa9e971c84bc253c53fbfea3c7ebe6/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/95010c81b682cb979ff3b4f2a6aa6576/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fc266127c935e1835cf20757d3fe581c/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1e5972877c3873b7a1aac86a2f4bba75/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b6af0cb714a199fda52a11619981cb0d/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8292e9a29c31b23123bfa531f9b24d9b/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8b0eda1e0717ec0690d6766e688dace7/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c95394b9922b11a072e992c8d4e2feb5/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/439ba05c490dac452c5aa3fafed9fe9f/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c6894caf2471e76e06aa04f0073d8af5/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3c149c1b1c09ff2c958605cf994742a2/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ae15b6627cbbd1ce3802b4b74fc69e66/output.h5\n</code></pre> <pre><code>cluster_indices = ensemble.cluster_indices(\"T4c\")\n</code></pre> <pre><code>colors = ensemble.task_error().colors\n</code></pre> <pre><code>fig, axes = plt.subplots(\n    1, len(cluster_indices), subplot_kw={\"projection\": \"polar\"}, figsize=[2, 1]\n)\nfor cluster_id, indices in cluster_indices.items():\n    plot_angular_tuning(\n        r.sel(network_id=indices),\n        \"T4c\",\n        intensity=1,\n        colors=colors[indices],\n        zorder=ensemble.zorder()[indices],\n        groundtruth=True if cluster_id == 0 else False,\n        fig=fig,\n        ax=axes[cluster_id],\n    )\n    plt_utils.add_cluster_marker(\n        fig, axes[cluster_id], marker=plt_utils.get_marker(cluster_id)\n    )\n</code></pre>"},{"location":"examples/figure_03_naturalistic_stimuli_responses/#e","title":"e","text":"<pre><code>for cluster_id, indices in cluster_indices.items():\n    with ensemble.select_items(indices):\n        fig, ax = ensemble.flash_response_index(\n            cell_types=[\"Mi1\", \"Tm3\", \"Mi4\", \"Mi9\", \"CT1(M10)\"], figsize=[1, 1]\n        )\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d9d302eebb41d955bb76dcf9d6ce623a/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13f5d9136003d68fa860867f0ed89c64/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6ec38263ed72b3a302f55bd519d68643/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/048c1466b844b8be367b875fab782256/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/561c8275f604bf5964ebd8efa2ab0838/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8420baf27ddfbc229fec85b8f120585/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cdc3f7c2ec749662cacbbdcfab68b20c/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fbe28b2c3479ad70f2bf834804a2f2e4/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2be1d7c4107840002da135361590bfd2/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/da9d8f4c595528a025e132eafd136811/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d7ee5201fbdff9af915c98ec360d965d/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/14b3ea9edce7830400c706c4e5cfd837/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c38d25e378ccf53e2b1a82d07ae7bd36/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b024899a3bdb9e8e5b8d61e3a31a3a93/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ad1a12821e91231ee3904730e966f606/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f50d3ad3e852e9ea84ff525c72852342/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f7b363e64c33457a02edda9fddc79146/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/269b129996eac25aa41126c7d9c82d8e/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/97c93292d143ae87f6eef3481ab4e599/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/27117719316168e5da83fb6fd2139c91/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7f0e081bc0267c61950be3747b17018e/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dfcd7b1252d46090bf7800d71a0dae87/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ce586787c6012312271bdbae030a2421/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/89765426d20cb4128e6ae2f6e40935b1/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/48821b4559120bcbf7849cb9626a9ae8/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d40898560e671ce6e500f4630ae947df/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/10b8f7a7549287ca405c81dcf3041654/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/63675086df41498a9cede772e2978d2d/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab99f826d34e249fc1f2cea8fd747e87/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cadc6df1cbe896cc9b1c8ce54a026223/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c197fa3e757aabcad536066c410c129d/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ca0abb0d8af62ceb2b9ad8b3d991eb06/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ecc4b64ad753e775719a388d36fec0d5/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e42d0947783fb6e20b6fa64e52673736/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/35a1b2051f95863d9d2f6c714664dbc6/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1cd4c76720f4c5f4d8a509115b3421be/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1e029ce12c4b5abe92e2ab758b5a8b7c/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7e62723760ce9fae5aeba8f21520fe27/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/18355da7c1c7de01840b2535fdb35be5/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3b636f6044f1d054e1582b8c59e33d45/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dc3021b6d874259ce680448aa18aa720/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e249fd943a7b3a8f2c2512b1fed770a4/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6bf68b3fedc6377305eb2af5a7454ed8/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/979bf63975c42bf9ccb591d82329a063/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b586edc75eed4b51d57fe25bef5e0bbf/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/aefa5c9c78a5707480818c28b6385e0e/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d5692ff7246fc52a58c5ac0b3355f98c/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9e47796714a9a70117ea8f9c391e5d29/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a0f340a824a87d2dbc00cd667c820565/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5ab3bc543bff7cd96820551969819039/output.h5\n</code></pre>"},{"location":"examples/figure_04_mechanisms/","title":"Figure 4","text":""},{"location":"examples/figure_04_mechanisms/#a","title":"a","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom flyvis import EnsembleView\nfrom flyvis.analysis.visualization import plots\nfrom flyvis.analysis.moving_bar_responses import plot_angular_tuning\n</code></pre> <pre><code>ensemble = EnsembleView(\"flow/0000\")\n</code></pre> <pre><code>Loading ensemble:   0%|          | 0/50 [00:00&lt;?, ?it/s]\n\n\n[2024-12-08 19:45:35] ensemble:166 Loaded 50 networks.\n</code></pre> <pre><code>stims_and_resps = ensemble.moving_edge_responses()\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e236e47b9a57dc6d7b692906aca84495/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2a1519d1c3b8bf0d0776e8ff2618353d/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/787654b3c56e4015939e72adfa768448/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d4697cbfdcda0d4b910d26a3f48a2dd/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/546ffb3b9036631dbb8bc4f2d8c3639f/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3fd5d79c2106974104a0362fd7e725a9/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2ed32905ad23f346996a76987694ac26/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/13a800f25b57556abf12f6548482733b/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c965f6ca1b4766760aff06bb066dcc4b/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/829fa2f59d755e13c7c04fd5a1a579bc/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/466b4cd31001f19423c507e2f3773c41/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9d71a4899b11135e9e39f192e82f06e0/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ba1826533e24098d930150b0168b01cf/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6662e8bb61523d17742c9dd11aa62eeb/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cc480f1ea566ea82bfd19fcdf78cc27e/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8bd5ed52daae786768e228fb58cd3210/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9db907610103a5d3087f87ca0c71a079/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a12d63acadac2a74de55632d4cbabfe6/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2f9340bb144de1c040c6f2a9b58a8376/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e54f818c033f10227d1c003fc779b0c6/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab7e02a752bf6ee954804773846aa1d7/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f5d6259ad9e757467b9ad037056132b8/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/968df97051a8ce2c4cf1a05f4b19359b/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f89eb2dfe2edd056df6f20260a22445/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f08ba3ff4e47076a25f868011998fae/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5d8879e61a3f98f4f81ff3cc31f67f3c/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c8ed3248070002d27bd42b83e49e1eb2/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0efca814750b326442bb2057c2a3141d/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/875bc3ea335ae2f70612495aa9a753c4/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/383a5857257bc8be754e28b37b2e4e79/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ab8a858f91290a52306a0bb6f9545ed5/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1481eb1faa2b00dcc79036a1bf9f3b9b/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ac160912a60ac748329b349c16ba207f/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/660978a75b531be9c285d84986160ca6/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fa00c670234802d529e1981655483861/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1ae43649496d389d88bc56ca7ccaa383/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d50ab62a3869886437176a4ecf124d75/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/37238a6c41451b197bc11f3c37aef4f2/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9cfa9e971c84bc253c53fbfea3c7ebe6/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/95010c81b682cb979ff3b4f2a6aa6576/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fc266127c935e1835cf20757d3fe581c/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1e5972877c3873b7a1aac86a2f4bba75/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b6af0cb714a199fda52a11619981cb0d/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8292e9a29c31b23123bfa531f9b24d9b/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8b0eda1e0717ec0690d6766e688dace7/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c95394b9922b11a072e992c8d4e2feb5/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/439ba05c490dac452c5aa3fafed9fe9f/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c6894caf2471e76e06aa04f0073d8af5/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3c149c1b1c09ff2c958605cf994742a2/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ae15b6627cbbd1ce3802b4b74fc69e66/output.h5\n</code></pre> <pre><code>stims_and_resps['responses'] /= (norm := ensemble.responses_norm(rectified=True))\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/86b080e815ea9ec928a380df83961c32/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b59b4553d26177882434e7a38fcb1f36/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34edb9af3c92827b50340e6903d4f04c/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6d4092c24a8f5e5ea8a651c5d62a4cb1/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f60dd61be87e6f68b35174932ea805a3/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f680e802d1c70a1263dd82076bf33a36/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/04b4c82e6a1f299e0a95ce53517d4da6/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/56af0790abaf8e03689c4950c6dea1b6/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fe446c2e81fb5c187996c349bf81fc75/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/39a60bf26ca578c6f8a61ade8fc76594/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bd1d5ba31d334757b630351b33f3c7c8/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/78fbe4ae4959a666c6937dd423b9020b/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e4b5a3ca0a903bbb40acb438b1f79e9c/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34543762cd47e40c949ca970749e77e3/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2801e68f00e754372714a56be09caf9f/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/42f01aafe2d1710ab594ae807a362bd9/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b94b14adb8899e4eccc118660ea958c7/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9410fc09859bbade170b51880731dea9/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/544420c7e8246afcd778ee0b353106db/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8dacb927f956aa97478480571577228d/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/531b4dc891cbcd37ac5f86738293c135/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/03684bc5f57d843f1716241f9a0fae72/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b990cd15cf042aa0355aa481aa7d6b41/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/91cfee0552809c386b0a3e8eb754e6d6/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/301b1b68961db10e21d4f7bcf56c9906/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fb26a6ba42c0925fa1021919378d8e27/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/99a1c6ed825f339bda0b78dfbe6d96d3/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9b18d2b42700af7481eccf2d6fa67589/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/528ab0ad496af746d023a6ba873ee0dc/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/df9a3ba79ce02c718ae39f1b691c2074/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/680207b961d14356a08d7e7e4749e59f/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/407f839a987942f6e2856df581147e43/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dfd4875c806ccd1307ff6d7e804e1edf/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/22cd80bc7c98d11c5065ad66d38157b6/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b6e433dcae4b37f7e59b29319839fc50/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/31e5ac10422aa1e1ebabb64c7b173e3c/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4e94417495f0a61657c87c57fc87a1f0/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7f6e7c8a72d475d81acf839a74db4b38/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/03f4135c61293835075130d011bd5d18/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/448f5e3d0b9ad7043ab9d4c22f91dd34/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3e6c91f652149ed9c014bff467b93d6a/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/69572eb846355916126a1c8cfef5274f/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f61388fda823e11dcc52a930c1ef3e93/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dea992edd01893cbdf4d5b27de0d49ad/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e81fe1e9587b7a4d7a1b5a4ebfd3c6c2/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5a1a4580bf311568a60974671660c5c8/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/64f5f362d0a819dcf5666b901342c2c0/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/185b9cebe11b9efe2a625627cb848cba/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1f72e3f57bfa4c1ddb6a6eee76cd02d4/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5afe04583aca5c1f5a960427a81ae439/output.h5\n</code></pre> <pre><code># retrieve cluster indices for averaging across best clusters\ncell_types = [\n    \"L1\",\n    \"L2\",\n    \"L3\",\n    \"L4\",\n    \"L5\",\n    \"Mi1\",\n    \"Tm3\",\n    \"Mi4\",\n    \"Mi9\",\n    \"CT1(M10)\",\n    \"T4a\",\n    \"T4b\",\n    \"T4c\",\n    \"T4d\",\n    \"T5a\",\n    \"T5b\",\n    \"T5c\",\n    \"T5d\",\n    \"Tm1\",\n    \"Tm2\",\n    \"Tm4\",\n    \"Tm9\",\n    \"CT1(Lo1)\",\n    \"TmY3\",\n]\ncluster_indices = {}\nfor cell_type in cell_types:\n    if cell_type not in cluster_indices:\n        cluster_indices[cell_type] = ensemble.cluster_indices(cell_type)\n</code></pre> <pre><code>[2024-12-08 19:46:03] clustering:835 Loaded L1 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:05] clustering:835 Loaded L2 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:05] clustering:835 Loaded L3 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:05] clustering:835 Loaded L4 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:06] clustering:835 Loaded L5 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:06] clustering:835 Loaded Mi1 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:06] clustering:835 Loaded Tm3 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:08] clustering:835 Loaded Mi4 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:08] clustering:835 Loaded Mi9 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:08] clustering:835 Loaded CT1(M10) embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:09] clustering:835 Loaded T4a embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:09] clustering:835 Loaded T4b embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:09] clustering:835 Loaded T4c embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:11] clustering:835 Loaded T4d embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:11] clustering:835 Loaded T5a embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:11] clustering:835 Loaded T5b embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:12] clustering:835 Loaded T5c embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:12] clustering:835 Loaded T5d embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:12] clustering:835 Loaded Tm1 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:14] clustering:835 Loaded Tm2 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:14] clustering:835 Loaded Tm4 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:14] clustering:835 Loaded Tm9 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:15] clustering:835 Loaded CT1(Lo1) embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n[2024-12-08 19:46:15] clustering:835 Loaded TmY3 embedding and clustering from ../flyvis/data/results/flow/0000/umap_and_clustering\n</code></pre> <pre><code># plot the tuning across the best clusters\nfig, axes, _ = plots.plt_utils.get_axis_grid(\n    range(4),\n    projection=\"polar\",\n    aspect_ratio=4,\n    figsize=[2.95, 0.83],\n    wspace=0.25,\n)\nfor i, cell_type in enumerate([\"T4a\", \"T4b\", \"T4c\", \"T4d\"]):\n    plot_angular_tuning(\n        stims_and_resps.sel(network_id=cluster_indices[cell_type][0]),\n        cell_type=cell_type,\n        intensity=1,\n        fig=fig,\n        ax=axes[i],\n        groundtruth=True,\n        groundtruth_linewidth=1.0,\n        average_models=True,\n        model_dim=2,\n        zorder=100,\n    )\n    axes[i].set_xlabel(cell_type)\n</code></pre> <pre><code>fig, axes, _ = plots.plt_utils.get_axis_grid(\n    range(4),\n    projection=\"polar\",\n    aspect_ratio=4,\n    figsize=[2.95, 0.83],\n    wspace=0.25,\n)\nfor i, cell_type in enumerate([\"T5a\", \"T5b\", \"T5c\", \"T5d\"]):\n    plot_angular_tuning(\n        stims_and_resps.sel(network_id=cluster_indices[cell_type][0]),\n        cell_type=cell_type,\n        intensity=0,\n        fig=fig,\n        ax=axes[i],\n        groundtruth=True,\n        groundtruth_linewidth=1.0,\n        average_models=True,\n        model_dim=2,\n        zorder=100,\n    )\n    axes[i].set_xlabel(cell_type)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#b","title":"b","text":"<pre><code>from datamate import namespacify\n\nfrom flyvis.analysis.moving_edge_currents import CellTypeArray, MovingEdgeCurrentView\nfrom flyvis.datasets import MovingEdge\n</code></pre> <pre><code>target_types = [\"T4c\"]\n</code></pre> <pre><code>experiment_data = ensemble.moving_edge_currents()\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/76849b40141278cefcc862b3f6659ba5/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/8e6bd32c454c648680655e7f2871e627/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/d0ac7bb2ab7b7119a0bb1269cd683d08/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/653bdd4721187ae84e758dae9d6610f0/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/b0637f0887f5de9f484219d7554f5ffb/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/47d685de8eacb2aa9fbed5600963f93a/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/c3f961ff00a85da65c01b0782e6f426d/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/b2169b06bd2df3df137d4d8775135cb4/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/b383c0f13ffbcacb474a5570bef0b956/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/152983be8c045568382c7deae109d598/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/54b506f186ed4f283ce82065821190f6/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/9ee81ee2e0e5bf36be84d620906c04be/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/97d028f568a2280227679c7316e0d3dd/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/b119f33525d997bfe687ab27ff458d27/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/734a0ff8c13886f44ce7e5ba51c03fed/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/e652f08ceafef4705667feb6f9aacb02/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/5e6616fce254c1924baa42cc29d597a9/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/ebd7a1f764ab22a5b6f1c8b1893df890/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/f4514ad829f92ccb9c6fd79c080256bc/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/0b6767f45f458dc422881276cd939c80/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/eb288683bd310f9666cb370e12306e6b/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/0c6343091868c0781ce78c28e2b75318/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/14394b2b30865eac660ea23c50304853/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/bf27b7734da9d4024ae772b2dfa1b1d5/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/ae6f04eb0742ef804d762fe87b7c8ec8/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/f0d8af5b4c957e4739986fe6cb4ffe2d/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/c17a4ca007f66c5d941da038a71e74b5/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/6034c0727c9c3bb92b1ed4119cabc07a/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/164147b65952214516096a57220c2e59/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/6fbcc443e3b7bd76e97a7a42e17ebdcb/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/740e01f86bd0f4c6612c7331b9a6fdbc/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/2e747b63bc2246432bfca692e8934943/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/bcee34a67e5111c44b40938689bd75ad/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/2a8c239a00db5484dbaa08406bf7daf3/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/bc644cdd2ef938750b9a3687f3a33eb4/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/e7226daaee903f5d5d34502e4f2bf5ef/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/bd54ca75f0dbd7a9e5264bc1f1d2859c/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/f028e38a1c2ac7a7840abe17e81d2b74/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/dd1bdf5eee665318e601a224ff0f9966/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/241b95cefe7de73bc89998dba816a9b7/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/0e5bd81a79f05d2d93ff3b236da12f5b/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/9a69669dcf658e32a912f1577d5319e4/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/c8b8d0d59a4054a642e9bb36b5c503d9/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/97c319c726dbcfdc9d774b6ba402c3ac/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/0584ab2e7f5fd121ded1e65465d00db6/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/0205bca14cc79394afc2b5b478ec3f76/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/100310a04c0684906b71a4ff0cdbb18f/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/821e82fbbe69aa165a1343502f936864/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/dc21fa59526ea5e531f7ec1b81013164/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses_currents/compute_currents/8ab95b4bb22ec1073678533467881a54/output.h5\n</code></pre> <pre><code>dataset = MovingEdge(**experiment_data[0].config)\n</code></pre> <pre><code>current_views = {}\n</code></pre> <pre><code>norm = CellTypeArray(ensemble.responses_norm(rectified=False), ensemble[0].connectome)\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/86b080e815ea9ec928a380df83961c32/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b59b4553d26177882434e7a38fcb1f36/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34edb9af3c92827b50340e6903d4f04c/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6d4092c24a8f5e5ea8a651c5d62a4cb1/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f60dd61be87e6f68b35174932ea805a3/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f680e802d1c70a1263dd82076bf33a36/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/04b4c82e6a1f299e0a95ce53517d4da6/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/56af0790abaf8e03689c4950c6dea1b6/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fe446c2e81fb5c187996c349bf81fc75/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/39a60bf26ca578c6f8a61ade8fc76594/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bd1d5ba31d334757b630351b33f3c7c8/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/78fbe4ae4959a666c6937dd423b9020b/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e4b5a3ca0a903bbb40acb438b1f79e9c/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/34543762cd47e40c949ca970749e77e3/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2801e68f00e754372714a56be09caf9f/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/42f01aafe2d1710ab594ae807a362bd9/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b94b14adb8899e4eccc118660ea958c7/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9410fc09859bbade170b51880731dea9/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/544420c7e8246afcd778ee0b353106db/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8dacb927f956aa97478480571577228d/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/531b4dc891cbcd37ac5f86738293c135/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/03684bc5f57d843f1716241f9a0fae72/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b990cd15cf042aa0355aa481aa7d6b41/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/91cfee0552809c386b0a3e8eb754e6d6/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/301b1b68961db10e21d4f7bcf56c9906/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fb26a6ba42c0925fa1021919378d8e27/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/99a1c6ed825f339bda0b78dfbe6d96d3/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9b18d2b42700af7481eccf2d6fa67589/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/528ab0ad496af746d023a6ba873ee0dc/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/df9a3ba79ce02c718ae39f1b691c2074/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/680207b961d14356a08d7e7e4749e59f/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/407f839a987942f6e2856df581147e43/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dfd4875c806ccd1307ff6d7e804e1edf/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/22cd80bc7c98d11c5065ad66d38157b6/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b6e433dcae4b37f7e59b29319839fc50/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/31e5ac10422aa1e1ebabb64c7b173e3c/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/4e94417495f0a61657c87c57fc87a1f0/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7f6e7c8a72d475d81acf839a74db4b38/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/03f4135c61293835075130d011bd5d18/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/448f5e3d0b9ad7043ab9d4c22f91dd34/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3e6c91f652149ed9c014bff467b93d6a/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/69572eb846355916126a1c8cfef5274f/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f61388fda823e11dcc52a930c1ef3e93/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dea992edd01893cbdf4d5b27de0d49ad/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e81fe1e9587b7a4d7a1b5a4ebfd3c6c2/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5a1a4580bf311568a60974671660c5c8/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/64f5f362d0a819dcf5666b901342c2c0/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/185b9cebe11b9efe2a625627cb848cba/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1f72e3f57bfa4c1ddb6a6eee76cd02d4/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5afe04583aca5c1f5a960427a81ae439/output.h5\n</code></pre> <pre><code>for target_type in target_types:\n    if target_type not in current_views:\n        current_views[target_type] = MovingEdgeCurrentView(\n            ensemble, target_type, experiment_data, dataset.arg_df\n        )\n    view = current_views[target_type]\n</code></pre> <pre><code>for target_type in target_types:\n    current_views[target_type] = view.divide_by_given_norm(norm)\n</code></pre> <pre><code>cell_type = \"T4c\"\ncurrent_view = current_views[cell_type]\n</code></pre> <pre><code>fig, ax = current_view.model_selection(cluster_indices[cell_type][0]).plot_response(\n    1, 90, t_end=1.0\n)\nxlim_responses = ax.get_xlim()\nax.set_ylabel(\"voltage (a.u.)\", fontsize=5)\nax.set_xlabel(\"time (s)\", fontsize=5)\n</code></pre> <pre><code>Text(0.5, 0, 'time (s)')\n</code></pre> <pre><code>fig, ax, legend_fig, legend_ax = current_view.model_selection(\n    cluster_indices[cell_type][0]\n).plot_temporal_contributions(\n    1,\n    90,\n    t_start=0,\n    t_end=1,\n    model_average=True,\n    legend=False,\n    sum_exc_inh=False,\n    only_sum=False,\n    max_figure_height_cm=3.3941,\n    panel_height_cm=3.3941,\n    max_figure_width_cm=4.0513,\n    panel_width_cm=4.0513,\n    hide_source_types=None,\n)\nylim = ax.get_ylim()\nax.set_ylabel(\"current (a.u.)\", fontsize=5)\n</code></pre> <pre><code>Text(0, 0.5, 'current (a.u.)')\n</code></pre> <pre><code>fig, ax, _ = current_view.model_selection(\n    cluster_indices[cell_type][0]\n).plot_spatial_contribution_grid(\n    t_start=0,\n    t_end=1,\n)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#d","title":"d","text":"<pre><code>from flyvis.utils.color_utils import flash_response_color_labels\nfrom flyvis.analysis.visualization.figsize_utils import fit_panel_size\nfrom scipy.signal import find_peaks\nfrom flyvis.utils.hex_utils import hex_rows\nfrom flyvis.analysis.visualization import plt_utils, plots\nfrom flyvis.analysis.visualization.plots import plot_strf\nfrom flyvis.datasets.dots import SpatialImpulses\n</code></pre> <pre><code>norm = ensemble.responses_norm()\n</code></pre> <pre><code>flashes_and_resps = ensemble.spatial_impulses_responses()\nflashes_and_resps['responses'] = flashes_and_resps['responses'] / norm\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2d2d4e2d2cfaad8878a87109deb7d5c2/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/71754eaade11ba8d16c1a201412bf7ae/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8c48bea08616768696a48db13fb87308/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bf3c22e5e8f4563e81884d9d57286bbf/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c6ac24db6d259378105f81aa42a05c6b/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/722acb1ffffa7bed2e8a80654803a9f7/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/44a470e24c54202883ca749b36ef6b30/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/912b1ac9e22f01edee4179611e6dc932/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dc8b5e243a98265a13f45c497e501c52/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e490c801c7f4e9a85601df024bb5a7c6/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e12a7f144283ff6edaba36c1f88d9c6e/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ef2e2a6928189788dde0adf9b2f24112/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/55b40083216ac8134e33cd75354c3b43/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f2f52e89a2689937f785a140a4635f47/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d44cab94108cc667796c0bb1ab1870ca/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3610dd38e046b09bba4daf912744a0f2/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/22f7be37b6cda8d0e726ddf07c8225fe/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5c7d138de8b68f06bf4af7ce052ea5bc/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/80c6a8f36cf25a8aff043beedf1290a7/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d00a6dd5655034ef2d6e326da100ede3/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/aa270cad8acf6b5c41de2a24ee4562b6/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/53567a59fc60b1de3f23d422a487f4e2/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/244a4daa4918f2ad0271a8c77615c85e/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fb2a3c2363c43914573551f60787b460/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bdbbd8944401ca56490e37bf1d5d9d9a/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bdcabfee16d574bf0df6eee2942d7acd/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e17a49d22492bca12c1c92b60f9e81ba/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5449e41f76b8a9e4bcf9d187958b799e/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/678d3f1b9826740d78c48d5f6808b0ac/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/fa48098f04020e65caf96aebc1445744/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9687466e3eb86b1d18877a9f72884b09/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0a4a09107cf6faef2476ce19fe1da6b6/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/27f854e692d05cfaa33ec08ea19c0a79/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/b60b5af14bbc520eda085463716a7f3c/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/50a4e18c2906b2e389269c48f5e84212/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7e6c1f71b085def5dd3092423dfe5207/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/15702246b6c9cfff146d765ea8741c29/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c811d18962b6c9c8ffabcb32e1095e32/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cc639c40f3287375d49dbb54c72defef/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8cd851cab347136d16542c99cbf22f73/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/dc6fe25bedd97e72ee7e111cc49cc997/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e6002b431d61cfed6a405262abe2e436/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8106c7ca781903f5359ef477e6df590b/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d80d78810e09a8ad1e1dd3a7de15babc/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1be7afa3562b27a6a54d968b8679d926/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/2ba3ff7d598aa4eeb8c3373b7a83e5aa/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5dd11c0c7c16316ea1c441e11d588339/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c9c00c3541b2d83a6126a8c46c7ca513/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9efc4b3f20b870f9e9590b715b78542f/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/185f5eef93d622b872c61d4cfcfcb856/output.h5\n</code></pre> <pre><code>dataset = SpatialImpulses(**flashes_and_resps.attrs['config'])\n</code></pre> <pre><code>srf_cell_types = [\n    \"Mi1\",\n    \"Tm3\",\n    \"Mi4\",\n    \"Mi9\",\n    \"CT1(M10)\",\n    \"Tm1\",\n    \"Tm2\",\n    \"Tm4\",\n    \"Tm9\",\n    \"CT1(Lo1)\",\n]\n</code></pre> <pre><code>def strf_to_srf(strf):\n    # subtract spatial mean of baseline response\n    strf = (strf - strf.isel(frame=0).mean(\"sample\").item()).squeeze().values.T\n\n    # find the absmax of the response to central impulse, corresponding to\n    # x.shape[0]//2\n    absmax_index = find_peaks(np.abs(strf[:, strf.shape[1] // 2]))[0]\n    absmax_index = absmax_index[0] if absmax_index.any() else 0\n    return strf[absmax_index].squeeze()\n\n\nmean_srfs = {}\nfor cell_type in srf_cell_types:\n    strfs = (\n        flashes_and_resps['responses']\n        .sel(network_id=cluster_indices[cell_type][0])\n        .custom.where(time=\"&gt;=0,&lt;0.25\", t_impulse=0.02, cell_type=cell_type, intensity=1)\n        .mean(\"network_id\")\n    )\n    mean_srfs[cell_type] = strf_to_srf(strfs)\n</code></pre> <pre><code>x, y = hex_rows(2, 5)\nfig, axes, pos = plt_utils.ax_scatter(\n    x, y, figsize=[3.5, 2], hpad=0, wpad=0.1, wspace=-0.5, hspace=-0.4\n)\n\naxes = np.array(axes).reshape(2, 5)\n\nfor i, row in enumerate(np.array(srf_cell_types).reshape(2, 5)):\n    for j, cell_type in enumerate(row):\n        crange = np.max(np.abs(mean_srfs[cell_type]))\n        fig, ax, _ = plots.hex_scatter(\n            dataset.dots.u,\n            dataset.dots.v,\n            mean_srfs[cell_type],\n            cmap=plt.cm.coolwarm,\n            vmin=-crange,\n            vmax=crange,\n            figsize=[3, 3],\n            cbar=False,\n            fig=fig,\n            ax=axes[1 - i, j],\n        )\n        ax.set_xlabel(cell_type, fontsize=6, labelpad=-10)\n\nfor ax in axes.flatten():\n    flash_response_color_labels(ax)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#e","title":"e","text":"<pre><code>from flyvis.datasets.dots import CentralImpulses\n</code></pre> <pre><code>central_flash_and_resps = ensemble.central_impulses_responses()\ncentral_flash_and_resps['responses'] = central_flash_and_resps['responses'] / norm\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_responses/be8df01501679115e480dfbdfec07289/output.h5\n../flyvis/data/results/flow/0000/001/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e5692cdb8bb0e60dc178d499a105e5f7/output.h5\n../flyvis/data/results/flow/0000/002/__cache__/flyvis/analysis/stimulus_responses/compute_responses/630efbbd356392e65b71f292be40c799/output.h5\n../flyvis/data/results/flow/0000/003/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3e66af7fdd42a887310d4dd43e4a7166/output.h5\n../flyvis/data/results/flow/0000/004/__cache__/flyvis/analysis/stimulus_responses/compute_responses/74dab578f4bbeb2461537db9a743f1d8/output.h5\n../flyvis/data/results/flow/0000/005/__cache__/flyvis/analysis/stimulus_responses/compute_responses/293be039c33f85e7c93d3133e6e463ad/output.h5\n../flyvis/data/results/flow/0000/006/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3feb3df86d00bfd0a6b9e26fa3679e0e/output.h5\n../flyvis/data/results/flow/0000/007/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f24e5488b5e83c0c5e147931fed907e/output.h5\n../flyvis/data/results/flow/0000/008/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a29e9ded634ae08f68d29d0a7ddf4c52/output.h5\n../flyvis/data/results/flow/0000/009/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9f491a319a3ef6a55c5536fd8da74206/output.h5\n../flyvis/data/results/flow/0000/010/__cache__/flyvis/analysis/stimulus_responses/compute_responses/7383c36f6da91977b75ed90a41f3e2bb/output.h5\n../flyvis/data/results/flow/0000/011/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e218512cfab71f7af0bad8cbb73ac189/output.h5\n../flyvis/data/results/flow/0000/012/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f0ef12d799e845ee71ebe34885be6da0/output.h5\n../flyvis/data/results/flow/0000/013/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a70907ce899291f704b7046bf175852b/output.h5\n../flyvis/data/results/flow/0000/014/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1113fe703aa113587df4a140fa8d6297/output.h5\n../flyvis/data/results/flow/0000/015/__cache__/flyvis/analysis/stimulus_responses/compute_responses/cdf6827dc0c9dd2b5b8fb4845bb53532/output.h5\n../flyvis/data/results/flow/0000/016/__cache__/flyvis/analysis/stimulus_responses/compute_responses/c34e3dfbb26d66a089d2fb0390c27245/output.h5\n../flyvis/data/results/flow/0000/017/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0012ce35203234df10b0fc0bac1f9b14/output.h5\n../flyvis/data/results/flow/0000/018/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8cf7a8ab5ce9cfa7ead57b41f0390e74/output.h5\n../flyvis/data/results/flow/0000/019/__cache__/flyvis/analysis/stimulus_responses/compute_responses/643f9b1eae1799a677c9becd2406ce66/output.h5\n../flyvis/data/results/flow/0000/020/__cache__/flyvis/analysis/stimulus_responses/compute_responses/19021d6d49cc79906fefc16cfe3692e5/output.h5\n../flyvis/data/results/flow/0000/021/__cache__/flyvis/analysis/stimulus_responses/compute_responses/391546df244a2c4f57e6430f0afdd3ef/output.h5\n../flyvis/data/results/flow/0000/022/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1d545a44fc2348a60b888268250a3081/output.h5\n../flyvis/data/results/flow/0000/023/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ae96c9222859046f5e6411f3cd24d169/output.h5\n../flyvis/data/results/flow/0000/024/__cache__/flyvis/analysis/stimulus_responses/compute_responses/69b02d4367f505af3b918f18872af8b2/output.h5\n../flyvis/data/results/flow/0000/025/__cache__/flyvis/analysis/stimulus_responses/compute_responses/ff0bcf8ff773c85721af33fbe968c598/output.h5\n../flyvis/data/results/flow/0000/026/__cache__/flyvis/analysis/stimulus_responses/compute_responses/8bf7c0e1301cb715fcfe61fd640f5fc3/output.h5\n../flyvis/data/results/flow/0000/027/__cache__/flyvis/analysis/stimulus_responses/compute_responses/080a0a7eba9ce68206e7e9b9268a69ad/output.h5\n../flyvis/data/results/flow/0000/028/__cache__/flyvis/analysis/stimulus_responses/compute_responses/40f7afebfe91179c1fe80647c6eba3a5/output.h5\n../flyvis/data/results/flow/0000/029/__cache__/flyvis/analysis/stimulus_responses/compute_responses/f9c9e4fe01ec1c7804896e4ec93e79ba/output.h5\n../flyvis/data/results/flow/0000/030/__cache__/flyvis/analysis/stimulus_responses/compute_responses/3a573de66bcf491d4ff94350d7ace94f/output.h5\n../flyvis/data/results/flow/0000/031/__cache__/flyvis/analysis/stimulus_responses/compute_responses/25bc69338a22ced0bb953f275391d0aa/output.h5\n../flyvis/data/results/flow/0000/032/__cache__/flyvis/analysis/stimulus_responses/compute_responses/bf1ba8d88b36f311ab43706a7c73df3e/output.h5\n../flyvis/data/results/flow/0000/033/__cache__/flyvis/analysis/stimulus_responses/compute_responses/46c831379915af87fe827f6946218d25/output.h5\n../flyvis/data/results/flow/0000/034/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1012fde3b3d65d22526fdc0d02175ff1/output.h5\n../flyvis/data/results/flow/0000/035/__cache__/flyvis/analysis/stimulus_responses/compute_responses/d6414e75ec0279734d3d178da2abbdbc/output.h5\n../flyvis/data/results/flow/0000/036/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9839ea6d3872ab96c116e448ebb64b86/output.h5\n../flyvis/data/results/flow/0000/037/__cache__/flyvis/analysis/stimulus_responses/compute_responses/5ac36250e56f0381790cc561eb7d8f18/output.h5\n../flyvis/data/results/flow/0000/038/__cache__/flyvis/analysis/stimulus_responses/compute_responses/93ec3211dbe2c399722f4269abdfe545/output.h5\n../flyvis/data/results/flow/0000/039/__cache__/flyvis/analysis/stimulus_responses/compute_responses/a77668e327f31c7f2689587073cd04a6/output.h5\n../flyvis/data/results/flow/0000/040/__cache__/flyvis/analysis/stimulus_responses/compute_responses/0b4ab971adef7523cb6037c053bf0b96/output.h5\n../flyvis/data/results/flow/0000/041/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6eccec2e10eb196afc15e8b39cd6cfaa/output.h5\n../flyvis/data/results/flow/0000/042/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e1cbe151037d72998e2f12cab7d6f115/output.h5\n../flyvis/data/results/flow/0000/043/__cache__/flyvis/analysis/stimulus_responses/compute_responses/6a59e8fb6f787f68564e821926511139/output.h5\n../flyvis/data/results/flow/0000/044/__cache__/flyvis/analysis/stimulus_responses/compute_responses/9a4b551e66ff7c2785be3c9f3aa13e76/output.h5\n../flyvis/data/results/flow/0000/045/__cache__/flyvis/analysis/stimulus_responses/compute_responses/db98713ffaf2b0d005838233b0db8e56/output.h5\n../flyvis/data/results/flow/0000/046/__cache__/flyvis/analysis/stimulus_responses/compute_responses/1d34f8bd433a2af139726eb8516a6712/output.h5\n../flyvis/data/results/flow/0000/047/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e5d7e0c2d990c0601a73f1de14bcacd1/output.h5\n../flyvis/data/results/flow/0000/048/__cache__/flyvis/analysis/stimulus_responses/compute_responses/e740d2c4ded9c0c2cf45da34bf6f01cd/output.h5\n../flyvis/data/results/flow/0000/049/__cache__/flyvis/analysis/stimulus_responses/compute_responses/452bf05d27f5405b580d766b837692c1/output.h5\n</code></pre> <pre><code>dataset = CentralImpulses(**central_flash_and_resps.attrs['config'])\n</code></pre> <pre><code>trf_cell_types = np.array([\n    \"Mi1\",\n    \"Tm3\",\n    \"Mi4\",\n    \"Mi9\",\n    \"CT1(M10)\",\n    \"Tm1\",\n    \"Tm2\",\n    \"Tm4\",\n    \"Tm9\",\n    \"CT1(Lo1)\",\n    \"L1\",\n    \"L2\",\n    \"L3\",\n    \"L4\",\n    \"L5\",\n]).reshape(5, 3, order=\"F\")\n</code></pre> <pre><code>durations = [0.02, 0.05, 0.1, 0.2, 0.3]\non_cmap = plt_utils.truncate_colormap(plt.cm.Blues_r, minval=0.0, maxval=0.4).resampled(\n    len(durations)\n)\noff_cmap = plt_utils.truncate_colormap(plt.cm.Blues_r, minval=0.5, maxval=0.9).resampled(\n    len(durations)\n)\ncmaps = {\n    1.0: [on_cmap(i) for i in range(on_cmap.N)][::-1],\n    0: [off_cmap(i) for i in range(off_cmap.N)][::-1],\n}\n</code></pre> <pre><code>fig, axes = fit_panel_size(\n    5,\n    3,\n    max_figure_height_cm=5.35,\n    max_figure_width_cm=8,\n    panel_width_cm=8 / 3,\n    panel_height_cm=5.35 / 10,\n).axis_grid(wspace=0.6, hspace=0.0, as_matrix=True)\nfor i, row in enumerate(trf_cell_types):\n    for j, cell_type in enumerate(row):\n        ax = axes[i, j]\n        for q, duration in enumerate(durations[::-1]):\n            for intensity in [0, 1]:\n                color = cmaps[intensity][\n                    q\n                ]  # plt.cm.Blues(256) if intensity == 1 else plt.cm.Blues(128)\n                #                 linestyle = \"solid\" if intensity == 1 else \"dashed\"\n                zorder = 1 if intensity == 1 else 0\n\n                r = (\n                    central_flash_and_resps['responses']\n                    .sel(network_id=cluster_indices[cell_type][0])\n                    .custom.where(\n                        time=\"&gt;=0,&lt;1.0\",\n                        cell_type=cell_type,\n                        intensity=intensity,\n                        t_impulse=duration,\n                    )\n                    .mean(\"network_id\")\n                )\n                # subtract baseline after model averaging to plot it centered\n                mean = (r - r.isel(frame=0).values).squeeze()\n                ax.plot(r.time, mean, linewidth=0.5, color=color, zorder=zorder)\n        ax.hlines(\n            mean[0],\n            r.time.min(),\n            r.time.max(),\n            linewidth=0.5,\n            color=\"0.5\",\n            zorder=-1,\n        )\n\n        plt_utils.rm_spines(ax)\n        ax.yaxis.set_label_position(\"right\")\n        ax.set_ylabel(\n            cell_type,\n            fontsize=6,\n            rotation=0,\n            ha=\"left\",\n            va=\"center\",\n            labelpad=0.1,\n        )\n        #         ylim = np.array)\n        ylim = np.array(ax.get_ylim())\n        ylim = (-max(abs(ylim)), max(abs(ylim)))\n        ax.set_ylim(ylim)\n\nfor ax in axes.flatten():\n    flash_response_color_labels(ax)\n</code></pre> <p>stimulus</p> <pre><code>fig, axes = fit_panel_size(\n    5,\n    3,\n    max_figure_height_cm=5.35,\n    max_figure_width_cm=8,\n    panel_width_cm=8 / 3,\n    panel_height_cm=5.35 / 10,\n).axis_grid(wspace=0.6, hspace=0.0, as_matrix=True, unmask_n=1)\nax = axes[0, 0]\nfor j, duration in enumerate(durations[::-1]):\n    for intensity in [0, 1]:\n        color = cmaps[intensity][j]\n        #                 linestyle = \"solid\" if intensity == 1 else \"dashed\"\n        zorder = 1 if intensity == 1 else 0\n        stim = (\n            central_flash_and_resps['stimulus']\n            .custom.where(\n                time=f\"&gt;=-{2 * central_flash_and_resps.attrs['config']['dt']},&lt;1.0\",\n                intensity=intensity,\n                t_impulse=duration,\n                u_in=0,\n                v_in=0,\n            )\n            .squeeze()\n        )\n        ax.plot(stim, linewidth=0.5, color=color, zorder=zorder)\nax.hlines(\n    0,\n    stim.time.min(),\n    stim.time.max(),\n    linewidth=0.5,\n    color=\"0.5\",\n    zorder=-1,\n)\n\nplt_utils.rm_spines(ax)\n\nylim = np.array(ax.get_ylim())\nylim = (-max(abs(ylim)), max(abs(ylim)))\nax.set_ylim(ylim)\n</code></pre> <pre><code>(-1.05, 1.05)\n</code></pre> <p></p>"},{"location":"examples/figure_04_mechanisms/#extended-data-fig-9","title":"Extended Data Fig. 9","text":""},{"location":"examples/figure_04_mechanisms/#t4c","title":"T4c","text":"<pre><code>strfs = (\n    flashes_and_resps['responses']\n    .sel(network_id=cluster_indices[\"T4c\"][0])\n    .custom.where(t_impulse=0.02, cell_type=\"T4c\", time=\"&gt;=0,&lt;0.25\", intensity=1)\n    .mean(\"network_id\")\n)\n</code></pre> <pre><code>strfs = (strfs - strfs.isel(frame=0).mean().values).squeeze()\n</code></pre> <pre><code>fig, axes = plot_strf(strfs.time, strfs.values.T)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#t5c","title":"T5c","text":"<pre><code>strfs = (\n    flashes_and_resps['responses']\n    .sel(network_id=cluster_indices[\"T5c\"][0])\n    .custom.where(t_impulse=0.02, cell_type=\"T5c\", time=\"&gt;=0,&lt;0.25\", intensity=1)\n    .mean(\"network_id\")\n)\n</code></pre> <pre><code>strfs = (strfs - strfs.isel(frame=0).mean().values).squeeze()\n</code></pre> <pre><code>fig, axes = plot_strf(strfs.time, strfs.values.T)\n</code></pre>"},{"location":"examples/figure_04_mechanisms/#f","title":"f","text":"<pre><code>from flyvis.analysis.optimal_stimuli import plot_stim_response\n</code></pre> <pre><code>network_view = ensemble[0]\n</code></pre> <pre><code>optstims = network_view.optimal_stimulus_responses(\"T4c\")\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_optimal_stimulus_responses/ea86aff181a9f399fbee084d9288d046/output.h5\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(\n    optstims.regularized_stimulus,\n    optstims.response,\n    1 / 100,\n    *network_view.get_uv(\"T4c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <pre><code>optstims = network_view.optimal_stimulus_responses(\"T5c\")\n</code></pre> <pre><code>../flyvis/data/results/flow/0000/000/__cache__/flyvis/analysis/stimulus_responses/compute_optimal_stimulus_responses/a38e42e1f7bbf752220e73af955d1c5a/output.h5\n</code></pre> <pre><code>stim_resp_plot = plot_stim_response(\n    optstims.regularized_stimulus,\n    optstims.response,\n    1 / 100,\n    *network_view.get_uv(\"T5c\"),\n    figsize=[5, 1.6],\n    ylabel=None,\n    label_peak_response=False,\n)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"reference/animations/","title":"Animations","text":""},{"location":"reference/animations/#flyvisanalysisanimationsimshow","title":"flyvis.analysis.animations.imshow","text":""},{"location":"reference/animations/#classes","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.imshow.Imshow","title":"flyvis.analysis.animations.imshow.Imshow","text":"<p>               Bases: <code>Animation</code></p> <p>Animates an array of images using imshow.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>ndarray</code> <p>Array of images to animate (n_samples, n_frames, height, width).</p> required <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure instance or None.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axis instance or None.</p> <code>None</code> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step. Must be False if this animation is composed with others.</p> <code>True</code> <code>figsize</code> <code>List[int]</code> <p>Size of the figure.</p> <code>[1, 1]</code> <code>sleep</code> <code>float</code> <p>Time to sleep between frames.</p> <code>0.01</code> <code>**kwargs</code> <p>Additional arguments passed to plt.imshow.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>The figure object.</p> <code>ax</code> <code>Axes</code> <p>The axes object.</p> <code>kwargs</code> <code>dict</code> <p>Additional arguments for imshow.</p> <code>update</code> <code>bool</code> <p>Whether to update the canvas after each step.</p> <code>n_samples</code> <code>int</code> <p>Number of samples in the images array.</p> <code>frames</code> <code>int</code> <p>Number of frames in each sample.</p> <code>images</code> <code>ndarray</code> <p>Array of images to animate.</p> <code>sleep</code> <code>float</code> <p>Time to sleep between frames.</p> <code>img</code> <code>AxesImage</code> <p>The image object created by imshow.</p> Note <p>The <code>images</code> array should have shape (n_samples, n_frames, height, width).</p> Source code in <code>flyvis/analysis/animations/imshow.py</code> <pre><code>class Imshow(Animation):\n    \"\"\"Animates an array of images using imshow.\n\n    Args:\n        images: Array of images to animate (n_samples, n_frames, height, width).\n        fig: Existing Figure instance or None.\n        ax: Existing Axis instance or None.\n        update: Whether to update the canvas after an animation step.\n            Must be False if this animation is composed with others.\n        figsize: Size of the figure.\n        sleep: Time to sleep between frames.\n        **kwargs: Additional arguments passed to plt.imshow.\n\n    Attributes:\n        fig (plt.Figure): The figure object.\n        ax (plt.Axes): The axes object.\n        kwargs (dict): Additional arguments for imshow.\n        update (bool): Whether to update the canvas after each step.\n        n_samples (int): Number of samples in the images array.\n        frames (int): Number of frames in each sample.\n        images (np.ndarray): Array of images to animate.\n        sleep (float): Time to sleep between frames.\n        img (plt.AxesImage): The image object created by imshow.\n\n    Note:\n        The `images` array should have shape (n_samples, n_frames, height, width).\n    \"\"\"\n\n    def __init__(\n        self,\n        images: np.ndarray,\n        fig: Optional[plt.Figure] = None,\n        ax: Optional[plt.Axes] = None,\n        update: bool = True,\n        figsize: List[int] = [1, 1],\n        sleep: float = 0.01,\n        **kwargs,\n    ) -&gt; None:\n        super().__init__()\n        self.fig, self.ax = plt_utils.init_plot(\n            figsize=figsize,\n            fig=fig,\n            ax=ax,\n            position=[0, 0, 1, 1],\n            set_axis_off=True,\n        )\n        self.kwargs = kwargs\n        self.update = update\n        self.n_samples, self.frames = images.shape[:2]\n        self.images = images\n        self.sleep = sleep\n        super().__init__(None, self.fig)\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize the animation.\n\n        Args:\n            frame: The initial frame to display.\n        \"\"\"\n        self.img = self.ax.imshow(self.images[self.batch_sample, frame], **self.kwargs)\n        if self.sleep is not None:\n            sleep(self.sleep)\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate a single frame.\n\n        Args:\n            frame: The frame number to animate.\n        \"\"\"\n        self.img.set_data(self.images[self.batch_sample, frame])\n\n        if self.update:\n            self.update_figure()\n\n        if self.sleep is not None:\n            sleep(self.sleep)\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.imshow.Imshow.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>The initial frame to display.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/imshow.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize the animation.\n\n    Args:\n        frame: The initial frame to display.\n    \"\"\"\n    self.img = self.ax.imshow(self.images[self.batch_sample, frame], **self.kwargs)\n    if self.sleep is not None:\n        sleep(self.sleep)\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.imshow.Imshow.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>The frame number to animate.</p> required Source code in <code>flyvis/analysis/animations/imshow.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate a single frame.\n\n    Args:\n        frame: The frame number to animate.\n    \"\"\"\n    self.img.set_data(self.images[self.batch_sample, frame])\n\n    if self.update:\n        self.update_figure()\n\n    if self.sleep is not None:\n        sleep(self.sleep)\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationshexscatter","title":"flyvis.analysis.animations.hexscatter","text":""},{"location":"reference/animations/#classes_1","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.hexscatter.HexScatter","title":"flyvis.analysis.animations.hexscatter.HexScatter","text":"<p>               Bases: <code>Animation</code></p> <p>Regular hex-scatter animation.</p> <p>For hexals not on a regular hex grid, use the function pad_to_regular_hex.</p> <p>Parameters:</p> Name Type Description Default <code>hexarray</code> <code>ndarray</code> <p>Shape (n_samples, n_frames, 1, n_input_elements).</p> required <code>u</code> <code>Optional[List[float]]</code> <p>List of u coordinates of elements to plot.</p> <code>None</code> <code>v</code> <code>Optional[List[float]]</code> <p>List of v coordinates of elements to plot.</p> <code>None</code> <code>cranges</code> <code>Optional[List[float]]</code> <p>Color minimal and maximal abs value (n_samples).</p> <code>None</code> <code>vmin</code> <code>Optional[float]</code> <p>Color minimal value.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Color maximal value.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure instance or None.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axis instance or None.</p> <code>None</code> <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> <code>0</code> <code>cmap</code> <code>Union[str, Colormap]</code> <p>Colormap for the hex-scatter.</p> <code>get_cmap('binary_r')</code> <code>edgecolor</code> <code>Optional[str]</code> <p>Edgecolor for the hexals. None for no edge.</p> <code>None</code> <code>update_edge_color</code> <code>bool</code> <p>Whether to update the edgecolor after an animation step.</p> <code>True</code> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step. Must be False if this animation is composed with others using AnimationCollector.</p> <code>False</code> <code>label</code> <code>str</code> <p>Label of the animation. Formatted with the current sample and frame number per frame.</p> <code>'Sample: {}\\nFrame: {}'</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Location of the label.</p> <code>(0.1, 0.95)</code> <code>fontsize</code> <code>float</code> <p>Fontsize.</p> <code>5</code> <code>cbar</code> <code>bool</code> <p>Display colorbar.</p> <code>True</code> <code>background_color</code> <code>str</code> <p>Background color.</p> <code>'none'</code> <code>midpoint</code> <code>Optional[float]</code> <p>Midpoint for diverging colormaps.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Matplotlib figure instance.</p> <code>ax</code> <code>Axes</code> <p>Matplotlib axes instance.</p> <code>background_color</code> <code>str</code> <p>Background color.</p> <code>hexarray</code> <code>ndarray</code> <p>Hex array data.</p> <code>cranges</code> <code>Optional[List[float]]</code> <p>Color ranges.</p> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for color mapping.</p> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for color mapping.</p> <code>midpoint</code> <code>Optional[float]</code> <p>Midpoint for diverging colormaps.</p> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>batch_sample</code> <code>int</code> <p>Batch sample index.</p> <code>cmap</code> <p>Colormap for the hex-scatter.</p> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step.</p> <code>label</code> <code>str</code> <p>Label template for the animation.</p> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Label position.</p> <code>label_text</code> <p>Text object for the label.</p> <code>n_samples</code> <code>int</code> <p>Number of samples.</p> <code>frames</code> <code>int</code> <p>Number of frames.</p> <code>extent</code> <code>int</code> <p>Hex extent.</p> <code>edgecolor</code> <code>Optional[str]</code> <p>Edgecolor for the hexals.</p> <code>update_edge_color</code> <code>bool</code> <p>Whether to update the edgecolor.</p> <code>fontsize</code> <code>float</code> <p>Font size.</p> <code>cbar</code> <code>bool</code> <p>Whether to display colorbar.</p> <code>u</code> <code>List[float]</code> <p>U coordinates of elements to plot.</p> <code>v</code> <code>List[float]</code> <p>V coordinates of elements to plot.</p> Source code in <code>flyvis/analysis/animations/hexscatter.py</code> <pre><code>class HexScatter(Animation):\n    \"\"\"Regular hex-scatter animation.\n\n    For hexals not on a regular hex grid, use the function pad_to_regular_hex.\n\n    Args:\n        hexarray: Shape (n_samples, n_frames, 1, n_input_elements).\n        u: List of u coordinates of elements to plot.\n        v: List of v coordinates of elements to plot.\n        cranges: Color minimal and maximal abs value (n_samples).\n        vmin: Color minimal value.\n        vmax: Color maximal value.\n        fig: Existing Figure instance or None.\n        ax: Existing Axis instance or None.\n        batch_sample: Batch sample to start from.\n        cmap: Colormap for the hex-scatter.\n        edgecolor: Edgecolor for the hexals. None for no edge.\n        update_edge_color: Whether to update the edgecolor after an animation step.\n        update: Whether to update the canvas after an animation step.\n            Must be False if this animation is composed with others using\n            AnimationCollector.\n        label: Label of the animation. Formatted with the current sample and\n            frame number per frame.\n        labelxy: Location of the label.\n        fontsize: Fontsize.\n        cbar: Display colorbar.\n        background_color: Background color.\n        midpoint: Midpoint for diverging colormaps.\n\n    Attributes:\n        fig (Figure): Matplotlib figure instance.\n        ax (Axes): Matplotlib axes instance.\n        background_color (str): Background color.\n        hexarray (np.ndarray): Hex array data.\n        cranges (Optional[List[float]]): Color ranges.\n        vmin (Optional[float]): Minimum value for color mapping.\n        vmax (Optional[float]): Maximum value for color mapping.\n        midpoint (Optional[float]): Midpoint for diverging colormaps.\n        kwargs (dict): Additional keyword arguments.\n        batch_sample (int): Batch sample index.\n        cmap: Colormap for the hex-scatter.\n        update (bool): Whether to update the canvas after an animation step.\n        label (str): Label template for the animation.\n        labelxy (Tuple[float, float]): Label position.\n        label_text: Text object for the label.\n        n_samples (int): Number of samples.\n        frames (int): Number of frames.\n        extent (int): Hex extent.\n        edgecolor (Optional[str]): Edgecolor for the hexals.\n        update_edge_color (bool): Whether to update the edgecolor.\n        fontsize (float): Font size.\n        cbar (bool): Whether to display colorbar.\n        u (List[float]): U coordinates of elements to plot.\n        v (List[float]): V coordinates of elements to plot.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        hexarray: np.ndarray,\n        u: Optional[List[float]] = None,\n        v: Optional[List[float]] = None,\n        cranges: Optional[List[float]] = None,\n        vmin: Optional[float] = None,\n        vmax: Optional[float] = None,\n        fig: Optional[Figure] = None,\n        ax: Optional[Axes] = None,\n        batch_sample: int = 0,\n        cmap: Union[str, Colormap] = cm.get_cmap(\"binary_r\"),\n        edgecolor: Optional[str] = None,\n        update_edge_color: bool = True,\n        update: bool = False,\n        label: str = \"Sample: {}\\nFrame: {}\",\n        labelxy: Tuple[float, float] = (0.1, 0.95),\n        fontsize: float = 5,\n        cbar: bool = True,\n        background_color: str = \"none\",\n        midpoint: Optional[float] = None,\n        **kwargs,\n    ):\n        self.fig = fig\n        self.ax = ax\n        self.background_color = background_color\n        self.hexarray = utils.tensor_utils.to_numpy(hexarray)\n        self.cranges = cranges\n        self.vmin = vmin\n        self.vmax = vmax\n        self.midpoint = midpoint\n        self.kwargs = kwargs\n        self.batch_sample = batch_sample\n        self.cmap = cmap\n        self.update = update\n        self.label = label\n        self.labelxy = labelxy\n        self.label_text = None\n        self.n_samples, self.frames = hexarray.shape[0:2]\n        self.extent = utils.hex_utils.get_hextent(hexarray.shape[-1])\n        self.edgecolor = edgecolor\n        self.update_edge_color = update_edge_color\n        self.fontsize = fontsize\n        self.cbar = cbar\n        if u is None or v is None:\n            u, v = utils.hex_utils.get_hex_coords(self.extent)\n        self.u = u\n        self.v = v\n        super().__init__(None, self.fig)\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize the animation.\n\n        Args:\n            frame: Frame number to initialize.\n\n        \"\"\"\n        if frame &lt; 0:\n            frame += self.frames\n        u, v = utils.hex_utils.get_hex_coords(self.extent)\n        _values = self.hexarray[self.batch_sample]\n        _vmin = _values.min()\n        _vmax = _values.max()\n        values = _values[frame].squeeze()\n        vmin = (\n            -self.cranges[self.batch_sample]\n            if self.cranges is not None\n            else self.vmin\n            if self.vmin is not None\n            else _vmin\n        )\n        vmax = (\n            +self.cranges[self.batch_sample]\n            if self.cranges is not None\n            else self.vmax\n            if self.vmax is not None\n            else _vmax\n        )\n        scalarmapper, norm = plt_utils.get_scalarmapper(\n            scalarmapper=None,\n            cmap=self.cmap,\n            norm=None,\n            vmin=vmin,\n            vmax=vmax,\n            midpoint=self.midpoint,\n        )\n        self.fig, self.ax, (self.label_text, _) = plots.hex_scatter(\n            self.u,\n            self.v,\n            values,\n            fig=self.fig,\n            midpoint=None,\n            scalarmapper=scalarmapper,\n            norm=norm,\n            ax=self.ax,\n            cmap=self.cmap,\n            annotate=False,\n            labelxy=self.labelxy,\n            label=self.label.format(self.batch_sample, frame),\n            edgecolor=self.edgecolor,\n            fill=False,\n            cbar=False,\n            fontsize=self.fontsize,\n            **self.kwargs,\n        )\n        self.fig.patch.set_facecolor(self.background_color)\n        self.ax.patch.set_facecolor(self.background_color)\n        if self.cbar:\n            plt_utils.add_colorbar_to_fig(\n                self.fig,\n                [self.ax],\n                label=\"\",\n                width=0.01,\n                height=0.5,\n                x_offset=-2,\n                cmap=self.cmap,\n                norm=norm,\n                fontsize=self.fontsize - 1,\n                tick_length=1,\n                tick_width=0.25,\n                rm_outline=True,\n                n_ticks=5,\n                n_decimals=0,\n            )\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate a single frame.\n\n        Args:\n            frame: Frame number to animate.\n\n        \"\"\"\n        if frame &lt; 0:\n            frame += self.frames\n        _values = self.hexarray[self.batch_sample]\n        _vmin = _values.min()\n        _vmax = _values.max()\n        values = _values[frame].squeeze()\n        vmin = (\n            -self.cranges[self.batch_sample]\n            if self.cranges is not None\n            else self.vmin\n            if self.vmin is not None\n            else _vmin\n        )\n        vmax = (\n            +self.cranges[self.batch_sample]\n            if self.cranges is not None\n            else self.vmax\n            if self.vmax is not None\n            else _vmax\n        )\n        scalarmapper, norm = plt_utils.get_scalarmapper(\n            scalarmapper=None,\n            cmap=self.cmap,\n            norm=None,\n            vmin=vmin,\n            vmax=vmax,\n            midpoint=self.midpoint,\n        )\n        if self.cbar:\n            for ax in self.fig.axes:\n                if ax.get_label() == \"cbar\":\n                    ax.remove()\n            plt_utils.add_colorbar_to_fig(\n                self.fig,\n                [self.ax],\n                label=\"\",\n                width=0.01,\n                height=0.5,\n                x_offset=-2,\n                cmap=self.cmap,\n                norm=norm,\n                fontsize=self.fontsize - 1,\n                tick_length=1,\n                tick_width=0.25,\n                rm_outline=True,\n                n_ticks=5,\n                n_decimals=0,\n            )\n        fcolors = scalarmapper.to_rgba(values)\n        for i, fc in enumerate(fcolors):\n            if self.update_edge_color:\n                self.ax.patches[i].set_color(fc)\n            else:\n                self.ax.patches[i].set_facecolor(fc)\n\n        if self.label:\n            self.label_text.set_text(self.label.format(self.batch_sample, frame))\n\n        if self.update:\n            self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.hexscatter.HexScatter.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to initialize.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/hexscatter.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize the animation.\n\n    Args:\n        frame: Frame number to initialize.\n\n    \"\"\"\n    if frame &lt; 0:\n        frame += self.frames\n    u, v = utils.hex_utils.get_hex_coords(self.extent)\n    _values = self.hexarray[self.batch_sample]\n    _vmin = _values.min()\n    _vmax = _values.max()\n    values = _values[frame].squeeze()\n    vmin = (\n        -self.cranges[self.batch_sample]\n        if self.cranges is not None\n        else self.vmin\n        if self.vmin is not None\n        else _vmin\n    )\n    vmax = (\n        +self.cranges[self.batch_sample]\n        if self.cranges is not None\n        else self.vmax\n        if self.vmax is not None\n        else _vmax\n    )\n    scalarmapper, norm = plt_utils.get_scalarmapper(\n        scalarmapper=None,\n        cmap=self.cmap,\n        norm=None,\n        vmin=vmin,\n        vmax=vmax,\n        midpoint=self.midpoint,\n    )\n    self.fig, self.ax, (self.label_text, _) = plots.hex_scatter(\n        self.u,\n        self.v,\n        values,\n        fig=self.fig,\n        midpoint=None,\n        scalarmapper=scalarmapper,\n        norm=norm,\n        ax=self.ax,\n        cmap=self.cmap,\n        annotate=False,\n        labelxy=self.labelxy,\n        label=self.label.format(self.batch_sample, frame),\n        edgecolor=self.edgecolor,\n        fill=False,\n        cbar=False,\n        fontsize=self.fontsize,\n        **self.kwargs,\n    )\n    self.fig.patch.set_facecolor(self.background_color)\n    self.ax.patch.set_facecolor(self.background_color)\n    if self.cbar:\n        plt_utils.add_colorbar_to_fig(\n            self.fig,\n            [self.ax],\n            label=\"\",\n            width=0.01,\n            height=0.5,\n            x_offset=-2,\n            cmap=self.cmap,\n            norm=norm,\n            fontsize=self.fontsize - 1,\n            tick_length=1,\n            tick_width=0.25,\n            rm_outline=True,\n            n_ticks=5,\n            n_decimals=0,\n        )\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.hexscatter.HexScatter.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to animate.</p> required Source code in <code>flyvis/analysis/animations/hexscatter.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate a single frame.\n\n    Args:\n        frame: Frame number to animate.\n\n    \"\"\"\n    if frame &lt; 0:\n        frame += self.frames\n    _values = self.hexarray[self.batch_sample]\n    _vmin = _values.min()\n    _vmax = _values.max()\n    values = _values[frame].squeeze()\n    vmin = (\n        -self.cranges[self.batch_sample]\n        if self.cranges is not None\n        else self.vmin\n        if self.vmin is not None\n        else _vmin\n    )\n    vmax = (\n        +self.cranges[self.batch_sample]\n        if self.cranges is not None\n        else self.vmax\n        if self.vmax is not None\n        else _vmax\n    )\n    scalarmapper, norm = plt_utils.get_scalarmapper(\n        scalarmapper=None,\n        cmap=self.cmap,\n        norm=None,\n        vmin=vmin,\n        vmax=vmax,\n        midpoint=self.midpoint,\n    )\n    if self.cbar:\n        for ax in self.fig.axes:\n            if ax.get_label() == \"cbar\":\n                ax.remove()\n        plt_utils.add_colorbar_to_fig(\n            self.fig,\n            [self.ax],\n            label=\"\",\n            width=0.01,\n            height=0.5,\n            x_offset=-2,\n            cmap=self.cmap,\n            norm=norm,\n            fontsize=self.fontsize - 1,\n            tick_length=1,\n            tick_width=0.25,\n            rm_outline=True,\n            n_ticks=5,\n            n_decimals=0,\n        )\n    fcolors = scalarmapper.to_rgba(values)\n    for i, fc in enumerate(fcolors):\n        if self.update_edge_color:\n            self.ax.patches[i].set_color(fc)\n        else:\n            self.ax.patches[i].set_facecolor(fc)\n\n    if self.label:\n        self.label_text.set_text(self.label.format(self.batch_sample, frame))\n\n    if self.update:\n        self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationshexflow","title":"flyvis.analysis.animations.hexflow","text":""},{"location":"reference/animations/#classes_2","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.hexflow.HexFlow","title":"flyvis.analysis.animations.hexflow.HexFlow","text":"<p>               Bases: <code>Animation</code></p> <p>Hexscatter of a color encoded flow field.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <code>Union[ndarray, Tensor]</code> <p>Optic flow of shape (n_samples, n_frames, 2, n_input_elements).</p> required <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure instance or None.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axis instance or None.</p> <code>None</code> <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> <code>0</code> <code>cmap</code> <code>Colormap</code> <p>Colormap for the hex-scatter.</p> <code>cm_uniform_2d</code> <code>cwheel</code> <code>bool</code> <p>Display colorwheel.</p> <code>False</code> <code>cwheelxy</code> <code>Tuple[float, float]</code> <p>Colorwheel offset x and y.</p> <code>()</code> <code>label</code> <code>str</code> <p>Label of the animation.</p> <code>'Sample: {}\\nFrame: {}'</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Normalized x and y location of the label.</p> <code>(0, 1)</code> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step.</p> <code>False</code> <code>path</code> <code>Optional[str]</code> <p>Path to save the animation to.</p> <code>None</code> <code>figsize</code> <code>List[float]</code> <p>Figure size.</p> <code>[2, 2]</code> <code>fontsize</code> <code>float</code> <p>Font size.</p> <code>5</code> <code>background_color</code> <code>Literal['none']</code> <p>Background color of the figure and axis.</p> <code>'none'</code> <p>Attributes:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Figure instance.</p> <code>ax</code> <code>Axes</code> <p>Axis instance.</p> <code>background_color</code> <code>str</code> <p>Background color of the figure and axis.</p> <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step. Must be False if this animation is composed with others using AnimationCollector.</p> <code>cmap</code> <p>Colormap for the hex-scatter.</p> <code>cwheel</code> <code>bool</code> <p>Display colorwheel.</p> <code>cwheelxy</code> <code>Tuple[float, float]</code> <p>Colorwheel offset x and y.</p> <code>label</code> <code>str</code> <p>Label of the animation.</p> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Normalized x and y location of the label.</p> <code>label_text</code> <code>Text</code> <p>Text instance for the label.</p> <code>sm</code> <code>ScalarMappable</code> <p>ScalarMappable instance for color mapping.</p> <code>fontsize</code> <code>float</code> <p>Font size.</p> <code>figsize</code> <code>List[float, float]</code> <p>Figure size.</p> <code>flow</code> <code>ndarray</code> <p>Optic flow data.</p> <code>n_samples</code> <code>int</code> <p>Number of samples in the flow data.</p> <code>frames</code> <code>int</code> <p>Number of frames in the flow data.</p> <code>extent</code> <code>Tuple[float, float, float, float]</code> <p>Extent of the hexagonal grid.</p> Note <p>All kwargs are passed to ~flyvis.analysis.visualization.plots.hex_flow.</p> Source code in <code>flyvis/analysis/animations/hexflow.py</code> <pre><code>class HexFlow(Animation):\n    \"\"\"Hexscatter of a color encoded flow field.\n\n    Args:\n        flow: Optic flow of shape (n_samples, n_frames, 2, n_input_elements).\n        fig: Existing Figure instance or None.\n        ax: Existing Axis instance or None.\n        batch_sample: Batch sample to start from.\n        cmap: Colormap for the hex-scatter.\n        cwheel: Display colorwheel.\n        cwheelxy: Colorwheel offset x and y.\n        label: Label of the animation.\n        labelxy: Normalized x and y location of the label.\n        update: Whether to update the canvas after an animation step.\n        path: Path to save the animation to.\n        figsize: Figure size.\n        fontsize: Font size.\n        background_color: Background color of the figure and axis.\n\n    Attributes:\n        fig (Figure): Figure instance.\n        ax (Axes): Axis instance.\n        background_color (str): Background color of the figure and axis.\n        batch_sample (int): Batch sample to start from.\n        kwargs (dict): Additional keyword arguments.\n        update (bool): Whether to update the canvas after an animation step.\n            Must be False if this animation is composed with others using\n            AnimationCollector.\n        cmap: Colormap for the hex-scatter.\n        cwheel (bool): Display colorwheel.\n        cwheelxy (Tuple[float, float]): Colorwheel offset x and y.\n        label (str): Label of the animation.\n        labelxy (Tuple[float, float]): Normalized x and y location of the label.\n        label_text (Text): Text instance for the label.\n        sm (ScalarMappable): ScalarMappable instance for color mapping.\n        fontsize (float): Font size.\n        figsize (List[float, float]): Figure size.\n        flow (np.ndarray): Optic flow data.\n        n_samples (int): Number of samples in the flow data.\n        frames (int): Number of frames in the flow data.\n        extent (Tuple[float, float, float, float]): Extent of the hexagonal grid.\n\n    Note:\n        All kwargs are passed to ~flyvis.analysis.visualization.plots.hex_flow.\n    \"\"\"\n\n    def __init__(\n        self,\n        flow: Union[np.ndarray, \"torch.Tensor\"],\n        fig: Optional[Figure] = None,\n        ax: Optional[Axes] = None,\n        batch_sample: int = 0,\n        cmap: \"Colormap\" = plt_utils.cm_uniform_2d,\n        cwheel: bool = False,\n        cwheelxy: Tuple[float, float] = (),\n        label: str = \"Sample: {}\\nFrame: {}\",\n        labelxy: Tuple[float, float] = (0, 1),\n        update: bool = False,\n        path: Optional[str] = None,\n        figsize: List[float] = [2, 2],\n        fontsize: float = 5,\n        background_color: Literal[\"none\"] = \"none\",\n        **kwargs,\n    ):\n        self.fig = fig\n        self.ax = ax\n        self.background_color = background_color\n        self.batch_sample = batch_sample\n        self.kwargs = kwargs\n        self.update = update\n        self.cmap = cmap\n        self.cwheel = cwheel\n        self.cwheelxy = cwheelxy\n\n        self.label = label\n        self.labelxy = labelxy\n        self.label_text: Optional[Text] = None\n        self.sm: Optional[ScalarMappable] = None\n        self.fontsize = fontsize\n        self.figsize = figsize\n\n        self.flow = utils.tensor_utils.to_numpy(flow)\n\n        self.n_samples, self.frames = self.flow.shape[0:2]\n        self.extent = utils.hex_utils.get_hextent(self.flow.shape[-1])\n        super().__init__(path, self.fig)\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize the animation.\n\n        Args:\n            frame: Frame number to initialize with.\n        \"\"\"\n        u, v = utils.hex_utils.get_hex_coords(self.extent)\n        self.fig, self.ax, (self.label_text, self.sm, _, _) = plots.hex_flow(\n            u,\n            v,\n            self.flow[self.batch_sample, frame],\n            fig=self.fig,\n            ax=self.ax,\n            cwheel=self.cwheel,\n            cwheelxy=self.cwheelxy,\n            cmap=self.cmap,\n            annotate=False,\n            labelxy=self.labelxy,\n            label=self.label.format(self.batch_sample, frame),\n            figsize=self.figsize,\n            fontsize=self.fontsize,\n            **self.kwargs,\n        )\n        self.fig.patch.set_facecolor(self.background_color)\n        self.ax.patch.set_facecolor(self.background_color)\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate a single frame.\n\n        Args:\n            frame: Frame number to animate.\n        \"\"\"\n        flow = self.flow[self.batch_sample, frame]\n\n        r = np.sqrt(flow[0] ** 2 + flow[1] ** 2)\n        r /= r.max()\n        theta = np.arctan2(flow[1], flow[0])\n        color = self.sm.to_rgba(theta)\n        color[:, -1] = r\n\n        for i, fc in enumerate(color):\n            self.ax.patches[i].set_color(fc)\n\n        if self.label:\n            self.label_text.set_text(self.label.format(self.batch_sample, frame))\n\n        if self.update:\n            self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.hexflow.HexFlow.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to initialize with.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/hexflow.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize the animation.\n\n    Args:\n        frame: Frame number to initialize with.\n    \"\"\"\n    u, v = utils.hex_utils.get_hex_coords(self.extent)\n    self.fig, self.ax, (self.label_text, self.sm, _, _) = plots.hex_flow(\n        u,\n        v,\n        self.flow[self.batch_sample, frame],\n        fig=self.fig,\n        ax=self.ax,\n        cwheel=self.cwheel,\n        cwheelxy=self.cwheelxy,\n        cmap=self.cmap,\n        annotate=False,\n        labelxy=self.labelxy,\n        label=self.label.format(self.batch_sample, frame),\n        figsize=self.figsize,\n        fontsize=self.fontsize,\n        **self.kwargs,\n    )\n    self.fig.patch.set_facecolor(self.background_color)\n    self.ax.patch.set_facecolor(self.background_color)\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.hexflow.HexFlow.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to animate.</p> required Source code in <code>flyvis/analysis/animations/hexflow.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate a single frame.\n\n    Args:\n        frame: Frame number to animate.\n    \"\"\"\n    flow = self.flow[self.batch_sample, frame]\n\n    r = np.sqrt(flow[0] ** 2 + flow[1] ** 2)\n    r /= r.max()\n    theta = np.arctan2(flow[1], flow[0])\n    color = self.sm.to_rgba(theta)\n    color[:, -1] = r\n\n    for i, fc in enumerate(color):\n        self.ax.patches[i].set_color(fc)\n\n    if self.label:\n        self.label_text.set_text(self.label.format(self.batch_sample, frame))\n\n    if self.update:\n        self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationssintel","title":"flyvis.analysis.animations.sintel","text":""},{"location":"reference/animations/#classes_3","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.sintel.SintelSample","title":"flyvis.analysis.animations.sintel.SintelSample","text":"<p>               Bases: <code>AnimationCollector</code></p> <p>Sintel-specific animation of input, target, and groundtruth data.</p> <p>Parameters:</p> Name Type Description Default <code>lum</code> <code>ndarray</code> <p>Input of shape (n_samples, n_frames, n_hexals).</p> required <code>target</code> <code>ndarray</code> <p>Target of shape (n_samples, n_frames, n_dims, n_features).</p> required <code>prediction</code> <code>Optional[ndarray]</code> <p>Optional prediction of shape (n_samples, n_frames, n_dims, n_features).</p> <code>None</code> <code>target_cmap</code> <code>str</code> <p>Colormap for the target (depth).</p> <code>colormaps['binary_r']</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Normalized x and y location of the label.</p> <code>(-0.1, 1)</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>3.6</code> <code>title1</code> <code>str</code> <p>Title for the input panel.</p> <code>'input'</code> <code>title2</code> <code>str</code> <p>Title for the target panel.</p> <code>'target'</code> <code>title3</code> <code>str</code> <p>Title for the prediction panel.</p> <code>'prediction'</code> <p>Attributes:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Matplotlib figure instance.</p> <code>axes</code> <code>List[Axes]</code> <p>List of matplotlib axes instances.</p> <code>lum</code> <code>ndarray</code> <p>Input data.</p> <code>target</code> <code>ndarray</code> <p>Target data.</p> <code>prediction</code> <code>Optional[ndarray]</code> <p>Prediction data.</p> <code>extent</code> <code>Tuple[float, float, float, float]</code> <p>Extent of the hexagonal grid.</p> <code>n_samples</code> <code>int</code> <p>Number of samples.</p> <code>frames</code> <code>int</code> <p>Number of frames.</p> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step.</p> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Normalized x and y location of the label.</p> <code>animations</code> <code>List</code> <p>List of animation objects.</p> <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> Source code in <code>flyvis/analysis/animations/sintel.py</code> <pre><code>class SintelSample(AnimationCollector):\n    \"\"\"Sintel-specific animation of input, target, and groundtruth data.\n\n    Args:\n        lum: Input of shape (n_samples, n_frames, n_hexals).\n        target: Target of shape (n_samples, n_frames, n_dims, n_features).\n        prediction: Optional prediction of shape\n            (n_samples, n_frames, n_dims, n_features).\n        target_cmap: Colormap for the target (depth).\n        fontsize: Font size for labels and titles.\n        labelxy: Normalized x and y location of the label.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        title1: Title for the input panel.\n        title2: Title for the target panel.\n        title3: Title for the prediction panel.\n\n    Attributes:\n        fig (Figure): Matplotlib figure instance.\n        axes (List[Axes]): List of matplotlib axes instances.\n        lum (np.ndarray): Input data.\n        target (np.ndarray): Target data.\n        prediction (Optional[np.ndarray]): Prediction data.\n        extent (Tuple[float, float, float, float]): Extent of the hexagonal grid.\n        n_samples (int): Number of samples.\n        frames (int): Number of frames.\n        update (bool): Whether to update the canvas after an animation step.\n        labelxy (Tuple[float, float]): Normalized x and y location of the label.\n        animations (List): List of animation objects.\n        batch_sample (int): Batch sample to start from.\n    \"\"\"\n\n    def __init__(\n        self,\n        lum: np.ndarray,\n        target: np.ndarray,\n        prediction: Optional[np.ndarray] = None,\n        target_cmap: str = colormaps[\"binary_r\"],\n        fontsize: float = 5,\n        labelxy: Tuple[float, float] = (-0.1, 1),\n        max_figure_height_cm: float = 22,\n        panel_height_cm: float = 3,\n        max_figure_width_cm: float = 18,\n        panel_width_cm: float = 3.6,\n        title1: str = \"input\",\n        title2: str = \"target\",\n        title3: str = \"prediction\",\n    ) -&gt; None:\n        figsize = figsize_utils.figsize_from_n_items(\n            2 if prediction is None else 3,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        self.fig, self.axes = figsize.axis_grid(\n            hspace=0.0,\n            wspace=0,\n            fontsize=fontsize,\n            unmask_n=2 if prediction is None else 3,\n        )\n\n        self.lum = lum\n        self.target = target\n        self.prediction = prediction\n        self.extent = utils.hex_utils.get_hextent(self.lum.shape[-1])\n\n        self.n_samples, self.frames = self.lum.shape[0:2]\n        self.update = False\n        self.labelxy = labelxy\n\n        animations = []\n        animations.append(\n            HexScatter(\n                self.lum,\n                fig=self.fig,\n                ax=self.axes[0],\n                title=title1,\n                edgecolor=None,\n                update_edge_color=True,\n                fontsize=fontsize,\n                cbar=True,\n                labelxy=labelxy,\n            )\n        )\n\n        if self.target.shape[-2] == 2:\n            animations.append(\n                HexFlow(\n                    flow=self.target,\n                    fig=self.fig,\n                    ax=self.axes[1],\n                    cwheel=True,\n                    cwheelxy=(-0.7, 0.7),\n                    title=title2,\n                    label=\"\",\n                    fontsize=fontsize,\n                )\n            )\n            if prediction is not None:\n                animations.append(\n                    HexFlow(\n                        flow=self.prediction,\n                        fig=self.fig,\n                        ax=self.axes[2],\n                        cwheel=True,\n                        cwheelxy=(-0.7, 0.7),\n                        title=title3,\n                        label=\"\",\n                        fontsize=fontsize,\n                    )\n                )\n        else:\n            animations.append(\n                HexScatter(\n                    self.target,\n                    fig=self.fig,\n                    ax=self.axes[1],\n                    cmap=target_cmap,\n                    title=title2,\n                    edgecolor=None,\n                    fontsize=fontsize,\n                    cbar=True,\n                    labelxy=labelxy,\n                )\n            )\n            if prediction is not None:\n                animations.append(\n                    HexScatter(\n                        self.prediction,\n                        fig=self.fig,\n                        ax=self.axes[2],\n                        cmap=target_cmap,\n                        title=title3,\n                        edgecolor=None,\n                        fontsize=fontsize,\n                        cbar=True,\n                        labelxy=labelxy,\n                    )\n                )\n        self.animations = animations\n        self.batch_sample = 0\n        super().__init__(None, self.fig)\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationsactivations","title":"flyvis.analysis.animations.activations","text":""},{"location":"reference/animations/#classes_4","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.activations.StimulusResponse","title":"flyvis.analysis.animations.activations.StimulusResponse","text":"<p>               Bases: <code>AnimationCollector</code></p> <p>Hex-scatter animations for input and responses.</p> <p>Parameters:</p> Name Type Description Default <code>stimulus</code> <code>ndarray</code> <p>Hexagonal input.</p> required <code>responses</code> <code>Union[ndarray, List[ndarray]]</code> <p>Hexagonal activation of particular neuron type.</p> required <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> <code>0</code> <code>figsize_scale</code> <code>float</code> <p>Scale factor for figure size.</p> <code>1</code> <code>fontsize</code> <code>int</code> <p>Font size for the plot.</p> <code>5</code> <code>u</code> <code>Optional[List[int]]</code> <p>List of u coordinates of neurons to plot.</p> <code>None</code> <code>v</code> <code>Optional[List[int]]</code> <p>List of v coordinates of neurons to plot.</p> <code>None</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>3.6</code> <p>Attributes:</p> Name Type Description <code>stimulus</code> <code>ndarray</code> <p>Numpy array of stimulus data.</p> <code>responses</code> <code>List[ndarray]</code> <p>List of numpy arrays of response data.</p> <code>update</code> <code>bool</code> <p>Flag to indicate if update is needed.</p> <code>n_samples</code> <code>int</code> <p>Number of samples.</p> <code>frames</code> <code>int</code> <p>Number of frames.</p> <code>fig</code> <code>Figure</code> <p>Matplotlib figure object.</p> <code>axes</code> <code>List[Axes]</code> <p>List of matplotlib axes objects.</p> <code>animations</code> <code>List[HexScatter]</code> <p>List of HexScatter animation objects.</p> <code>batch_sample</code> <code>int</code> <p>Batch sample index.</p> Note <p>If u and v are not specified, all neurons are plotted.</p> Source code in <code>flyvis/analysis/animations/activations.py</code> <pre><code>class StimulusResponse(AnimationCollector):\n    \"\"\"Hex-scatter animations for input and responses.\n\n    Args:\n        stimulus: Hexagonal input.\n        responses: Hexagonal activation of particular neuron type.\n        batch_sample: Batch sample to start from.\n        figsize_scale: Scale factor for figure size.\n        fontsize: Font size for the plot.\n        u: List of u coordinates of neurons to plot.\n        v: List of v coordinates of neurons to plot.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n\n    Attributes:\n        stimulus (np.ndarray): Numpy array of stimulus data.\n        responses (List[np.ndarray]): List of numpy arrays of response data.\n        update (bool): Flag to indicate if update is needed.\n        n_samples (int): Number of samples.\n        frames (int): Number of frames.\n        fig (matplotlib.figure.Figure): Matplotlib figure object.\n        axes (List[matplotlib.axes.Axes]): List of matplotlib axes objects.\n        animations (List[HexScatter]): List of HexScatter animation objects.\n        batch_sample (int): Batch sample index.\n\n    Note:\n        If u and v are not specified, all neurons are plotted.\n    \"\"\"\n\n    def __init__(\n        self,\n        stimulus: np.ndarray,\n        responses: Union[np.ndarray, List[np.ndarray]],\n        batch_sample: int = 0,\n        figsize_scale: float = 1,\n        fontsize: int = 5,\n        u: Optional[List[int]] = None,\n        v: Optional[List[int]] = None,\n        max_figure_height_cm: float = 22,\n        panel_height_cm: float = 3,\n        max_figure_width_cm: float = 18,\n        panel_width_cm: float = 3.6,\n    ) -&gt; None:\n        self.stimulus = utils.tensor_utils.to_numpy(stimulus)\n\n        # case: multiple response\n        if isinstance(responses, List):\n            self.responses = [utils.tensor_utils.to_numpy(r) for r in responses]\n        else:\n            self.responses = [utils.tensor_utils.to_numpy(responses)]\n\n        self.update = False\n        self.n_samples, self.frames = self.responses[0].shape[:2]\n\n        figsize = figsize_utils.figsize_from_n_items(\n            1 + len(self.responses),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        self.fig, self.axes = figsize.axis_grid(\n            unmask_n=1 + len(self.responses), hspace=0.0, wspace=0, fontsize=fontsize\n        )\n\n        stimulus_samples = self.stimulus.shape[0]\n        if stimulus_samples != self.n_samples and stimulus_samples == 1:\n            self.stimulus = np.repeat(self.stimulus, self.n_samples, axis=0)\n\n        animations = []\n\n        animations.append(\n            HexScatter(\n                self.stimulus,\n                fig=self.fig,\n                ax=self.axes[0],\n                title=\"stimulus\",\n                labelxy=(-0.1, 1),\n                update=False,\n                title_y=0.9,\n            )\n        )\n\n        cranges = np.max(np.abs(self.responses), axis=(0, 2, 3, 4))\n\n        for i, responses in enumerate(self.responses, 1):\n            animations.append(\n                HexScatter(\n                    responses,\n                    fig=self.fig,\n                    ax=self.axes[i],\n                    cmap=cm.get_cmap(\"seismic\"),\n                    title=f\"response {i}\" if len(self.responses) &gt; 1 else \"response\",\n                    label=\"\",\n                    midpoint=0,\n                    update=False,\n                    u=u,\n                    v=v,\n                    cranges=cranges,\n                    cbar=i == len(self.responses),\n                    title_y=0.9,\n                )\n            )\n\n        self.animations = animations\n        self.batch_sample = batch_sample\n        super().__init__(None, self.fig)\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationsnetwork","title":"flyvis.analysis.animations.network","text":""},{"location":"reference/animations/#classes_5","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.network.WholeNetworkAnimation","title":"flyvis.analysis.animations.network.WholeNetworkAnimation","text":"<p>               Bases: <code>Animation</code></p> <p>Create an animation of the whole network activity.</p> <p>This class generates an animation that visualizes the activity of a neural network, including input, rendering, predicted flow, and target flow if provided.</p> <p>Attributes:</p> Name Type Description <code>fig_backbone</code> <code>WholeNetworkFigure</code> <p>The backbone figure for the animation.</p> <code>fig</code> <code>Figure</code> <p>The main figure object.</p> <code>ax_dict</code> <code>dict</code> <p>Dictionary of axes for different components of the animation.</p> <code>batch_sample</code> <code>int</code> <p>The index of the batch sample to animate.</p> <code>kwargs</code> <code>dict</code> <p>Additional keyword arguments.</p> <code>update</code> <code>bool</code> <p>Whether to update the figure during animation.</p> <code>label</code> <code>str</code> <p>Label format string for the animation.</p> <code>labelxy</code> <code>tuple[float, float]</code> <p>Position of the label.</p> <code>fontsize</code> <code>int</code> <p>Font size for labels.</p> <code>cmap</code> <code>Colormap</code> <p>Colormap for the animation.</p> <code>n_samples</code> <code>int</code> <p>Number of samples in the responses.</p> <code>frames</code> <code>int</code> <p>Number of frames in the responses.</p> <code>responses</code> <code>LayerActivity</code> <p>Layer activity data.</p> <code>cartesian_input</code> <code>Optional[Any]</code> <p>Cartesian input data.</p> <code>rendered_input</code> <code>Optional[Any]</code> <p>Rendered input data.</p> <code>predicted_flow</code> <code>Optional[Any]</code> <p>Predicted flow data.</p> <code>target_flow</code> <code>Optional[Any]</code> <p>Target flow data.</p> <code>color_norm_per</code> <code>str</code> <p>Color normalization method.</p> <code>voltage_axes</code> <code>list</code> <p>List of voltage axes for different cell types.</p> Source code in <code>flyvis/analysis/animations/network.py</code> <pre><code>class WholeNetworkAnimation(Animation):\n    \"\"\"\n    Create an animation of the whole network activity.\n\n    This class generates an animation that visualizes the activity of a neural network,\n    including input, rendering, predicted flow, and target flow if provided.\n\n    Attributes:\n        fig_backbone (WholeNetworkFigure): The backbone figure for the animation.\n        fig (matplotlib.figure.Figure): The main figure object.\n        ax_dict (dict): Dictionary of axes for different components of the animation.\n        batch_sample (int): The index of the batch sample to animate.\n        kwargs (dict): Additional keyword arguments.\n        update (bool): Whether to update the figure during animation.\n        label (str): Label format string for the animation.\n        labelxy (tuple[float, float]): Position of the label.\n        fontsize (int): Font size for labels.\n        cmap (matplotlib.colors.Colormap): Colormap for the animation.\n        n_samples (int): Number of samples in the responses.\n        frames (int): Number of frames in the responses.\n        responses (LayerActivity): Layer activity data.\n        cartesian_input (Optional[Any]): Cartesian input data.\n        rendered_input (Optional[Any]): Rendered input data.\n        predicted_flow (Optional[Any]): Predicted flow data.\n        target_flow (Optional[Any]): Target flow data.\n        color_norm_per (str): Color normalization method.\n        voltage_axes (list): List of voltage axes for different cell types.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: Any,\n        responses: Any,\n        cartesian_input: Optional[Any] = None,\n        rendered_input: Optional[Any] = None,\n        predicted_flow: Optional[Any] = None,\n        target_flow: Optional[Any] = None,\n        batch_sample: int = 0,\n        update: bool = False,\n        color_norm_per: Literal[\"batch\"] = \"batch\",\n        label: str = \"Sample: {}\\nFrame: {}\",\n        cmap: Any = plt.get_cmap(\"binary_r\"),\n        labelxy: tuple[float, float] = (0, 0.9),\n        titlepad: int = 1,\n        fontsize: int = 5,\n        **kwargs: Any,\n    ) -&gt; None:\n        self.fig_backbone = WholeNetworkFigure(\n            connectome,\n            video=cartesian_input is not None,\n            rendering=rendered_input is not None,\n            motion_decoder=predicted_flow is not None,\n            decoded_motion=predicted_flow is not None,\n            pixel_accurate_motion=target_flow is not None,\n        )\n        self.fig_backbone.init_figure()\n        self.fig = self.fig_backbone.fig\n        self.ax_dict = self.fig_backbone.ax_dict\n\n        plt.rc(\"axes\", titlepad=titlepad)\n        self.batch_sample = batch_sample\n        self.kwargs = kwargs\n        self.update = update\n        self.label = label\n        self.labelxy = labelxy\n        self.fontsize = fontsize\n        self.cmap = cmap\n        self.n_samples, self.frames = responses.shape[:2]\n\n        self.responses = LayerActivity(responses, connectome, keepref=True)\n        self.cartesian_input = cartesian_input\n        self.rendered_input = rendered_input\n        self.predicted_flow = predicted_flow\n        self.target_flow = target_flow\n        self.color_norm_per = color_norm_per\n        path = None\n        super().__init__(path, self.fig)\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"\n        Initialize the animation components.\n\n        Args:\n            frame: The initial frame number.\n        \"\"\"\n        if self.fig_backbone.video:\n            self.cartesian_input = Imshow(\n                self.cartesian_input,\n                vmin=0,\n                vmax=1,\n                cmap=plt.cm.binary_r,\n                fig=self.fig,\n                ax=self.ax_dict[\"video\"],\n            )\n            self.cartesian_input.init(frame)\n            self.cartesian_input.update = False\n\n        if self.fig_backbone.rendering:\n            self.rendered_input = HexScatter(\n                self.rendered_input,\n                vmin=0,\n                vmax=1,\n                cmap=plt.cm.binary_r,\n                fig=self.fig,\n                ax=self.ax_dict[\"rendering\"],\n                edgecolor=None,\n                cbar=False,\n                label=\"\",\n                background_color=self.fig_backbone.facecolor,\n            )\n            self.rendered_input.init(frame)\n            self.rendered_input.update = False\n\n        if self.fig_backbone.decoded_motion:\n            self.predicted_flow = HexFlow(\n                self.predicted_flow,\n                fig=self.fig,\n                ax=self.ax_dict[\"decoded motion\"],\n                label=\"\",\n                cwheel=True,\n                cwheelradius=0.5,\n                fontsize=5,\n            )\n            self.predicted_flow.init(frame)\n            self.predicted_flow.update = False\n\n        if self.fig_backbone.pixel_accurate_motion:\n            self.target_flow = HexFlow(\n                self.target_flow,\n                fig=self.fig,\n                ax=self.ax_dict[\"pixel-accurate motion\"],\n                label=\"\",\n            )\n            self.target_flow.init(frame)\n            self.target_flow.update = False\n\n        self.voltage_axes = []\n        for cell_type in self.fig_backbone.cell_types:\n            voltage = self.responses[cell_type][:, :, None]\n            nodes = self.fig_backbone.nodes\n            nodes = nodes[nodes.type == cell_type]\n            u, v = nodes[[\"u\", \"v\"]].values.T\n            anim = HexScatter(\n                voltage,\n                u=u,\n                v=v,\n                label=\"\",\n                cbar=False,\n                edgecolor=None,\n                ax=self.ax_dict[cell_type],\n                fig=self.fig,\n                cmap=plt.cm.binary_r,\n            )\n            anim.init(frame)\n            anim.update = False\n            self.voltage_axes.append(anim)\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"\n        Update the animation for a given frame.\n\n        Args:\n            frame: The current frame number.\n        \"\"\"\n        if self.fig_backbone.video:\n            self.cartesian_input.animate(frame)\n        if self.fig_backbone.rendering:\n            self.rendered_input.animate(frame)\n        if self.fig_backbone.decoded_motion:\n            self.predicted_flow.animate(frame)\n        if self.fig_backbone.pixel_accurate_motion:\n            self.target_flow.animate(frame)\n\n        for anim in self.voltage_axes:\n            anim.animate(frame)\n\n        if self.update:\n            self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.network.WholeNetworkAnimation.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation components.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>The initial frame number.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/network.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"\n    Initialize the animation components.\n\n    Args:\n        frame: The initial frame number.\n    \"\"\"\n    if self.fig_backbone.video:\n        self.cartesian_input = Imshow(\n            self.cartesian_input,\n            vmin=0,\n            vmax=1,\n            cmap=plt.cm.binary_r,\n            fig=self.fig,\n            ax=self.ax_dict[\"video\"],\n        )\n        self.cartesian_input.init(frame)\n        self.cartesian_input.update = False\n\n    if self.fig_backbone.rendering:\n        self.rendered_input = HexScatter(\n            self.rendered_input,\n            vmin=0,\n            vmax=1,\n            cmap=plt.cm.binary_r,\n            fig=self.fig,\n            ax=self.ax_dict[\"rendering\"],\n            edgecolor=None,\n            cbar=False,\n            label=\"\",\n            background_color=self.fig_backbone.facecolor,\n        )\n        self.rendered_input.init(frame)\n        self.rendered_input.update = False\n\n    if self.fig_backbone.decoded_motion:\n        self.predicted_flow = HexFlow(\n            self.predicted_flow,\n            fig=self.fig,\n            ax=self.ax_dict[\"decoded motion\"],\n            label=\"\",\n            cwheel=True,\n            cwheelradius=0.5,\n            fontsize=5,\n        )\n        self.predicted_flow.init(frame)\n        self.predicted_flow.update = False\n\n    if self.fig_backbone.pixel_accurate_motion:\n        self.target_flow = HexFlow(\n            self.target_flow,\n            fig=self.fig,\n            ax=self.ax_dict[\"pixel-accurate motion\"],\n            label=\"\",\n        )\n        self.target_flow.init(frame)\n        self.target_flow.update = False\n\n    self.voltage_axes = []\n    for cell_type in self.fig_backbone.cell_types:\n        voltage = self.responses[cell_type][:, :, None]\n        nodes = self.fig_backbone.nodes\n        nodes = nodes[nodes.type == cell_type]\n        u, v = nodes[[\"u\", \"v\"]].values.T\n        anim = HexScatter(\n            voltage,\n            u=u,\n            v=v,\n            label=\"\",\n            cbar=False,\n            edgecolor=None,\n            ax=self.ax_dict[cell_type],\n            fig=self.fig,\n            cmap=plt.cm.binary_r,\n        )\n        anim.init(frame)\n        anim.update = False\n        self.voltage_axes.append(anim)\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.network.WholeNetworkAnimation.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Update the animation for a given frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>The current frame number.</p> required Source code in <code>flyvis/analysis/animations/network.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"\n    Update the animation for a given frame.\n\n    Args:\n        frame: The current frame number.\n    \"\"\"\n    if self.fig_backbone.video:\n        self.cartesian_input.animate(frame)\n    if self.fig_backbone.rendering:\n        self.rendered_input.animate(frame)\n    if self.fig_backbone.decoded_motion:\n        self.predicted_flow.animate(frame)\n    if self.fig_backbone.pixel_accurate_motion:\n        self.target_flow.animate(frame)\n\n    for anim in self.voltage_axes:\n        anim.animate(frame)\n\n    if self.update:\n        self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationsanimations","title":"flyvis.analysis.animations.animations","text":""},{"location":"reference/animations/#classes_6","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation","title":"flyvis.analysis.animations.animations.Animation","text":"<p>Base class for animations.</p> <p>Subclasses must implement <code>init</code> and <code>animate</code> methods.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Union[str, Path]]</code> <p>Path to save the animation.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure instance or None.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix for the animation path.</p> <code>'{}'</code> <p>Attributes:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>Figure instance for the animation.</p> <code>update</code> <code>bool</code> <p>Whether to update the canvas after each animation step.</p> <code>batch_sample</code> <code>int</code> <p>Sample to animate.</p> <code>frames</code> <code>int</code> <p>Number of frames in the animation.</p> <code>n_samples</code> <code>int</code> <p>Number of samples in the animation.</p> <code>path</code> <code>Path</code> <p>Path to save the animation.</p> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>class Animation:\n    \"\"\"Base class for animations.\n\n    Subclasses must implement `init` and `animate` methods.\n\n    Args:\n        path: Path to save the animation.\n        fig: Existing Figure instance or None.\n        suffix: Suffix for the animation path.\n\n    Attributes:\n        fig (matplotlib.figure.Figure): Figure instance for the animation.\n        update (bool): Whether to update the canvas after each animation step.\n        batch_sample (int): Sample to animate.\n        frames (int): Number of frames in the animation.\n        n_samples (int): Number of samples in the animation.\n        path (Path): Path to save the animation.\n    \"\"\"\n\n    fig: Optional[matplotlib.figure.Figure] = None\n    update: bool = True\n    batch_sample: int = 0\n    frames: int = 0\n    n_samples: int = 0\n\n    def __init__(\n        self,\n        path: Optional[Union[str, Path]] = None,\n        fig: Optional[matplotlib.figure.Figure] = None,\n        suffix: str = \"{}\",\n    ):\n        self.path = Path(ANIMATION_DIR if path is None else path) / suffix.format(\n            self.__class__.__name__\n        )\n        self.fig = fig\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize the animation.\n\n        Args:\n            frame: Initial frame number.\n\n        Raises:\n            NotImplementedError: If not implemented by subclass.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses should implement this method.\")\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate a single frame.\n\n        Args:\n            frame: Frame number to animate.\n\n        Raises:\n            NotImplementedError: If not implemented by subclass.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses should implement this method.\")\n\n    def update_figure(self, clear_output: bool = True) -&gt; None:\n        \"\"\"Update the figure canvas.\n\n        Args:\n            clear_output: Whether to clear the previous output.\n        \"\"\"\n        self.fig.canvas.draw()\n        self.fig.canvas.flush_events()\n        if matplotlib.get_backend().lower() != \"nbagg\" or COLAB:\n            display.display(self.fig)\n            if clear_output:\n                display.clear_output(wait=True)\n\n    def animate_save(self, frame: int, dpi: int = 100) -&gt; None:\n        \"\"\"Update the figure to the given frame and save it.\n\n        Args:\n            frame: Frame number to animate and save.\n            dpi: Dots per inch for the saved image.\n        \"\"\"\n        self.animate(frame)\n        identifier = f\"{self.batch_sample:04}_{frame:04}\"\n        self.fig.savefig(\n            self._path / f\"{identifier}.png\",\n            dpi=dpi,\n            bbox_inches=\"tight\",\n            facecolor=self.fig.get_facecolor(),\n            edgecolor=\"none\",\n        )\n\n    def _get_indices(self, key: str, input: Union[str, Iterable]) -&gt; list[int]:\n        \"\"\"Get sorted list of indices based on input.\n\n        Args:\n            key: Attribute name to get total number of indices.\n            input: Input specifying which indices to return.\n\n        Returns:\n            Sorted list of indices.\n\n        Raises:\n            ValueError: If input is invalid.\n        \"\"\"\n        total = getattr(self, key)\n        _indices = set(range(total))\n        if isinstance(input, str) and input == \"all\":\n            indices = _indices\n        elif isinstance(input, Iterable):\n            indices = _indices.intersection(set(input))\n        else:\n            raise ValueError(f\"Invalid input for {key}: {input}\")\n        return sorted(indices)\n\n    def animate_in_notebook(\n        self,\n        frames: Union[str, Iterable] = \"all\",\n        samples: Union[str, Iterable] = \"all\",\n        repeat: int = 1,\n    ) -&gt; None:\n        \"\"\"Play animation within a Jupyter notebook.\n\n        Args:\n            frames: Frames to animate.\n            samples: Samples to animate.\n            repeat: Number of times to repeat the animation.\n        \"\"\"\n        frames_list, samples_list = self._initialize_animation(frames, samples)\n\n        if TESTING:\n            frames_list = frames_list[:1]\n            samples_list = samples_list[:1]\n            repeat = 1\n\n        try:\n            for _ in range(repeat):\n                for sample in samples_list:\n                    self.batch_sample = sample\n                    for frame in frames_list:\n                        self.animate(frame)\n                        sleep(0.1)  # Pause between frames\n        except KeyboardInterrupt:\n            print(\"Animation interrupted. Displaying last frame.\")\n            self.update_figure(clear_output=False)\n            return\n\n    def _verify_backend(self) -&gt; None:\n        \"\"\"Ensure the notebook backend is set correctly.\n\n        Raises:\n            RuntimeError: If matplotlib backend is not set to notebook.\n        \"\"\"\n        backend = matplotlib.get_backend().lower()\n        if backend != \"nbagg\" and not COLAB:\n            raise RuntimeError(\n                \"Matplotlib backend is not set to notebook. Use '%matplotlib notebook'.\"\n            )\n\n    def _initialize_animation(\n        self, frames: Union[str, Iterable], samples: Union[str, Iterable]\n    ) -&gt; tuple[list[int], list[int]]:\n        \"\"\"Initialize the animation state.\n\n        Args:\n            frames: Frames to animate.\n            samples: Samples to animate.\n\n        Returns:\n            Tuple of frames list and samples list.\n        \"\"\"\n        self.update = True\n        self.init()\n        frames_list = self._get_indices(\"frames\", frames)\n        samples_list = self._get_indices(\"n_samples\", samples)\n        return frames_list, samples_list\n\n    def plot(self, sample: int, frame: int) -&gt; None:\n        \"\"\"Plot a single frame for a specific sample.\n\n        Args:\n            sample: Sample number to plot.\n            frame: Frame number to plot.\n        \"\"\"\n        previous_sample = self.batch_sample\n        self.update = True\n        self.init()\n        self.batch_sample = sample\n        self.animate(frame)\n        self.batch_sample = previous_sample\n\n    def _create_temp_dir(self, path: Optional[Union[str, Path]] = None) -&gt; None:\n        \"\"\"Create a temporary directory as destination for the images.\n\n        Args:\n            path: Path to create the temporary directory.\n        \"\"\"\n        self._temp_dir = tempfile.TemporaryDirectory()\n        self._path = Path(self._temp_dir.name)\n\n    def to_vid(\n        self,\n        fname: str,\n        frames: Union[str, Iterable] = \"all\",\n        dpi: int = 100,\n        framerate: int = 30,\n        samples: Union[str, Iterable] = \"all\",\n        delete_if_exists: bool = False,\n        source_path: Optional[Union[str, Path]] = None,\n        dest_path: Optional[Union[str, Path]] = None,\n        type: Literal[\"mp4\", \"webm\"] = \"webm\",\n    ) -&gt; None:\n        \"\"\"Animate, save individual frames, and convert to video using ffmpeg.\n\n        Args:\n            fname: Output filename.\n            frames: Frames to animate.\n            dpi: Dots per inch for saved images.\n            framerate: Frame rate of the output video.\n            samples: Samples to animate.\n            delete_if_exists: Whether to delete existing output file.\n            source_path: Source path for temporary files.\n            dest_path: Destination path for the output video.\n            type: Output video type.\n        \"\"\"\n        self._create_temp_dir(path=source_path)\n        self.update = True\n        self.init()\n        frames_list = self._get_indices(\"frames\", frames)\n        samples_list = self._get_indices(\"n_samples\", samples)\n\n        try:\n            for sample in samples_list:\n                self.batch_sample = sample\n                for frame in frames_list:\n                    self.animate_save(frame, dpi=dpi)\n        except Exception as e:\n            logging.error(\"Error during animation: %s\", e)\n            raise\n\n        self.convert(\n            fname,\n            delete_if_exists=delete_if_exists,\n            framerate=framerate,\n            source_path=source_path,\n            dest_path=dest_path,\n            type=type,\n        )\n\n        self._temp_dir.cleanup()\n\n    def convert(\n        self,\n        fname: str,\n        delete_if_exists: bool = False,\n        framerate: int = 30,\n        source_path: Optional[Union[str, Path]] = None,\n        dest_path: Optional[Union[str, Path]] = None,\n        type: Literal[\"mp4\", \"webm\"] = \"mp4\",\n    ) -&gt; None:\n        \"\"\"Convert PNG files in the animations directory to video.\n\n        Args:\n            fname: Output filename.\n            delete_if_exists: Whether to delete existing output file.\n            framerate: Frame rate of the output video.\n            source_path: Source path for input PNG files.\n            dest_path: Destination path for the output video.\n            type: Output video type.\n        \"\"\"\n        dest_path = Path(dest_path or self.path)\n        dest_path.mkdir(parents=True, exist_ok=True)\n        convert(\n            source_path or self._path,\n            dest_path / f\"{fname}.{type}\",\n            framerate,\n            delete_if_exists,\n            type=type,\n        )\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Initial frame number.</p> <code>0</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented by subclass.</p> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize the animation.\n\n    Args:\n        frame: Initial frame number.\n\n    Raises:\n        NotImplementedError: If not implemented by subclass.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses should implement this method.\")\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to animate.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented by subclass.</p> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate a single frame.\n\n    Args:\n        frame: Frame number to animate.\n\n    Raises:\n        NotImplementedError: If not implemented by subclass.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses should implement this method.\")\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.update_figure","title":"update_figure","text":"<pre><code>update_figure(clear_output=True)\n</code></pre> <p>Update the figure canvas.</p> <p>Parameters:</p> Name Type Description Default <code>clear_output</code> <code>bool</code> <p>Whether to clear the previous output.</p> <code>True</code> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def update_figure(self, clear_output: bool = True) -&gt; None:\n    \"\"\"Update the figure canvas.\n\n    Args:\n        clear_output: Whether to clear the previous output.\n    \"\"\"\n    self.fig.canvas.draw()\n    self.fig.canvas.flush_events()\n    if matplotlib.get_backend().lower() != \"nbagg\" or COLAB:\n        display.display(self.fig)\n        if clear_output:\n            display.clear_output(wait=True)\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.animate_save","title":"animate_save","text":"<pre><code>animate_save(frame, dpi=100)\n</code></pre> <p>Update the figure to the given frame and save it.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to animate and save.</p> required <code>dpi</code> <code>int</code> <p>Dots per inch for the saved image.</p> <code>100</code> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def animate_save(self, frame: int, dpi: int = 100) -&gt; None:\n    \"\"\"Update the figure to the given frame and save it.\n\n    Args:\n        frame: Frame number to animate and save.\n        dpi: Dots per inch for the saved image.\n    \"\"\"\n    self.animate(frame)\n    identifier = f\"{self.batch_sample:04}_{frame:04}\"\n    self.fig.savefig(\n        self._path / f\"{identifier}.png\",\n        dpi=dpi,\n        bbox_inches=\"tight\",\n        facecolor=self.fig.get_facecolor(),\n        edgecolor=\"none\",\n    )\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.animate_in_notebook","title":"animate_in_notebook","text":"<pre><code>animate_in_notebook(frames='all', samples='all', repeat=1)\n</code></pre> <p>Play animation within a Jupyter notebook.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>Union[str, Iterable]</code> <p>Frames to animate.</p> <code>'all'</code> <code>samples</code> <code>Union[str, Iterable]</code> <p>Samples to animate.</p> <code>'all'</code> <code>repeat</code> <code>int</code> <p>Number of times to repeat the animation.</p> <code>1</code> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def animate_in_notebook(\n    self,\n    frames: Union[str, Iterable] = \"all\",\n    samples: Union[str, Iterable] = \"all\",\n    repeat: int = 1,\n) -&gt; None:\n    \"\"\"Play animation within a Jupyter notebook.\n\n    Args:\n        frames: Frames to animate.\n        samples: Samples to animate.\n        repeat: Number of times to repeat the animation.\n    \"\"\"\n    frames_list, samples_list = self._initialize_animation(frames, samples)\n\n    if TESTING:\n        frames_list = frames_list[:1]\n        samples_list = samples_list[:1]\n        repeat = 1\n\n    try:\n        for _ in range(repeat):\n            for sample in samples_list:\n                self.batch_sample = sample\n                for frame in frames_list:\n                    self.animate(frame)\n                    sleep(0.1)  # Pause between frames\n    except KeyboardInterrupt:\n        print(\"Animation interrupted. Displaying last frame.\")\n        self.update_figure(clear_output=False)\n        return\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.plot","title":"plot","text":"<pre><code>plot(sample, frame)\n</code></pre> <p>Plot a single frame for a specific sample.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>int</code> <p>Sample number to plot.</p> required <code>frame</code> <code>int</code> <p>Frame number to plot.</p> required Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def plot(self, sample: int, frame: int) -&gt; None:\n    \"\"\"Plot a single frame for a specific sample.\n\n    Args:\n        sample: Sample number to plot.\n        frame: Frame number to plot.\n    \"\"\"\n    previous_sample = self.batch_sample\n    self.update = True\n    self.init()\n    self.batch_sample = sample\n    self.animate(frame)\n    self.batch_sample = previous_sample\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.to_vid","title":"to_vid","text":"<pre><code>to_vid(fname, frames='all', dpi=100, framerate=30, samples='all', delete_if_exists=False, source_path=None, dest_path=None, type='webm')\n</code></pre> <p>Animate, save individual frames, and convert to video using ffmpeg.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>str</code> <p>Output filename.</p> required <code>frames</code> <code>Union[str, Iterable]</code> <p>Frames to animate.</p> <code>'all'</code> <code>dpi</code> <code>int</code> <p>Dots per inch for saved images.</p> <code>100</code> <code>framerate</code> <code>int</code> <p>Frame rate of the output video.</p> <code>30</code> <code>samples</code> <code>Union[str, Iterable]</code> <p>Samples to animate.</p> <code>'all'</code> <code>delete_if_exists</code> <code>bool</code> <p>Whether to delete existing output file.</p> <code>False</code> <code>source_path</code> <code>Optional[Union[str, Path]]</code> <p>Source path for temporary files.</p> <code>None</code> <code>dest_path</code> <code>Optional[Union[str, Path]]</code> <p>Destination path for the output video.</p> <code>None</code> <code>type</code> <code>Literal['mp4', 'webm']</code> <p>Output video type.</p> <code>'webm'</code> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def to_vid(\n    self,\n    fname: str,\n    frames: Union[str, Iterable] = \"all\",\n    dpi: int = 100,\n    framerate: int = 30,\n    samples: Union[str, Iterable] = \"all\",\n    delete_if_exists: bool = False,\n    source_path: Optional[Union[str, Path]] = None,\n    dest_path: Optional[Union[str, Path]] = None,\n    type: Literal[\"mp4\", \"webm\"] = \"webm\",\n) -&gt; None:\n    \"\"\"Animate, save individual frames, and convert to video using ffmpeg.\n\n    Args:\n        fname: Output filename.\n        frames: Frames to animate.\n        dpi: Dots per inch for saved images.\n        framerate: Frame rate of the output video.\n        samples: Samples to animate.\n        delete_if_exists: Whether to delete existing output file.\n        source_path: Source path for temporary files.\n        dest_path: Destination path for the output video.\n        type: Output video type.\n    \"\"\"\n    self._create_temp_dir(path=source_path)\n    self.update = True\n    self.init()\n    frames_list = self._get_indices(\"frames\", frames)\n    samples_list = self._get_indices(\"n_samples\", samples)\n\n    try:\n        for sample in samples_list:\n            self.batch_sample = sample\n            for frame in frames_list:\n                self.animate_save(frame, dpi=dpi)\n    except Exception as e:\n        logging.error(\"Error during animation: %s\", e)\n        raise\n\n    self.convert(\n        fname,\n        delete_if_exists=delete_if_exists,\n        framerate=framerate,\n        source_path=source_path,\n        dest_path=dest_path,\n        type=type,\n    )\n\n    self._temp_dir.cleanup()\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.Animation.convert","title":"convert","text":"<pre><code>convert(fname, delete_if_exists=False, framerate=30, source_path=None, dest_path=None, type='mp4')\n</code></pre> <p>Convert PNG files in the animations directory to video.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>str</code> <p>Output filename.</p> required <code>delete_if_exists</code> <code>bool</code> <p>Whether to delete existing output file.</p> <code>False</code> <code>framerate</code> <code>int</code> <p>Frame rate of the output video.</p> <code>30</code> <code>source_path</code> <code>Optional[Union[str, Path]]</code> <p>Source path for input PNG files.</p> <code>None</code> <code>dest_path</code> <code>Optional[Union[str, Path]]</code> <p>Destination path for the output video.</p> <code>None</code> <code>type</code> <code>Literal['mp4', 'webm']</code> <p>Output video type.</p> <code>'mp4'</code> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def convert(\n    self,\n    fname: str,\n    delete_if_exists: bool = False,\n    framerate: int = 30,\n    source_path: Optional[Union[str, Path]] = None,\n    dest_path: Optional[Union[str, Path]] = None,\n    type: Literal[\"mp4\", \"webm\"] = \"mp4\",\n) -&gt; None:\n    \"\"\"Convert PNG files in the animations directory to video.\n\n    Args:\n        fname: Output filename.\n        delete_if_exists: Whether to delete existing output file.\n        framerate: Frame rate of the output video.\n        source_path: Source path for input PNG files.\n        dest_path: Destination path for the output video.\n        type: Output video type.\n    \"\"\"\n    dest_path = Path(dest_path or self.path)\n    dest_path.mkdir(parents=True, exist_ok=True)\n    convert(\n        source_path or self._path,\n        dest_path / f\"{fname}.{type}\",\n        framerate,\n        delete_if_exists,\n        type=type,\n    )\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.AnimationCollector","title":"flyvis.analysis.animations.animations.AnimationCollector","text":"<p>               Bases: <code>Animation</code></p> <p>Collects Animations and updates all axes at once.</p> <p>Subclasses must populate the <code>animations</code> attribute with Animation objects and adhere to the Animation interface.</p> <p>Attributes:</p> Name Type Description <code>animations</code> <code>list[Animation]</code> <p>List of Animation objects to collect.</p> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>class AnimationCollector(Animation):\n    \"\"\"Collects Animations and updates all axes at once.\n\n    Subclasses must populate the `animations` attribute with Animation objects\n    and adhere to the Animation interface.\n\n    Attributes:\n        animations (list[Animation]): List of Animation objects to collect.\n    \"\"\"\n\n    animations: list[Animation] = []\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize all collected animations.\n\n        Args:\n            frame: Initial frame number.\n        \"\"\"\n        for animation in self.animations:\n            animation.init(frame)\n            animation.update = False\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate all collected animations for a single frame.\n\n        Args:\n            frame: Frame number to animate.\n        \"\"\"\n        for animation in self.animations:\n            animation.animate(frame)\n        if self.update:\n            self.update_figure()\n\n    def __setattr__(self, key: str, val: Any) -&gt; None:\n        \"\"\"Set attributes for all Animation objects at once.\n\n        Args:\n            key: Attribute name to set.\n            val: Value to set for the attribute.\n        \"\"\"\n        if key == \"batch_sample\" and hasattr(self, \"animations\"):\n            for animation in self.animations:\n                setattr(animation, key, val)\n        super().__setattr__(key, val)\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.AnimationCollector.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize all collected animations.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Initial frame number.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize all collected animations.\n\n    Args:\n        frame: Initial frame number.\n    \"\"\"\n    for animation in self.animations:\n        animation.init(frame)\n        animation.update = False\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.AnimationCollector.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate all collected animations for a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Frame number to animate.</p> required Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate all collected animations for a single frame.\n\n    Args:\n        frame: Frame number to animate.\n    \"\"\"\n    for animation in self.animations:\n        animation.animate(frame)\n    if self.update:\n        self.update_figure()\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.animations.AnimationCollector.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(key, val)\n</code></pre> <p>Set attributes for all Animation objects at once.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Attribute name to set.</p> required <code>val</code> <code>Any</code> <p>Value to set for the attribute.</p> required Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def __setattr__(self, key: str, val: Any) -&gt; None:\n    \"\"\"Set attributes for all Animation objects at once.\n\n    Args:\n        key: Attribute name to set.\n        val: Value to set for the attribute.\n    \"\"\"\n    if key == \"batch_sample\" and hasattr(self, \"animations\"):\n        for animation in self.animations:\n            setattr(animation, key, val)\n    super().__setattr__(key, val)\n</code></pre>"},{"location":"reference/animations/#functions","title":"Functions","text":""},{"location":"reference/animations/#flyvis.analysis.animations.animations.convert","title":"flyvis.analysis.animations.animations.convert","text":"<pre><code>convert(directory, dest, framerate, delete_if_exists, type='mp4')\n</code></pre> <p>Convert PNG files in directory to MP4 or WebM.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Union[str, Path]</code> <p>Source directory containing PNG files.</p> required <code>dest</code> <code>Union[str, Path]</code> <p>Destination path for the output video.</p> required <code>framerate</code> <code>int</code> <p>Frame rate of the output video.</p> required <code>delete_if_exists</code> <code>bool</code> <p>Whether to delete existing output file.</p> required <code>type</code> <code>Literal['mp4', 'webm']</code> <p>Output video type.</p> <code>'mp4'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If unsupported video type is specified.</p> <code>FileExistsError</code> <p>If output file exists and delete_if_exists is False.</p> Source code in <code>flyvis/analysis/animations/animations.py</code> <pre><code>def convert(\n    directory: Union[str, Path],\n    dest: Union[str, Path],\n    framerate: int,\n    delete_if_exists: bool,\n    type: Literal[\"mp4\", \"webm\"] = \"mp4\",\n) -&gt; None:\n    \"\"\"Convert PNG files in directory to MP4 or WebM.\n\n    Args:\n        directory: Source directory containing PNG files.\n        dest: Destination path for the output video.\n        framerate: Frame rate of the output video.\n        delete_if_exists: Whether to delete existing output file.\n        type: Output video type.\n\n    Raises:\n        ValueError: If unsupported video type is specified.\n        FileExistsError: If output file exists and delete_if_exists is False.\n    \"\"\"\n    video = Path(dest)\n\n    if type == \"mp4\":\n        kwargs = dict(\n            vcodec=\"libx264\",\n            vprofile=\"high\",\n            vlevel=\"4.0\",\n            vf=\"pad=ceil(iw/2)*2:ceil(ih/2)*2\",  # to make sizes even\n            pix_fmt=\"yuv420p\",\n            crf=18,\n        )\n    elif type == \"webm\":\n        kwargs = dict(\n            vcodec=\"libvpx-vp9\",\n            vf=\"pad=ceil(iw/2)*2:ceil(ih/2)*2\",\n            pix_fmt=\"yuva420p\",\n            crf=18,\n            threads=4,\n        )\n    else:\n        raise ValueError(f\"Unsupported video type: {type}\")\n\n    if video.exists():\n        if delete_if_exists:\n            video.unlink()\n        else:\n            raise FileExistsError(f\"File {video} already exists.\")\n\n    try:\n        (\n            ffmpeg.input(f\"{directory}/*_*.png\", pattern_type=\"glob\", framerate=framerate)\n            .output(str(video), **kwargs)\n            .run(\n                overwrite_output=True,\n                quiet=True,\n                capture_stdout=True,\n                capture_stderr=True,\n            )\n        )\n    except FileNotFoundError as e:\n        if \"ffmpeg\" in str(e):\n            logging.warning(\"Check ffmpeg installation: %s\", e)\n            return\n        else:\n            raise\n    except ffmpeg.Error as e:\n        logging.error(\"ffmpeg error: %s\", e.stderr.decode(\"utf8\"))\n        raise e\n\n    logging.info(\"Created %s\", video)\n</code></pre>"},{"location":"reference/animations/#flyvisanalysisanimationstraces","title":"flyvis.analysis.animations.traces","text":""},{"location":"reference/animations/#classes_7","title":"Classes","text":""},{"location":"reference/animations/#flyvis.analysis.animations.traces.Trace","title":"flyvis.analysis.animations.traces.Trace","text":"<p>               Bases: <code>Animation</code></p> <p>Animates a trace.</p> <p>Parameters:</p> Name Type Description Default <code>trace</code> <code>ndarray</code> <p>Trace of shape (n_samples, n_frames).</p> required <code>dt</code> <code>float</code> <p>Time step in seconds for accurate time axis.</p> <code>1</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure instance or None.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axis instance or None.</p> <code>None</code> <code>update</code> <code>bool</code> <p>Whether to update the canvas after an animation step. Must be False if this animation is composed with others.</p> <code>False</code> <code>color</code> <code>Optional[Union[str, ndarray]]</code> <p>Optional color of the trace.</p> <code>None</code> <code>title</code> <code>str</code> <p>Optional title of the animation.</p> <code>''</code> <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> <code>0</code> <code>dynamic_ax_lims</code> <code>bool</code> <p>Whether the ax limits of the trace are animated.</p> <code>True</code> <code>ylims</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Static y-limits for the trace for each sample.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Optional y-label of the trace.</p> <code>''</code> <code>contour</code> <code>Optional[ndarray]</code> <p>Optional background contour for trace in x direction.</p> <code>None</code> <code>label</code> <code>str</code> <p>Label of the animation. Formatted with the current sample and frame number.</p> <code>'Sample: {}\\nFrame: {}'</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Normalized x and y location of the label.</p> <code>(0.1, 0.95)</code> <code>fontsize</code> <code>float</code> <p>Fontsize.</p> <code>5</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Figure size.</p> <code>(2, 2)</code> <p>Attributes:</p> Name Type Description <code>trace</code> <code>ndarray</code> <p>Trace data.</p> <code>n_samples</code> <code>int</code> <p>Number of samples.</p> <code>frames</code> <code>int</code> <p>Number of frames.</p> <code>fig</code> <code>Optional[Figure]</code> <p>Figure instance.</p> <code>ax</code> <code>Optional[Axes]</code> <p>Axes instance.</p> <code>update</code> <code>bool</code> <p>Update flag.</p> <code>color</code> <code>Optional[Union[str, ndarray]]</code> <p>Color of the trace.</p> <code>label</code> <code>str</code> <p>Label format string.</p> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Label position.</p> <code>label_text</code> <p>Label text object.</p> <code>batch_sample</code> <code>int</code> <p>Current batch sample.</p> <code>fontsize</code> <code>float</code> <p>Font size.</p> <code>dynamic_ax_lims</code> <code>bool</code> <p>Dynamic axis limits flag.</p> <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> <code>ylims</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Y-axis limits.</p> <code>title</code> <code>str</code> <p>Plot title.</p> <code>contour</code> <code>Optional[ndarray]</code> <p>Contour data.</p> <code>contour_lims</code> <code>Optional[ndarray]</code> <p>Contour limits.</p> <code>dt</code> <code>float</code> <p>Time step.</p> <code>figsize</code> <code>Tuple[float, float]</code> <p>Figure size.</p> Source code in <code>flyvis/analysis/animations/traces.py</code> <pre><code>class Trace(Animation):\n    \"\"\"Animates a trace.\n\n    Args:\n        trace: Trace of shape (n_samples, n_frames).\n        dt: Time step in seconds for accurate time axis.\n        fig: Existing Figure instance or None.\n        ax: Existing Axis instance or None.\n        update: Whether to update the canvas after an animation step.\n            Must be False if this animation is composed with others.\n        color: Optional color of the trace.\n        title: Optional title of the animation.\n        batch_sample: Batch sample to start from.\n        dynamic_ax_lims: Whether the ax limits of the trace are animated.\n        ylims: Static y-limits for the trace for each sample.\n        ylabel: Optional y-label of the trace.\n        contour: Optional background contour for trace in x direction.\n        label: Label of the animation. Formatted with the current sample and frame number.\n        labelxy: Normalized x and y location of the label.\n        fontsize: Fontsize.\n        figsize: Figure size.\n\n    Attributes:\n        trace (np.ndarray): Trace data.\n        n_samples (int): Number of samples.\n        frames (int): Number of frames.\n        fig (Optional[Figure]): Figure instance.\n        ax (Optional[Axes]): Axes instance.\n        update (bool): Update flag.\n        color (Optional[Union[str, np.ndarray]]): Color of the trace.\n        label (str): Label format string.\n        labelxy (Tuple[float, float]): Label position.\n        label_text: Label text object.\n        batch_sample (int): Current batch sample.\n        fontsize (float): Font size.\n        dynamic_ax_lims (bool): Dynamic axis limits flag.\n        ylabel (str): Y-axis label.\n        ylims (Optional[List[Tuple[float, float]]]): Y-axis limits.\n        title (str): Plot title.\n        contour (Optional[np.ndarray]): Contour data.\n        contour_lims (Optional[np.ndarray]): Contour limits.\n        dt (float): Time step.\n        figsize (Tuple[float, float]): Figure size.\n    \"\"\"\n\n    def __init__(\n        self,\n        trace: np.ndarray,\n        dt: float = 1,\n        fig: Optional[Figure] = None,\n        ax: Optional[Axes] = None,\n        update: bool = False,\n        color: Optional[Union[str, np.ndarray]] = None,\n        title: str = \"\",\n        batch_sample: int = 0,\n        dynamic_ax_lims: bool = True,\n        ylims: Optional[List[Tuple[float, float]]] = None,\n        ylabel: str = \"\",\n        contour: Optional[np.ndarray] = None,\n        label: str = \"Sample: {}\\nFrame: {}\",\n        labelxy: Tuple[float, float] = (0.1, 0.95),\n        fontsize: float = 5,\n        figsize: Tuple[float, float] = (2, 2),\n    ):\n        self.trace = utils.tensor_utils.to_numpy(trace)\n        self.n_samples, self.frames = self.trace.shape\n        self.fig = fig\n        self.ax = ax\n        self.update = update\n        self.color = color\n        self.label = label\n        self.labelxy = labelxy\n        self.label_text = None\n        self.batch_sample = batch_sample\n        self.fontsize = fontsize\n        self._initial_frame = 0\n        self.dynamic_ax_lims = dynamic_ax_lims\n        self.ylabel = ylabel\n        self.ylims = ylims\n        self.title = title\n        self.contour = contour\n        if self.contour is not None:\n            self.contour_lims = np.array([\n                plt_utils.get_lims(c, 0.01) for c in self.contour\n            ])\n        self.dt = dt\n        self.figsize = figsize\n        super().__init__(None, self.fig)\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize the animation.\n\n        Args:\n            frame: Starting frame number.\n        \"\"\"\n        if frame &lt; 0:\n            frame += self.frames\n        trace = self.trace[self.batch_sample, self._initial_frame : frame + 1]\n        x = np.arange(frame + 1) * self.dt\n        self.fig, self.ax, _, self.label_text = plots.traces(\n            trace,\n            x=x,\n            contour=None,\n            smooth=None,\n            fig=self.fig,\n            ax=self.ax,\n            label=self.label,\n            color=self.color,\n            labelxy=self.labelxy,\n            xlabel=\"time in s\",\n            ylabel=self.ylabel,\n            fontsize=self.fontsize,\n            title=self.title,\n            figsize=self.figsize,\n        )\n\n        self._plot_contour()\n\n        if self.dynamic_ax_lims:\n            if self.ylims is not None:\n                ymin, ymax = self.ylims[self.batch_sample]\n            else:\n                ymin, ymax = plt_utils.get_lims(trace, 0.1)\n            xmin, xmax = plt_utils.get_lims(x, 0.1)\n            self.ax.axis([xmin, xmax, ymin, ymax])\n\n        self._sample = self.batch_sample\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate a single frame.\n\n        Args:\n            frame: Current frame number.\n        \"\"\"\n        if frame &lt; 0:\n            frame += self.frames\n        trace = self.trace[self.batch_sample, self._initial_frame : frame]\n        x = np.arange(self._initial_frame, frame) * self.dt\n        self.ax.lines[0].set_data(x, trace)\n\n        if self.batch_sample != self._sample:\n            self._plot_contour()\n\n        if self.dynamic_ax_lims:\n            if self.ylims is not None:\n                ymin, ymax = self.ylims[self.batch_sample]\n            else:\n                ymin, ymax = plt_utils.get_lims(trace, 0.1)\n            xmin, xmax = plt_utils.get_lims(x, 0.1)\n            self.ax.axis([xmin, xmax, ymin, ymax])\n\n        if self.label:\n            self.label_text.set_text(self.label.format(self.batch_sample))\n\n        if self.update:\n            self.update_figure()\n\n        self._sample = self.batch_sample\n\n    def _plot_contour(self) -&gt; None:\n        \"\"\"Plot the contour if available.\"\"\"\n        if self.contour is None:\n            return\n\n        contour = self.contour[self.batch_sample]\n\n        while self.ax.collections:\n            for c in self.ax.collections:\n                c.remove()\n\n        x = np.arange(len(contour)) * self.dt\n        _y = np.linspace(-2000, 2000, 100)\n        Z = np.tile(contour, (len(_y), 1))\n\n        self.ax.contourf(\n            x,\n            _y,\n            Z,\n            cmap=cm.get_cmap(\"binary_r\"),\n            levels=20,\n            zorder=-100,\n            alpha=0.2,\n            vmin=self.contour_lims[self.batch_sample, 0],\n            vmax=self.contour_lims[self.batch_sample, 1],\n        )\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.traces.Trace.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Starting frame number.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/traces.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize the animation.\n\n    Args:\n        frame: Starting frame number.\n    \"\"\"\n    if frame &lt; 0:\n        frame += self.frames\n    trace = self.trace[self.batch_sample, self._initial_frame : frame + 1]\n    x = np.arange(frame + 1) * self.dt\n    self.fig, self.ax, _, self.label_text = plots.traces(\n        trace,\n        x=x,\n        contour=None,\n        smooth=None,\n        fig=self.fig,\n        ax=self.ax,\n        label=self.label,\n        color=self.color,\n        labelxy=self.labelxy,\n        xlabel=\"time in s\",\n        ylabel=self.ylabel,\n        fontsize=self.fontsize,\n        title=self.title,\n        figsize=self.figsize,\n    )\n\n    self._plot_contour()\n\n    if self.dynamic_ax_lims:\n        if self.ylims is not None:\n            ymin, ymax = self.ylims[self.batch_sample]\n        else:\n            ymin, ymax = plt_utils.get_lims(trace, 0.1)\n        xmin, xmax = plt_utils.get_lims(x, 0.1)\n        self.ax.axis([xmin, xmax, ymin, ymax])\n\n    self._sample = self.batch_sample\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.traces.Trace.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Current frame number.</p> required Source code in <code>flyvis/analysis/animations/traces.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate a single frame.\n\n    Args:\n        frame: Current frame number.\n    \"\"\"\n    if frame &lt; 0:\n        frame += self.frames\n    trace = self.trace[self.batch_sample, self._initial_frame : frame]\n    x = np.arange(self._initial_frame, frame) * self.dt\n    self.ax.lines[0].set_data(x, trace)\n\n    if self.batch_sample != self._sample:\n        self._plot_contour()\n\n    if self.dynamic_ax_lims:\n        if self.ylims is not None:\n            ymin, ymax = self.ylims[self.batch_sample]\n        else:\n            ymin, ymax = plt_utils.get_lims(trace, 0.1)\n        xmin, xmax = plt_utils.get_lims(x, 0.1)\n        self.ax.axis([xmin, xmax, ymin, ymax])\n\n    if self.label:\n        self.label_text.set_text(self.label.format(self.batch_sample))\n\n    if self.update:\n        self.update_figure()\n\n    self._sample = self.batch_sample\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.traces.MultiTrace","title":"flyvis.analysis.animations.traces.MultiTrace","text":"<p>               Bases: <code>Animation</code></p> <p>Animates multiple traces in single plot.</p> <p>Parameters:</p> Name Type Description Default <code>trace</code> <code>ndarray</code> <p>Trace of shape (n_samples, n_frames, n_traces).</p> required <code>dt</code> <code>float</code> <p>Time step in seconds.</p> <code>1</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure instance or None.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axis instance or None.</p> <code>None</code> <code>update</code> <code>bool</code> <p>Whether to update the figure after each frame.</p> <code>False</code> <code>legend</code> <code>Optional[List[str]]</code> <p>Legends of the traces.</p> <code>None</code> <code>colors</code> <code>Optional[List[Union[str, ndarray]]]</code> <p>Optional colors of the traces.</p> <code>None</code> <code>title</code> <code>str</code> <p>Optional title of the animation.</p> <code>''</code> <code>batch_sample</code> <code>int</code> <p>Batch sample to start from.</p> <code>0</code> <code>dynamic_ax_lims</code> <code>bool</code> <p>Whether the ax limits of the trace are animated.</p> <code>True</code> <code>ylims</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Static y-limits for the trace for each sample.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Optional y-label of the trace.</p> <code>''</code> <code>contour</code> <code>Optional[ndarray]</code> <p>Optional background contour for trace in x direction.</p> <code>None</code> <code>label</code> <code>str</code> <p>Label of the animation. Formatted with the current sample and frame number.</p> <code>'Sample: {}\\nFrame: {}'</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Normalized x and y location of the label.</p> <code>(0.1, 0.95)</code> <code>fontsize</code> <code>float</code> <p>Fontsize.</p> <code>5</code> <code>path</code> <code>Optional[str]</code> <p>Path object to save animation to.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>trace</code> <code>ndarray</code> <p>Trace data.</p> <code>n_samples</code> <code>int</code> <p>Number of samples.</p> <code>frames</code> <code>int</code> <p>Number of frames.</p> <code>n_trace</code> <code>int</code> <p>Number of traces.</p> <code>fig</code> <code>Optional[Figure]</code> <p>Figure instance.</p> <code>ax</code> <code>Optional[Axes]</code> <p>Axes instance.</p> <code>update</code> <code>bool</code> <p>Update flag.</p> <code>colors</code> <code>Optional[List[Union[str, ndarray]]]</code> <p>Colors of the traces.</p> <code>label</code> <code>str</code> <p>Label format string.</p> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Label position.</p> <code>label_text</code> <p>Label text object.</p> <code>legend</code> <code>Optional[List[str]]</code> <p>Legend labels.</p> <code>batch_sample</code> <code>int</code> <p>Current batch sample.</p> <code>fontsize</code> <code>float</code> <p>Font size.</p> <code>dynamic_ax_lims</code> <code>bool</code> <p>Dynamic axis limits flag.</p> <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> <code>ylims</code> <code>Optional[List[Tuple[float, float]]]</code> <p>Y-axis limits.</p> <code>title</code> <code>str</code> <p>Plot title.</p> <code>contour</code> <code>Optional[ndarray]</code> <p>Contour data.</p> <code>dt</code> <code>float</code> <p>Time step.</p> Source code in <code>flyvis/analysis/animations/traces.py</code> <pre><code>class MultiTrace(Animation):\n    \"\"\"Animates multiple traces in single plot.\n\n    Args:\n        trace: Trace of shape (n_samples, n_frames, n_traces).\n        dt: Time step in seconds.\n        fig: Existing Figure instance or None.\n        ax: Existing Axis instance or None.\n        update: Whether to update the figure after each frame.\n        legend: Legends of the traces.\n        colors: Optional colors of the traces.\n        title: Optional title of the animation.\n        batch_sample: Batch sample to start from.\n        dynamic_ax_lims: Whether the ax limits of the trace are animated.\n        ylims: Static y-limits for the trace for each sample.\n        ylabel: Optional y-label of the trace.\n        contour: Optional background contour for trace in x direction.\n        label: Label of the animation. Formatted with the current sample and frame number.\n        labelxy: Normalized x and y location of the label.\n        fontsize: Fontsize.\n        path: Path object to save animation to.\n\n    Attributes:\n        trace (np.ndarray): Trace data.\n        n_samples (int): Number of samples.\n        frames (int): Number of frames.\n        n_trace (int): Number of traces.\n        fig (Optional[Figure]): Figure instance.\n        ax (Optional[Axes]): Axes instance.\n        update (bool): Update flag.\n        colors (Optional[List[Union[str, np.ndarray]]]): Colors of the traces.\n        label (str): Label format string.\n        labelxy (Tuple[float, float]): Label position.\n        label_text: Label text object.\n        legend (Optional[List[str]]): Legend labels.\n        batch_sample (int): Current batch sample.\n        fontsize (float): Font size.\n        dynamic_ax_lims (bool): Dynamic axis limits flag.\n        ylabel (str): Y-axis label.\n        ylims (Optional[List[Tuple[float, float]]]): Y-axis limits.\n        title (str): Plot title.\n        contour (Optional[np.ndarray]): Contour data.\n        dt (float): Time step.\n    \"\"\"\n\n    def __init__(\n        self,\n        trace: np.ndarray,\n        dt: float = 1,\n        fig: Optional[Figure] = None,\n        ax: Optional[Axes] = None,\n        update: bool = False,\n        legend: Optional[List[str]] = None,\n        colors: Optional[List[Union[str, np.ndarray]]] = None,\n        title: str = \"\",\n        batch_sample: int = 0,\n        dynamic_ax_lims: bool = True,\n        ylims: Optional[List[Tuple[float, float]]] = None,\n        ylabel: str = \"\",\n        contour: Optional[np.ndarray] = None,\n        label: str = \"Sample: {}\\nFrame: {}\",\n        labelxy: Tuple[float, float] = (0.1, 0.95),\n        fontsize: float = 5,\n        path: Optional[str] = None,\n    ):\n        self.trace = utils.tensor_utils.to_numpy(trace)\n        self.n_samples, self.frames, self.n_trace = self.trace.shape\n        self.fig = fig\n        self.ax = ax\n        self.update = update\n        self.colors = colors\n        self.label = label\n        self.labelxy = labelxy\n        self.label_text = None\n        self.legend = legend\n        self.batch_sample = batch_sample\n        self.fontsize = fontsize\n        self._initial_frame = 0\n        self.dynamic_ax_lims = dynamic_ax_lims\n        self.ylabel = ylabel\n        self.ylims = ylims\n        self.title = title\n        self.contour = contour\n        self.dt = dt\n        super().__init__(path, self.fig)\n\n    def init(self, frame: int = 0) -&gt; None:\n        \"\"\"Initialize the animation.\n\n        Args:\n            frame: Starting frame number.\n        \"\"\"\n        self._initial_frame = frame\n        trace = self.trace[self.batch_sample, frame]\n        x = np.arange(frame + 1) * self.dt\n        self.fig, self.ax, _, self.label_text = plots.traces(\n            trace[:, None],\n            x=x,\n            contour=self.contour,\n            smooth=None,\n            fig=self.fig,\n            ax=self.ax,\n            label=self.label,\n            color=self.colors,\n            labelxy=self.labelxy,\n            xlabel=\"time (s)\",\n            ylabel=self.ylabel,\n            fontsize=self.fontsize,\n            title=self.title,\n            legend=self.legend,\n        )\n        if not self.dynamic_ax_lims:\n            if self.ylims is not None:\n                ymin, ymax = self.ylims[self.batch_sample]\n            else:\n                ymin, ymax = plt_utils.get_lims(self.trace, 0.1)\n            xmin, xmax = plt_utils.get_lims(\n                np.arange(self._initial_frame, self.trace.shape[1]), 0.1\n            )\n            self.ax.axis([xmin, xmax, ymin, ymax])\n\n        self._sample = self.batch_sample\n\n    def animate(self, frame: int) -&gt; None:\n        \"\"\"Animate a single frame.\n\n        Args:\n            frame: Current frame number.\n        \"\"\"\n        trace = self.trace[self.batch_sample, self._initial_frame : frame]\n        x = np.arange(self._initial_frame, frame) * self.dt\n\n        for n in range(self.n_trace):\n            self.ax.lines[n].set_data(x, trace[:, n])\n\n        contour = self.contour[self.batch_sample] if self.contour is not None else None\n\n        if self.batch_sample != self._sample and contour is not None:\n            self.ax.collections = []\n            _x = np.arange(len(contour))\n            _y = np.linspace(-2000, 2000, 100)\n            Z = np.tile(contour, (len(_y), 1))\n            self.ax.contourf(\n                _x,\n                _y,\n                Z,\n                cmap=cm.get_cmap(\"bone\"),\n                levels=2,\n                alpha=0.3,\n                vmin=0,\n                vmax=1,\n            )\n\n        if self.dynamic_ax_lims:\n            if self.ylims is not None:\n                ymin, ymax = self.ylims[self.batch_sample]\n            else:\n                ymin, ymax = plt_utils.get_lims(trace, 0.1)\n            xmin, xmax = plt_utils.get_lims(x, 0.1)\n            self.ax.axis([xmin, xmax, ymin, ymax])\n\n        if self.label:\n            self.label_text.set_text(self.label.format(self.batch_sample, frame))\n\n        if self.update:\n            self.update_figure()\n\n        self._sample = self.batch_sample\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.traces.MultiTrace.init","title":"init","text":"<pre><code>init(frame=0)\n</code></pre> <p>Initialize the animation.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Starting frame number.</p> <code>0</code> Source code in <code>flyvis/analysis/animations/traces.py</code> <pre><code>def init(self, frame: int = 0) -&gt; None:\n    \"\"\"Initialize the animation.\n\n    Args:\n        frame: Starting frame number.\n    \"\"\"\n    self._initial_frame = frame\n    trace = self.trace[self.batch_sample, frame]\n    x = np.arange(frame + 1) * self.dt\n    self.fig, self.ax, _, self.label_text = plots.traces(\n        trace[:, None],\n        x=x,\n        contour=self.contour,\n        smooth=None,\n        fig=self.fig,\n        ax=self.ax,\n        label=self.label,\n        color=self.colors,\n        labelxy=self.labelxy,\n        xlabel=\"time (s)\",\n        ylabel=self.ylabel,\n        fontsize=self.fontsize,\n        title=self.title,\n        legend=self.legend,\n    )\n    if not self.dynamic_ax_lims:\n        if self.ylims is not None:\n            ymin, ymax = self.ylims[self.batch_sample]\n        else:\n            ymin, ymax = plt_utils.get_lims(self.trace, 0.1)\n        xmin, xmax = plt_utils.get_lims(\n            np.arange(self._initial_frame, self.trace.shape[1]), 0.1\n        )\n        self.ax.axis([xmin, xmax, ymin, ymax])\n\n    self._sample = self.batch_sample\n</code></pre>"},{"location":"reference/animations/#flyvis.analysis.animations.traces.MultiTrace.animate","title":"animate","text":"<pre><code>animate(frame)\n</code></pre> <p>Animate a single frame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>int</code> <p>Current frame number.</p> required Source code in <code>flyvis/analysis/animations/traces.py</code> <pre><code>def animate(self, frame: int) -&gt; None:\n    \"\"\"Animate a single frame.\n\n    Args:\n        frame: Current frame number.\n    \"\"\"\n    trace = self.trace[self.batch_sample, self._initial_frame : frame]\n    x = np.arange(self._initial_frame, frame) * self.dt\n\n    for n in range(self.n_trace):\n        self.ax.lines[n].set_data(x, trace[:, n])\n\n    contour = self.contour[self.batch_sample] if self.contour is not None else None\n\n    if self.batch_sample != self._sample and contour is not None:\n        self.ax.collections = []\n        _x = np.arange(len(contour))\n        _y = np.linspace(-2000, 2000, 100)\n        Z = np.tile(contour, (len(_y), 1))\n        self.ax.contourf(\n            _x,\n            _y,\n            Z,\n            cmap=cm.get_cmap(\"bone\"),\n            levels=2,\n            alpha=0.3,\n            vmin=0,\n            vmax=1,\n        )\n\n    if self.dynamic_ax_lims:\n        if self.ylims is not None:\n            ymin, ymax = self.ylims[self.batch_sample]\n        else:\n            ymin, ymax = plt_utils.get_lims(trace, 0.1)\n        xmin, xmax = plt_utils.get_lims(x, 0.1)\n        self.ax.axis([xmin, xmax, ymin, ymax])\n\n    if self.label:\n        self.label_text.set_text(self.label.format(self.batch_sample, frame))\n\n    if self.update:\n        self.update_figure()\n\n    self._sample = self.batch_sample\n</code></pre>"},{"location":"reference/augmentation/","title":"Hex Augmentations","text":""},{"location":"reference/augmentation/#geometric-transformations","title":"Geometric Transformations","text":""},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexRotate","title":"flyvis.datasets.augmentation.hex.HexRotate","text":"<p>               Bases: <code>Augmentation</code></p> <p>Rotate a sequence of regular hex-lattices by multiple of 60 degree.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of the regular hexagonal grid in columns.</p> required <code>n_rot</code> <code>int</code> <p>Number of 60 degree rotations. 0-5.</p> <code>0</code> <code>p_rot</code> <code>float</code> <p>Probability of rotating. If None, no rotation is performed.</p> <code>0.5</code> <p>Attributes:</p> Name Type Description <code>extent</code> <code>int</code> <p>Extent of the regular hexagonal grid in columns.</p> <code>n_rot</code> <code>int</code> <p>Number of 60 degree rotations. 0-5.</p> <code>p_rot</code> <code>float</code> <p>Probability of rotating.</p> <code>permutation_indices</code> <code>dict</code> <p>Cached indices for rotation.</p> <code>rotation_matrices</code> <code>dict</code> <p>Cached rotation matrices for rotation.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>class HexRotate(Augmentation):\n    \"\"\"Rotate a sequence of regular hex-lattices by multiple of 60 degree.\n\n    Args:\n        extent: Extent of the regular hexagonal grid in columns.\n        n_rot: Number of 60 degree rotations. 0-5.\n        p_rot: Probability of rotating. If None, no rotation is performed.\n\n    Attributes:\n        extent (int): Extent of the regular hexagonal grid in columns.\n        n_rot (int): Number of 60 degree rotations. 0-5.\n        p_rot (float): Probability of rotating.\n        permutation_indices (dict): Cached indices for rotation.\n        rotation_matrices (dict): Cached rotation matrices for rotation.\n    \"\"\"\n\n    def __init__(self, extent: int, n_rot: int = 0, p_rot: float = 0.5) -&gt; None:\n        self.extent = extent\n        self.rotation_matrices: dict = {}\n        self.permutation_indices: dict = {}\n        for n in range(6):\n            R2 = rotation_matrix(n * 60 * np.pi / 180, three_d=False)\n            R3 = rotation_matrix(n * 60 * np.pi / 180, three_d=True)\n            self.rotation_matrices[n] = [R2, R3]\n            self.permutation_indices[n] = rotation_permutation_index(extent, n)\n        self.n_rot = n_rot\n        self.p_rot = p_rot\n        self.set_or_sample(n_rot)\n\n    @property\n    def n_rot(self) -&gt; int:\n        \"\"\"Get the number of rotations.\"\"\"\n        return self._n_rot\n\n    @n_rot.setter\n    def n_rot(self, n_rot: int) -&gt; None:\n        \"\"\"Set the number of rotations.\"\"\"\n        self._n_rot = n_rot % 6\n\n    def rotate(self, seq: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Rotate a sequence on a regular hexagonal lattice.\n\n        Args:\n            seq: Sequence of shape (frames, dims, hexals).\n\n        Returns:\n            Rotated sequence of the same shape as seq.\n        \"\"\"\n        dims = seq.shape[-2]\n        seq = seq[..., self.permutation_indices[self.n_rot]]\n        if dims &gt; 1:\n            seq = self.rotation_matrices[self.n_rot][dims - 2] @ seq\n        return seq\n\n    def transform(self, seq: torch.Tensor, n_rot: Optional[int] = None) -&gt; torch.Tensor:\n        \"\"\"Rotate a sequence on a regular hexagonal lattice.\n\n        Args:\n            seq: Sequence of shape (frames, dims, hexals).\n            n_rot: Optional number of rotations to apply.\n\n        Returns:\n            Rotated sequence of the same shape as seq.\n        \"\"\"\n        if n_rot is not None:\n            self.n_rot = n_rot\n        if self.n_rot &gt; 0:\n            return self.rotate(seq)\n        return seq\n\n    def set_or_sample(self, n_rot: Optional[int] = None) -&gt; None:\n        \"\"\"Set or sample the number of rotations.\n\n        Args:\n            n_rot: Number of rotations to set. If None, sample randomly.\n        \"\"\"\n        if n_rot is None:\n            n_rot = (\n                np.random.randint(low=1, high=6)\n                if self.p_rot and self.p_rot &gt; np.random.rand()\n                else 0\n            )\n        self.n_rot = n_rot\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexRotate.n_rot","title":"n_rot  <code>property</code> <code>writable</code>","text":"<pre><code>n_rot\n</code></pre> <p>Get the number of rotations.</p>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexRotate.rotate","title":"rotate","text":"<pre><code>rotate(seq)\n</code></pre> <p>Rotate a sequence on a regular hexagonal lattice.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Sequence of shape (frames, dims, hexals).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Rotated sequence of the same shape as seq.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def rotate(self, seq: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Rotate a sequence on a regular hexagonal lattice.\n\n    Args:\n        seq: Sequence of shape (frames, dims, hexals).\n\n    Returns:\n        Rotated sequence of the same shape as seq.\n    \"\"\"\n    dims = seq.shape[-2]\n    seq = seq[..., self.permutation_indices[self.n_rot]]\n    if dims &gt; 1:\n        seq = self.rotation_matrices[self.n_rot][dims - 2] @ seq\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexRotate.transform","title":"transform","text":"<pre><code>transform(seq, n_rot=None)\n</code></pre> <p>Rotate a sequence on a regular hexagonal lattice.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Sequence of shape (frames, dims, hexals).</p> required <code>n_rot</code> <code>Optional[int]</code> <p>Optional number of rotations to apply.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Rotated sequence of the same shape as seq.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def transform(self, seq: torch.Tensor, n_rot: Optional[int] = None) -&gt; torch.Tensor:\n    \"\"\"Rotate a sequence on a regular hexagonal lattice.\n\n    Args:\n        seq: Sequence of shape (frames, dims, hexals).\n        n_rot: Optional number of rotations to apply.\n\n    Returns:\n        Rotated sequence of the same shape as seq.\n    \"\"\"\n    if n_rot is not None:\n        self.n_rot = n_rot\n    if self.n_rot &gt; 0:\n        return self.rotate(seq)\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexRotate.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(n_rot=None)\n</code></pre> <p>Set or sample the number of rotations.</p> <p>Parameters:</p> Name Type Description Default <code>n_rot</code> <code>Optional[int]</code> <p>Number of rotations to set. If None, sample randomly.</p> <code>None</code> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def set_or_sample(self, n_rot: Optional[int] = None) -&gt; None:\n    \"\"\"Set or sample the number of rotations.\n\n    Args:\n        n_rot: Number of rotations to set. If None, sample randomly.\n    \"\"\"\n    if n_rot is None:\n        n_rot = (\n            np.random.randint(low=1, high=6)\n            if self.p_rot and self.p_rot &gt; np.random.rand()\n            else 0\n        )\n    self.n_rot = n_rot\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexFlip","title":"flyvis.datasets.augmentation.hex.HexFlip","text":"<p>               Bases: <code>Augmentation</code></p> <p>Flip a sequence of regular hex-lattices across one of three hex-axes.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of the regular hexagonal grid.</p> required <code>axis</code> <code>int</code> <p>Flipping axis. 0 corresponds to no flipping.</p> <code>0</code> <code>p_flip</code> <code>float</code> <p>Probability of flipping. If None, no flipping is performed.</p> <code>0.5</code> <code>flip_axes</code> <code>List[int]</code> <p>List of valid flipping axes. Can contain 0, 1, 2, 3.</p> <code>[0, 1, 2, 3]</code> <p>Attributes:</p> Name Type Description <code>extent</code> <code>int</code> <p>Extent of the regular hexagonal grid.</p> <code>axis</code> <code>int</code> <p>Flipping axis.</p> <code>p_flip</code> <code>float</code> <p>Probability of flipping.</p> <code>flip_axes</code> <code>List[int]</code> <p>List of valid flipping axes.</p> <code>permutation_indices</code> <code>dict</code> <p>Cached indices for flipping.</p> <code>rotation_matrices</code> <code>dict</code> <p>Cached rotation matrices for flipping.</p> Note <p>This is to avoid redundant transformations from rotation and flipping. For example, flipping across the 1<sup>st</sup> axis is equivalent to rotating by 240 degrees and flipping across the 2<sup>nd</sup> axis.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>class HexFlip(Augmentation):\n    \"\"\"Flip a sequence of regular hex-lattices across one of three hex-axes.\n\n    Args:\n        extent: Extent of the regular hexagonal grid.\n        axis: Flipping axis. 0 corresponds to no flipping.\n        p_flip: Probability of flipping. If None, no flipping is performed.\n        flip_axes: List of valid flipping axes. Can contain 0, 1, 2, 3.\n\n    Attributes:\n        extent (int): Extent of the regular hexagonal grid.\n        axis (int): Flipping axis.\n        p_flip (float): Probability of flipping.\n        flip_axes (List[int]): List of valid flipping axes.\n        permutation_indices (dict): Cached indices for flipping.\n        rotation_matrices (dict): Cached rotation matrices for flipping.\n\n    Note:\n        This is to avoid redundant transformations from rotation and flipping.\n        For example, flipping across the 1st axis is equivalent to rotating by\n        240 degrees and flipping across the 2nd axis.\n    \"\"\"\n\n    def __init__(\n        self,\n        extent: int,\n        axis: int = 0,\n        p_flip: float = 0.5,\n        flip_axes: List[int] = [0, 1, 2, 3],\n    ) -&gt; None:\n        self.extent = extent\n        self.rotation_matrices: dict = {}\n        self.permutation_indices: dict = {}\n        for n, angle in enumerate([90, 150, 210], 1):\n            R2 = flip_matrix(np.radians(angle), three_d=False)\n            R3 = flip_matrix(np.radians(angle), three_d=True)\n            self.rotation_matrices[n] = [R2, R3]\n            self.permutation_indices[n] = flip_permutation_index(extent, n)\n        self.flip_axes = flip_axes\n        self.axis = axis\n        self.p_flip = p_flip\n        self.set_or_sample(axis)\n\n    @property\n    def axis(self) -&gt; int:\n        \"\"\"Get the flipping axis.\"\"\"\n        return self._axis\n\n    @axis.setter\n    def axis(self, axis: int) -&gt; None:\n        \"\"\"Set the flipping axis.\"\"\"\n        assert (\n            axis in self.flip_axes\n        ), f\"{axis} is not a valid axis. Must be in {self.flip_axes}.\"\n        self._axis = axis\n\n    def flip(self, seq: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Flip a sequence on a regular hexagonal lattice.\n\n        Args:\n            seq: Sequence of shape (frames, dims, hexals).\n\n        Returns:\n            Flipped sequence of the same shape as seq.\n        \"\"\"\n        dims = seq.shape[-2]\n        seq = seq[..., self.permutation_indices[self.axis]]\n        if dims &gt; 1:\n            seq = self.rotation_matrices[self.axis][dims - 2] @ seq\n        return seq\n\n    def transform(self, seq: torch.Tensor, axis: Optional[int] = None) -&gt; torch.Tensor:\n        \"\"\"Flip a sequence on a regular hexagonal lattice.\n\n        Args:\n            seq: Sequence of shape (frames, dims, hexals).\n            axis: Optional flipping axis to apply.\n\n        Returns:\n            Flipped sequence of the same shape as seq.\n        \"\"\"\n        if axis is not None:\n            self.axis = axis\n        if self.axis &gt; 0:\n            return self.flip(seq=seq)\n        return seq\n\n    def set_or_sample(self, axis: Optional[int] = None) -&gt; None:\n        \"\"\"Set or sample the flipping axis.\n\n        Args:\n            axis: Flipping axis to set. If None, sample randomly.\n        \"\"\"\n        if axis is None:\n            axis = (\n                np.random.randint(low=1, high=max(self.flip_axes) + 1)\n                if self.p_flip and self.p_flip &gt; np.random.rand()\n                else 0\n            )\n        self.axis = axis\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexFlip.axis","title":"axis  <code>property</code> <code>writable</code>","text":"<pre><code>axis\n</code></pre> <p>Get the flipping axis.</p>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexFlip.flip","title":"flip","text":"<pre><code>flip(seq)\n</code></pre> <p>Flip a sequence on a regular hexagonal lattice.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Sequence of shape (frames, dims, hexals).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Flipped sequence of the same shape as seq.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def flip(self, seq: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Flip a sequence on a regular hexagonal lattice.\n\n    Args:\n        seq: Sequence of shape (frames, dims, hexals).\n\n    Returns:\n        Flipped sequence of the same shape as seq.\n    \"\"\"\n    dims = seq.shape[-2]\n    seq = seq[..., self.permutation_indices[self.axis]]\n    if dims &gt; 1:\n        seq = self.rotation_matrices[self.axis][dims - 2] @ seq\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexFlip.transform","title":"transform","text":"<pre><code>transform(seq, axis=None)\n</code></pre> <p>Flip a sequence on a regular hexagonal lattice.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Sequence of shape (frames, dims, hexals).</p> required <code>axis</code> <code>Optional[int]</code> <p>Optional flipping axis to apply.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Flipped sequence of the same shape as seq.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def transform(self, seq: torch.Tensor, axis: Optional[int] = None) -&gt; torch.Tensor:\n    \"\"\"Flip a sequence on a regular hexagonal lattice.\n\n    Args:\n        seq: Sequence of shape (frames, dims, hexals).\n        axis: Optional flipping axis to apply.\n\n    Returns:\n        Flipped sequence of the same shape as seq.\n    \"\"\"\n    if axis is not None:\n        self.axis = axis\n    if self.axis &gt; 0:\n        return self.flip(seq=seq)\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.HexFlip.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(axis=None)\n</code></pre> <p>Set or sample the flipping axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>Optional[int]</code> <p>Flipping axis to set. If None, sample randomly.</p> <code>None</code> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def set_or_sample(self, axis: Optional[int] = None) -&gt; None:\n    \"\"\"Set or sample the flipping axis.\n\n    Args:\n        axis: Flipping axis to set. If None, sample randomly.\n    \"\"\"\n    if axis is None:\n        axis = (\n            np.random.randint(low=1, high=max(self.flip_axes) + 1)\n            if self.p_flip and self.p_flip &gt; np.random.rand()\n            else 0\n        )\n    self.axis = axis\n</code></pre>"},{"location":"reference/augmentation/#intensity-transformations","title":"Intensity Transformations","text":""},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.ContrastBrightness","title":"flyvis.datasets.augmentation.hex.ContrastBrightness","text":"<p>               Bases: <code>Augmentation</code></p> <p>Contrast transformation.</p> <p>The transformation is described as: <pre><code>pixel = max(0, contrast_factor * (pixel - 0.5) + 0.5\n            + contrast_factor * brightness_factor)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>contrast_factor</code> <code>Optional[float]</code> <p>Contrast factor.</p> <code>None</code> <code>brightness_factor</code> <code>Optional[float]</code> <p>Brightness factor.</p> <code>None</code> <code>contrast_std</code> <code>float</code> <p>Standard deviation of the contrast factor.</p> <code>0.2</code> <code>brightness_std</code> <code>float</code> <p>Standard deviation of the brightness factor.</p> <code>0.1</code> <p>Attributes:</p> Name Type Description <code>contrast_std</code> <code>float</code> <p>Standard deviation of the contrast factor.</p> <code>brightness_std</code> <code>float</code> <p>Standard deviation of the brightness factor.</p> <code>contrast_factor</code> <code>float</code> <p>Contrast factor.</p> <code>brightness_factor</code> <code>float</code> <p>Brightness factor.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>class ContrastBrightness(Augmentation):\n    \"\"\"Contrast transformation.\n\n    The transformation is described as:\n    ```python\n    pixel = max(0, contrast_factor * (pixel - 0.5) + 0.5\n                + contrast_factor * brightness_factor)\n    ```\n\n    Args:\n        contrast_factor: Contrast factor.\n        brightness_factor: Brightness factor.\n        contrast_std: Standard deviation of the contrast factor.\n        brightness_std: Standard deviation of the brightness factor.\n\n    Attributes:\n        contrast_std (float): Standard deviation of the contrast factor.\n        brightness_std (float): Standard deviation of the brightness factor.\n        contrast_factor (float): Contrast factor.\n        brightness_factor (float): Brightness factor.\n    \"\"\"\n\n    def __init__(\n        self,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        contrast_std: float = 0.2,\n        brightness_std: float = 0.1,\n    ) -&gt; None:\n        self.contrast_std = contrast_std\n        self.brightness_std = brightness_std\n        self.set_or_sample(contrast_factor, brightness_factor)\n\n    def transform(self, seq: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Apply the transformation to a sequence.\n\n        Args:\n            seq: Input sequence.\n\n        Returns:\n            Transformed sequence.\n        \"\"\"\n        if self.contrast_factor is not None:\n            return (\n                self.contrast_factor * (seq - 0.5)\n                + 0.5\n                + self.contrast_factor * self.brightness_factor\n            ).clamp(0)\n        return seq\n\n    def set_or_sample(\n        self,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n    ) -&gt; None:\n        \"\"\"Set or sample contrast and brightness factors.\n\n        Args:\n            contrast_factor: Contrast factor to set. If None, sample randomly.\n            brightness_factor: Brightness factor to set. If None, sample randomly.\n        \"\"\"\n        if contrast_factor is None:\n            # behaves like N(1, std) for small std, slightly biased towards\n            # high contrast in particular for large std deviations\n            # TODO: implement other sampling schemes\n            contrast_factor = (\n                np.exp(np.random.normal(0, self.contrast_std))\n                if self.contrast_std\n                else None\n            )\n        if brightness_factor is None:\n            brightness_factor = (\n                np.random.normal(0, self.brightness_std) if self.brightness_std else 0.0\n            )\n        self.contrast_factor = contrast_factor\n        self.brightness_factor = brightness_factor\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.ContrastBrightness.transform","title":"transform","text":"<pre><code>transform(seq)\n</code></pre> <p>Apply the transformation to a sequence.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Input sequence.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Transformed sequence.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def transform(self, seq: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Apply the transformation to a sequence.\n\n    Args:\n        seq: Input sequence.\n\n    Returns:\n        Transformed sequence.\n    \"\"\"\n    if self.contrast_factor is not None:\n        return (\n            self.contrast_factor * (seq - 0.5)\n            + 0.5\n            + self.contrast_factor * self.brightness_factor\n        ).clamp(0)\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.ContrastBrightness.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(contrast_factor=None, brightness_factor=None)\n</code></pre> <p>Set or sample contrast and brightness factors.</p> <p>Parameters:</p> Name Type Description Default <code>contrast_factor</code> <code>Optional[float]</code> <p>Contrast factor to set. If None, sample randomly.</p> <code>None</code> <code>brightness_factor</code> <code>Optional[float]</code> <p>Brightness factor to set. If None, sample randomly.</p> <code>None</code> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def set_or_sample(\n    self,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Set or sample contrast and brightness factors.\n\n    Args:\n        contrast_factor: Contrast factor to set. If None, sample randomly.\n        brightness_factor: Brightness factor to set. If None, sample randomly.\n    \"\"\"\n    if contrast_factor is None:\n        # behaves like N(1, std) for small std, slightly biased towards\n        # high contrast in particular for large std deviations\n        # TODO: implement other sampling schemes\n        contrast_factor = (\n            np.exp(np.random.normal(0, self.contrast_std))\n            if self.contrast_std\n            else None\n        )\n    if brightness_factor is None:\n        brightness_factor = (\n            np.random.normal(0, self.brightness_std) if self.brightness_std else 0.0\n        )\n    self.contrast_factor = contrast_factor\n    self.brightness_factor = brightness_factor\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.PixelNoise","title":"flyvis.datasets.augmentation.hex.PixelNoise","text":"<p>               Bases: <code>Augmentation</code></p> <p>Pixelwise gaussian noise.</p> <p>The transformation is described as: <pre><code>pixel = pixel + N(0, std)\n</code></pre></p> <p>It biases the signal to noise ratio: high for light, low for dark pixels.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>float</code> <p>Standard deviation of the gaussian noise.</p> <code>0.08</code> <p>Attributes:</p> Name Type Description <code>std</code> <code>float</code> <p>Standard deviation of the gaussian noise.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>class PixelNoise(Augmentation):\n    \"\"\"Pixelwise gaussian noise.\n\n    The transformation is described as:\n    ```python\n    pixel = pixel + N(0, std)\n    ```\n\n    It biases the signal to noise ratio: high for light, low for dark pixels.\n\n    Args:\n        std: Standard deviation of the gaussian noise.\n\n    Attributes:\n        std (float): Standard deviation of the gaussian noise.\n    \"\"\"\n\n    def __init__(self, std: float = 0.08) -&gt; None:\n        self.std = std\n\n    def transform(self, seq: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Apply the transformation to a sequence.\n\n        Args:\n            seq: Input sequence.\n\n        Returns:\n            Transformed sequence.\n        \"\"\"\n        if self.std:\n            noise = torch.randn_like(seq) * self.std\n            return (seq + noise).clamp(0)\n        return seq\n\n    def set_or_sample(self, std: Optional[float] = None) -&gt; None:\n        \"\"\"Set or sample the standard deviation of the gaussian noise.\n\n        Args:\n            std: Standard deviation of the gaussian noise to set.\n                If None, no change is made.\n        \"\"\"\n        if std is None:\n            return\n        self.std = std\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.PixelNoise.transform","title":"transform","text":"<pre><code>transform(seq)\n</code></pre> <p>Apply the transformation to a sequence.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Input sequence.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Transformed sequence.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def transform(self, seq: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Apply the transformation to a sequence.\n\n    Args:\n        seq: Input sequence.\n\n    Returns:\n        Transformed sequence.\n    \"\"\"\n    if self.std:\n        noise = torch.randn_like(seq) * self.std\n        return (seq + noise).clamp(0)\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.PixelNoise.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(std=None)\n</code></pre> <p>Set or sample the standard deviation of the gaussian noise.</p> <p>Parameters:</p> Name Type Description Default <code>std</code> <code>Optional[float]</code> <p>Standard deviation of the gaussian noise to set. If None, no change is made.</p> <code>None</code> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def set_or_sample(self, std: Optional[float] = None) -&gt; None:\n    \"\"\"Set or sample the standard deviation of the gaussian noise.\n\n    Args:\n        std: Standard deviation of the gaussian noise to set.\n            If None, no change is made.\n    \"\"\"\n    if std is None:\n        return\n    self.std = std\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.GammaCorrection","title":"flyvis.datasets.augmentation.hex.GammaCorrection","text":"<p>               Bases: <code>Augmentation</code></p> <p>Gamma correction.</p> <p>The transformation is described as: <pre><code>pixel = pixel ** gamma\n</code></pre></p> <p>Gamma &gt; 1 increases the contrast, gamma &lt; 1 decreases the contrast.</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>float</code> <p>Gamma value.</p> <code>1</code> <code>std</code> <code>Optional[float]</code> <p>Standard deviation of the gamma value.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>gamma</code> <p>float Gamma value.</p> <code>std</code> <p>Optional[float] Standard deviation of the gamma value.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>class GammaCorrection(Augmentation):\n    \"\"\"Gamma correction.\n\n    The transformation is described as:\n    ```python\n    pixel = pixel ** gamma\n    ```\n\n    Gamma &gt; 1 increases the contrast, gamma &lt; 1 decreases the contrast.\n\n    Args:\n        gamma: Gamma value.\n        std: Standard deviation of the gamma value.\n\n    Attributes:\n        gamma: float\n            Gamma value.\n        std: Optional[float]\n            Standard deviation of the gamma value.\n    \"\"\"\n\n    def __init__(self, gamma: float = 1, std: Optional[float] = None) -&gt; None:\n        self.gamma = gamma\n        self.std = std\n\n    def transform(self, seq: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Apply the transformation to a sequence.\n\n        Args:\n            seq: Input sequence.\n\n        Returns:\n            Transformed sequence.\n        \"\"\"\n        if self.gamma:\n            return seq**self.gamma\n        return seq\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        if name == \"gamma\" and value &lt; 0:\n            raise ValueError(\"Gamma must be positive.\")\n        return super().__setattr__(name, value)\n\n    def set_or_sample(self, gamma: Optional[float] = None) -&gt; None:\n        \"\"\"Set or sample the gamma value.\n\n        Args:\n            gamma: Gamma value to set. If None, sample randomly.\n        \"\"\"\n        if gamma is None:\n            gamma = max(0, np.random.normal(1, self.std)) if self.std else 1.0\n        self.gamma = gamma\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.GammaCorrection.transform","title":"transform","text":"<pre><code>transform(seq)\n</code></pre> <p>Apply the transformation to a sequence.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Tensor</code> <p>Input sequence.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Transformed sequence.</p> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def transform(self, seq: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Apply the transformation to a sequence.\n\n    Args:\n        seq: Input sequence.\n\n    Returns:\n        Transformed sequence.\n    \"\"\"\n    if self.gamma:\n        return seq**self.gamma\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.hex.GammaCorrection.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(gamma=None)\n</code></pre> <p>Set or sample the gamma value.</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>Optional[float]</code> <p>Gamma value to set. If None, sample randomly.</p> <code>None</code> Source code in <code>flyvis/datasets/augmentation/hex.py</code> <pre><code>def set_or_sample(self, gamma: Optional[float] = None) -&gt; None:\n    \"\"\"Set or sample the gamma value.\n\n    Args:\n        gamma: Gamma value to set. If None, sample randomly.\n    \"\"\"\n    if gamma is None:\n        gamma = max(0, np.random.normal(1, self.std)) if self.std else 1.0\n    self.gamma = gamma\n</code></pre>"},{"location":"reference/augmentation/#temporal-augmentations","title":"Temporal Augmentations","text":""},{"location":"reference/augmentation/#flyvis.datasets.augmentation.temporal.Interpolate","title":"flyvis.datasets.augmentation.temporal.Interpolate","text":"<p>               Bases: <code>Augmentation</code></p> <p>Interpolate a sequence to a target framerate.</p> <p>Attributes:</p> Name Type Description <code>original_framerate</code> <code>int</code> <p>The original framerate of the sequence.</p> <code>target_framerate</code> <code>float</code> <p>The target framerate after interpolation.</p> <code>mode</code> <code>str</code> <p>The interpolation mode.</p> <code>align_corners</code> <code>bool | None</code> <p>Alignment of corners for interpolation.</p> Source code in <code>flyvis/datasets/augmentation/temporal.py</code> <pre><code>class Interpolate(Augmentation):\n    \"\"\"Interpolate a sequence to a target framerate.\n\n    Attributes:\n        original_framerate (int): The original framerate of the sequence.\n        target_framerate (float): The target framerate after interpolation.\n        mode (str): The interpolation mode.\n        align_corners (bool | None): Alignment of corners for interpolation.\n    \"\"\"\n\n    def __init__(self, original_framerate: int, target_framerate: float, mode: str):\n        self.original_framerate = original_framerate\n        self.target_framerate = target_framerate\n        self.mode = mode\n        self.align_corners = (\n            True if mode in [\"linear\", \"bilinear\", \"bicubic\", \"trilinear\"] else None\n        )\n\n    def transform(self, sequence: torch.Tensor, dim: int = 0) -&gt; torch.Tensor:\n        \"\"\"Resample the sequence along the specified dimension.\n\n        Args:\n            sequence: Sequence to resample of ndim == 3.\n            dim: Dimension along which to resample.\n\n        Returns:\n            torch.Tensor: Resampled sequence.\n\n        Raises:\n            AssertionError: If the input sequence is not 3D.\n        \"\"\"\n        assert sequence.ndim == 3, \"only 3D sequences are supported\"\n        if sequence.dtype == torch.long:\n            sequence = sequence.float()\n        return nnf.interpolate(\n            sequence.transpose(dim, -1),\n            size=math.ceil(\n                self.target_framerate / self.original_framerate * sequence.shape[dim]\n            ),\n            mode=self.mode,\n            align_corners=self.align_corners,\n        ).transpose(dim, -1)\n\n    def piecewise_constant_indices(self, length: int) -&gt; torch.Tensor:\n        \"\"\"Return indices to sample from a sequence with piecewise constant interpolation.\n\n        Args:\n            length: Length of the original sequence.\n\n        Returns:\n            torch.Tensor: Indices for piecewise constant interpolation.\n        \"\"\"\n        indices = torch.arange(length, dtype=torch.float)[None, None]\n        return (\n            nnf.interpolate(\n                indices,\n                size=math.ceil(self.target_framerate / self.original_framerate * length),\n                mode=\"nearest-exact\",\n                align_corners=None,\n            )\n            .flatten()\n            .long()\n        )\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.temporal.Interpolate.transform","title":"transform","text":"<pre><code>transform(sequence, dim=0)\n</code></pre> <p>Resample the sequence along the specified dimension.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Tensor</code> <p>Sequence to resample of ndim == 3.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to resample.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Resampled sequence.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the input sequence is not 3D.</p> Source code in <code>flyvis/datasets/augmentation/temporal.py</code> <pre><code>def transform(self, sequence: torch.Tensor, dim: int = 0) -&gt; torch.Tensor:\n    \"\"\"Resample the sequence along the specified dimension.\n\n    Args:\n        sequence: Sequence to resample of ndim == 3.\n        dim: Dimension along which to resample.\n\n    Returns:\n        torch.Tensor: Resampled sequence.\n\n    Raises:\n        AssertionError: If the input sequence is not 3D.\n    \"\"\"\n    assert sequence.ndim == 3, \"only 3D sequences are supported\"\n    if sequence.dtype == torch.long:\n        sequence = sequence.float()\n    return nnf.interpolate(\n        sequence.transpose(dim, -1),\n        size=math.ceil(\n            self.target_framerate / self.original_framerate * sequence.shape[dim]\n        ),\n        mode=self.mode,\n        align_corners=self.align_corners,\n    ).transpose(dim, -1)\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.temporal.Interpolate.piecewise_constant_indices","title":"piecewise_constant_indices","text":"<pre><code>piecewise_constant_indices(length)\n</code></pre> <p>Return indices to sample from a sequence with piecewise constant interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>length</code> <code>int</code> <p>Length of the original sequence.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Indices for piecewise constant interpolation.</p> Source code in <code>flyvis/datasets/augmentation/temporal.py</code> <pre><code>def piecewise_constant_indices(self, length: int) -&gt; torch.Tensor:\n    \"\"\"Return indices to sample from a sequence with piecewise constant interpolation.\n\n    Args:\n        length: Length of the original sequence.\n\n    Returns:\n        torch.Tensor: Indices for piecewise constant interpolation.\n    \"\"\"\n    indices = torch.arange(length, dtype=torch.float)[None, None]\n    return (\n        nnf.interpolate(\n            indices,\n            size=math.ceil(self.target_framerate / self.original_framerate * length),\n            mode=\"nearest-exact\",\n            align_corners=None,\n        )\n        .flatten()\n        .long()\n    )\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.temporal.CropFrames","title":"flyvis.datasets.augmentation.temporal.CropFrames","text":"<p>               Bases: <code>Augmentation</code></p> <p>Crop frames from a sequence.</p> <p>Attributes:</p> Name Type Description <code>n_frames</code> <code>int</code> <p>Number of frames to crop.</p> <code>all_frames</code> <code>bool</code> <p>Whether to return all frames.</p> <code>start</code> <code>int</code> <p>Starting frame for cropping.</p> <code>random</code> <code>bool</code> <p>Whether to use random cropping.</p> Source code in <code>flyvis/datasets/augmentation/temporal.py</code> <pre><code>class CropFrames(Augmentation):\n    \"\"\"Crop frames from a sequence.\n\n    Attributes:\n        n_frames (int): Number of frames to crop.\n        all_frames (bool): Whether to return all frames.\n        start (int): Starting frame for cropping.\n        random (bool): Whether to use random cropping.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_frames: int,\n        start: int = 0,\n        all_frames: bool = False,\n        random: bool = False,\n    ):\n        self.n_frames = n_frames\n        self.all_frames = all_frames\n        self.start = start\n        self.random = random\n\n    def transform(self, sequence: torch.Tensor, dim: int = 0) -&gt; torch.Tensor:\n        \"\"\"Crop the sequence along the specified dimension.\n\n        Args:\n            sequence: Sequence to crop of shape (..., n_frames, ...).\n            dim: Dimension along which to crop.\n\n        Returns:\n            torch.Tensor: Cropped sequence.\n\n        Raises:\n            ValueError: If n_frames is greater than the total sequence length.\n        \"\"\"\n        if self.all_frames:\n            return sequence\n        total_seq_length = sequence.shape[dim]\n        if self.n_frames &gt; total_seq_length:\n            raise ValueError(\n                f\"cannot crop {self.n_frames} frames from a total\"\n                f\" of {total_seq_length} frames\"\n            )\n        start = self.start if self.random else 0\n        indx = [slice(None)] * sequence.ndim\n        indx[dim] = slice(start, start + self.n_frames)\n        return sequence[indx]\n\n    def set_or_sample(\n        self, start: int | None = None, total_sequence_length: int | None = None\n    ):\n        \"\"\"Set or sample the starting frame for cropping.\n\n        Args:\n            start: Starting frame for cropping.\n            total_sequence_length: Total length of the sequence.\n\n        Raises:\n            ValueError: If n_frames is greater than the total sequence length.\n        \"\"\"\n        if total_sequence_length and self.n_frames &gt; total_sequence_length:\n            raise ValueError(\n                f\"cannot crop {self.n_frames} frames from a total\"\n                f\" of {total_sequence_length} frames\"\n            )\n        if start is None and total_sequence_length:\n            start = np.random.randint(\n                low=0, high=total_sequence_length - self.n_frames or 1\n            )\n        self.start = start\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.temporal.CropFrames.transform","title":"transform","text":"<pre><code>transform(sequence, dim=0)\n</code></pre> <p>Crop the sequence along the specified dimension.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Tensor</code> <p>Sequence to crop of shape (\u2026, n_frames, \u2026).</p> required <code>dim</code> <code>int</code> <p>Dimension along which to crop.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Cropped sequence.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_frames is greater than the total sequence length.</p> Source code in <code>flyvis/datasets/augmentation/temporal.py</code> <pre><code>def transform(self, sequence: torch.Tensor, dim: int = 0) -&gt; torch.Tensor:\n    \"\"\"Crop the sequence along the specified dimension.\n\n    Args:\n        sequence: Sequence to crop of shape (..., n_frames, ...).\n        dim: Dimension along which to crop.\n\n    Returns:\n        torch.Tensor: Cropped sequence.\n\n    Raises:\n        ValueError: If n_frames is greater than the total sequence length.\n    \"\"\"\n    if self.all_frames:\n        return sequence\n    total_seq_length = sequence.shape[dim]\n    if self.n_frames &gt; total_seq_length:\n        raise ValueError(\n            f\"cannot crop {self.n_frames} frames from a total\"\n            f\" of {total_seq_length} frames\"\n        )\n    start = self.start if self.random else 0\n    indx = [slice(None)] * sequence.ndim\n    indx[dim] = slice(start, start + self.n_frames)\n    return sequence[indx]\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.temporal.CropFrames.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(start=None, total_sequence_length=None)\n</code></pre> <p>Set or sample the starting frame for cropping.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int | None</code> <p>Starting frame for cropping.</p> <code>None</code> <code>total_sequence_length</code> <code>int | None</code> <p>Total length of the sequence.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_frames is greater than the total sequence length.</p> Source code in <code>flyvis/datasets/augmentation/temporal.py</code> <pre><code>def set_or_sample(\n    self, start: int | None = None, total_sequence_length: int | None = None\n):\n    \"\"\"Set or sample the starting frame for cropping.\n\n    Args:\n        start: Starting frame for cropping.\n        total_sequence_length: Total length of the sequence.\n\n    Raises:\n        ValueError: If n_frames is greater than the total sequence length.\n    \"\"\"\n    if total_sequence_length and self.n_frames &gt; total_sequence_length:\n        raise ValueError(\n            f\"cannot crop {self.n_frames} frames from a total\"\n            f\" of {total_sequence_length} frames\"\n        )\n    if start is None and total_sequence_length:\n        start = np.random.randint(\n            low=0, high=total_sequence_length - self.n_frames or 1\n        )\n    self.start = start\n</code></pre>"},{"location":"reference/augmentation/#base-class","title":"Base Class","text":""},{"location":"reference/augmentation/#flyvis.datasets.augmentation.augmentation.Augmentation","title":"flyvis.datasets.augmentation.augmentation.Augmentation","text":"<p>Base class for data augmentation operations.</p> <p>This class provides a framework for implementing various data augmentation techniques. Subclasses should override the <code>transform</code> method to implement specific augmentation logic.</p> <p>Attributes:</p> Name Type Description <code>augment</code> <code>bool</code> <p>Flag to enable or disable augmentation.</p> Source code in <code>flyvis/datasets/augmentation/augmentation.py</code> <pre><code>class Augmentation:\n    \"\"\"\n    Base class for data augmentation operations.\n\n    This class provides a framework for implementing various data augmentation\n    techniques. Subclasses should override the `transform` method to implement\n    specific augmentation logic.\n\n    Attributes:\n        augment (bool): Flag to enable or disable augmentation.\n    \"\"\"\n\n    augment: bool = True\n\n    def __call__(self, seq: Sequence[Any], *args: Any, **kwargs: Any) -&gt; Sequence[Any]:\n        \"\"\"\n        Apply augmentation to the input sequence if enabled.\n\n        Args:\n            seq: Input sequence to be augmented.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Augmented sequence if augmentation is enabled,\n                otherwise the original sequence.\n        \"\"\"\n        if self.augment:\n            return self.transform(seq, *args, **kwargs)\n        return seq\n\n    def transform(self, seq: Sequence[Any], *args: Any, **kwargs: Any) -&gt; Sequence[Any]:\n        \"\"\"\n        Apply the augmentation transformation to the input sequence.\n\n        This method should be overridden by subclasses to implement specific\n        augmentation logic.\n\n        Args:\n            seq: Input sequence to be transformed.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Transformed sequence.\n        \"\"\"\n        return seq\n\n    def set_or_sample(self, *args: Any) -&gt; None:\n        \"\"\"\n        Set or sample augmentation parameters.\n\n        This method can be used to set fixed parameters or sample random\n        parameters for the augmentation process.\n\n        Args:\n            *args: Arguments for setting or sampling parameters.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.augmentation.Augmentation.__call__","title":"__call__","text":"<pre><code>__call__(seq, *args, **kwargs)\n</code></pre> <p>Apply augmentation to the input sequence if enabled.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Sequence[Any]</code> <p>Input sequence to be augmented.</p> required <code>*args</code> <code>Any</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Sequence[Any]</code> <p>Augmented sequence if augmentation is enabled, otherwise the original sequence.</p> Source code in <code>flyvis/datasets/augmentation/augmentation.py</code> <pre><code>def __call__(self, seq: Sequence[Any], *args: Any, **kwargs: Any) -&gt; Sequence[Any]:\n    \"\"\"\n    Apply augmentation to the input sequence if enabled.\n\n    Args:\n        seq: Input sequence to be augmented.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Augmented sequence if augmentation is enabled,\n            otherwise the original sequence.\n    \"\"\"\n    if self.augment:\n        return self.transform(seq, *args, **kwargs)\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.augmentation.Augmentation.transform","title":"transform","text":"<pre><code>transform(seq, *args, **kwargs)\n</code></pre> <p>Apply the augmentation transformation to the input sequence.</p> <p>This method should be overridden by subclasses to implement specific augmentation logic.</p> <p>Parameters:</p> Name Type Description Default <code>seq</code> <code>Sequence[Any]</code> <p>Input sequence to be transformed.</p> required <code>*args</code> <code>Any</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Sequence[Any]</code> <p>Transformed sequence.</p> Source code in <code>flyvis/datasets/augmentation/augmentation.py</code> <pre><code>def transform(self, seq: Sequence[Any], *args: Any, **kwargs: Any) -&gt; Sequence[Any]:\n    \"\"\"\n    Apply the augmentation transformation to the input sequence.\n\n    This method should be overridden by subclasses to implement specific\n    augmentation logic.\n\n    Args:\n        seq: Input sequence to be transformed.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Transformed sequence.\n    \"\"\"\n    return seq\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.augmentation.Augmentation.set_or_sample","title":"set_or_sample","text":"<pre><code>set_or_sample(*args)\n</code></pre> <p>Set or sample augmentation parameters.</p> <p>This method can be used to set fixed parameters or sample random parameters for the augmentation process.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Arguments for setting or sampling parameters.</p> <code>()</code> Source code in <code>flyvis/datasets/augmentation/augmentation.py</code> <pre><code>def set_or_sample(self, *args: Any) -&gt; None:\n    \"\"\"\n    Set or sample augmentation parameters.\n\n    This method can be used to set fixed parameters or sample random\n    parameters for the augmentation process.\n\n    Args:\n        *args: Arguments for setting or sampling parameters.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/augmentation/#utils","title":"Utils","text":""},{"location":"reference/augmentation/#flyvis.datasets.augmentation.utils","title":"flyvis.datasets.augmentation.utils","text":""},{"location":"reference/augmentation/#flyvis.datasets.augmentation.utils.rotation_matrix","title":"rotation_matrix","text":"<pre><code>rotation_matrix(angle_in_rad, three_d=False)\n</code></pre> <p>Generate a rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>angle_in_rad</code> <code>float</code> <p>Rotation angle in radians.</p> required <code>three_d</code> <code>bool</code> <p>If True, generate a 3D rotation matrix.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Rotation matrix as a torch.Tensor.</p> Source code in <code>flyvis/datasets/augmentation/utils.py</code> <pre><code>def rotation_matrix(angle_in_rad: float, three_d: bool = False) -&gt; torch.Tensor:\n    \"\"\"Generate a rotation matrix.\n\n    Args:\n        angle_in_rad: Rotation angle in radians.\n        three_d: If True, generate a 3D rotation matrix.\n\n    Returns:\n        Rotation matrix as a torch.Tensor.\n    \"\"\"\n    if three_d:\n        return torch.tensor(\n            np.array([\n                [np.cos(angle_in_rad), -np.sin(angle_in_rad), 0],\n                [np.sin(angle_in_rad), np.cos(angle_in_rad), 0],\n                [0, 0, 1],\n            ]),\n            dtype=torch.float,\n        )\n    return torch.tensor(\n        np.array([\n            [np.cos(angle_in_rad), -np.sin(angle_in_rad)],\n            [np.sin(angle_in_rad), np.cos(angle_in_rad)],\n        ]),\n        dtype=torch.float,\n    )\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.utils.rotation_permutation_index","title":"rotation_permutation_index","text":"<pre><code>rotation_permutation_index(extent, n_rot)\n</code></pre> <p>Calculate rotation permutation indices for hex coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of the regular hexagonal grid.</p> required <code>n_rot</code> <code>int</code> <p>Number of 60-degree rotations.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Permutation indices as a torch.Tensor.</p> Source code in <code>flyvis/datasets/augmentation/utils.py</code> <pre><code>def rotation_permutation_index(extent: int, n_rot: int) -&gt; torch.Tensor:\n    \"\"\"Calculate rotation permutation indices for hex coordinates.\n\n    Args:\n        extent: Extent of the regular hexagonal grid.\n        n_rot: Number of 60-degree rotations.\n\n    Returns:\n        Permutation indices as a torch.Tensor.\n    \"\"\"\n    u, v = hex_utils.get_hex_coords(extent)\n    u_new, v_new = rotate_Nx60(u, v, n_rot)\n    return hex_utils.sort_u_then_v_index(u_new, v_new)\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.utils.rotate_Nx60","title":"rotate_Nx60","text":"<pre><code>rotate_Nx60(u, v, n)\n</code></pre> <p>Rotate hex coordinates by multiples of 60 degrees.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>ndarray</code> <p>U coordinates of hex grid.</p> required <code>v</code> <code>ndarray</code> <p>V coordinates of hex grid.</p> required <code>n</code> <code>int</code> <p>Number of 60-degree rotations.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple of rotated U and V coordinates.</p> Note <p>Resource: http://devmag.org.za/2013/08/31/geometry-with-hex-coordinates/</p> Source code in <code>flyvis/datasets/augmentation/utils.py</code> <pre><code>def rotate_Nx60(u: np.ndarray, v: np.ndarray, n: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Rotate hex coordinates by multiples of 60 degrees.\n\n    Args:\n        u: U coordinates of hex grid.\n        v: V coordinates of hex grid.\n        n: Number of 60-degree rotations.\n\n    Returns:\n        Tuple of rotated U and V coordinates.\n\n    Note:\n        Resource: http://devmag.org.za/2013/08/31/geometry-with-hex-coordinates/\n    \"\"\"\n\n    def rotate(u: np.ndarray, v: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Rotate hex coordinates by 60 degrees.\n\n        Rotation matrix R = [[0, -1], [1, 1]]\n        \"\"\"\n        return -v, u + v\n\n    for _ in range(n % 6):\n        u, v = rotate(u, v)\n\n    return u, v\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.utils.flip_matrix","title":"flip_matrix","text":"<pre><code>flip_matrix(angle_in_rad, three_d=False)\n</code></pre> <p>Generate a flip matrix for mirroring over a line.</p> <p>Parameters:</p> Name Type Description Default <code>angle_in_rad</code> <code>float</code> <p>Angle of the flip axis in radians.</p> required <code>three_d</code> <code>bool</code> <p>If True, generate a 3D flip matrix.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Flip matrix as a torch.Tensor.</p> Note <p>Reference: https://math.stackexchange.com/questions/807031/</p> Source code in <code>flyvis/datasets/augmentation/utils.py</code> <pre><code>def flip_matrix(angle_in_rad: float, three_d: bool = False) -&gt; torch.Tensor:\n    \"\"\"Generate a flip matrix for mirroring over a line.\n\n    Args:\n        angle_in_rad: Angle of the flip axis in radians.\n        three_d: If True, generate a 3D flip matrix.\n\n    Returns:\n        Flip matrix as a torch.Tensor.\n\n    Note:\n        Reference: https://math.stackexchange.com/questions/807031/\n    \"\"\"\n    if three_d:\n        return torch.tensor(\n            np.array([\n                [np.cos(2 * angle_in_rad), np.sin(2 * angle_in_rad), 0],\n                [np.sin(2 * angle_in_rad), -np.cos(2 * angle_in_rad), 0],\n                [0, 0, 1],\n            ]),\n            dtype=torch.float,\n        )\n    return torch.tensor(\n        np.array([\n            [np.cos(2 * angle_in_rad), np.sin(2 * angle_in_rad)],\n            [np.sin(2 * angle_in_rad), -np.cos(2 * angle_in_rad)],\n        ]),\n        dtype=torch.float,\n    )\n</code></pre>"},{"location":"reference/augmentation/#flyvis.datasets.augmentation.utils.flip_permutation_index","title":"flip_permutation_index","text":"<pre><code>flip_permutation_index(extent, axis)\n</code></pre> <p>Get indices used to flip the sequence.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of the regular hexagonal grid.</p> required <code>axis</code> <code>Literal[1, 2, 3]</code> <p>Axis to flip across (1, 2, or 3).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Permutation indices as a torch.Tensor.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If axis is not in [1, 2, 3].</p> Source code in <code>flyvis/datasets/augmentation/utils.py</code> <pre><code>def flip_permutation_index(extent: int, axis: Literal[1, 2, 3]) -&gt; torch.Tensor:\n    \"\"\"Get indices used to flip the sequence.\n\n    Args:\n        extent: Extent of the regular hexagonal grid.\n        axis: Axis to flip across (1, 2, or 3).\n\n    Returns:\n        Permutation indices as a torch.Tensor.\n\n    Raises:\n        ValueError: If axis is not in [1, 2, 3].\n    \"\"\"\n    u, v = hex_utils.get_hex_coords(extent)\n    if axis == 1:\n        # flip across v = 0, that is the x axis.\n        u_new = u + v\n        v_new = -v\n    elif axis == 2:\n        # flip across u = 0, that is the y axis.\n        u_new = -u\n        v_new = u + v\n    elif axis == 3:\n        # flip across u + v = 0, that is the 'z' axis of the hex lattice.\n        u_new = -v\n        v_new = -u\n    else:\n        raise ValueError(\"axis must be in [1, 2, 3].\")\n    return hex_utils.sort_u_then_v_index(u_new, v_new)\n</code></pre>"},{"location":"reference/cli/","title":"Command Line Interface","text":"<p>The command line interface provides a set of tools for managing training, validating, recording, and analyzing models.</p>"},{"location":"reference/cli/#basic-syntax","title":"Basic Syntax","text":"<pre><code>flyvis [COMMANDS] [OPTIONS]\n</code></pre>"},{"location":"reference/cli/#basic-commands","title":"Basic Commands","text":"<p>The following ordered commands represent a complete pipeline:</p> <ul> <li><code>train</code> - Train models</li> <li><code>validate</code> - Run validation on trained models</li> <li><code>record</code> - Record model responses</li> <li><code>analysis</code> - Perform analysis on model results</li> <li><code>notebook-per-model</code> - Generate individual model analysis notebooks</li> <li><code>notebook-per-ensemble</code> - Generate ensemble analysis notebooks</li> </ul> <p>Run as: <pre><code>flyvis train validate record analysis notebook-per-model notebook-per-ensemble [OPTIONS]\n</code></pre></p>"},{"location":"reference/cli/#common-options","title":"Common Options","text":"<ul> <li><code>--ensemble_id ENSEMBLE_ID</code> - Unique identifier for the model ensemble (e.g., \u201c0001\u201d)</li> <li><code>--task_name TASK_NAME</code> - Name of the task to execute (e.g., \u201cflow\u201d)</li> </ul>"},{"location":"reference/cli/#other-commands","title":"Other Commands","text":"<p>Other commands available are:</p> <ul> <li><code>train-single</code> - Train a single model</li> <li><code>val-single</code> - Validate a single model</li> <li><code>synthetic-recordings-single</code> - Record responses for a single model</li> <li><code>ensemble-analysis</code> - Perform analysis on an ensemble</li> <li><code>download-pretrained-models</code> - Download pretrained models</li> <li><code>notebook</code> - Run a notebook</li> </ul> <p>See the cli entry point page for more information or run <code>flyvis --help</code> for a full list of commands.</p>"},{"location":"reference/cli/#script-reference","title":"Script Reference","text":"<p>The following scripts are called by the commands above:</p>"},{"location":"reference/cli/#training-scripts","title":"Training Scripts","text":"<ul> <li><code>train</code> - Main training script for model ensembles</li> <li><code>train_single</code> - Training script for individual models</li> </ul>"},{"location":"reference/cli/#validation-scripts","title":"Validation Scripts","text":"<ul> <li><code>validate</code> - Main validation script for model ensembles</li> <li><code>val_single</code> - Validation script for individual models</li> </ul>"},{"location":"reference/cli/#analysis-scripts","title":"Analysis Scripts","text":"<ul> <li><code>record</code> - Record model responses</li> <li><code>synthetic_recordings_single</code> - Generate synthetic recordings for individual models</li> <li><code>analysis</code> - Launch analysis script for model ensembles</li> <li><code>ensemble_analysis</code> - Analysis script for model ensembles</li> </ul>"},{"location":"reference/cli/#notebook-generation","title":"Notebook Generation","text":"<ul> <li><code>notebook_per_model</code> - Generate analysis notebooks for individual models</li> <li><code>notebook_per_ensemble</code> - Generate analysis notebooks for ensembles</li> <li><code>notebook</code> - General notebook execution script</li> </ul>"},{"location":"reference/cli/#utilities","title":"Utilities","text":"<ul> <li><code>download_pretrained_models</code> - Download pre-trained models</li> </ul>"},{"location":"reference/cli/#example-usage","title":"Example Usage","text":"<p>Some common usage patterns for the <code>flyvis</code> CLI:</p> <pre><code># Example 1: Display the default training configuration\nflyvis train --help\n\n# Example 2: Full pipeline for an ensemble 0001 with 4 models on the flow task with defaults (dry run)\nflyvis \\\n    train validate record analysis notebook-per-model notebook-per-ensemble \\\n    --ensemble_id 0001 \\\n    --task_name flow \\\n    --start 0 \\\n    --end 4 \\\n    --dry\n\n# Example 3: (Re)run the recording of responses and analysis for the existing ensemble 0001\nflyvis \\\n    validate record analysis \\\n    --ensemble_id 0001 \\\n    --task_name flow\n\n# Example 4: Run analysis and generate notebooks for an existing ensemble 0003 with defaults\nflyvis \\\n    analysis notebook-per-model notebook-per-ensemble \\\n    --ensemble_id 0003 \\\n    --task_name flow\n\n# Example 5: Full pipeline for ensemble 0004 on the flow task, with custom ensemble analysis notebook\nflyvis \\\n    train validate record analysis notebook-per-model notebook-per-ensemble \\\n    --ensemble_id 0004 \\\n    --task_name flow \\\n    --notebook_path custom_notebook.ipynb\n\n# Example 6: Run only the record and analysis steps for existing ensemble 0005 on the depth task, with a dry run\nflyvis \\\n    record analysis \\\n    --ensemble_id 0005 \\\n    --task_name depth \\\n    --dry\n\n# Example 7: Full pipeline for ensemble 0006 on the flow task, with custom training settings\nflyvis \\\n    train validate record analysis notebook-per-model notebook-per-ensemble \\\n    --ensemble_id 0006 \\\n    --task_name flow \\\n    --start 0 \\\n    --end 5 \\\n    --nP 8 \\\n    task.n_iters=1000  # note: this combines hydra and argparse syntax\n\n# Example 8: Run a notebook for each model in ensemble 0001\nflyvis notebook-per-model --notebook_per_model_path notebooks/record_custom_stimuli_responses.ipynb \\\n    --ensemble_id 0001 \\\n    --task_name flow \\\n    stim_height:int=4 \\\n    stim_width:int=2 \\\n    speed:float=25\n\n# Example 9: Run a notebook for the entire ensemble 0001\nflyvis notebook-per-ensemble --notebook_path notebooks/analyze_custom_stimuli_responses.ipynb \\\n    --ensemble_id 0001 \\\n    --task_name flow\n</code></pre>"},{"location":"reference/cli/#additional-notes","title":"Additional Notes","text":"<ul> <li>Note that all arguments are passed through from the entry point to the underlying scripts, so you can use all scripts through the entry-point <code>flyvis</code>.</li> <li>The CLI combines the usage of argparse arguments like <code>--ensemble_id</code> and <code>--task_name</code>, hydra arguments like <code>task.n_iters</code> and <code>solver.optim.lr</code>, and passes also typed arguments, like <code>ensemble_id:str=0001</code> to paperpile for notebook execution (required arguments depend on the notebook definition).</li> <li>See the help menu for each script for more information. This is not exhaustively tested in all available configurations, please report any issues on the GitHub repository.</li> </ul>"},{"location":"reference/connectome/","title":"Connectomes","text":""},{"location":"reference/connectome/#connectome-protocol","title":"Connectome protocol","text":"<p>Connectomes must implement the <code>Connectome</code> protocol to be compatible with <code>flyvis.network.network.Network</code>.</p>"},{"location":"reference/connectome/#flyvis.connectome.connectome.Connectome","title":"flyvis.connectome.connectome.Connectome","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for connectome classes compatible with flyvis.network.Network.</p> Note <p>Nodes and edges have additional attributes that require compatibility with <code>Parameter</code> class implementations. For instance, when a parameter for edges is derived from synapse counts, the edges have an <code>n_syn</code> attribute (ArrayFile or np.ndarray).</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>class Connectome(Protocol):\n    \"\"\"Protocol for connectome classes compatible with flyvis.network.Network.\n\n    Note:\n        Nodes and edges have additional attributes that require compatibility\n        with `Parameter` class implementations. For instance, when a parameter\n        for edges is derived from synapse counts, the edges have an `n_syn`\n        attribute (ArrayFile or np.ndarray).\n    \"\"\"\n\n    class nodes:\n        index: Union[np.ndarray, ArrayFile]\n        ...\n\n    class edges:\n        source_index: Union[np.ndarray, ArrayFile]\n        target_index: Union[np.ndarray, ArrayFile]\n        ...\n</code></pre>"},{"location":"reference/connectome/#compilation-from-average-filters","title":"Compilation from average filters","text":""},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeFromAvgFilters","title":"flyvis.connectome.connectome.ConnectomeFromAvgFilters","text":"<p>               Bases: <code>Directory</code></p> <p>Compiles a connectome graph from average convolutional filters.</p> <p>The graph consists of cells (nodes) and synapse sets (edges).</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <p>The name of a JSON connectome file.</p> <code>name</code> <code>extent</code> <p>The array radius, in columns.</p> <code>15</code> <code>n_syn_fill</code> <p>The number of synapses to assume in data gaps.</p> <code>1</code> <p>Attributes:</p> Name Type Description <code>unique_cell_types</code> <code>ArrayFile</code> <p>Identified cell types.</p> <code>input_cell_types</code> <code>ArrayFile</code> <p>Input cell types.</p> <code>intermediate_cell_types</code> <code>ArrayFile</code> <p>Hidden cell types.</p> <code>output_cell_types</code> <code>ArrayFile</code> <p>Decoded cell types.</p> <code>central_cells_index</code> <code>ArrayFile</code> <p>Index of central cell in nodes table for each cell type in unique_cell_types.</p> <code>layout</code> <code>ArrayFile</code> <p>Input, hidden, output definitions for visualization.</p> <code>nodes</code> <code>NodeDir</code> <p>Table with a row for each individual node/cell.</p> <code>edges</code> <code>EdgeDir</code> <p>Table with a row for each edge.</p> Note <p>A connectome can be constructed from a JSON model file following this schema:</p> <pre><code>{\n    \"nodes\": [{\n        \"name\": string,\n        \"pattern\": (\n            [\"stride\", [&lt;u_stride:int&gt;, &lt;v_stride:int&gt;]]\n            | [\"tile\", &lt;stride:int&gt;]\n            | [\"single\", null]\n        )\n    }*],\n    \"edges\": [{\n        \"src\": string,\n        \"tar\": string,\n        \"alpha\": int,\n        \"offsets\": [[\n            [&lt;du:int&gt;, &lt;dv:int&gt;],\n            &lt;n_synapses:number&gt;\n            ]*],\n        }*]\n    }\n}\n</code></pre> <p>See \u201cdata/connectome/fib25-fib19_v2.2.json\u201d for an example.</p> Example <pre><code>config = Namespace(file='fib25-fib19_v2.2.json', extent=15, n_syn_fill=1)\nconnectome = Connectome(config)\n</code></pre> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>@register_connectome\n@root(flyvis.root_dir / \"connectome\")\nclass ConnectomeFromAvgFilters(Directory):\n    \"\"\"Compiles a connectome graph from average convolutional filters.\n\n    The graph consists of cells (nodes) and synapse sets (edges).\n\n    Args:\n        file: The name of a JSON connectome file.\n        extent: The array radius, in columns.\n        n_syn_fill: The number of synapses to assume in data gaps.\n\n    Attributes:\n        unique_cell_types (ArrayFile): Identified cell types.\n        input_cell_types (ArrayFile): Input cell types.\n        intermediate_cell_types (ArrayFile): Hidden cell types.\n        output_cell_types (ArrayFile): Decoded cell types.\n        central_cells_index (ArrayFile): Index of central cell in nodes table\n            for each cell type in unique_cell_types.\n        layout (ArrayFile): Input, hidden, output definitions for visualization.\n        nodes (NodeDir): Table with a row for each individual node/cell.\n        edges (EdgeDir): Table with a row for each edge.\n\n    Note:\n        A connectome can be constructed from a JSON model file following this schema:\n\n        ```json\n        {\n            \"nodes\": [{\n                \"name\": string,\n                \"pattern\": (\n                    [\"stride\", [&lt;u_stride:int&gt;, &lt;v_stride:int&gt;]]\n                    | [\"tile\", &lt;stride:int&gt;]\n                    | [\"single\", null]\n                )\n            }*],\n            \"edges\": [{\n                \"src\": string,\n                \"tar\": string,\n                \"alpha\": int,\n                \"offsets\": [[\n                    [&lt;du:int&gt;, &lt;dv:int&gt;],\n                    &lt;n_synapses:number&gt;\n                    ]*],\n                }*]\n            }\n        }\n        ```\n\n        See \"data/connectome/fib25-fib19_v2.2.json\" for an example.\n\n    Example:\n        ```python\n        config = Namespace(file='fib25-fib19_v2.2.json', extent=15, n_syn_fill=1)\n        connectome = Connectome(config)\n        ```\n    \"\"\"\n\n    def __init__(self, file=flyvis.connectome_file.name, extent=15, n_syn_fill=1) -&gt; None:\n        # case 0: file is an absolute path\n        if Path(file).exists():\n            file = Path(file)\n        # case 1: file is specified within the package resources\n        elif (resources.files(\"flyvis.connectome\") / file).is_file():\n            file = resources.files(\"flyvis.connectome\").joinpath(file)\n        # case 2: file is specified relative to the root directory\n        elif (flyvis.root_dir / \"connectome\" / file).exists():\n            file = flyvis.root_dir / \"connectome\" / file\n        else:\n            raise FileNotFoundError(f\"Connectome file {file} not found.\")\n\n        # Load the connectome spec.\n        spec = json.loads(Path(file).read_text())\n\n        # Store unique cell types and layout variables.\n        self.unique_cell_types = np.bytes_([n[\"name\"] for n in spec[\"nodes\"]])\n        self.input_cell_types = np.bytes_(spec[\"input_units\"])\n        self.output_cell_types = np.bytes_(spec[\"output_units\"])\n        intermediate_cell_types, _ = nodes_edges_utils.order_node_type_list(\n            np.array(\n                list(\n                    set(self.unique_cell_types)\n                    - set(self.input_cell_types)\n                    - set(self.output_cell_types)\n                )\n            ).astype(str)\n        )\n        self.intermediate_cell_types = np.array(intermediate_cell_types).astype(\"S\")\n\n        layout = []\n        layout.extend(\n            list(\n                zip(\n                    self.input_cell_types,\n                    [b\"retina\" for _ in range(len(self.input_cell_types))],\n                )\n            )\n        )\n        layout.extend(\n            list(\n                zip(\n                    self.intermediate_cell_types,\n                    [b\"intermediate\" for _ in range(len(self.intermediate_cell_types))],\n                )\n            )\n        )\n        layout.extend(\n            list(\n                zip(\n                    self.output_cell_types,\n                    [b\"output\" for _ in range(len(self.output_cell_types))],\n                )\n            )\n        )\n        self.layout = np.bytes_(layout)\n\n        # Construct nodes and edges.\n        nodes: List[Node] = []\n        edges: List[Edge] = []\n        add_nodes(nodes, spec[\"nodes\"], extent)\n        add_edges(edges, nodes, spec[\"edges\"], n_syn_fill)\n\n        # Define node roles (input, intermediate, output).\n        _role = {node: \"intermediate\" for node in set([n.type for n in nodes])}\n        _role.update({node: \"input\" for node in _role if node in spec[\"input_units\"]})\n        _role.update({node: \"output\" for node in _role if node in spec[\"output_units\"]})\n\n        # Store the graph.\n        self.nodes = dict(  # type: ignore\n            index=np.int64([n.id for n in nodes]),\n            type=np.bytes_([n.type for n in nodes]),\n            u=np.int32([n.u for n in nodes]),\n            v=np.int32([n.v for n in nodes]),\n            role=np.bytes_([_role[n.type] for n in nodes]),\n        )\n\n        self.edges = dict(  # type: ignore\n            # [Essential fields]\n            source_index=np.int64([e.source.id for e in edges]),\n            target_index=np.int64([e.target.id for e in edges]),\n            sign=np.float32([e.sign for e in edges]),\n            n_syn=np.float32([e.n_syn for e in edges]),\n            # [Convenience fields]\n            source_type=np.bytes_([e.source.type for e in edges]),\n            target_type=np.bytes_([e.target.type for e in edges]),\n            source_u=np.int32([e.source.u for e in edges]),\n            target_u=np.int32([e.target.u for e in edges]),\n            source_v=np.int32([e.source.v for e in edges]),\n            target_v=np.int32([e.target.v for e in edges]),\n            du=np.int32([e.target.u - e.source.u for e in edges]),\n            dv=np.int32([e.target.v - e.source.v for e in edges]),\n            n_syn_certainty=np.float32([e.n_syn_certainty for e in edges]),\n        )\n\n        # Store central indices.\n        self.central_cells_index = np.int64(\n            np.nonzero((self.nodes.u[:] == 0) &amp; (self.nodes.v[:] == 0))[0]\n        )\n\n        # Store layer indices.\n        layer_index = {}\n        for cell_type in self.unique_cell_types[:]:\n            node_indices = np.nonzero(self.nodes[\"type\"][:] == cell_type)[0]\n            layer_index[cell_type.decode()] = np.int64(node_indices)\n        self.nodes.layer_index = layer_index\n</code></pre>"},{"location":"reference/connectome/#analysis-and-visualization","title":"Analysis and visualization","text":""},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView","title":"flyvis.connectome.connectome.ConnectomeView","text":"<p>Visualization of the connectome data.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Directory of the connectome.</p> required <code>groups</code> <code>List[str]</code> <p>Regular expressions to sort the nodes by.</p> <code>['R\\\\d', 'L\\\\d', 'Lawf\\\\d', 'A', 'C\\\\d', 'CT\\\\d.*', 'Mi\\\\d{1,2}', 'T\\\\d{1,2}.*', 'Tm.*\\\\d{1,2}.*']</code> <p>Attributes:</p> Name Type Description <code>dir</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory.</p> <code>edges</code> <code>Directory</code> <p>Edge table.</p> <code>nodes</code> <code>Directory</code> <p>Node table.</p> <code>cell_types_unsorted</code> <code>List[str]</code> <p>Unsorted list of cell types.</p> <code>cell_types_sorted</code> <code>List[str]</code> <p>Sorted list of cell types.</p> <code>cell_types_sort_index</code> <code>List[int]</code> <p>Indices for sorting cell types.</p> <code>layout</code> <code>Dict[str, str]</code> <p>Layout information for cell types.</p> <code>node_indexer</code> <code>NodeIndexer</code> <p>Indexer for nodes.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>class ConnectomeView:\n    \"\"\"Visualization of the connectome data.\n\n    Args:\n        connectome: Directory of the connectome.\n        groups: Regular expressions to sort the nodes by.\n\n    Attributes:\n        dir (ConnectomeFromAvgFilters): Connectome directory.\n        edges (Directory): Edge table.\n        nodes (Directory): Node table.\n        cell_types_unsorted (List[str]): Unsorted list of cell types.\n        cell_types_sorted (List[str]): Sorted list of cell types.\n        cell_types_sort_index (List[int]): Indices for sorting cell types.\n        layout (Dict[str, str]): Layout information for cell types.\n        node_indexer (NodeIndexer): Indexer for nodes.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: ConnectomeFromAvgFilters,\n        groups: List[str] = [\n            r\"R\\d\",\n            r\"L\\d\",\n            r\"Lawf\\d\",\n            r\"A\",\n            r\"C\\d\",\n            r\"CT\\d.*\",\n            r\"Mi\\d{1,2}\",\n            r\"T\\d{1,2}.*\",\n            r\"Tm.*\\d{1,2}.*\",\n        ],\n    ) -&gt; None:\n        self.dir = connectome\n\n        assert \"nodes\" in self.dir and \"edges\" in self.dir\n\n        self.edges = self.dir.edges\n        self.nodes = self.dir.nodes\n\n        self.cell_types_unsorted = self.dir.unique_cell_types[:].astype(str)\n\n        (\n            self.cell_types_sorted,\n            self.cell_types_sort_index,\n        ) = nodes_edges_utils.order_node_type_list(\n            self.dir.unique_cell_types[:].astype(str), groups\n        )\n\n        self.layout = dict(self.dir.layout[:].astype(str))\n        self.node_indexer = nodes_edges_utils.NodeIndexer(self.dir)\n\n    def connectivity_matrix(\n        self,\n        mode: str = \"n_syn\",\n        only_sign: Optional[str] = None,\n        cell_types: Optional[List[str]] = None,\n        no_symlog: Optional[bool] = False,\n        min_number: Optional[float] = None,\n        cmap: Optional[Colormap] = None,\n        size_scale: Optional[float] = None,\n        title: Optional[str] = None,\n        cbar_label: Optional[str] = None,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot the connectivity matrix as counts or weights.\n\n        Args:\n            mode: 'n_syn' for number of input synapses, 'count' for number of neurons.\n            only_sign: '+' for excitatory projections, '-' for inhibitory projections.\n            cell_types: Subset of nodes to display.\n            no_symlog: Disable symmetric log scale.\n            min_number: Minimum value to display.\n            cmap: Custom colormap.\n            size_scale: Size of the scattered squares.\n            title: Custom title for the plot.\n            cbar_label: Custom colorbar label.\n            **kwargs: Additional arguments passed to the heatmap plot function.\n\n        Returns:\n            Figure: Matplotlib figure object.\n        \"\"\"\n        _kwargs = dict(\n            n_syn=dict(\n                symlog=1e-5,\n                grid=True,\n                cmap=cmap or cm.get_cmap(\"seismic\"),\n                title=title or \"Connectivity between identified cell types\",\n                cbar_label=cbar_label or r\"$\\pm\\sum_{pre} N_\\mathrm{syn.}^{pre, post}$\",\n                size_scale=size_scale or 0.05,\n            ),\n            count=dict(\n                grid=True,\n                cmap=cmap or cm.get_cmap(\"seismic\"),\n                midpoint=0,\n                title=title or \"Number of Input Neurons\",\n                cbar_label=cbar_label or r\"$\\sum_{pre} 1$\",\n                size_scale=size_scale or 0.05,\n            ),\n        )\n\n        kwargs.update(_kwargs[mode])\n        if no_symlog:\n            kwargs.update(symlog=None)\n            kwargs.update(midpoint=0)\n\n        edges = self.edges.to_df()\n\n        # to take projections onto central nodes (home columns) into account\n        edges = edges[(edges.target_u == 0) &amp; (edges.target_v == 0)]\n\n        # filter edges to allow providing a subset of cell types\n        cell_types = cell_types or self.cell_types_sorted\n        edges = df_utils.filter_by_column_values(\n            df_utils.filter_by_column_values(\n                edges, column=\"source_type\", values=cell_types\n            ),\n            column=\"target_type\",\n            values=cell_types,\n        )\n        weights = self._weights()[edges.index]\n\n        # lookup table for key -&gt; (i, j)\n        type_index = {node_typ: i for i, node_typ in enumerate(cell_types)}\n        matrix = np.zeros([len(type_index), len(type_index)])\n\n        for srctyp, tgttyp, weight in zip(\n            edges.source_type.values, edges.target_type.values, weights\n        ):\n            if mode == \"count\":\n                # to simply count the number of projections\n                matrix[type_index[srctyp], type_index[tgttyp]] += 1\n            elif mode in [\"weight\", \"n_syn\"]:\n                # to sum the synapse counts\n                matrix[type_index[srctyp], type_index[tgttyp]] += weight\n            else:\n                raise ValueError\n\n        # to filter out all connections weaker than min_number\n        if min_number is not None:\n            matrix[np.abs(matrix) &lt;= min_number] = np.nan\n\n        # to display either only excitatory or inhibitory connections\n        if only_sign == \"+\":\n            matrix[matrix &lt; 0] = 0\n            kwargs.update(symlog=None, midpoint=0)\n        elif only_sign == \"-\":\n            matrix[matrix &gt; 0] = 0\n            kwargs.update(symlog=None, midpoint=0)\n        elif only_sign is None:\n            pass\n        else:\n            raise ValueError\n\n        return plots.heatmap(matrix, cell_types, **kwargs)\n\n    def _weights(self) -&gt; NDArray:\n        \"\"\"Calculate weights for edges.\n\n        Returns:\n            NDArray: Array of edge weights.\n        \"\"\"\n        return self.edges.sign[:] * self.edges.n_syn[:]\n\n    def network_layout(\n        self,\n        max_extent: int = 5,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot retinotopic hexagonal lattice columnar organization of the network.\n\n        Args:\n            max_extent: Integer column radius to visualize.\n            **kwargs: Additional arguments passed to hex_layout_all.\n\n        Returns:\n            Figure: Matplotlib figure object.\n        \"\"\"\n        backbone = WholeNetworkFigure(self.dir)\n        backbone.init_figure(figsize=[7, 3])\n        return self.hex_layout_all(\n            max_extent=max_extent, fig=backbone.fig, axes=backbone.axes, **kwargs\n        )\n\n    def hex_layout(\n        self,\n        cell_type: str,\n        max_extent: int = 5,\n        edgecolor: str = \"none\",\n        edgewidth: float = 0.5,\n        alpha: float = 1,\n        fill: bool = False,\n        cmap: Optional[Colormap] = None,\n        fig: Optional[Figure] = None,\n        ax: Optional[Axes] = None,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot retinotopic hexagonal lattice organization of a cell type.\n\n        Args:\n            cell_type: Type of cell to plot.\n            max_extent: Maximum extent of the layout.\n            edgecolor: Color of the hexagon edges.\n            edgewidth: Width of the hexagon edges.\n            alpha: Transparency of the hexagons.\n            fill: Whether to fill the hexagons.\n            cmap: Custom colormap.\n            fig: Existing figure to plot on.\n            ax: Existing axis to plot on.\n            **kwargs: Additional arguments passed to hex_scatter.\n\n        Returns:\n            Figure: Matplotlib figure object.\n        \"\"\"\n        nodes = self.nodes.to_df()\n        node_condition = nodes.type == cell_type\n        u, v = nodes.u[node_condition], nodes.v[node_condition]\n        max_extent = hex_utils.get_extent(u, v) if max_extent is None else max_extent\n        extent_condition = (\n            (-max_extent &lt;= u)\n            &amp; (u &lt;= max_extent)\n            &amp; (-max_extent &lt;= v)\n            &amp; (v &lt;= max_extent)\n            &amp; (-max_extent &lt;= u + v)\n            &amp; (u + v &lt;= max_extent)\n        )\n        u, v = u[extent_condition].values, v[extent_condition].values\n\n        label = cell_type\n        if ax is not None:\n            # prevent labeling twice\n            label = cell_type if cell_type not in [t.get_text() for t in ax.texts] else \"\"\n\n        fig, ax, _ = plots.hex_scatter(\n            u,\n            v,\n            values=1,\n            label=label,\n            fig=fig,\n            ax=ax,\n            edgecolor=edgecolor,\n            edgewidth=edgewidth,\n            alpha=alpha,\n            fill=fill,\n            cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n            cbar=False,\n            **kwargs,\n        )\n        return fig\n\n    def hex_layout_all(\n        self,\n        cell_types: Optional[List[str]] = None,\n        max_extent: int = 5,\n        edgecolor: str = \"none\",\n        alpha: float = 1,\n        fill: bool = False,\n        cmap: Optional[Colormap] = None,\n        fig: Optional[Figure] = None,\n        axes: Optional[List[Axes]] = None,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot retinotopic hexagonal lattice organization of all cell types.\n\n        Args:\n            cell_types: List of cell types to plot.\n            max_extent: Maximum extent of the layout.\n            edgecolor: Color of the hexagon edges.\n            alpha: Transparency of the hexagons.\n            fill: Whether to fill the hexagons.\n            cmap: Custom colormap.\n            fig: Existing figure to plot on.\n            axes: List of existing axes to plot on.\n            **kwargs: Additional arguments passed to hex_layout.\n\n        Returns:\n            Figure: Matplotlib figure object.\n        \"\"\"\n        cell_types = self.cell_types_sorted if cell_types is None else cell_types\n        if fig is None or axes is None:\n            fig, axes, (gw, gh) = plt_utils.get_axis_grid(self.cell_types_sorted)\n\n        for i, cell_type in enumerate(cell_types):\n            self.hex_layout(\n                cell_type,\n                edgecolor=edgecolor,\n                edgewidth=0.1,\n                alpha=alpha,\n                fill=fill,\n                max_extent=max_extent,\n                cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n                fig=fig,\n                ax=axes[i],\n                **kwargs,\n            )\n        return fig\n\n    def get_uv(self, cell_type: str) -&gt; Tuple[NDArray, NDArray]:\n        \"\"\"Get hex-coordinates of a particular cell type.\n\n        Args:\n            cell_type: Type of cell to get coordinates for.\n\n        Returns:\n            Tuple[NDArray, NDArray]: Arrays of u and v coordinates.\n        \"\"\"\n        nodes = self.nodes.to_df()\n        nodes = nodes[nodes.type == cell_type]\n        u, v = nodes[[\"u\", \"v\"]].values.T\n        return u, v\n\n    def sources_list(self, cell_type: str) -&gt; NDArray:\n        \"\"\"Get presynaptic cell types.\n\n        Args:\n            cell_type: Type of cell to get sources for.\n\n        Returns:\n            NDArray: Array of presynaptic cell types.\n        \"\"\"\n        edges = self.edges.to_df()\n        return np.unique(edges[edges.target_type == cell_type].source_type.values)\n\n    def targets_list(self, cell_type: str) -&gt; NDArray:\n        \"\"\"Get postsynaptic cell types.\n\n        Args:\n            cell_type: Type of cell to get targets for.\n\n        Returns:\n            NDArray: Array of postsynaptic cell types.\n        \"\"\"\n        edges = self.edges.to_df()\n        return np.unique(edges[edges.source_type == cell_type].target_type.values)\n\n    def receptive_field(\n        self,\n        source: str = \"Mi9\",\n        target: str = \"T4a\",\n        rfs: Optional[\"ReceptiveFields\"] = None,\n        max_extent: Optional[int] = None,\n        vmin: Optional[float] = None,\n        vmax: Optional[float] = None,\n        title: str = \"{source} :\u2192 {target}\",\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot the receptive field of a target cell type from a source cell type.\n\n        Args:\n            source: Source cell type.\n            target: Target cell type.\n            rfs: ReceptiveFields object. If None, it will be created.\n            max_extent: Maximum extent of the receptive field.\n            vmin: Minimum value for colormap.\n            vmax: Maximum value for colormap.\n            title: Title format string for the plot.\n            **kwargs: Additional arguments passed to plots.kernel.\n\n        Returns:\n            Matplotlib Figure object.\n        \"\"\"\n        if rfs is None:\n            rfs = ReceptiveFields(target, self.edges.to_df())\n            max_extent = max_extent or rfs.max_extent\n\n        weights = self._weights()\n\n        # to derive color range values taking all inputs into account\n        vmin = min(\n            0,\n            min(weights[rfs[source].index].min() for source in rfs.source_types),\n        )\n        vmax = max(\n            0,\n            max(weights[rfs[source].index].max() for source in rfs.source_types),\n        )\n\n        weights = weights[rfs[source].index]\n        label = \"\"\n\n        # requires to look from the target cell, ie mirror the coordinates\n        du_inv, dv_inv = -rfs[source].du.values, -rfs[source].dv.values\n        fig, ax, (label_text, scalarmapper) = plots.kernel(\n            du_inv,\n            dv_inv,\n            weights,\n            label=label,\n            max_extent=max_extent,\n            fill=True,\n            vmin=vmin,\n            vmax=vmax,\n            title=title.format(**locals()),\n            **kwargs,\n        )\n        return fig\n\n    def receptive_fields_grid(\n        self,\n        target: str,\n        sources: Optional[Iterable[str]] = None,\n        sort_alphabetically: bool = True,\n        ax_titles: str = \"{source} :\u2192 {target}\",\n        figsize: List[int] = [20, 20],\n        max_extent: Optional[int] = None,\n        fig: Optional[Figure] = None,\n        axes: Optional[List[Axes]] = None,\n        ignore_sign_error: bool = False,\n        max_figure_height_cm: float = 22,\n        panel_height_cm: float = 3,\n        max_figure_width_cm: float = 18,\n        panel_width_cm: float = 3.6,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot receptive fields of a target cell type in a grid layout.\n\n        Args:\n            target: Target cell type.\n            sources: Iterable of source cell types. If None, all sources are used.\n            sort_alphabetically: Whether to sort source types alphabetically.\n            ax_titles: Title format string for each subplot.\n            figsize: Figure size in inches.\n            max_extent: Maximum extent of the receptive fields.\n            fig: Existing figure to plot on.\n            axes: List of existing axes to plot on.\n            ignore_sign_error: Whether to ignore sign errors in plotting.\n            max_figure_height_cm: Maximum figure height in cm.\n            panel_height_cm: Height of each panel in cm.\n            max_figure_width_cm: Maximum figure width in cm.\n            panel_width_cm: Width of each panel in cm.\n            **kwargs: Additional arguments passed to receptive_field.\n\n        Returns:\n            Matplotlib Figure object.\n        \"\"\"\n\n        rfs = ReceptiveFields(target, self.edges.to_df())\n        max_extent = max_extent or rfs.max_extent\n        weights = self._weights()\n\n        # to sort in descending order by sum of inputs\n        sorted_sum_of_inputs = dict(\n            sorted(\n                valmap(lambda v: weights[v.index].sum(), rfs).items(),\n                key=lambda item: item[1],\n                reverse=True,\n            )\n        )\n        # to sort alphabetically in case sources is specified\n        if sort_alphabetically:\n            sources, _ = nodes_edges_utils.order_node_type_list(sources)\n        sources = sources or list(sorted_sum_of_inputs.keys())\n\n        # to derive color range values taking all inputs into account\n        vmin = min(0, min(weights[rfs[source].index].min() for source in sources))\n        vmax = max(0, max(weights[rfs[source].index].max() for source in sources))\n\n        if fig is None or axes is None:\n            figsize = figsize_from_n_items(\n                len(rfs.source_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=len(rfs.source_types), hspace=0.0, wspace=0\n            )\n\n        cbar = kwargs.get(\"cbar\", False)\n        for i, src in enumerate(sources):\n            if i == 0 and cbar:\n                cbar = True\n                kwargs.update(cbar=cbar)\n            else:\n                cbar = False\n                kwargs.update(cbar=cbar)\n            try:\n                self.receptive_field(\n                    target=target,\n                    source=src,\n                    fig=fig,\n                    ax=axes[i],\n                    title=ax_titles,\n                    vmin=vmin,\n                    vmax=vmax,\n                    rfs=rfs,\n                    max_extent=max_extent,\n                    annotate=False,\n                    annotate_coords=False,\n                    title_y=0.9,\n                    **kwargs,\n                )\n            except plots.SignError as e:\n                if ignore_sign_error:\n                    pass\n                else:\n                    raise e\n        return fig\n\n    def projective_field(\n        self,\n        source: str = \"Mi9\",\n        target: str = \"T4a\",\n        title: str = \"{source} \u2192: {target}\",\n        prfs: Optional[\"ProjectiveFields\"] = None,\n        max_extent: Optional[int] = None,\n        vmin: Optional[float] = None,\n        vmax: Optional[float] = None,\n        **kwargs,\n    ) -&gt; Optional[Figure]:\n        \"\"\"Plot the projective field from a source cell type to a target cell type.\n\n        Args:\n            source: Source cell type.\n            target: Target cell type.\n            title: Title format string for the plot.\n            prfs: ProjectiveFields object. If None, it will be created.\n            max_extent: Maximum extent of the projective field.\n            vmin: Minimum value for colormap.\n            vmax: Maximum value for colormap.\n            **kwargs: Additional arguments passed to plots.kernel.\n\n        Returns:\n            Matplotlib Figure object or None if max_extent is None.\n        \"\"\"\n        if prfs is None:\n            prfs = ProjectiveFields(source, self.edges.to_df())\n            max_extent = max_extent or prfs.max_extent\n        if max_extent is None:\n            return None\n        weights = self._weights()\n\n        # to derive color range values taking all inputs into account\n        vmin = min(\n            0,\n            min(weights[prfs[target].index].min() for target in prfs.target_types),\n        )\n\n        vmax = max(\n            0,\n            max(weights[prfs[target].index].max() for target in prfs.target_types),\n        )\n\n        weights = weights[prfs[target].index]\n        label = \"\"\n        du, dv = prfs[target].du.values, prfs[target].dv.values\n        fig, ax, (label_text, scalarmapper) = plots.kernel(\n            du,\n            dv,\n            weights,\n            label=label,\n            fill=True,\n            max_extent=max_extent,\n            vmin=vmin,\n            vmax=vmax,\n            title=title.format(**locals()),\n            **kwargs,\n        )\n        return fig\n\n    def projective_fields_grid(\n        self,\n        source: str,\n        targets: Optional[Iterable[str]] = None,\n        fig: Optional[Figure] = None,\n        axes: Optional[List[Axes]] = None,\n        figsize: List[int] = [20, 20],\n        ax_titles: str = \"{source} \u2192: {target}\",\n        max_figure_height_cm: float = 22,\n        panel_height_cm: float = 3,\n        max_figure_width_cm: float = 18,\n        panel_width_cm: float = 3.6,\n        max_extent: Optional[int] = None,\n        sort_alphabetically: bool = False,\n        ignore_sign_error: bool = False,\n        **kwargs,\n    ) -&gt; Figure:\n        \"\"\"Plot projective fields of a source cell type in a grid layout.\n\n        Args:\n            source: Source cell type.\n            targets: Iterable of target cell types. If None, all targets are used.\n            fig: Existing figure to plot on.\n            axes: List of existing axes to plot on.\n            figsize: Figure size in inches.\n            ax_titles: Title format string for each subplot.\n            max_figure_height_cm: Maximum figure height in cm.\n            panel_height_cm: Height of each panel in cm.\n            max_figure_width_cm: Maximum figure width in cm.\n            panel_width_cm: Width of each panel in cm.\n            max_extent: Maximum extent of the projective fields.\n            sort_alphabetically: Whether to sort target types alphabetically.\n            ignore_sign_error: Whether to ignore sign errors in plotting.\n            **kwargs: Additional arguments passed to projective_field.\n\n        Returns:\n            Matplotlib Figure object.\n        \"\"\"\n        prfs = ProjectiveFields(source, self.edges.to_df())\n        max_extent = max_extent or prfs.max_extent\n        weights = self._weights()\n        sorted_sum_of_outputs = dict(\n            sorted(\n                valmap(lambda v: weights[v.index].sum(), prfs).items(),\n                key=lambda item: item[1],\n                reverse=True,\n            )\n        )\n\n        # to sort alphabetically in case sources is specified\n        if sort_alphabetically:\n            targets, _ = nodes_edges_utils.order_node_type_list(targets)\n\n        targets = targets or list(sorted_sum_of_outputs.keys())\n\n        vmin = min(0, min(weights[prfs[target].index].min() for target in targets))\n        vmax = max(0, max(weights[prfs[target].index].max() for target in targets))\n\n        if fig is None or axes is None:\n            figsize = figsize_from_n_items(\n                len(prfs.target_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=len(prfs.target_types), hspace=0.0, wspace=0\n            )\n\n        cbar = kwargs.get(\"cbar\", False)\n        for i, target in enumerate(targets):\n            if i == 0 and cbar:\n                cbar = True\n                kwargs.update(cbar=cbar)\n            else:\n                cbar = False\n                kwargs.update(cbar=cbar)\n            try:\n                self.projective_field(\n                    source=source,\n                    target=target,\n                    fig=fig,\n                    ax=axes[i],\n                    title=ax_titles,\n                    prfs=prfs,\n                    max_extent=max_extent,\n                    vmin=vmin,\n                    vmax=vmax,\n                    annotate_coords=False,\n                    annotate=False,\n                    title_y=0.9,\n                    **kwargs,\n                )\n            except plots.SignError as e:\n                if ignore_sign_error:\n                    pass\n                else:\n                    raise e\n        return fig\n\n    def receptive_fields_df(self, target_type: str) -&gt; \"ReceptiveFields\":\n        \"\"\"Get receptive fields for a target cell type.\n\n        Args:\n            target_type: Target cell type.\n\n        Returns:\n            ReceptiveFields object.\n        \"\"\"\n        return ReceptiveFields(target_type, self.edges.to_df())\n\n    def projective_fields_df(self, source_type: str) -&gt; \"ProjectiveFields\":\n        \"\"\"Get projective fields for a source cell type.\n\n        Args:\n            source_type: Source cell type.\n\n        Returns:\n            ProjectiveFields object.\n        \"\"\"\n        return ProjectiveFields(source_type, self.edges.to_df())\n\n    def receptive_fields_sum(self, target_type: str) -&gt; Dict[str, int]:\n        \"\"\"Get sum of synapses for each source type in the receptive field.\n\n        Args:\n            target_type: Target cell type.\n\n        Returns:\n            Dictionary mapping source types to synapse counts.\n        \"\"\"\n        return ReceptiveFields(target_type, self.edges.to_df()).sum()\n\n    def projective_fields_sum(self, source_type: str) -&gt; Dict[str, int]:\n        \"\"\"Get sum of synapses for each target type in the projective field.\n\n        Args:\n            source_type: Source cell type.\n\n        Returns:\n            Dictionary mapping target types to synapse counts.\n        \"\"\"\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.connectivity_matrix","title":"connectivity_matrix","text":"<pre><code>connectivity_matrix(mode='n_syn', only_sign=None, cell_types=None, no_symlog=False, min_number=None, cmap=None, size_scale=None, title=None, cbar_label=None, **kwargs)\n</code></pre> <p>Plot the connectivity matrix as counts or weights.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>\u2018n_syn\u2019 for number of input synapses, \u2018count\u2019 for number of neurons.</p> <code>'n_syn'</code> <code>only_sign</code> <code>Optional[str]</code> <p>\u2019+\u2019 for excitatory projections, \u2018-\u2019 for inhibitory projections.</p> <code>None</code> <code>cell_types</code> <code>Optional[List[str]]</code> <p>Subset of nodes to display.</p> <code>None</code> <code>no_symlog</code> <code>Optional[bool]</code> <p>Disable symmetric log scale.</p> <code>False</code> <code>min_number</code> <code>Optional[float]</code> <p>Minimum value to display.</p> <code>None</code> <code>cmap</code> <code>Optional[Colormap]</code> <p>Custom colormap.</p> <code>None</code> <code>size_scale</code> <code>Optional[float]</code> <p>Size of the scattered squares.</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>Custom title for the plot.</p> <code>None</code> <code>cbar_label</code> <code>Optional[str]</code> <p>Custom colorbar label.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the heatmap plot function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>Matplotlib figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def connectivity_matrix(\n    self,\n    mode: str = \"n_syn\",\n    only_sign: Optional[str] = None,\n    cell_types: Optional[List[str]] = None,\n    no_symlog: Optional[bool] = False,\n    min_number: Optional[float] = None,\n    cmap: Optional[Colormap] = None,\n    size_scale: Optional[float] = None,\n    title: Optional[str] = None,\n    cbar_label: Optional[str] = None,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot the connectivity matrix as counts or weights.\n\n    Args:\n        mode: 'n_syn' for number of input synapses, 'count' for number of neurons.\n        only_sign: '+' for excitatory projections, '-' for inhibitory projections.\n        cell_types: Subset of nodes to display.\n        no_symlog: Disable symmetric log scale.\n        min_number: Minimum value to display.\n        cmap: Custom colormap.\n        size_scale: Size of the scattered squares.\n        title: Custom title for the plot.\n        cbar_label: Custom colorbar label.\n        **kwargs: Additional arguments passed to the heatmap plot function.\n\n    Returns:\n        Figure: Matplotlib figure object.\n    \"\"\"\n    _kwargs = dict(\n        n_syn=dict(\n            symlog=1e-5,\n            grid=True,\n            cmap=cmap or cm.get_cmap(\"seismic\"),\n            title=title or \"Connectivity between identified cell types\",\n            cbar_label=cbar_label or r\"$\\pm\\sum_{pre} N_\\mathrm{syn.}^{pre, post}$\",\n            size_scale=size_scale or 0.05,\n        ),\n        count=dict(\n            grid=True,\n            cmap=cmap or cm.get_cmap(\"seismic\"),\n            midpoint=0,\n            title=title or \"Number of Input Neurons\",\n            cbar_label=cbar_label or r\"$\\sum_{pre} 1$\",\n            size_scale=size_scale or 0.05,\n        ),\n    )\n\n    kwargs.update(_kwargs[mode])\n    if no_symlog:\n        kwargs.update(symlog=None)\n        kwargs.update(midpoint=0)\n\n    edges = self.edges.to_df()\n\n    # to take projections onto central nodes (home columns) into account\n    edges = edges[(edges.target_u == 0) &amp; (edges.target_v == 0)]\n\n    # filter edges to allow providing a subset of cell types\n    cell_types = cell_types or self.cell_types_sorted\n    edges = df_utils.filter_by_column_values(\n        df_utils.filter_by_column_values(\n            edges, column=\"source_type\", values=cell_types\n        ),\n        column=\"target_type\",\n        values=cell_types,\n    )\n    weights = self._weights()[edges.index]\n\n    # lookup table for key -&gt; (i, j)\n    type_index = {node_typ: i for i, node_typ in enumerate(cell_types)}\n    matrix = np.zeros([len(type_index), len(type_index)])\n\n    for srctyp, tgttyp, weight in zip(\n        edges.source_type.values, edges.target_type.values, weights\n    ):\n        if mode == \"count\":\n            # to simply count the number of projections\n            matrix[type_index[srctyp], type_index[tgttyp]] += 1\n        elif mode in [\"weight\", \"n_syn\"]:\n            # to sum the synapse counts\n            matrix[type_index[srctyp], type_index[tgttyp]] += weight\n        else:\n            raise ValueError\n\n    # to filter out all connections weaker than min_number\n    if min_number is not None:\n        matrix[np.abs(matrix) &lt;= min_number] = np.nan\n\n    # to display either only excitatory or inhibitory connections\n    if only_sign == \"+\":\n        matrix[matrix &lt; 0] = 0\n        kwargs.update(symlog=None, midpoint=0)\n    elif only_sign == \"-\":\n        matrix[matrix &gt; 0] = 0\n        kwargs.update(symlog=None, midpoint=0)\n    elif only_sign is None:\n        pass\n    else:\n        raise ValueError\n\n    return plots.heatmap(matrix, cell_types, **kwargs)\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.network_layout","title":"network_layout","text":"<pre><code>network_layout(max_extent=5, **kwargs)\n</code></pre> <p>Plot retinotopic hexagonal lattice columnar organization of the network.</p> <p>Parameters:</p> Name Type Description Default <code>max_extent</code> <code>int</code> <p>Integer column radius to visualize.</p> <code>5</code> <code>**kwargs</code> <p>Additional arguments passed to hex_layout_all.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>Matplotlib figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def network_layout(\n    self,\n    max_extent: int = 5,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot retinotopic hexagonal lattice columnar organization of the network.\n\n    Args:\n        max_extent: Integer column radius to visualize.\n        **kwargs: Additional arguments passed to hex_layout_all.\n\n    Returns:\n        Figure: Matplotlib figure object.\n    \"\"\"\n    backbone = WholeNetworkFigure(self.dir)\n    backbone.init_figure(figsize=[7, 3])\n    return self.hex_layout_all(\n        max_extent=max_extent, fig=backbone.fig, axes=backbone.axes, **kwargs\n    )\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.hex_layout","title":"hex_layout","text":"<pre><code>hex_layout(cell_type, max_extent=5, edgecolor='none', edgewidth=0.5, alpha=1, fill=False, cmap=None, fig=None, ax=None, **kwargs)\n</code></pre> <p>Plot retinotopic hexagonal lattice organization of a cell type.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>Type of cell to plot.</p> required <code>max_extent</code> <code>int</code> <p>Maximum extent of the layout.</p> <code>5</code> <code>edgecolor</code> <code>str</code> <p>Color of the hexagon edges.</p> <code>'none'</code> <code>edgewidth</code> <code>float</code> <p>Width of the hexagon edges.</p> <code>0.5</code> <code>alpha</code> <code>float</code> <p>Transparency of the hexagons.</p> <code>1</code> <code>fill</code> <code>bool</code> <p>Whether to fill the hexagons.</p> <code>False</code> <code>cmap</code> <code>Optional[Colormap]</code> <p>Custom colormap.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing axis to plot on.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to hex_scatter.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>Matplotlib figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def hex_layout(\n    self,\n    cell_type: str,\n    max_extent: int = 5,\n    edgecolor: str = \"none\",\n    edgewidth: float = 0.5,\n    alpha: float = 1,\n    fill: bool = False,\n    cmap: Optional[Colormap] = None,\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot retinotopic hexagonal lattice organization of a cell type.\n\n    Args:\n        cell_type: Type of cell to plot.\n        max_extent: Maximum extent of the layout.\n        edgecolor: Color of the hexagon edges.\n        edgewidth: Width of the hexagon edges.\n        alpha: Transparency of the hexagons.\n        fill: Whether to fill the hexagons.\n        cmap: Custom colormap.\n        fig: Existing figure to plot on.\n        ax: Existing axis to plot on.\n        **kwargs: Additional arguments passed to hex_scatter.\n\n    Returns:\n        Figure: Matplotlib figure object.\n    \"\"\"\n    nodes = self.nodes.to_df()\n    node_condition = nodes.type == cell_type\n    u, v = nodes.u[node_condition], nodes.v[node_condition]\n    max_extent = hex_utils.get_extent(u, v) if max_extent is None else max_extent\n    extent_condition = (\n        (-max_extent &lt;= u)\n        &amp; (u &lt;= max_extent)\n        &amp; (-max_extent &lt;= v)\n        &amp; (v &lt;= max_extent)\n        &amp; (-max_extent &lt;= u + v)\n        &amp; (u + v &lt;= max_extent)\n    )\n    u, v = u[extent_condition].values, v[extent_condition].values\n\n    label = cell_type\n    if ax is not None:\n        # prevent labeling twice\n        label = cell_type if cell_type not in [t.get_text() for t in ax.texts] else \"\"\n\n    fig, ax, _ = plots.hex_scatter(\n        u,\n        v,\n        values=1,\n        label=label,\n        fig=fig,\n        ax=ax,\n        edgecolor=edgecolor,\n        edgewidth=edgewidth,\n        alpha=alpha,\n        fill=fill,\n        cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n        cbar=False,\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.hex_layout_all","title":"hex_layout_all","text":"<pre><code>hex_layout_all(cell_types=None, max_extent=5, edgecolor='none', alpha=1, fill=False, cmap=None, fig=None, axes=None, **kwargs)\n</code></pre> <p>Plot retinotopic hexagonal lattice organization of all cell types.</p> <p>Parameters:</p> Name Type Description Default <code>cell_types</code> <code>Optional[List[str]]</code> <p>List of cell types to plot.</p> <code>None</code> <code>max_extent</code> <code>int</code> <p>Maximum extent of the layout.</p> <code>5</code> <code>edgecolor</code> <code>str</code> <p>Color of the hexagon edges.</p> <code>'none'</code> <code>alpha</code> <code>float</code> <p>Transparency of the hexagons.</p> <code>1</code> <code>fill</code> <code>bool</code> <p>Whether to fill the hexagons.</p> <code>False</code> <code>cmap</code> <code>Optional[Colormap]</code> <p>Custom colormap.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>axes</code> <code>Optional[List[Axes]]</code> <p>List of existing axes to plot on.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to hex_layout.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Figure</code> <code>Figure</code> <p>Matplotlib figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def hex_layout_all(\n    self,\n    cell_types: Optional[List[str]] = None,\n    max_extent: int = 5,\n    edgecolor: str = \"none\",\n    alpha: float = 1,\n    fill: bool = False,\n    cmap: Optional[Colormap] = None,\n    fig: Optional[Figure] = None,\n    axes: Optional[List[Axes]] = None,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot retinotopic hexagonal lattice organization of all cell types.\n\n    Args:\n        cell_types: List of cell types to plot.\n        max_extent: Maximum extent of the layout.\n        edgecolor: Color of the hexagon edges.\n        alpha: Transparency of the hexagons.\n        fill: Whether to fill the hexagons.\n        cmap: Custom colormap.\n        fig: Existing figure to plot on.\n        axes: List of existing axes to plot on.\n        **kwargs: Additional arguments passed to hex_layout.\n\n    Returns:\n        Figure: Matplotlib figure object.\n    \"\"\"\n    cell_types = self.cell_types_sorted if cell_types is None else cell_types\n    if fig is None or axes is None:\n        fig, axes, (gw, gh) = plt_utils.get_axis_grid(self.cell_types_sorted)\n\n    for i, cell_type in enumerate(cell_types):\n        self.hex_layout(\n            cell_type,\n            edgecolor=edgecolor,\n            edgewidth=0.1,\n            alpha=alpha,\n            fill=fill,\n            max_extent=max_extent,\n            cmap=cmap or plt_utils.get_alpha_colormap(\"#2f3541\", 1),\n            fig=fig,\n            ax=axes[i],\n            **kwargs,\n        )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.get_uv","title":"get_uv","text":"<pre><code>get_uv(cell_type)\n</code></pre> <p>Get hex-coordinates of a particular cell type.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>Type of cell to get coordinates for.</p> required <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray]</code> <p>Tuple[NDArray, NDArray]: Arrays of u and v coordinates.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def get_uv(self, cell_type: str) -&gt; Tuple[NDArray, NDArray]:\n    \"\"\"Get hex-coordinates of a particular cell type.\n\n    Args:\n        cell_type: Type of cell to get coordinates for.\n\n    Returns:\n        Tuple[NDArray, NDArray]: Arrays of u and v coordinates.\n    \"\"\"\n    nodes = self.nodes.to_df()\n    nodes = nodes[nodes.type == cell_type]\n    u, v = nodes[[\"u\", \"v\"]].values.T\n    return u, v\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.sources_list","title":"sources_list","text":"<pre><code>sources_list(cell_type)\n</code></pre> <p>Get presynaptic cell types.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>Type of cell to get sources for.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Array of presynaptic cell types.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def sources_list(self, cell_type: str) -&gt; NDArray:\n    \"\"\"Get presynaptic cell types.\n\n    Args:\n        cell_type: Type of cell to get sources for.\n\n    Returns:\n        NDArray: Array of presynaptic cell types.\n    \"\"\"\n    edges = self.edges.to_df()\n    return np.unique(edges[edges.target_type == cell_type].source_type.values)\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.targets_list","title":"targets_list","text":"<pre><code>targets_list(cell_type)\n</code></pre> <p>Get postsynaptic cell types.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>Type of cell to get targets for.</p> required <p>Returns:</p> Name Type Description <code>NDArray</code> <code>NDArray</code> <p>Array of postsynaptic cell types.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def targets_list(self, cell_type: str) -&gt; NDArray:\n    \"\"\"Get postsynaptic cell types.\n\n    Args:\n        cell_type: Type of cell to get targets for.\n\n    Returns:\n        NDArray: Array of postsynaptic cell types.\n    \"\"\"\n    edges = self.edges.to_df()\n    return np.unique(edges[edges.source_type == cell_type].target_type.values)\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.receptive_field","title":"receptive_field","text":"<pre><code>receptive_field(source='Mi9', target='T4a', rfs=None, max_extent=None, vmin=None, vmax=None, title='{source} :\u2192 {target}', **kwargs)\n</code></pre> <p>Plot the receptive field of a target cell type from a source cell type.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source cell type.</p> <code>'Mi9'</code> <code>target</code> <code>str</code> <p>Target cell type.</p> <code>'T4a'</code> <code>rfs</code> <code>Optional[ReceptiveFields]</code> <p>ReceptiveFields object. If None, it will be created.</p> <code>None</code> <code>max_extent</code> <code>Optional[int]</code> <p>Maximum extent of the receptive field.</p> <code>None</code> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for colormap.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for colormap.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title format string for the plot.</p> <code>'{source} :\u2192 {target}'</code> <code>**kwargs</code> <p>Additional arguments passed to plots.kernel.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib Figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def receptive_field(\n    self,\n    source: str = \"Mi9\",\n    target: str = \"T4a\",\n    rfs: Optional[\"ReceptiveFields\"] = None,\n    max_extent: Optional[int] = None,\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    title: str = \"{source} :\u2192 {target}\",\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot the receptive field of a target cell type from a source cell type.\n\n    Args:\n        source: Source cell type.\n        target: Target cell type.\n        rfs: ReceptiveFields object. If None, it will be created.\n        max_extent: Maximum extent of the receptive field.\n        vmin: Minimum value for colormap.\n        vmax: Maximum value for colormap.\n        title: Title format string for the plot.\n        **kwargs: Additional arguments passed to plots.kernel.\n\n    Returns:\n        Matplotlib Figure object.\n    \"\"\"\n    if rfs is None:\n        rfs = ReceptiveFields(target, self.edges.to_df())\n        max_extent = max_extent or rfs.max_extent\n\n    weights = self._weights()\n\n    # to derive color range values taking all inputs into account\n    vmin = min(\n        0,\n        min(weights[rfs[source].index].min() for source in rfs.source_types),\n    )\n    vmax = max(\n        0,\n        max(weights[rfs[source].index].max() for source in rfs.source_types),\n    )\n\n    weights = weights[rfs[source].index]\n    label = \"\"\n\n    # requires to look from the target cell, ie mirror the coordinates\n    du_inv, dv_inv = -rfs[source].du.values, -rfs[source].dv.values\n    fig, ax, (label_text, scalarmapper) = plots.kernel(\n        du_inv,\n        dv_inv,\n        weights,\n        label=label,\n        max_extent=max_extent,\n        fill=True,\n        vmin=vmin,\n        vmax=vmax,\n        title=title.format(**locals()),\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.receptive_fields_grid","title":"receptive_fields_grid","text":"<pre><code>receptive_fields_grid(target, sources=None, sort_alphabetically=True, ax_titles='{source} :\u2192 {target}', figsize=[20, 20], max_extent=None, fig=None, axes=None, ignore_sign_error=False, max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, **kwargs)\n</code></pre> <p>Plot receptive fields of a target cell type in a grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>Target cell type.</p> required <code>sources</code> <code>Optional[Iterable[str]]</code> <p>Iterable of source cell types. If None, all sources are used.</p> <code>None</code> <code>sort_alphabetically</code> <code>bool</code> <p>Whether to sort source types alphabetically.</p> <code>True</code> <code>ax_titles</code> <code>str</code> <p>Title format string for each subplot.</p> <code>'{source} :\u2192 {target}'</code> <code>figsize</code> <code>List[int]</code> <p>Figure size in inches.</p> <code>[20, 20]</code> <code>max_extent</code> <code>Optional[int]</code> <p>Maximum extent of the receptive fields.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>axes</code> <code>Optional[List[Axes]]</code> <p>List of existing axes to plot on.</p> <code>None</code> <code>ignore_sign_error</code> <code>bool</code> <p>Whether to ignore sign errors in plotting.</p> <code>False</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in cm.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in cm.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in cm.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in cm.</p> <code>3.6</code> <code>**kwargs</code> <p>Additional arguments passed to receptive_field.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib Figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def receptive_fields_grid(\n    self,\n    target: str,\n    sources: Optional[Iterable[str]] = None,\n    sort_alphabetically: bool = True,\n    ax_titles: str = \"{source} :\u2192 {target}\",\n    figsize: List[int] = [20, 20],\n    max_extent: Optional[int] = None,\n    fig: Optional[Figure] = None,\n    axes: Optional[List[Axes]] = None,\n    ignore_sign_error: bool = False,\n    max_figure_height_cm: float = 22,\n    panel_height_cm: float = 3,\n    max_figure_width_cm: float = 18,\n    panel_width_cm: float = 3.6,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot receptive fields of a target cell type in a grid layout.\n\n    Args:\n        target: Target cell type.\n        sources: Iterable of source cell types. If None, all sources are used.\n        sort_alphabetically: Whether to sort source types alphabetically.\n        ax_titles: Title format string for each subplot.\n        figsize: Figure size in inches.\n        max_extent: Maximum extent of the receptive fields.\n        fig: Existing figure to plot on.\n        axes: List of existing axes to plot on.\n        ignore_sign_error: Whether to ignore sign errors in plotting.\n        max_figure_height_cm: Maximum figure height in cm.\n        panel_height_cm: Height of each panel in cm.\n        max_figure_width_cm: Maximum figure width in cm.\n        panel_width_cm: Width of each panel in cm.\n        **kwargs: Additional arguments passed to receptive_field.\n\n    Returns:\n        Matplotlib Figure object.\n    \"\"\"\n\n    rfs = ReceptiveFields(target, self.edges.to_df())\n    max_extent = max_extent or rfs.max_extent\n    weights = self._weights()\n\n    # to sort in descending order by sum of inputs\n    sorted_sum_of_inputs = dict(\n        sorted(\n            valmap(lambda v: weights[v.index].sum(), rfs).items(),\n            key=lambda item: item[1],\n            reverse=True,\n        )\n    )\n    # to sort alphabetically in case sources is specified\n    if sort_alphabetically:\n        sources, _ = nodes_edges_utils.order_node_type_list(sources)\n    sources = sources or list(sorted_sum_of_inputs.keys())\n\n    # to derive color range values taking all inputs into account\n    vmin = min(0, min(weights[rfs[source].index].min() for source in sources))\n    vmax = max(0, max(weights[rfs[source].index].max() for source in sources))\n\n    if fig is None or axes is None:\n        figsize = figsize_from_n_items(\n            len(rfs.source_types),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(\n            unmask_n=len(rfs.source_types), hspace=0.0, wspace=0\n        )\n\n    cbar = kwargs.get(\"cbar\", False)\n    for i, src in enumerate(sources):\n        if i == 0 and cbar:\n            cbar = True\n            kwargs.update(cbar=cbar)\n        else:\n            cbar = False\n            kwargs.update(cbar=cbar)\n        try:\n            self.receptive_field(\n                target=target,\n                source=src,\n                fig=fig,\n                ax=axes[i],\n                title=ax_titles,\n                vmin=vmin,\n                vmax=vmax,\n                rfs=rfs,\n                max_extent=max_extent,\n                annotate=False,\n                annotate_coords=False,\n                title_y=0.9,\n                **kwargs,\n            )\n        except plots.SignError as e:\n            if ignore_sign_error:\n                pass\n            else:\n                raise e\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.projective_field","title":"projective_field","text":"<pre><code>projective_field(source='Mi9', target='T4a', title='{source} \u2192: {target}', prfs=None, max_extent=None, vmin=None, vmax=None, **kwargs)\n</code></pre> <p>Plot the projective field from a source cell type to a target cell type.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source cell type.</p> <code>'Mi9'</code> <code>target</code> <code>str</code> <p>Target cell type.</p> <code>'T4a'</code> <code>title</code> <code>str</code> <p>Title format string for the plot.</p> <code>'{source} \u2192: {target}'</code> <code>prfs</code> <code>Optional[ProjectiveFields]</code> <p>ProjectiveFields object. If None, it will be created.</p> <code>None</code> <code>max_extent</code> <code>Optional[int]</code> <p>Maximum extent of the projective field.</p> <code>None</code> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for colormap.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for colormap.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to plots.kernel.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Figure]</code> <p>Matplotlib Figure object or None if max_extent is None.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def projective_field(\n    self,\n    source: str = \"Mi9\",\n    target: str = \"T4a\",\n    title: str = \"{source} \u2192: {target}\",\n    prfs: Optional[\"ProjectiveFields\"] = None,\n    max_extent: Optional[int] = None,\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    **kwargs,\n) -&gt; Optional[Figure]:\n    \"\"\"Plot the projective field from a source cell type to a target cell type.\n\n    Args:\n        source: Source cell type.\n        target: Target cell type.\n        title: Title format string for the plot.\n        prfs: ProjectiveFields object. If None, it will be created.\n        max_extent: Maximum extent of the projective field.\n        vmin: Minimum value for colormap.\n        vmax: Maximum value for colormap.\n        **kwargs: Additional arguments passed to plots.kernel.\n\n    Returns:\n        Matplotlib Figure object or None if max_extent is None.\n    \"\"\"\n    if prfs is None:\n        prfs = ProjectiveFields(source, self.edges.to_df())\n        max_extent = max_extent or prfs.max_extent\n    if max_extent is None:\n        return None\n    weights = self._weights()\n\n    # to derive color range values taking all inputs into account\n    vmin = min(\n        0,\n        min(weights[prfs[target].index].min() for target in prfs.target_types),\n    )\n\n    vmax = max(\n        0,\n        max(weights[prfs[target].index].max() for target in prfs.target_types),\n    )\n\n    weights = weights[prfs[target].index]\n    label = \"\"\n    du, dv = prfs[target].du.values, prfs[target].dv.values\n    fig, ax, (label_text, scalarmapper) = plots.kernel(\n        du,\n        dv,\n        weights,\n        label=label,\n        fill=True,\n        max_extent=max_extent,\n        vmin=vmin,\n        vmax=vmax,\n        title=title.format(**locals()),\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.projective_fields_grid","title":"projective_fields_grid","text":"<pre><code>projective_fields_grid(source, targets=None, fig=None, axes=None, figsize=[20, 20], ax_titles='{source} \u2192: {target}', max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, max_extent=None, sort_alphabetically=False, ignore_sign_error=False, **kwargs)\n</code></pre> <p>Plot projective fields of a source cell type in a grid layout.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source cell type.</p> required <code>targets</code> <code>Optional[Iterable[str]]</code> <p>Iterable of target cell types. If None, all targets are used.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>axes</code> <code>Optional[List[Axes]]</code> <p>List of existing axes to plot on.</p> <code>None</code> <code>figsize</code> <code>List[int]</code> <p>Figure size in inches.</p> <code>[20, 20]</code> <code>ax_titles</code> <code>str</code> <p>Title format string for each subplot.</p> <code>'{source} \u2192: {target}'</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in cm.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in cm.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in cm.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in cm.</p> <code>3.6</code> <code>max_extent</code> <code>Optional[int]</code> <p>Maximum extent of the projective fields.</p> <code>None</code> <code>sort_alphabetically</code> <code>bool</code> <p>Whether to sort target types alphabetically.</p> <code>False</code> <code>ignore_sign_error</code> <code>bool</code> <p>Whether to ignore sign errors in plotting.</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments passed to projective_field.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib Figure object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def projective_fields_grid(\n    self,\n    source: str,\n    targets: Optional[Iterable[str]] = None,\n    fig: Optional[Figure] = None,\n    axes: Optional[List[Axes]] = None,\n    figsize: List[int] = [20, 20],\n    ax_titles: str = \"{source} \u2192: {target}\",\n    max_figure_height_cm: float = 22,\n    panel_height_cm: float = 3,\n    max_figure_width_cm: float = 18,\n    panel_width_cm: float = 3.6,\n    max_extent: Optional[int] = None,\n    sort_alphabetically: bool = False,\n    ignore_sign_error: bool = False,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot projective fields of a source cell type in a grid layout.\n\n    Args:\n        source: Source cell type.\n        targets: Iterable of target cell types. If None, all targets are used.\n        fig: Existing figure to plot on.\n        axes: List of existing axes to plot on.\n        figsize: Figure size in inches.\n        ax_titles: Title format string for each subplot.\n        max_figure_height_cm: Maximum figure height in cm.\n        panel_height_cm: Height of each panel in cm.\n        max_figure_width_cm: Maximum figure width in cm.\n        panel_width_cm: Width of each panel in cm.\n        max_extent: Maximum extent of the projective fields.\n        sort_alphabetically: Whether to sort target types alphabetically.\n        ignore_sign_error: Whether to ignore sign errors in plotting.\n        **kwargs: Additional arguments passed to projective_field.\n\n    Returns:\n        Matplotlib Figure object.\n    \"\"\"\n    prfs = ProjectiveFields(source, self.edges.to_df())\n    max_extent = max_extent or prfs.max_extent\n    weights = self._weights()\n    sorted_sum_of_outputs = dict(\n        sorted(\n            valmap(lambda v: weights[v.index].sum(), prfs).items(),\n            key=lambda item: item[1],\n            reverse=True,\n        )\n    )\n\n    # to sort alphabetically in case sources is specified\n    if sort_alphabetically:\n        targets, _ = nodes_edges_utils.order_node_type_list(targets)\n\n    targets = targets or list(sorted_sum_of_outputs.keys())\n\n    vmin = min(0, min(weights[prfs[target].index].min() for target in targets))\n    vmax = max(0, max(weights[prfs[target].index].max() for target in targets))\n\n    if fig is None or axes is None:\n        figsize = figsize_from_n_items(\n            len(prfs.target_types),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(\n            unmask_n=len(prfs.target_types), hspace=0.0, wspace=0\n        )\n\n    cbar = kwargs.get(\"cbar\", False)\n    for i, target in enumerate(targets):\n        if i == 0 and cbar:\n            cbar = True\n            kwargs.update(cbar=cbar)\n        else:\n            cbar = False\n            kwargs.update(cbar=cbar)\n        try:\n            self.projective_field(\n                source=source,\n                target=target,\n                fig=fig,\n                ax=axes[i],\n                title=ax_titles,\n                prfs=prfs,\n                max_extent=max_extent,\n                vmin=vmin,\n                vmax=vmax,\n                annotate_coords=False,\n                annotate=False,\n                title_y=0.9,\n                **kwargs,\n            )\n        except plots.SignError as e:\n            if ignore_sign_error:\n                pass\n            else:\n                raise e\n    return fig\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.receptive_fields_df","title":"receptive_fields_df","text":"<pre><code>receptive_fields_df(target_type)\n</code></pre> <p>Get receptive fields for a target cell type.</p> <p>Parameters:</p> Name Type Description Default <code>target_type</code> <code>str</code> <p>Target cell type.</p> required <p>Returns:</p> Type Description <code>ReceptiveFields</code> <p>ReceptiveFields object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def receptive_fields_df(self, target_type: str) -&gt; \"ReceptiveFields\":\n    \"\"\"Get receptive fields for a target cell type.\n\n    Args:\n        target_type: Target cell type.\n\n    Returns:\n        ReceptiveFields object.\n    \"\"\"\n    return ReceptiveFields(target_type, self.edges.to_df())\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.projective_fields_df","title":"projective_fields_df","text":"<pre><code>projective_fields_df(source_type)\n</code></pre> <p>Get projective fields for a source cell type.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>Source cell type.</p> required <p>Returns:</p> Type Description <code>ProjectiveFields</code> <p>ProjectiveFields object.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def projective_fields_df(self, source_type: str) -&gt; \"ProjectiveFields\":\n    \"\"\"Get projective fields for a source cell type.\n\n    Args:\n        source_type: Source cell type.\n\n    Returns:\n        ProjectiveFields object.\n    \"\"\"\n    return ProjectiveFields(source_type, self.edges.to_df())\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.receptive_fields_sum","title":"receptive_fields_sum","text":"<pre><code>receptive_fields_sum(target_type)\n</code></pre> <p>Get sum of synapses for each source type in the receptive field.</p> <p>Parameters:</p> Name Type Description Default <code>target_type</code> <code>str</code> <p>Target cell type.</p> required <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary mapping source types to synapse counts.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def receptive_fields_sum(self, target_type: str) -&gt; Dict[str, int]:\n    \"\"\"Get sum of synapses for each source type in the receptive field.\n\n    Args:\n        target_type: Target cell type.\n\n    Returns:\n        Dictionary mapping source types to synapse counts.\n    \"\"\"\n    return ReceptiveFields(target_type, self.edges.to_df()).sum()\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ConnectomeView.projective_fields_sum","title":"projective_fields_sum","text":"<pre><code>projective_fields_sum(source_type)\n</code></pre> <p>Get sum of synapses for each target type in the projective field.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>Source cell type.</p> required <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dictionary mapping target types to synapse counts.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def projective_fields_sum(self, source_type: str) -&gt; Dict[str, int]:\n    \"\"\"Get sum of synapses for each target type in the projective field.\n\n    Args:\n        source_type: Source cell type.\n\n    Returns:\n        Dictionary mapping target types to synapse counts.\n    \"\"\"\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ReceptiveFields","title":"flyvis.connectome.connectome.ReceptiveFields","text":"<p>               Bases: <code>Namespace</code></p> <p>Dictionary of receptive field dataframes for a specific cell type.</p> <p>Parameters:</p> Name Type Description Default <code>target_type</code> <code>str</code> <p>Target cell type.</p> required <code>edges</code> <code>DataFrame</code> <p>All edges of a Connectome.</p> required <p>Attributes:</p> Name Type Description <code>target_type</code> <p>The target cell type.</p> <code>source_types</code> <p>List of source cell types.</p> <code>_extents</code> <p>List of extents for each source type.</p> Example <pre><code>rf = ReceptiveFields(\"T4a\", edges_dataframe)\n</code></pre> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>class ReceptiveFields(Namespace):\n    \"\"\"Dictionary of receptive field dataframes for a specific cell type.\n\n    Args:\n        target_type: Target cell type.\n        edges: All edges of a Connectome.\n\n    Attributes:\n        target_type: The target cell type.\n        source_types: List of source cell types.\n        _extents: List of extents for each source type.\n\n    Example:\n        ```python\n        rf = ReceptiveFields(\"T4a\", edges_dataframe)\n        ```\n    \"\"\"\n\n    def __init__(self, target_type: str, edges: DataFrame, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"_extents\", [])\n        _receptive_fields_edge_dfs(self, target_type, edges)\n\n    @property\n    def extents(self) -&gt; Dict[str, int]:\n        \"\"\"Dictionary of extents for each source type.\"\"\"\n        return dict(zip(self.source_types, self._extents))\n\n    @property\n    def max_extent(self) -&gt; Optional[int]:\n        \"\"\"Maximum extent across all source types.\"\"\"\n        return max(self._extents) if self._extents else None\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}({self.target_type})\"\n\n    def sum(self) -&gt; Dict[str, float]:\n        \"\"\"Sum of synapses for each source type.\"\"\"\n        return {key: self[key].n_syn.sum() for key in self}\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ReceptiveFields.extents","title":"extents  <code>property</code>","text":"<pre><code>extents\n</code></pre> <p>Dictionary of extents for each source type.</p>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ReceptiveFields.max_extent","title":"max_extent  <code>property</code>","text":"<pre><code>max_extent\n</code></pre> <p>Maximum extent across all source types.</p>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ReceptiveFields.sum","title":"sum","text":"<pre><code>sum()\n</code></pre> <p>Sum of synapses for each source type.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def sum(self) -&gt; Dict[str, float]:\n    \"\"\"Sum of synapses for each source type.\"\"\"\n    return {key: self[key].n_syn.sum() for key in self}\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ProjectiveFields","title":"flyvis.connectome.connectome.ProjectiveFields","text":"<p>               Bases: <code>Namespace</code></p> <p>Dictionary of projective field dataframes for a specific cell type.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>Source cell type.</p> required <code>edges</code> <code>DataFrame</code> <p>All edges of a Connectome.</p> required <p>Attributes:</p> Name Type Description <code>source_type</code> <p>The source cell type.</p> <code>target_types</code> <p>List of target cell types.</p> <code>_extents</code> <p>List of extents for each target type.</p> Example <pre><code>pf = ProjectiveFields(\"Mi9\", edges_dataframe)\n</code></pre> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>class ProjectiveFields(Namespace):\n    \"\"\"Dictionary of projective field dataframes for a specific cell type.\n\n    Args:\n        source_type: Source cell type.\n        edges: All edges of a Connectome.\n\n    Attributes:\n        source_type: The source cell type.\n        target_types: List of target cell types.\n        _extents: List of extents for each target type.\n\n    Example:\n        ```python\n        pf = ProjectiveFields(\"Mi9\", edges_dataframe)\n        ```\n    \"\"\"\n\n    def __init__(self, source_type: str, edges: DataFrame, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"_extents\", [])\n        _projective_fields_edge_dfs(self, source_type, edges)\n\n    @property\n    def extents(self) -&gt; Dict[str, int]:\n        \"\"\"Dictionary of extents for each target type.\"\"\"\n        return dict(zip(self.target_types, self._extents))\n\n    @property\n    def max_extent(self) -&gt; Optional[int]:\n        \"\"\"Maximum extent across all target types.\"\"\"\n        return max(self._extents) if self._extents else None\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}({self.source_type})\"\n\n    def sum(self) -&gt; Dict[str, float]:\n        \"\"\"Sum of synapses for each target type.\"\"\"\n        return {key: self[key].n_syn.sum() for key in self}\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ProjectiveFields.extents","title":"extents  <code>property</code>","text":"<pre><code>extents\n</code></pre> <p>Dictionary of extents for each target type.</p>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ProjectiveFields.max_extent","title":"max_extent  <code>property</code>","text":"<pre><code>max_extent\n</code></pre> <p>Maximum extent across all target types.</p>"},{"location":"reference/connectome/#flyvis.connectome.connectome.ProjectiveFields.sum","title":"sum","text":"<pre><code>sum()\n</code></pre> <p>Sum of synapses for each target type.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def sum(self) -&gt; Dict[str, float]:\n    \"\"\"Sum of synapses for each target type.\"\"\"\n    return {key: self[key].n_syn.sum() for key in self}\n</code></pre>"},{"location":"reference/connectome/#miscellaneous","title":"Miscellaneous","text":""},{"location":"reference/connectome/#flyvis.connectome.connectome.init_connectome","title":"flyvis.connectome.connectome.init_connectome","text":"<pre><code>init_connectome(**kwargs)\n</code></pre> <p>Initialize a Connectome instance from a config dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>A dictionary containing the connectome configuration.</p> required <p>Returns:</p> Type Description <code>Connectome</code> <p>An instance of a class implementing the Connectome(Protocol).</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the specified connectome type is not available.</p> Example <pre><code>config = {\n    \"type\": \"ConnectomeFromAvgFilters\",\n    **config\n}\nconnectome = init_connectome(**config)\n</code></pre> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def init_connectome(**kwargs) -&gt; Connectome:\n    \"\"\"Initialize a Connectome instance from a config dictionary.\n\n    Args:\n        config: A dictionary containing the connectome configuration.\n\n    Returns:\n        An instance of a class implementing the Connectome(Protocol).\n\n    Raises:\n        KeyError: If the specified connectome type is not available.\n\n    Example:\n        ```python\n        config = {\n            \"type\": \"ConnectomeFromAvgFilters\",\n            **config\n        }\n        connectome = init_connectome(**config)\n        ```\n    \"\"\"\n    connectome_class = AVAILABLE_CONNECTOMES[kwargs.pop(\"type\")]\n\n    connectome = connectome_class(**kwargs)\n    is_valid, error_msg = is_connectome_protocol(connectome)\n    assert is_valid, (\n        f\"Connectome class {connectome} does \"\n        f\"not implement the Connectome(Protocol): {error_msg}\"\n    )\n    return connectome\n</code></pre>"},{"location":"reference/connectome/#flyvis.connectome.connectome.get_avgfilt_connectome","title":"flyvis.connectome.connectome.get_avgfilt_connectome","text":"<pre><code>get_avgfilt_connectome(config)\n</code></pre> <p>Create a ConnectomeView instance from a config for ConnectomeFromAvgFilters.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Containing ConnectomeFromAvgFilters configuration.</p> required <p>Returns:</p> Type Description <code>ConnectomeView</code> <p>ConnectomeView instance.</p> Source code in <code>flyvis/connectome/connectome.py</code> <pre><code>def get_avgfilt_connectome(config: dict) -&gt; ConnectomeView:\n    \"\"\"Create a ConnectomeView instance from a config for ConnectomeFromAvgFilters.\n\n    Args:\n        config: Containing ConnectomeFromAvgFilters configuration.\n\n    Returns:\n        ConnectomeView instance.\n    \"\"\"\n    return ConnectomeView(ConnectomeFromAvgFilters(**config))\n</code></pre>"},{"location":"reference/datasets/","title":"Datasets","text":""},{"location":"reference/datasets/#base-classes","title":"Base Classes","text":""},{"location":"reference/datasets/#flyvis.datasets.datasets.SequenceDataset","title":"flyvis.datasets.datasets.SequenceDataset","text":"<p>               Bases: <code>Dataset</code></p> <p>Base class for all sequence datasets.</p> <p>All sequence datasets can subclass this class. They are expected to implement the following attributes and methods.</p> <p>Attributes:</p> Name Type Description <code>framerate</code> <code>int</code> <p>Framerate of the original sequences.</p> <code>dt</code> <code>float</code> <p>Sampling and integration time constant.</p> <code>t_pre</code> <code>float</code> <p>Warmup time.</p> <code>t_post</code> <code>float</code> <p>Cooldown time.</p> <code>arg_df</code> <code>DataFrame</code> <p>required DataFrame containing the dataset parameters.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>class SequenceDataset(torch.utils.data.Dataset):\n    \"\"\"Base class for all sequence datasets.\n\n    All sequence datasets can subclass this class. They are expected to implement\n    the following attributes and methods.\n\n    Attributes:\n        framerate (int): Framerate of the original sequences.\n        dt (float): Sampling and integration time constant.\n        t_pre (float): Warmup time.\n        t_post (float): Cooldown time.\n        arg_df (pd.DataFrame): required DataFrame containing the dataset parameters.\n    \"\"\"\n\n    arg_df: pd.DataFrame = None\n    dt: float = None\n    t_pre: float = None\n    t_post: float = None\n\n    def get_item(self, key: int) -&gt; Any:\n        \"\"\"Return an item of the dataset.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            The dataset item at the specified index.\n        \"\"\"\n\n    def __len__(self) -&gt; int:\n        \"\"\"Size of the dataset.\"\"\"\n        return len(self.arg_df)\n\n    def __getitem__(self, key: Union[slice, Iterable, int, np.int_]) -&gt; Any:\n        \"\"\"Implements advanced indexing.\n\n        Args:\n            key: Index, slice, or iterable of indices.\n\n        Returns:\n            The dataset item(s) at the specified index/indices.\n\n        Raises:\n            IndexError: If the index is out of range.\n            TypeError: If the key type is invalid.\n        \"\"\"\n        return getitem(self, key)\n\n    def get_temporal_sample_indices(\n        self, n_frames: int, total_seq_length: int, augment: bool = None\n    ) -&gt; torch.Tensor:\n        \"\"\"Returns temporal indices to sample from a sequence.\n\n        Args:\n            n_frames: Number of sequence frames to sample from.\n            total_seq_length: Total sequence length.\n            augment: If True, picks the start frame at random. If False, starts at 0.\n\n        Returns:\n            Tensor of temporal indices.\n\n        Note:\n            Interpolates between start_index and start_index + n_frames and rounds the\n            resulting float values to integer to create indices. This can lead to\n            irregularities in terms of how many times each raw data frame is sampled.\n        \"\"\"\n        augment = augment if augment is not None else getattr(self, \"augment\", False)\n        framerate = getattr(self, \"original_framerate\", 1 / self.dt)\n        return get_temporal_sample_indices(\n            n_frames, total_seq_length, framerate, self.dt, augment\n        )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.SequenceDataset.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Return an item of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The dataset item at the specified index.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>def get_item(self, key: int) -&gt; Any:\n    \"\"\"Return an item of the dataset.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        The dataset item at the specified index.\n    \"\"\"\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.SequenceDataset.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Size of the dataset.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Size of the dataset.\"\"\"\n    return len(self.arg_df)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.SequenceDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Implements advanced indexing.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Union[slice, Iterable, int, int_]</code> <p>Index, slice, or iterable of indices.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The dataset item(s) at the specified index/indices.</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the index is out of range.</p> <code>TypeError</code> <p>If the key type is invalid.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>def __getitem__(self, key: Union[slice, Iterable, int, np.int_]) -&gt; Any:\n    \"\"\"Implements advanced indexing.\n\n    Args:\n        key: Index, slice, or iterable of indices.\n\n    Returns:\n        The dataset item(s) at the specified index/indices.\n\n    Raises:\n        IndexError: If the index is out of range.\n        TypeError: If the key type is invalid.\n    \"\"\"\n    return getitem(self, key)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.SequenceDataset.get_temporal_sample_indices","title":"get_temporal_sample_indices","text":"<pre><code>get_temporal_sample_indices(n_frames, total_seq_length, augment=None)\n</code></pre> <p>Returns temporal indices to sample from a sequence.</p> <p>Parameters:</p> Name Type Description Default <code>n_frames</code> <code>int</code> <p>Number of sequence frames to sample from.</p> required <code>total_seq_length</code> <code>int</code> <p>Total sequence length.</p> required <code>augment</code> <code>bool</code> <p>If True, picks the start frame at random. If False, starts at 0.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of temporal indices.</p> Note <p>Interpolates between start_index and start_index + n_frames and rounds the resulting float values to integer to create indices. This can lead to irregularities in terms of how many times each raw data frame is sampled.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>def get_temporal_sample_indices(\n    self, n_frames: int, total_seq_length: int, augment: bool = None\n) -&gt; torch.Tensor:\n    \"\"\"Returns temporal indices to sample from a sequence.\n\n    Args:\n        n_frames: Number of sequence frames to sample from.\n        total_seq_length: Total sequence length.\n        augment: If True, picks the start frame at random. If False, starts at 0.\n\n    Returns:\n        Tensor of temporal indices.\n\n    Note:\n        Interpolates between start_index and start_index + n_frames and rounds the\n        resulting float values to integer to create indices. This can lead to\n        irregularities in terms of how many times each raw data frame is sampled.\n    \"\"\"\n    augment = augment if augment is not None else getattr(self, \"augment\", False)\n    framerate = getattr(self, \"original_framerate\", 1 / self.dt)\n    return get_temporal_sample_indices(\n        n_frames, total_seq_length, framerate, self.dt, augment\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.StimulusDataset","title":"flyvis.datasets.datasets.StimulusDataset","text":"<p>               Bases: <code>SequenceDataset</code></p> <p>Base class for stimulus datasets.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>class StimulusDataset(SequenceDataset):\n    \"\"\"Base class for stimulus datasets.\"\"\"\n\n    def get_stimulus_index(self, kwargs: Dict[str, Any]) -&gt; int:\n        \"\"\"Get the sequence id for a set of arguments.\n\n        Args:\n            kwargs: Dictionary containing independent arguments or parameters\n                describing the sample of the dataset.\n\n        Returns:\n            The sequence id for the given arguments.\n\n        Raises:\n            ValueError: If arg_df attribute is not specified.\n\n        Note:\n            The child dataset implements the specific method:\n            ```python\n            def get_stimulus_index(self, arg1, arg2, ...):\n                return StimulusDataset.get_stimulus_index(locals())\n            ```\n            with locals() specifying kwargs in terms of `arg1`, `arg2`, ...\n            to index arg_df.\n        \"\"\"\n        if getattr(self, \"arg_df\", None) is None:\n            raise ValueError(\"arg_df attribute not specified.\")\n\n        if \"self\" in kwargs:\n            del kwargs[\"self\"]\n\n        return where_dataframe(self.arg_df, **kwargs).item()\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.StimulusDataset.get_stimulus_index","title":"get_stimulus_index","text":"<pre><code>get_stimulus_index(kwargs)\n</code></pre> <p>Get the sequence id for a set of arguments.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>Dict[str, Any]</code> <p>Dictionary containing independent arguments or parameters describing the sample of the dataset.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The sequence id for the given arguments.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If arg_df attribute is not specified.</p> Note <p>The child dataset implements the specific method: <pre><code>def get_stimulus_index(self, arg1, arg2, ...):\n    return StimulusDataset.get_stimulus_index(locals())\n</code></pre> with locals() specifying kwargs in terms of <code>arg1</code>, <code>arg2</code>, \u2026 to index arg_df.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>def get_stimulus_index(self, kwargs: Dict[str, Any]) -&gt; int:\n    \"\"\"Get the sequence id for a set of arguments.\n\n    Args:\n        kwargs: Dictionary containing independent arguments or parameters\n            describing the sample of the dataset.\n\n    Returns:\n        The sequence id for the given arguments.\n\n    Raises:\n        ValueError: If arg_df attribute is not specified.\n\n    Note:\n        The child dataset implements the specific method:\n        ```python\n        def get_stimulus_index(self, arg1, arg2, ...):\n            return StimulusDataset.get_stimulus_index(locals())\n        ```\n        with locals() specifying kwargs in terms of `arg1`, `arg2`, ...\n        to index arg_df.\n    \"\"\"\n    if getattr(self, \"arg_df\", None) is None:\n        raise ValueError(\"arg_df attribute not specified.\")\n\n    if \"self\" in kwargs:\n        del kwargs[\"self\"]\n\n    return where_dataframe(self.arg_df, **kwargs).item()\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.MultiTaskDataset","title":"flyvis.datasets.datasets.MultiTaskDataset","text":"<p>               Bases: <code>SequenceDataset</code></p> <p>Base class for all (multi-)task sequence datasets.</p> <p>All (multi-)task sequence datasets can subclass this class. They are expected to implement the following additional attributes and methods.</p> <p>Attributes:</p> Name Type Description <code>tasks</code> <code>List[str]</code> <p>A list of all tasks.</p> <code>augment</code> <code>bool</code> <p>Turns augmentation on and off.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>class MultiTaskDataset(SequenceDataset):\n    \"\"\"Base class for all (multi-)task sequence datasets.\n\n    All (multi-)task sequence datasets can subclass this class. They are expected\n    to implement the following additional attributes and methods.\n\n    Attributes:\n        tasks (List[str]): A list of all tasks.\n        augment (bool): Turns augmentation on and off.\n    \"\"\"\n\n    tasks: List[str] = []\n    augment: bool = False\n\n    @contextmanager\n    def augmentation(self, abool: bool) -&gt; None:\n        \"\"\"Contextmanager to turn augmentation on or off in a code block.\n\n        Args:\n            abool: Boolean value to set augmentation.\n\n        Example:\n            ```python\n            with dataset.augmentation(True):\n                for i, data in enumerate(dataloader):\n                    ...  # all data is augmented\n            ```\n        \"\"\"\n        _prev = self.augment\n        self.augment = abool\n        try:\n            yield\n        finally:\n            self.augment = _prev\n\n    def get_random_data_split(\n        self, fold: int, n_folds: int, shuffle: bool = True, seed: int = 0\n    ) -&gt; np.ndarray:\n        \"\"\"Returns a random data split.\n\n        Args:\n            fold: Current fold number.\n            n_folds: Total number of folds.\n            shuffle: Whether to shuffle the data.\n            seed: Random seed for reproducibility.\n\n        Returns:\n            Array of indices for the data split.\n        \"\"\"\n        return get_random_data_split(\n            fold,\n            n_samples=len(self),\n            n_folds=n_folds,\n            shuffle=shuffle,\n            seed=seed,\n        )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.MultiTaskDataset.augmentation","title":"augmentation","text":"<pre><code>augmentation(abool)\n</code></pre> <p>Contextmanager to turn augmentation on or off in a code block.</p> <p>Parameters:</p> Name Type Description Default <code>abool</code> <code>bool</code> <p>Boolean value to set augmentation.</p> required Example <pre><code>with dataset.augmentation(True):\n    for i, data in enumerate(dataloader):\n        ...  # all data is augmented\n</code></pre> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>@contextmanager\ndef augmentation(self, abool: bool) -&gt; None:\n    \"\"\"Contextmanager to turn augmentation on or off in a code block.\n\n    Args:\n        abool: Boolean value to set augmentation.\n\n    Example:\n        ```python\n        with dataset.augmentation(True):\n            for i, data in enumerate(dataloader):\n                ...  # all data is augmented\n        ```\n    \"\"\"\n    _prev = self.augment\n    self.augment = abool\n    try:\n        yield\n    finally:\n        self.augment = _prev\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.datasets.MultiTaskDataset.get_random_data_split","title":"get_random_data_split","text":"<pre><code>get_random_data_split(fold, n_folds, shuffle=True, seed=0)\n</code></pre> <p>Returns a random data split.</p> <p>Parameters:</p> Name Type Description Default <code>fold</code> <code>int</code> <p>Current fold number.</p> required <code>n_folds</code> <code>int</code> <p>Total number of folds.</p> required <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the data.</p> <code>True</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of indices for the data split.</p> Source code in <code>flyvis/datasets/datasets.py</code> <pre><code>def get_random_data_split(\n    self, fold: int, n_folds: int, shuffle: bool = True, seed: int = 0\n) -&gt; np.ndarray:\n    \"\"\"Returns a random data split.\n\n    Args:\n        fold: Current fold number.\n        n_folds: Total number of folds.\n        shuffle: Whether to shuffle the data.\n        seed: Random seed for reproducibility.\n\n    Returns:\n        Array of indices for the data split.\n    \"\"\"\n    return get_random_data_split(\n        fold,\n        n_samples=len(self),\n        n_folds=n_folds,\n        shuffle=shuffle,\n        seed=seed,\n    )\n</code></pre>"},{"location":"reference/datasets/#flashes","title":"Flashes","text":""},{"location":"reference/datasets/#flyvis.datasets.flashes.Flashes","title":"flyvis.datasets.flashes.Flashes","text":"<p>               Bases: <code>SequenceDataset</code></p> <p>Flashes dataset.</p> <p>Parameters:</p> Name Type Description Default <code>boxfilter</code> <code>Dict[str, int]</code> <p>Parameters for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>dynamic_range</code> <code>List[float]</code> <p>Range of intensities. E.g. [0, 1] renders flashes with decrement 0.5-&gt;0 and increment 0.5-&gt;1.</p> <code>[0, 1]</code> <code>t_stim</code> <code>float</code> <p>Duration of the stimulus.</p> <code>1.0</code> <code>t_pre</code> <code>float</code> <p>Duration of the grey stimulus.</p> <code>1.0</code> <code>dt</code> <code>float</code> <p>Timesteps.</p> <code>1 / 200</code> <code>radius</code> <code>List[int]</code> <p>Radius of the stimulus.</p> <code>[-1, 6]</code> <code>alternations</code> <code>Tuple[int, ...]</code> <p>Sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> <code>(0, 1, 0)</code> <p>Attributes:</p> Name Type Description <code>dt</code> <code>Union[float, None]</code> <p>Timestep.</p> <code>t_post</code> <code>float</code> <p>Post-stimulus time.</p> <code>flashes_dir</code> <p>Directory containing rendered flashes.</p> <code>config</code> <p>Configuration object.</p> <code>baseline</code> <p>Baseline intensity.</p> <code>arg_df</code> <p>DataFrame containing flash parameters.</p> Note <p>Zero alternation is the prestimulus and baseline. One alternation is the central stimulus. Has to start with zero alternation. <code>t_pre</code> is the duration of the prestimulus and <code>t_stim</code> is the duration of the stimulus.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>class Flashes(SequenceDataset):\n    \"\"\"Flashes dataset.\n\n    Args:\n        boxfilter: Parameters for the BoxEye filter.\n        dynamic_range: Range of intensities. E.g. [0, 1] renders flashes\n            with decrement 0.5-&gt;0 and increment 0.5-&gt;1.\n        t_stim: Duration of the stimulus.\n        t_pre: Duration of the grey stimulus.\n        dt: Timesteps.\n        radius: Radius of the stimulus.\n        alternations: Sequence of alternations between lower or upper intensity and\n            baseline of the dynamic range.\n\n    Attributes:\n        dt: Timestep.\n        t_post: Post-stimulus time.\n        flashes_dir: Directory containing rendered flashes.\n        config: Configuration object.\n        baseline: Baseline intensity.\n        arg_df: DataFrame containing flash parameters.\n\n    Note:\n        Zero alternation is the prestimulus and baseline. One alternation is the\n        central stimulus. Has to start with zero alternation. `t_pre` is the\n        duration of the prestimulus and `t_stim` is the duration of the stimulus.\n    \"\"\"\n\n    dt: Union[float, None] = None\n    t_post: float = 0.0\n\n    def __init__(\n        self,\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        dynamic_range: List[float] = [0, 1],\n        t_stim: float = 1.0,\n        t_pre: float = 1.0,\n        dt: float = 1 / 200,\n        radius: List[int] = [-1, 6],\n        alternations: Tuple[int, ...] = (0, 1, 0),\n    ):\n        assert alternations[0] == 0, \"First alternation must be 0.\"\n        self.flashes_dir = RenderedFlashes(\n            boxfilter=boxfilter,\n            dynamic_range=dynamic_range,\n            t_stim=t_stim,\n            t_pre=t_pre,\n            dt=dt,\n            radius=radius,\n            alternations=alternations,\n        )\n        self.config = self.flashes_dir.config\n        baseline = 2 * (sum(dynamic_range) / 2,)\n        intensity = dynamic_range.copy()\n\n        params = [\n            (p[0][0], p[0][1], p[1])\n            for p in list(product(zip(baseline, intensity), radius))\n        ]\n        self.baseline = baseline[0]\n        self.arg_df = pd.DataFrame(params, columns=[\"baseline\", \"intensity\", \"radius\"])\n\n        self.dt = dt\n\n    @property\n    def t_pre(self) -&gt; float:\n        \"\"\"Duration of the prestimulus and zero alternation.\"\"\"\n        return self.config.t_pre\n\n    @property\n    def t_stim(self) -&gt; float:\n        \"\"\"Duration of the one alternation.\"\"\"\n        return self.config.t_stim\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Index the dataset.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Flash sequence at the given index.\n        \"\"\"\n        return torch.Tensor(self.flashes_dir.flashes[key])\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the dataset.\"\"\"\n        return f\"Flashes dataset. Parametrization: \\n{self.arg_df}\"\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.flashes.Flashes.t_pre","title":"t_pre  <code>property</code>","text":"<pre><code>t_pre\n</code></pre> <p>Duration of the prestimulus and zero alternation.</p>"},{"location":"reference/datasets/#flyvis.datasets.flashes.Flashes.t_stim","title":"t_stim  <code>property</code>","text":"<pre><code>t_stim\n</code></pre> <p>Duration of the one alternation.</p>"},{"location":"reference/datasets/#flyvis.datasets.flashes.Flashes.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Index the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Flash sequence at the given index.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Index the dataset.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Flash sequence at the given index.\n    \"\"\"\n    return torch.Tensor(self.flashes_dir.flashes[key])\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.flashes.Flashes.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Return a string representation of the dataset.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the dataset.\"\"\"\n    return f\"Flashes dataset. Parametrization: \\n{self.arg_df}\"\n</code></pre>"},{"location":"reference/datasets/#moving-bar","title":"Moving Bar","text":""},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar","title":"flyvis.datasets.moving_bar.MovingBar","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Moving bar stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>widths</code> <code>list[int]</code> <p>Width of the bar in half ommatidia.</p> <code>[1, 2, 4]</code> <code>offsets</code> <code>tuple[int, int]</code> <p>First and last offset to the central column in half ommatidia.</p> <code>(-10, 11)</code> <code>intensities</code> <code>list[float]</code> <p>Intensity of the bar.</p> <code>[0, 1]</code> <code>speeds</code> <code>list[float]</code> <p>Speed of the bar in half ommatidia per second.</p> <code>[2.4, 4.8, 9.7, 13, 19, 25]</code> <code>height</code> <code>int</code> <p>Height of the bar in half ommatidia.</p> <code>9</code> <code>dt</code> <code>float</code> <p>Time step in seconds.</p> <code>1 / 200</code> <code>device</code> <code>str</code> <p>Device to store the stimulus.</p> <code>device</code> <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of the bar in radians from left to right of image plane. np.radians(90) is the center.</p> <code>radians(90)</code> <code>post_pad_mode</code> <code>Literal['continue', 'value', 'reflect']</code> <p>Padding mode after the stimulus. One of \u2018continue\u2019, \u2018value\u2019, \u2018reflect\u2019. If \u2018value\u2019 the padding is filled with <code>bg_intensity</code>.</p> <code>'value'</code> <code>t_pre</code> <code>float</code> <p>Time before the stimulus in seconds.</p> <code>1.0</code> <code>t_post</code> <code>float</code> <p>Time after the stimulus in seconds.</p> <code>1.0</code> <code>build_stim_on_init</code> <code>bool</code> <p>Build the stimulus on initialization.</p> <code>True</code> <code>shuffle_offsets</code> <code>bool</code> <p>Shuffle the offsets to remove spatio-temporal correlation.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Seed for the random state.</p> <code>0</code> <code>angles</code> <code>list[int]</code> <p>List of angles in degrees.</p> <code>[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]</code> <p>Attributes:</p> Name Type Description <code>config</code> <code>Namespace</code> <p>Configuration parameters.</p> <code>omm_width</code> <code>float</code> <p>Width of ommatidium in radians.</p> <code>led_width</code> <code>float</code> <p>Width of LED in radians.</p> <code>angles</code> <code>ndarray</code> <p>Array of angles in degrees.</p> <code>widths</code> <code>ndarray</code> <p>Array of widths in half ommatidia.</p> <code>offsets</code> <code>ndarray</code> <p>Array of offsets in half ommatidia.</p> <code>intensities</code> <code>ndarray</code> <p>Array of intensities.</p> <code>speeds</code> <code>ndarray</code> <p>Array of speeds in half ommatidia per second.</p> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>n_bars</code> <code>int</code> <p>Number of bars.</p> <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of bar in radians.</p> <code>t_stim</code> <code>ndarray</code> <p>Stimulation times for each speed.</p> <code>t_stim_max</code> <code>float</code> <p>Maximum stimulation time.</p> <code>height</code> <code>float</code> <p>Height of bar in radians.</p> <code>post_pad_mode</code> <code>str</code> <p>Padding mode after the stimulus.</p> <code>arg_df</code> <code>DataFrame</code> <p>DataFrame of stimulus parameters.</p> <code>arg_group_df</code> <code>DataFrame</code> <p>Grouped DataFrame of stimulus parameters.</p> <code>device</code> <code>str</code> <p>Device for storing stimuli.</p> <code>shuffle_offsets</code> <code>bool</code> <p>Whether to shuffle offsets.</p> <code>randomstate</code> <code>RandomState</code> <p>Random state for shuffling.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>class MovingBar(StimulusDataset):\n    \"\"\"Moving bar stimulus.\n\n    Args:\n        widths: Width of the bar in half ommatidia.\n        offsets: First and last offset to the central column in half ommatidia.\n        intensities: Intensity of the bar.\n        speeds: Speed of the bar in half ommatidia per second.\n        height: Height of the bar in half ommatidia.\n        dt: Time step in seconds.\n        device: Device to store the stimulus.\n        bar_loc_horizontal: Horizontal location of the bar in radians from left to\n            right of image plane. np.radians(90) is the center.\n        post_pad_mode: Padding mode after the stimulus. One of 'continue', 'value',\n            'reflect'. If 'value' the padding is filled with `bg_intensity`.\n        t_pre: Time before the stimulus in seconds.\n        t_post: Time after the stimulus in seconds.\n        build_stim_on_init: Build the stimulus on initialization.\n        shuffle_offsets: Shuffle the offsets to remove spatio-temporal correlation.\n        seed: Seed for the random state.\n        angles: List of angles in degrees.\n\n    Attributes:\n        config (Namespace): Configuration parameters.\n        omm_width (float): Width of ommatidium in radians.\n        led_width (float): Width of LED in radians.\n        angles (np.ndarray): Array of angles in degrees.\n        widths (np.ndarray): Array of widths in half ommatidia.\n        offsets (np.ndarray): Array of offsets in half ommatidia.\n        intensities (np.ndarray): Array of intensities.\n        speeds (np.ndarray): Array of speeds in half ommatidia per second.\n        bg_intensity (float): Background intensity.\n        n_bars (int): Number of bars.\n        bar_loc_horizontal (float): Horizontal location of bar in radians.\n        t_stim (np.ndarray): Stimulation times for each speed.\n        t_stim_max (float): Maximum stimulation time.\n        height (float): Height of bar in radians.\n        post_pad_mode (str): Padding mode after the stimulus.\n        arg_df (pd.DataFrame): DataFrame of stimulus parameters.\n        arg_group_df (pd.DataFrame): Grouped DataFrame of stimulus parameters.\n        device (str): Device for storing stimuli.\n        shuffle_offsets (bool): Whether to shuffle offsets.\n        randomstate (np.random.RandomState): Random state for shuffling.\n    \"\"\"\n\n    arg_df: pd.DataFrame = None\n\n    def __init__(\n        self,\n        widths: list[int] = [1, 2, 4],\n        offsets: tuple[int, int] = (-10, 11),\n        intensities: list[float] = [0, 1],\n        speeds: list[float] = [2.4, 4.8, 9.7, 13, 19, 25],\n        height: int = 9,\n        dt: float = 1 / 200,\n        device: str = flyvis.device,\n        bar_loc_horizontal: float = np.radians(90),\n        post_pad_mode: Literal[\"continue\", \"value\", \"reflect\"] = \"value\",\n        t_pre: float = 1.0,\n        t_post: float = 1.0,\n        build_stim_on_init: bool = True,\n        shuffle_offsets: bool = False,\n        seed: int = 0,\n        angles: list[int] = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n    ) -&gt; None:\n        super().__init__()\n        # HexEye parameter\n        self.omm_width = np.radians(5.8)  # radians(5.8 degree)\n\n        # Monitor parameter\n        self.led_width = np.radians(2.25)  # Gruntman et al. 2018\n\n        _locals = locals()\n        self.config = Namespace({\n            arg: _locals[arg]\n            for arg in [\n                \"widths\",\n                \"offsets\",\n                \"intensities\",\n                \"speeds\",\n                \"height\",\n                \"bar_loc_horizontal\",\n                \"shuffle_offsets\",\n                \"post_pad_mode\",\n                \"t_pre\",\n                \"t_post\",\n                \"dt\",\n                \"angles\",\n            ]\n        })\n\n        # Stim parameter\n        self.angles = np.array(angles)\n        self.widths = np.array(widths)  # half ommatidia\n        if len(offsets) == 2:\n            self.offsets = np.arange(*offsets)  # half ommatidia\n        else:\n            assert (\n                np.mean(offsets[1:] - offsets[:-1]) == 1\n            )  # t_stim assumes spacing of 1 corresponding to 2.25 deg\n            self.offsets = offsets\n        self.intensities = np.array(intensities)\n        self.speeds = np.array(speeds)\n        self.bg_intensity = 0.5\n        self.n_bars = 1\n        self.bar_loc_horizontal = bar_loc_horizontal\n\n        self.t_stim = (len(self.offsets) * self.led_width) / (\n            self.speeds * self.omm_width\n        )\n        self.t_stim_max = np.max(self.t_stim)\n\n        self._speed_to_t_stim = dict(zip(self.speeds, self.t_stim))\n\n        self.height = self.led_width * height\n\n        self.post_pad_mode = post_pad_mode\n        self._t_pre = t_pre\n        self._t_post = t_post\n\n        params = [\n            (*p[:-1], *p[-1])\n            for p in list(\n                product(\n                    self.angles,\n                    self.widths,\n                    self.intensities,\n                    zip(self.t_stim, self.speeds),\n                )\n            )\n        ]\n        self.arg_df = pd.DataFrame(\n            params, columns=[\"angle\", \"width\", \"intensity\", \"t_stim\", \"speed\"]\n        )\n\n        self.arg_group_df = self.arg_df.groupby(\n            [\"angle\", \"width\", \"intensity\"], sort=False, as_index=False\n        ).all()\n\n        self.device = device\n        self.shuffle_offsets = shuffle_offsets\n        self.randomstate = None\n        if self.shuffle_offsets:\n            self.randomstate = np.random.RandomState(seed=seed)\n\n        self._dt = dt\n\n        self._built = False\n        if build_stim_on_init:\n            self._build()\n            self._resample()\n            self._built = True\n\n    @property\n    def dt(self) -&gt; float:\n        \"\"\"Time step in seconds.\"\"\"\n        return getattr(self, \"_dt\", None)\n\n    @dt.setter\n    def dt(self, value: float) -&gt; None:\n        if self._dt == value:\n            self._dt = value\n            if self._built:\n                self._resample()\n            return\n        logging.warning(\n            \"Cannot override dt=%s because responses with dt=%s are initialized. \"\n            \"Keeping dt=%s.\",\n            value,\n            self._dt,\n            self._dt,\n        )\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"{self.__class__.__name__}\\n\"\n            + \"Config:\\n\"\n            + repr(self.config)\n            + \"Stimulus parameter:\\n\"\n            + repr(self.arg_df)\n        )\n\n    @property\n    def t_pre(self) -&gt; float:\n        \"\"\"Time before stimulus onset in seconds.\"\"\"\n        return self._t_pre\n\n    @property\n    def t_post(self) -&gt; float:\n        \"\"\"Time after stimulus offset in seconds.\"\"\"\n        return self._t_post\n\n    def _build(self) -&gt; None:\n        \"\"\"Build the stimulus.\"\"\"\n        self.wrap = RenderedOffsets(\n            dict(\n                angles=self.angles,\n                widths=self.widths,\n                intensities=self.intensities,\n                offsets=self.offsets,\n                led_width=self.led_width,\n                height=self.height,\n                n_bars=self.n_bars,\n                bg_intensity=self.bg_intensity,\n                bar_loc_horizontal=self.bar_loc_horizontal,\n            )\n        )\n\n        self._offsets = torch.tensor(self.wrap.offsets[:], device=self.device)\n        self._built = True\n\n    def _resample(self) -&gt; None:\n        \"\"\"Resample the stimulus at runtime.\"\"\"\n        # resampling at runtime to allow for changing dt and to save GB of\n        # storage.\n        self.sequences = {}\n        self.indices = {}\n        for t, speed in zip(self.t_stim, self.speeds):\n            sequence, indices = resample(\n                self._offsets,\n                t,\n                self.dt,\n                dim=1,\n                device=self.device,\n                return_indices=True,\n            )\n            if self.shuffle_offsets:\n                # breakpoint()\n                sequence = shuffle(sequence, self.randomstate)\n            sequence = pad(\n                sequence,\n                t + self.t_pre,\n                self.dt,\n                mode=\"start\",\n                fill=self.bg_intensity,\n            )\n            sequence = pad(\n                sequence,\n                t + self.t_pre + self.t_post,\n                self.dt,\n                mode=\"end\",\n                pad_mode=self.post_pad_mode,\n                fill=self.bg_intensity,\n            )\n            # Because we fix the distance that the bar moves but vary speeds we\n            # have different stimulation times. To make all sequences equal\n            # length for storing them in a single tensor, we pad them with nans\n            # based on the maximal stimulation time (slowest speed). The nans\n            # can later be removed before processing the traces.\n            sequence = pad(\n                sequence,\n                self.t_stim_max + self.t_pre + self.t_post,\n                self.dt,\n                mode=\"end\",\n                fill=np.nan,\n            )\n            self.sequences[speed] = sequence\n            self.indices[speed] = indices\n\n    def _key(self, angle: float, width: float, intensity: float, speed: float) -&gt; int:\n        \"\"\"Get the key for a specific stimulus configuration.\"\"\"\n        try:\n            return self.arg_df.query(\n                f\"angle=={angle}\"\n                f\" &amp; width=={width}\"\n                f\" &amp; intensity == {intensity}\"\n                f\" &amp; speed == {speed}\"\n            ).index.values.item()\n        except ValueError:\n            raise ValueError(\n                f\"angle: {angle}, width: {width}, intensity: {intensity}, \"\n                f\"speed: {speed} invalid.\"\n            ) from None\n\n    def get_sequence_id_from_arguments(\n        self, angle: float, width: float, intensity: float, speed: float\n    ) -&gt; int:\n        \"\"\"Get sequence ID from stimulus arguments.\"\"\"\n        return self.get_stimulus_index(locals())\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a given key.\"\"\"\n        return self.arg_df.iloc[key].values\n\n    def _group_key(self, angle: float, width: float, intensity: float) -&gt; int:\n        \"\"\"Get group key for a specific stimulus configuration.\"\"\"\n        return self.arg_group_df.query(\n            f\"angle=={angle}\" f\" &amp; width=={width}\" f\" &amp; intensity == {intensity}\"\n        ).index.values.item()\n\n    def _group_params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get group parameters for a given key.\"\"\"\n        return self.arg_group_df.iloc[key].values\n\n    def get(\n        self, angle: float, width: float, intensity: float, speed: float\n    ) -&gt; torch.Tensor:\n        \"\"\"Get stimulus for specific parameters.\"\"\"\n        key = self._key(angle, width, intensity, speed)\n        return self[key]\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get stimulus for a specific key.\"\"\"\n        angle, width, intensity, _, speed = self._params(key)\n        return self.sequences[speed][self._group_key(angle, width, intensity)]\n\n    def mask(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n        t_stim: Optional[float] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Create a mask for specific stimulus parameters.\"\"\"\n        # 22x faster than df.query\n        values = self.arg_df.values\n\n        def iterparam(param, name, axis, and_condition):\n            condition = np.zeros(len(values)).astype(bool)\n            if isinstance(param, Iterable):\n                for p in param:\n                    _new = values.take(axis, axis=1) == p\n                    assert any(_new), f\"{name} {p} not in dataset.\"\n                    condition = np.logical_or(condition, _new)\n            else:\n                _new = values.take(axis, axis=1) == param\n                assert any(_new), f\"{name} {param} not in dataset.\"\n                condition = np.logical_or(condition, _new)\n            return condition &amp; and_condition\n\n        condition = np.ones(len(values)).astype(bool)\n        if angle is not None:\n            condition = iterparam(angle, \"angle\", 0, condition)\n        if width is not None:\n            condition = iterparam(width, \"width\", 1, condition)\n        if intensity is not None:\n            condition = iterparam(intensity, \"intensity\", 2, condition)\n        if t_stim is not None:\n            condition = iterparam(t_stim, \"t_stim\", 3, condition)\n        if speed is not None:\n            condition = iterparam(speed, \"speed\", 4, condition)\n        return condition\n\n    @property\n    def time(self) -&gt; np.ndarray:\n        \"\"\"Time array for the stimulus.\"\"\"\n        return np.arange(-self.t_pre, self.t_stim_max + self.t_post - self.dt, self.dt)\n\n    def stimulus(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n        pre_stim: bool = True,\n        post_stim: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Get stimulus for specific parameters.\n\n        Args:\n            angle: Angle of the bar.\n            width: Width of the bar.\n            intensity: Intensity of the bar.\n            speed: Speed of the bar.\n            pre_stim: Include pre-stimulus period.\n            post_stim: Include post-stimulus period.\n\n        Returns:\n            Stimulus array.\n        \"\"\"\n        key = self._key(angle, width, intensity, speed)\n        stim = self[key][:, 360].cpu().numpy()\n        if not post_stim:\n            stim = filter_post([stim], self.t_post, self.dt).squeeze()\n        if not pre_stim:\n            stim = filter_pre(stim[None], self.t_pre, self.dt).squeeze()\n        return stim\n\n    def stimulus_parameters(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n    ) -&gt; tuple[list, ...]:\n        \"\"\"Get stimulus parameters.\"\"\"\n\n        def _number_to_list(*args):\n            returns = tuple()\n            for arg in args:\n                if isinstance(arg, Number):\n                    returns += ([arg],)\n                else:\n                    returns += (arg,)\n            return returns\n\n        angle, width, speed, intensity = _number_to_list(angle, width, speed, intensity)\n        angle = angle or self.angles\n        width = width or self.widths\n        intensity = intensity or self.intensities\n        speed = speed or self.speeds\n        return angle, width, intensity, speed\n\n    def sample_shape(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n    ) -&gt; tuple[int, ...]:\n        \"\"\"Get shape of stimulus sample for given parameters.\"\"\"\n        if isinstance(angle, Number):\n            angle = [angle]\n        if isinstance(width, Number):\n            width = [width]\n        if isinstance(speed, Number):\n            speed = [speed]\n        if isinstance(intensity, Number):\n            intensity = [intensity]\n        angle = angle or self.angles\n        width = width or self.widths\n        intensity = intensity or self.intensities\n        speed = speed or self.speeds\n        return (\n            len(angle),\n            len(width),\n            len(intensity),\n            len(speed),\n        )\n\n    def time_to_center(self, speed: float) -&gt; float:\n        \"\"\"Calculate time for bar to reach center at given speed.\"\"\"\n        # Note: time = distance / velocity, i.e.\n        #     time = (n_leds * led_width) / (speed * omm_width)\n        #     with speed in ommatidia / s.\n        return np.abs(self.config.offsets[0]) * self.led_width / (speed * self.omm_width)\n\n    def get_time_with_origin_at_onset(self) -&gt; np.ndarray:\n        \"\"\"Get time array with origin at stimulus onset.\"\"\"\n        return np.linspace(\n            -self.t_pre,\n            self.t_stim_max - self.t_pre + self.t_post,\n            int(self.t_stim_max / self.dt)\n            + int(self.t_post / self.dt)\n            + int(self.t_pre / self.dt),\n        )\n\n    def get_time_with_origin_at_center(self, speed: float) -&gt; np.ndarray:\n        \"\"\"Get time array with origin where bar reaches central column.\"\"\"\n        time_to_center = self.time_to_center(speed)\n        n_steps = (\n            int(self.t_stim_max / self.dt)\n            + int(self.t_post / self.dt)\n            + int(self.t_pre / self.dt)\n        )\n        return np.linspace(\n            -(self.t_pre + time_to_center),\n            n_steps * self.dt - (self.t_pre + time_to_center),\n            n_steps,\n        )\n\n    def stimulus_cartoon(\n        self,\n        angle: float,\n        width: float,\n        intensity: float,\n        speed: float,\n        time_after_stimulus_onset: float = 0.5,\n        fig: Optional[plt.Figure] = None,\n        ax: Optional[plt.Axes] = None,\n        facecolor: str = \"#000000\",\n        cmap: Colormap = plt.cm.bone,\n        alpha: float = 0.5,\n        vmin: float = 0,\n        vmax: float = 1,\n        edgecolor: str = \"none\",\n        central_hex_color: str = \"#2f7cb9\",\n        **kwargs,\n    ) -&gt; tuple[plt.Figure, plt.Axes]:\n        \"\"\"Create a cartoon representation of the stimulus.\"\"\"\n        fig, ax = init_plot(fig=fig, ax=ax)\n\n        time = (\n            np.arange(\n                0,\n                self.t_pre + self.t_stim_max + self.t_post - self.dt,\n                self.dt,\n            )\n            - self.t_pre\n        )\n        index = np.argmin(np.abs(time - time_after_stimulus_onset))\n\n        fig, ax, _ = quick_hex_scatter(\n            self.get(angle=angle, width=width, speed=speed, intensity=intensity)\n            .cpu()\n            .numpy()[index],\n            vmin=vmin,\n            vmax=vmax,\n            cbar=False,\n            figsize=[1, 1],\n            max_extent=5,\n            fig=fig,\n            ax=ax,\n            cmap=cmap,\n            alpha=alpha,\n            edgecolor=edgecolor,\n            **kwargs,\n        )\n        rotation = np.array([\n            [\n                np.cos(np.radians(angle - 90)),\n                -np.sin(np.radians(angle - 90)),\n            ],\n            [\n                np.sin(np.radians(angle - 90)),\n                np.cos(np.radians(angle - 90)),\n            ],\n        ])\n        x = rotation @ np.array([0, -5])\n        dx = rotation @ np.array([0, 1])\n        ax.arrow(\n            *x,\n            *dx,\n            facecolor=facecolor,\n            width=0.75,\n            head_length=2.5,\n            edgecolor=\"k\",\n            linewidth=0.25,\n        )\n        _hex = RegularPolygon(\n            (0, 0),\n            numVertices=6,\n            radius=1,\n            linewidth=1,\n            orientation=np.radians(30),\n            edgecolor=central_hex_color,\n            facecolor=central_hex_color,\n            alpha=1,\n            ls=\"-\",\n        )\n        ax.add_patch(_hex)\n\n        return fig, ax\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.dt","title":"dt  <code>property</code> <code>writable</code>","text":"<pre><code>dt\n</code></pre> <p>Time step in seconds.</p>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.t_pre","title":"t_pre  <code>property</code>","text":"<pre><code>t_pre\n</code></pre> <p>Time before stimulus onset in seconds.</p>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.t_post","title":"t_post  <code>property</code>","text":"<pre><code>t_post\n</code></pre> <p>Time after stimulus offset in seconds.</p>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.time","title":"time  <code>property</code>","text":"<pre><code>time\n</code></pre> <p>Time array for the stimulus.</p>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.get_sequence_id_from_arguments","title":"get_sequence_id_from_arguments","text":"<pre><code>get_sequence_id_from_arguments(angle, width, intensity, speed)\n</code></pre> <p>Get sequence ID from stimulus arguments.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_sequence_id_from_arguments(\n    self, angle: float, width: float, intensity: float, speed: float\n) -&gt; int:\n    \"\"\"Get sequence ID from stimulus arguments.\"\"\"\n    return self.get_stimulus_index(locals())\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.get","title":"get","text":"<pre><code>get(angle, width, intensity, speed)\n</code></pre> <p>Get stimulus for specific parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get(\n    self, angle: float, width: float, intensity: float, speed: float\n) -&gt; torch.Tensor:\n    \"\"\"Get stimulus for specific parameters.\"\"\"\n    key = self._key(angle, width, intensity, speed)\n    return self[key]\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get stimulus for a specific key.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get stimulus for a specific key.\"\"\"\n    angle, width, intensity, _, speed = self._params(key)\n    return self.sequences[speed][self._group_key(angle, width, intensity)]\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.mask","title":"mask","text":"<pre><code>mask(angle=None, width=None, intensity=None, speed=None, t_stim=None)\n</code></pre> <p>Create a mask for specific stimulus parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def mask(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n    t_stim: Optional[float] = None,\n) -&gt; np.ndarray:\n    \"\"\"Create a mask for specific stimulus parameters.\"\"\"\n    # 22x faster than df.query\n    values = self.arg_df.values\n\n    def iterparam(param, name, axis, and_condition):\n        condition = np.zeros(len(values)).astype(bool)\n        if isinstance(param, Iterable):\n            for p in param:\n                _new = values.take(axis, axis=1) == p\n                assert any(_new), f\"{name} {p} not in dataset.\"\n                condition = np.logical_or(condition, _new)\n        else:\n            _new = values.take(axis, axis=1) == param\n            assert any(_new), f\"{name} {param} not in dataset.\"\n            condition = np.logical_or(condition, _new)\n        return condition &amp; and_condition\n\n    condition = np.ones(len(values)).astype(bool)\n    if angle is not None:\n        condition = iterparam(angle, \"angle\", 0, condition)\n    if width is not None:\n        condition = iterparam(width, \"width\", 1, condition)\n    if intensity is not None:\n        condition = iterparam(intensity, \"intensity\", 2, condition)\n    if t_stim is not None:\n        condition = iterparam(t_stim, \"t_stim\", 3, condition)\n    if speed is not None:\n        condition = iterparam(speed, \"speed\", 4, condition)\n    return condition\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.stimulus","title":"stimulus","text":"<pre><code>stimulus(angle=None, width=None, intensity=None, speed=None, pre_stim=True, post_stim=True)\n</code></pre> <p>Get stimulus for specific parameters.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>Optional[float]</code> <p>Angle of the bar.</p> <code>None</code> <code>width</code> <code>Optional[float]</code> <p>Width of the bar.</p> <code>None</code> <code>intensity</code> <code>Optional[float]</code> <p>Intensity of the bar.</p> <code>None</code> <code>speed</code> <code>Optional[float]</code> <p>Speed of the bar.</p> <code>None</code> <code>pre_stim</code> <code>bool</code> <p>Include pre-stimulus period.</p> <code>True</code> <code>post_stim</code> <code>bool</code> <p>Include post-stimulus period.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Stimulus array.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def stimulus(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n    pre_stim: bool = True,\n    post_stim: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Get stimulus for specific parameters.\n\n    Args:\n        angle: Angle of the bar.\n        width: Width of the bar.\n        intensity: Intensity of the bar.\n        speed: Speed of the bar.\n        pre_stim: Include pre-stimulus period.\n        post_stim: Include post-stimulus period.\n\n    Returns:\n        Stimulus array.\n    \"\"\"\n    key = self._key(angle, width, intensity, speed)\n    stim = self[key][:, 360].cpu().numpy()\n    if not post_stim:\n        stim = filter_post([stim], self.t_post, self.dt).squeeze()\n    if not pre_stim:\n        stim = filter_pre(stim[None], self.t_pre, self.dt).squeeze()\n    return stim\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.stimulus_parameters","title":"stimulus_parameters","text":"<pre><code>stimulus_parameters(angle=None, width=None, intensity=None, speed=None)\n</code></pre> <p>Get stimulus parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def stimulus_parameters(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n) -&gt; tuple[list, ...]:\n    \"\"\"Get stimulus parameters.\"\"\"\n\n    def _number_to_list(*args):\n        returns = tuple()\n        for arg in args:\n            if isinstance(arg, Number):\n                returns += ([arg],)\n            else:\n                returns += (arg,)\n        return returns\n\n    angle, width, speed, intensity = _number_to_list(angle, width, speed, intensity)\n    angle = angle or self.angles\n    width = width or self.widths\n    intensity = intensity or self.intensities\n    speed = speed or self.speeds\n    return angle, width, intensity, speed\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.sample_shape","title":"sample_shape","text":"<pre><code>sample_shape(angle=None, width=None, intensity=None, speed=None)\n</code></pre> <p>Get shape of stimulus sample for given parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def sample_shape(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n) -&gt; tuple[int, ...]:\n    \"\"\"Get shape of stimulus sample for given parameters.\"\"\"\n    if isinstance(angle, Number):\n        angle = [angle]\n    if isinstance(width, Number):\n        width = [width]\n    if isinstance(speed, Number):\n        speed = [speed]\n    if isinstance(intensity, Number):\n        intensity = [intensity]\n    angle = angle or self.angles\n    width = width or self.widths\n    intensity = intensity or self.intensities\n    speed = speed or self.speeds\n    return (\n        len(angle),\n        len(width),\n        len(intensity),\n        len(speed),\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.time_to_center","title":"time_to_center","text":"<pre><code>time_to_center(speed)\n</code></pre> <p>Calculate time for bar to reach center at given speed.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def time_to_center(self, speed: float) -&gt; float:\n    \"\"\"Calculate time for bar to reach center at given speed.\"\"\"\n    # Note: time = distance / velocity, i.e.\n    #     time = (n_leds * led_width) / (speed * omm_width)\n    #     with speed in ommatidia / s.\n    return np.abs(self.config.offsets[0]) * self.led_width / (speed * self.omm_width)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.get_time_with_origin_at_onset","title":"get_time_with_origin_at_onset","text":"<pre><code>get_time_with_origin_at_onset()\n</code></pre> <p>Get time array with origin at stimulus onset.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_time_with_origin_at_onset(self) -&gt; np.ndarray:\n    \"\"\"Get time array with origin at stimulus onset.\"\"\"\n    return np.linspace(\n        -self.t_pre,\n        self.t_stim_max - self.t_pre + self.t_post,\n        int(self.t_stim_max / self.dt)\n        + int(self.t_post / self.dt)\n        + int(self.t_pre / self.dt),\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.get_time_with_origin_at_center","title":"get_time_with_origin_at_center","text":"<pre><code>get_time_with_origin_at_center(speed)\n</code></pre> <p>Get time array with origin where bar reaches central column.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_time_with_origin_at_center(self, speed: float) -&gt; np.ndarray:\n    \"\"\"Get time array with origin where bar reaches central column.\"\"\"\n    time_to_center = self.time_to_center(speed)\n    n_steps = (\n        int(self.t_stim_max / self.dt)\n        + int(self.t_post / self.dt)\n        + int(self.t_pre / self.dt)\n    )\n    return np.linspace(\n        -(self.t_pre + time_to_center),\n        n_steps * self.dt - (self.t_pre + time_to_center),\n        n_steps,\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.moving_bar.MovingBar.stimulus_cartoon","title":"stimulus_cartoon","text":"<pre><code>stimulus_cartoon(angle, width, intensity, speed, time_after_stimulus_onset=0.5, fig=None, ax=None, facecolor='#000000', cmap=plt.cm.bone, alpha=0.5, vmin=0, vmax=1, edgecolor='none', central_hex_color='#2f7cb9', **kwargs)\n</code></pre> <p>Create a cartoon representation of the stimulus.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def stimulus_cartoon(\n    self,\n    angle: float,\n    width: float,\n    intensity: float,\n    speed: float,\n    time_after_stimulus_onset: float = 0.5,\n    fig: Optional[plt.Figure] = None,\n    ax: Optional[plt.Axes] = None,\n    facecolor: str = \"#000000\",\n    cmap: Colormap = plt.cm.bone,\n    alpha: float = 0.5,\n    vmin: float = 0,\n    vmax: float = 1,\n    edgecolor: str = \"none\",\n    central_hex_color: str = \"#2f7cb9\",\n    **kwargs,\n) -&gt; tuple[plt.Figure, plt.Axes]:\n    \"\"\"Create a cartoon representation of the stimulus.\"\"\"\n    fig, ax = init_plot(fig=fig, ax=ax)\n\n    time = (\n        np.arange(\n            0,\n            self.t_pre + self.t_stim_max + self.t_post - self.dt,\n            self.dt,\n        )\n        - self.t_pre\n    )\n    index = np.argmin(np.abs(time - time_after_stimulus_onset))\n\n    fig, ax, _ = quick_hex_scatter(\n        self.get(angle=angle, width=width, speed=speed, intensity=intensity)\n        .cpu()\n        .numpy()[index],\n        vmin=vmin,\n        vmax=vmax,\n        cbar=False,\n        figsize=[1, 1],\n        max_extent=5,\n        fig=fig,\n        ax=ax,\n        cmap=cmap,\n        alpha=alpha,\n        edgecolor=edgecolor,\n        **kwargs,\n    )\n    rotation = np.array([\n        [\n            np.cos(np.radians(angle - 90)),\n            -np.sin(np.radians(angle - 90)),\n        ],\n        [\n            np.sin(np.radians(angle - 90)),\n            np.cos(np.radians(angle - 90)),\n        ],\n    ])\n    x = rotation @ np.array([0, -5])\n    dx = rotation @ np.array([0, 1])\n    ax.arrow(\n        *x,\n        *dx,\n        facecolor=facecolor,\n        width=0.75,\n        head_length=2.5,\n        edgecolor=\"k\",\n        linewidth=0.25,\n    )\n    _hex = RegularPolygon(\n        (0, 0),\n        numVertices=6,\n        radius=1,\n        linewidth=1,\n        orientation=np.radians(30),\n        edgecolor=central_hex_color,\n        facecolor=central_hex_color,\n        alpha=1,\n        ls=\"-\",\n    )\n    ax.add_patch(_hex)\n\n    return fig, ax\n</code></pre>"},{"location":"reference/datasets/#impulses","title":"Impulses","text":""},{"location":"reference/datasets/#flyvis.datasets.dots.Dots","title":"flyvis.datasets.dots.Dots","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Render flashes aka dots per ommatidia.</p> Note <p>Renders directly in receptor space, does not use BoxEye or HexEye as eye-model.</p> <p>Parameters:</p> Name Type Description Default <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>max_extent</code> <code>int</code> <p>Maximum extent of the stimulus.</p> <code>15</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>1 / 200</code> <code>t_impulse</code> <code>Optional[float]</code> <p>Impulse duration.</p> <code>None</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>Literal['sustained', 'impulse']</code> <p>Stimulus mode (\u2018sustained\u2019 or \u2018impulse\u2019).</p> <code>'sustained'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> <p>Attributes:</p> Name Type Description <code>dt</code> <code>Optional[float]</code> <p>Time step.</p> <code>arg_df</code> <code>Optional[DataFrame]</code> <p>DataFrame containing stimulus parameters.</p> <code>config</code> <p>Namespace containing configuration parameters.</p> <code>t_stim</code> <p>Stimulus duration.</p> <code>n_ommatidia</code> <p>Number of ommatidia.</p> <code>offsets</code> <p>Array of ommatidia offsets.</p> <code>u</code> <p>U-coordinates of the hexagonal grid.</p> <code>v</code> <p>V-coordinates of the hexagonal grid.</p> <code>extent_condition</code> <p>Boolean mask for the extent condition.</p> <code>max_extent</code> <p>Maximum extent of the stimulus.</p> <code>bg_intensity</code> <p>Background intensity.</p> <code>intensities</code> <p>List of stimulus intensities.</p> <code>device</code> <p>Torch device for computations.</p> <code>mode</code> <p>Stimulus mode (\u2018sustained\u2019 or \u2018impulse\u2019).</p> <code>params</code> <p>List of stimulus parameters.</p> <code>t_impulse</code> <p>Impulse duration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dot_column_radius is greater than max_extent.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>class Dots(StimulusDataset):\n    \"\"\"\n    Render flashes aka dots per ommatidia.\n\n    Note:\n        Renders directly in receptor space, does not use BoxEye or HexEye as eye-model.\n\n    Args:\n        dot_column_radius: Radius of the dot column.\n        max_extent: Maximum extent of the stimulus.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        t_impulse: Impulse duration.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode ('sustained' or 'impulse').\n        device: Torch device for computations.\n\n    Attributes:\n        dt: Time step.\n        arg_df: DataFrame containing stimulus parameters.\n        config: Namespace containing configuration parameters.\n        t_stim: Stimulus duration.\n        n_ommatidia: Number of ommatidia.\n        offsets: Array of ommatidia offsets.\n        u: U-coordinates of the hexagonal grid.\n        v: V-coordinates of the hexagonal grid.\n        extent_condition: Boolean mask for the extent condition.\n        max_extent: Maximum extent of the stimulus.\n        bg_intensity: Background intensity.\n        intensities: List of stimulus intensities.\n        device: Torch device for computations.\n        mode: Stimulus mode ('sustained' or 'impulse').\n        params: List of stimulus parameters.\n        t_impulse: Impulse duration.\n\n    Raises:\n        ValueError: If dot_column_radius is greater than max_extent.\n    \"\"\"\n\n    dt: Optional[float] = None\n    arg_df: Optional[pd.DataFrame] = None\n\n    def __init__(\n        self,\n        dot_column_radius: int = 0,\n        max_extent: int = 15,\n        bg_intensity: float = 0.5,\n        t_stim: float = 5,\n        dt: float = 1 / 200,\n        t_impulse: Optional[float] = None,\n        n_ommatidia: int = 721,\n        t_pre: float = 2.0,\n        t_post: float = 0,\n        intensity: float = 1,\n        mode: Literal[\"sustained\", \"impulse\"] = \"sustained\",\n        device: torch.device = flyvis.device,\n    ):\n        if dot_column_radius &gt; max_extent:\n            raise ValueError(\"dot_column_radius must be smaller than max_extent\")\n        self.config = Namespace(\n            dot_column_radius=dot_column_radius,\n            max_extent=max_extent,\n            bg_intensity=bg_intensity,\n            t_stim=t_stim,\n            dt=dt,\n            n_ommatidia=n_ommatidia,\n            t_pre=t_pre,\n            t_post=t_post,\n            intensity=intensity,\n            mode=mode,\n            t_impulse=t_impulse,\n        )\n\n        self.t_stim = t_stim\n        self.t_pre = t_pre\n        self.t_post = t_post\n\n        self.n_ommatidia = n_ommatidia\n        self.offsets = np.arange(self.n_ommatidia)\n\n        u, v = hex_utils.get_hex_coords(hex_utils.get_hextent(n_ommatidia))\n        extent_condition = (\n            (-max_extent &lt;= u)\n            &amp; (u &lt;= max_extent)\n            &amp; (-max_extent &lt;= v)\n            &amp; (v &lt;= max_extent)\n            &amp; (-max_extent &lt;= u + v)\n            &amp; (u + v &lt;= max_extent)\n        )\n        self.u = u[extent_condition]\n        self.v = v[extent_condition]\n        # self.offsets = self.offsets[extent_condition]\n        self.extent_condition = extent_condition\n\n        # to have multi column dots at every location, construct coordinate_indices\n        # for each central column\n        coordinate_indices = []\n        for u, v in zip(self.u, self.v):\n            ring = HexLattice.filled_circle(\n                radius=dot_column_radius, center=Hexal(u, v, 0), as_lattice=True\n            )\n            # mask = np.array([~np.isnan(h.value) for h in h1])\n            coordinate_indices.append(self.offsets[ring.where(1)])\n\n        self.max_extent = max_extent\n        self.bg_intensity = bg_intensity\n\n        self.intensities = [2 * bg_intensity - intensity, intensity]\n        self.device = device\n        self.mode = mode\n\n        self.params = [\n            (*p[0], p[-1])\n            for p in list(\n                product(\n                    zip(self.u, self.v, self.offsets, coordinate_indices),\n                    self.intensities,\n                )\n            )\n        ]\n\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\"u\", \"v\", \"offset\", \"coordinate_index\", \"intensity\"],\n        )\n\n        self.dt = dt\n        self.t_impulse = t_impulse or self.dt\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a specific key.\n\n        Args:\n            key: Index of the parameters to retrieve.\n\n        Returns:\n            Array of parameters for the given key.\n        \"\"\"\n        return self.arg_df.iloc[key].values\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get a stimulus item for a specific key.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Tensor representing the stimulus sequence.\n        \"\"\"\n        # create maps with background value\n        _dot = (\n            torch.ones(self.n_ommatidia, device=self.device)[None, None]\n            * self.bg_intensity\n        )\n        # fill at the ommatitdium at offset with intensity\n        _, _, _, coordinate_index, intensity = self._params(key)\n        _dot[:, :, coordinate_index] = torch.tensor(intensity, device=self.device).float()\n\n        # repeat for stustained stimulus\n        if self.mode == \"sustained\":\n            sequence = resample(_dot, self.t_stim, self.dt, dim=1, device=self.device)\n\n        elif self.mode == \"impulse\":\n            # pad remaining stimulus duration i.e. self.t_stim - self.dt with\n            # background intensity\n            if self.t_impulse == self.dt:\n                sequence = pad(\n                    _dot,\n                    self.t_stim,\n                    self.dt,\n                    mode=\"end\",\n                    fill=self.bg_intensity,\n                )\n            # first resample for t_impulse/dt then pad remaining stimulus\n            # duration, i.e. t_stim - t_impulse with background intensity\n            else:\n                sequence = resample(\n                    _dot, self.t_impulse, self.dt, dim=1, device=self.device\n                )\n                sequence = pad(\n                    sequence,\n                    self.t_stim,\n                    self.dt,\n                    mode=\"end\",\n                    fill=self.bg_intensity,\n                )\n\n        # pad with pre stimulus background\n        sequence = pad(\n            sequence,\n            self.t_stim + self.t_pre,\n            self.dt,\n            mode=\"start\",\n            fill=self.bg_intensity,\n        )\n        # pad with post stimulus background\n        sequence = pad(\n            sequence,\n            self.t_stim + self.t_pre + self.t_post,\n            self.dt,\n            mode=\"end\",\n            fill=self.bg_intensity,\n        )\n        return sequence.squeeze()\n\n    def get_stimulus_index(self, u: float, v: float, intensity: float) -&gt; int:\n        \"\"\"Get sequence ID from given arguments.\n\n        Args:\n            u: U-coordinate.\n            v: V-coordinate.\n            intensity: Stimulus intensity.\n\n        Returns:\n            Sequence ID.\n        \"\"\"\n        return StimulusDataset.get_stimulus_index(self, locals())\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.Dots.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get a stimulus item for a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor representing the stimulus sequence.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get a stimulus item for a specific key.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Tensor representing the stimulus sequence.\n    \"\"\"\n    # create maps with background value\n    _dot = (\n        torch.ones(self.n_ommatidia, device=self.device)[None, None]\n        * self.bg_intensity\n    )\n    # fill at the ommatitdium at offset with intensity\n    _, _, _, coordinate_index, intensity = self._params(key)\n    _dot[:, :, coordinate_index] = torch.tensor(intensity, device=self.device).float()\n\n    # repeat for stustained stimulus\n    if self.mode == \"sustained\":\n        sequence = resample(_dot, self.t_stim, self.dt, dim=1, device=self.device)\n\n    elif self.mode == \"impulse\":\n        # pad remaining stimulus duration i.e. self.t_stim - self.dt with\n        # background intensity\n        if self.t_impulse == self.dt:\n            sequence = pad(\n                _dot,\n                self.t_stim,\n                self.dt,\n                mode=\"end\",\n                fill=self.bg_intensity,\n            )\n        # first resample for t_impulse/dt then pad remaining stimulus\n        # duration, i.e. t_stim - t_impulse with background intensity\n        else:\n            sequence = resample(\n                _dot, self.t_impulse, self.dt, dim=1, device=self.device\n            )\n            sequence = pad(\n                sequence,\n                self.t_stim,\n                self.dt,\n                mode=\"end\",\n                fill=self.bg_intensity,\n            )\n\n    # pad with pre stimulus background\n    sequence = pad(\n        sequence,\n        self.t_stim + self.t_pre,\n        self.dt,\n        mode=\"start\",\n        fill=self.bg_intensity,\n    )\n    # pad with post stimulus background\n    sequence = pad(\n        sequence,\n        self.t_stim + self.t_pre + self.t_post,\n        self.dt,\n        mode=\"end\",\n        fill=self.bg_intensity,\n    )\n    return sequence.squeeze()\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.Dots.get_stimulus_index","title":"get_stimulus_index","text":"<pre><code>get_stimulus_index(u, v, intensity)\n</code></pre> <p>Get sequence ID from given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>float</code> <p>U-coordinate.</p> required <code>v</code> <code>float</code> <p>V-coordinate.</p> required <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Sequence ID.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_stimulus_index(self, u: float, v: float, intensity: float) -&gt; int:\n    \"\"\"Get sequence ID from given arguments.\n\n    Args:\n        u: U-coordinate.\n        v: V-coordinate.\n        intensity: Stimulus intensity.\n\n    Returns:\n        Sequence ID.\n    \"\"\"\n    return StimulusDataset.get_stimulus_index(self, locals())\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.SpatialImpulses","title":"flyvis.datasets.dots.SpatialImpulses","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Spatial flashes for spatial receptive field mapping.</p> <p>Parameters:</p> Name Type Description Default <code>impulse_durations</code> <code>List[float]</code> <p>List of impulse durations.</p> <code>[0.005, 0.02]</code> <code>max_extent</code> <code>int</code> <p>Maximum extent of the stimulus.</p> <code>4</code> <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>0.005</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Stimulus mode.</p> <code>'impulse'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> <p>Attributes:</p> Name Type Description <code>arg_df</code> <code>Optional[DataFrame]</code> <p>DataFrame containing stimulus parameters.</p> <code>dt</code> <code>Optional[float]</code> <p>Time step.</p> <code>dots</code> <p>Instance of the Dots class.</p> <code>impulse_durations</code> <p>List of impulse durations.</p> <code>config</code> <p>Configuration namespace.</p> <code>params</code> <p>List of stimulus parameters.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>class SpatialImpulses(StimulusDataset):\n    \"\"\"Spatial flashes for spatial receptive field mapping.\n\n    Args:\n        impulse_durations: List of impulse durations.\n        max_extent: Maximum extent of the stimulus.\n        dot_column_radius: Radius of the dot column.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode.\n        device: Torch device for computations.\n\n    Attributes:\n        arg_df: DataFrame containing stimulus parameters.\n        dt: Time step.\n        dots: Instance of the Dots class.\n        impulse_durations: List of impulse durations.\n        config: Configuration namespace.\n        params: List of stimulus parameters.\n    \"\"\"\n\n    arg_df: Optional[pd.DataFrame] = None\n    dt: Optional[float] = None\n\n    def __init__(\n        self,\n        impulse_durations: List[float] = [5e-3, 20e-3],\n        max_extent: int = 4,\n        dot_column_radius: int = 0,\n        bg_intensity: float = 0.5,\n        t_stim: float = 5,\n        dt: float = 0.005,\n        n_ommatidia: int = 721,\n        t_pre: float = 2.0,\n        t_post: float = 0,\n        intensity: float = 1,\n        mode: str = \"impulse\",\n        device: torch.device = flyvis.device,\n    ):\n        self.dots = Dots(\n            dot_column_radius=dot_column_radius,\n            max_extent=max_extent,\n            bg_intensity=bg_intensity,\n            t_stim=t_stim,\n            dt=dt,\n            n_ommatidia=n_ommatidia,\n            t_pre=t_pre,\n            t_post=t_post,\n            intensity=intensity,\n            mode=mode,\n            device=device,\n        )\n        self.dt = dt\n        self.impulse_durations = impulse_durations\n\n        self.config = self.dots.config\n        self.config.update(impulse_durations=impulse_durations)\n\n        self.params = [\n            (*p[0], p[1])\n            for p in product(self.dots.arg_df.values.tolist(), impulse_durations)\n        ]\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\n                \"u\",\n                \"v\",\n                \"offset\",\n                \"coordinate_index\",\n                \"intensity\",\n                \"t_impulse\",\n            ],\n        )\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a specific key.\n\n        Args:\n            key: Index of the parameters to retrieve.\n\n        Returns:\n            Array of parameters for the given key.\n        \"\"\"\n        return self.arg_df.iloc[key].values\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get a stimulus item for a specific key.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Tensor representing the stimulus sequence.\n        \"\"\"\n        u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n        self.dots.t_impulse = t_impulse\n        return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Get string representation of the dataset.\"\"\"\n        return repr(self.arg_df)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.SpatialImpulses.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get a stimulus item for a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor representing the stimulus sequence.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get a stimulus item for a specific key.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Tensor representing the stimulus sequence.\n    \"\"\"\n    u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n    self.dots.t_impulse = t_impulse\n    return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.SpatialImpulses.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Get string representation of the dataset.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Get string representation of the dataset.\"\"\"\n    return repr(self.arg_df)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.CentralImpulses","title":"flyvis.datasets.dots.CentralImpulses","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Flashes at the center of the visual field for temporal receptive field mapping.</p> <p>Parameters:</p> Name Type Description Default <code>impulse_durations</code> <code>List[float]</code> <p>List of impulse durations.</p> <code>[0.005, 0.02, 0.05, 0.1, 0.2, 0.3]</code> <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>0.005</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Stimulus mode.</p> <code>'impulse'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> <p>Attributes:</p> Name Type Description <code>arg_df</code> <code>Optional[DataFrame]</code> <p>DataFrame containing stimulus parameters.</p> <code>dt</code> <code>Optional[float]</code> <p>Time step.</p> <code>dots</code> <p>Instance of the Dots class.</p> <code>impulse_durations</code> <p>List of impulse durations.</p> <code>config</code> <p>Configuration namespace.</p> <code>params</code> <p>List of stimulus parameters.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>class CentralImpulses(StimulusDataset):\n    \"\"\"Flashes at the center of the visual field for temporal receptive field mapping.\n\n    Args:\n        impulse_durations: List of impulse durations.\n        dot_column_radius: Radius of the dot column.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode.\n        device: Torch device for computations.\n\n    Attributes:\n        arg_df: DataFrame containing stimulus parameters.\n        dt: Time step.\n        dots: Instance of the Dots class.\n        impulse_durations: List of impulse durations.\n        config: Configuration namespace.\n        params: List of stimulus parameters.\n    \"\"\"\n\n    arg_df: Optional[pd.DataFrame] = None\n    dt: Optional[float] = None\n\n    def __init__(\n        self,\n        impulse_durations: List[float] = [5e-3, 20e-3, 50e-3, 100e-3, 200e-3, 300e-3],\n        dot_column_radius: int = 0,\n        bg_intensity: float = 0.5,\n        t_stim: float = 5,\n        dt: float = 0.005,\n        n_ommatidia: int = 721,\n        t_pre: float = 2.0,\n        t_post: float = 0,\n        intensity: float = 1,\n        mode: str = \"impulse\",\n        device: torch.device = flyvis.device,\n    ):\n        \"\"\"Initialize the CentralImpulses dataset.\n\n        Args:\n            impulse_durations: List of impulse durations.\n            dot_column_radius: Radius of the dot column.\n            bg_intensity: Background intensity.\n            t_stim: Stimulus duration.\n            dt: Time step.\n            n_ommatidia: Number of ommatidia.\n            t_pre: Pre-stimulus duration.\n            t_post: Post-stimulus duration.\n            intensity: Stimulus intensity.\n            mode: Stimulus mode.\n            device: Torch device for computations.\n        \"\"\"\n        self.dots = Dots(\n            dot_column_radius=dot_column_radius,\n            max_extent=dot_column_radius,\n            bg_intensity=bg_intensity,\n            t_stim=t_stim,\n            dt=dt,\n            n_ommatidia=n_ommatidia,\n            t_pre=t_pre,\n            t_post=t_post,\n            intensity=intensity,\n            mode=mode,\n            device=device,\n        )\n        self.impulse_durations = impulse_durations\n        self.config = self.dots.config\n        self.config.update(impulse_durations=impulse_durations)\n        self.params = [\n            (*p[0], p[1])\n            for p in product(self.dots.arg_df.values.tolist(), impulse_durations)\n        ]\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\n                \"u\",\n                \"v\",\n                \"offset\",\n                \"coordinate_index\",\n                \"intensity\",\n                \"t_impulse\",\n            ],\n        )\n        self.dt = dt\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a specific key.\n\n        Args:\n            key: Index of the parameters to retrieve.\n\n        Returns:\n            Array of parameters for the given key.\n        \"\"\"\n        return self.arg_df.iloc[key].values\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get a stimulus item for a specific key.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Tensor representing the stimulus sequence.\n        \"\"\"\n        u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n        self.dots.t_impulse = t_impulse\n        return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n\n    @property\n    def t_pre(self) -&gt; float:\n        \"\"\"Get pre-stimulus duration.\"\"\"\n        return self.dots.t_pre\n\n    @property\n    def t_post(self) -&gt; float:\n        \"\"\"Get post-stimulus duration.\"\"\"\n        return self.dots.t_post\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Get string representation of the dataset.\"\"\"\n        return repr(self.arg_df)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.CentralImpulses.t_pre","title":"t_pre  <code>property</code>","text":"<pre><code>t_pre\n</code></pre> <p>Get pre-stimulus duration.</p>"},{"location":"reference/datasets/#flyvis.datasets.dots.CentralImpulses.t_post","title":"t_post  <code>property</code>","text":"<pre><code>t_post\n</code></pre> <p>Get post-stimulus duration.</p>"},{"location":"reference/datasets/#flyvis.datasets.dots.CentralImpulses.__init__","title":"__init__","text":"<pre><code>__init__(impulse_durations=[0.005, 0.02, 0.05, 0.1, 0.2, 0.3], dot_column_radius=0, bg_intensity=0.5, t_stim=5, dt=0.005, n_ommatidia=721, t_pre=2.0, t_post=0, intensity=1, mode='impulse', device=flyvis.device)\n</code></pre> <p>Initialize the CentralImpulses dataset.</p> <p>Parameters:</p> Name Type Description Default <code>impulse_durations</code> <code>List[float]</code> <p>List of impulse durations.</p> <code>[0.005, 0.02, 0.05, 0.1, 0.2, 0.3]</code> <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>0.005</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Stimulus mode.</p> <code>'impulse'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def __init__(\n    self,\n    impulse_durations: List[float] = [5e-3, 20e-3, 50e-3, 100e-3, 200e-3, 300e-3],\n    dot_column_radius: int = 0,\n    bg_intensity: float = 0.5,\n    t_stim: float = 5,\n    dt: float = 0.005,\n    n_ommatidia: int = 721,\n    t_pre: float = 2.0,\n    t_post: float = 0,\n    intensity: float = 1,\n    mode: str = \"impulse\",\n    device: torch.device = flyvis.device,\n):\n    \"\"\"Initialize the CentralImpulses dataset.\n\n    Args:\n        impulse_durations: List of impulse durations.\n        dot_column_radius: Radius of the dot column.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode.\n        device: Torch device for computations.\n    \"\"\"\n    self.dots = Dots(\n        dot_column_radius=dot_column_radius,\n        max_extent=dot_column_radius,\n        bg_intensity=bg_intensity,\n        t_stim=t_stim,\n        dt=dt,\n        n_ommatidia=n_ommatidia,\n        t_pre=t_pre,\n        t_post=t_post,\n        intensity=intensity,\n        mode=mode,\n        device=device,\n    )\n    self.impulse_durations = impulse_durations\n    self.config = self.dots.config\n    self.config.update(impulse_durations=impulse_durations)\n    self.params = [\n        (*p[0], p[1])\n        for p in product(self.dots.arg_df.values.tolist(), impulse_durations)\n    ]\n    self.arg_df = pd.DataFrame(\n        self.params,\n        columns=[\n            \"u\",\n            \"v\",\n            \"offset\",\n            \"coordinate_index\",\n            \"intensity\",\n            \"t_impulse\",\n        ],\n    )\n    self.dt = dt\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.CentralImpulses.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get a stimulus item for a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor representing the stimulus sequence.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get a stimulus item for a specific key.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Tensor representing the stimulus sequence.\n    \"\"\"\n    u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n    self.dots.t_impulse = t_impulse\n    return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.dots.CentralImpulses.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Get string representation of the dataset.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Get string representation of the dataset.\"\"\"\n    return repr(self.arg_df)\n</code></pre>"},{"location":"reference/datasets/#sintel","title":"Sintel","text":""},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel","title":"flyvis.datasets.sintel.MultiTaskSintel","text":"<p>               Bases: <code>MultiTaskDataset</code></p> <p>Sintel dataset.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[str]</code> <p>List of tasks to include. May include \u2018flow\u2019, \u2018lum\u2019, or \u2018depth\u2019.</p> <code>['flow']</code> <code>boxfilter</code> <code>Dict[str, int]</code> <p>Key word arguments for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>vertical_splits</code> <code>int</code> <p>Number of vertical splits of each frame.</p> <code>3</code> <code>n_frames</code> <code>int</code> <p>Number of frames to render for each sequence.</p> <code>19</code> <code>center_crop_fraction</code> <code>float</code> <p>Fraction of the image to keep after cropping.</p> <code>0.7</code> <code>dt</code> <code>float</code> <p>Sampling and integration time constant.</p> <code>1 / 50</code> <code>augment</code> <code>bool</code> <p>Turns augmentation on and off.</p> <code>True</code> <code>random_temporal_crop</code> <code>bool</code> <p>Randomly crops a temporal window of length <code>n_frames</code> from each sequence.</p> <code>True</code> <code>all_frames</code> <code>bool</code> <p>If True, all frames are returned. If False, only <code>n_frames</code>. Takes precedence over <code>random_temporal_crop</code>.</p> <code>False</code> <code>resampling</code> <code>bool</code> <p>If True, piecewise-constant resamples the input sequence to the target framerate (1/dt).</p> <code>True</code> <code>interpolate</code> <code>bool</code> <p>If True, linearly interpolates the target sequence to the target framerate (1/dt).</p> <code>True</code> <code>p_flip</code> <code>float</code> <p>Probability of flipping the sequence across hexagonal axes.</p> <code>0.5</code> <code>p_rot</code> <code>float</code> <p>Probability of rotating the sequence by n*60 degrees.</p> <code>5 / 6</code> <code>contrast_std</code> <code>float</code> <p>Standard deviation of the contrast augmentation.</p> <code>0.2</code> <code>brightness_std</code> <code>float</code> <p>Standard deviation of the brightness augmentation.</p> <code>0.1</code> <code>gaussian_white_noise</code> <code>float</code> <p>Standard deviation of the pixel-wise gaussian white noise.</p> <code>0.08</code> <code>gamma_std</code> <code>Optional[float]</code> <p>Standard deviation of the gamma augmentation.</p> <code>None</code> <code>_init_cache</code> <code>bool</code> <p>If True, caches the dataset in memory.</p> <code>True</code> <code>unittest</code> <code>bool</code> <p>If True, only renders a single sequence.</p> <code>False</code> <code>flip_axes</code> <code>List[int]</code> <p>List of axes to flip over.</p> <code>[0, 1]</code> <p>Attributes:</p> Name Type Description <code>dt</code> <code>float</code> <p>Sampling and integration time constant.</p> <code>t_pre</code> <code>float</code> <p>Warmup time.</p> <code>t_post</code> <code>float</code> <p>Cooldown time.</p> <code>tasks</code> <code>List[str]</code> <p>List of all tasks.</p> <code>valid_tasks</code> <code>List[str]</code> <p>List of valid task names.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any element in tasks is invalid.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>class MultiTaskSintel(MultiTaskDataset):\n    \"\"\"Sintel dataset.\n\n    Args:\n        tasks: List of tasks to include. May include 'flow', 'lum', or 'depth'.\n        boxfilter: Key word arguments for the BoxEye filter.\n        vertical_splits: Number of vertical splits of each frame.\n        n_frames: Number of frames to render for each sequence.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        dt: Sampling and integration time constant.\n        augment: Turns augmentation on and off.\n        random_temporal_crop: Randomly crops a temporal window of length `n_frames` from\n            each sequence.\n        all_frames: If True, all frames are returned. If False, only `n_frames`. Takes\n            precedence over `random_temporal_crop`.\n        resampling: If True, piecewise-constant resamples the input sequence to the\n            target framerate (1/dt).\n        interpolate: If True, linearly interpolates the target sequence to the target\n            framerate (1/dt).\n        p_flip: Probability of flipping the sequence across hexagonal axes.\n        p_rot: Probability of rotating the sequence by n*60 degrees.\n        contrast_std: Standard deviation of the contrast augmentation.\n        brightness_std: Standard deviation of the brightness augmentation.\n        gaussian_white_noise: Standard deviation of the pixel-wise gaussian white noise.\n        gamma_std: Standard deviation of the gamma augmentation.\n        _init_cache: If True, caches the dataset in memory.\n        unittest: If True, only renders a single sequence.\n        flip_axes: List of axes to flip over.\n\n    Attributes:\n        dt (float): Sampling and integration time constant.\n        t_pre (float): Warmup time.\n        t_post (float): Cooldown time.\n        tasks (List[str]): List of all tasks.\n        valid_tasks (List[str]): List of valid task names.\n\n    Raises:\n        ValueError: If any element in tasks is invalid.\n    \"\"\"\n\n    original_framerate: int = 24\n    dt: float = 1 / 50\n    t_pre: float = 0.0\n    t_post: float = 0.0\n    tasks: List[str] = []\n    valid_tasks: List[str] = [\"lum\", \"flow\", \"depth\"]\n\n    def __init__(\n        self,\n        tasks: List[str] = [\"flow\"],\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        vertical_splits: int = 3,\n        n_frames: int = 19,\n        center_crop_fraction: float = 0.7,\n        dt: float = 1 / 50,\n        augment: bool = True,\n        random_temporal_crop: bool = True,\n        all_frames: bool = False,\n        resampling: bool = True,\n        interpolate: bool = True,\n        p_flip: float = 0.5,\n        p_rot: float = 5 / 6,\n        contrast_std: float = 0.2,\n        brightness_std: float = 0.1,\n        gaussian_white_noise: float = 0.08,\n        gamma_std: Optional[float] = None,\n        _init_cache: bool = True,\n        unittest: bool = False,\n        flip_axes: List[int] = [0, 1],\n        sintel_path: Optional[Union[str, Path]] = None,\n    ):\n        def check_tasks(tasks):\n            invalid_tasks = [x for x in tasks if x not in self.valid_tasks]\n            if invalid_tasks:\n                raise ValueError(f\"invalid tasks {invalid_tasks}\")\n\n            tasks = [v for v in self.valid_tasks if v in tasks]  # sort\n            # because the input 'lum' is always required\n            data_keys = tasks if \"lum\" in tasks else [\"lum\", *tasks]\n            return tasks, data_keys\n\n        self.tasks, self.data_keys = check_tasks(tasks)\n        self.interpolate = interpolate\n        self.n_frames = n_frames if not unittest else 3\n        self.dt = dt\n\n        self.all_frames = all_frames\n        self.resampling = resampling\n\n        self.boxfilter = boxfilter\n        self.extent = boxfilter[\"extent\"]\n        assert vertical_splits &gt;= 1\n        self.vertical_splits = vertical_splits\n        self.center_crop_fraction = center_crop_fraction\n\n        self.p_flip = p_flip\n        self.p_rot = p_rot\n        self.contrast_std = contrast_std\n        self.brightness_std = brightness_std\n        self.gaussian_white_noise = gaussian_white_noise\n        self.gamma_std = gamma_std\n        self.random_temporal_crop = random_temporal_crop\n        self.flip_axes = flip_axes\n        self.fix_augmentation_params = False\n\n        self.init_augmentation()\n        self._augmentations_are_initialized = True\n        # note: self.augment is a property with a setter that relies on\n        # _augmentations_are_initialized\n        self.augment = augment\n\n        self.unittest = unittest\n\n        # Download Sintel once and reuse the path\n        self.sintel_path = (\n            Path(sintel_path) if sintel_path else download_sintel(depth=\"depth\" in tasks)\n        )\n\n        self.rendered = RenderedSintel(\n            tasks=tasks,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            n_frames=n_frames,\n            center_crop_fraction=center_crop_fraction,\n            unittest=unittest,\n            sintel_path=self.sintel_path,\n        )\n\n        self.meta = sintel_meta(\n            self.rendered, self.sintel_path, n_frames, vertical_splits, \"depth\" in tasks\n        )\n\n        self.config = Namespace(\n            tasks=tasks,\n            interpolate=interpolate,\n            n_frames=n_frames,\n            dt=dt,\n            augment=augment,\n            all_frames=all_frames,\n            resampling=resampling,\n            random_temporal_crop=random_temporal_crop,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            p_flip=p_flip,\n            p_rot=p_rot,\n            contrast_std=contrast_std,\n            brightness_std=brightness_std,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma_std=gamma_std,\n            center_crop_fraction=center_crop_fraction,\n            flip_axes=flip_axes,\n        )\n\n        self.arg_df = pd.DataFrame(\n            dict(\n                index=np.arange(len(self.rendered)),\n                original_index=self.meta.sequence_indices.repeat(vertical_splits),\n                name=sorted(self.rendered.keys()),\n                original_n_frames=self.meta.frames_per_scene.repeat(vertical_splits),\n            )\n        )\n\n        if _init_cache:\n            self.init_cache()\n\n    def init_cache(self) -&gt; None:\n        \"\"\"Initialize the cache with preprocessed sequences.\"\"\"\n        self.cached_sequences = [\n            {\n                key: torch.tensor(val, dtype=torch.float32)\n                for key, val in self.rendered(seq_id).items()\n                if key in self.data_keys\n            }\n            for seq_id in range(len(self))\n        ]\n\n    def __repr__(self) -&gt; str:\n        repr = f\"{self.__class__.__name__} with {len(self)} sequences.\\n\"\n        repr += \"See docs, arg_df and meta for more details.\\n\"\n        return repr\n\n    @property\n    def docs(self) -&gt; str:\n        print(self.__doc__)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Custom attribute setter to handle special cases and update augmentation.\n\n        Args:\n            name: Name of the attribute to set.\n            value: Value to set the attribute to.\n\n        Raises:\n            AttributeError: If trying to change framerate or rendered initialization\n                attributes.\n        \"\"\"\n        # some changes have no effect cause they are fixed, or set by the pre-rendering\n        if name == \"framerate\":\n            raise AttributeError(\"cannot change framerate\")\n        if hasattr(self, \"rendered\") and name in self.rendered.config:\n            raise AttributeError(\"cannot change attribute of rendered initialization\")\n        super().__setattr__(name, value)\n        # also update augmentation because it may already be initialized\n        if getattr(self, \"_augmentations_are_initialized\", False):\n            self.update_augmentation(name, value)\n\n    def init_augmentation(self) -&gt; None:\n        \"\"\"Initialize augmentation callables.\"\"\"\n        self.temporal_crop = CropFrames(\n            self.n_frames, all_frames=self.all_frames, random=self.random_temporal_crop\n        )\n        self.jitter = ContrastBrightness(\n            contrast_std=self.contrast_std, brightness_std=self.brightness_std\n        )\n        self.rotate = HexRotate(self.extent, p_rot=self.p_rot)\n        self.flip = HexFlip(self.extent, p_flip=self.p_flip, flip_axes=self.flip_axes)\n        self.noise = PixelNoise(self.gaussian_white_noise)\n\n        self.piecewise_resample = Interpolate(\n            self.original_framerate, 1 / self.dt, mode=\"nearest-exact\"\n        )\n        self.linear_interpolate = Interpolate(\n            self.original_framerate,\n            1 / self.dt,\n            mode=\"linear\",\n        )\n        self.gamma_correct = GammaCorrection(1, self.gamma_std)\n\n    def update_augmentation(self, name: str, value: Any) -&gt; None:\n        \"\"\"Update augmentation parameters based on attribute changes.\n\n        Args:\n            name: Name of the attribute that changed.\n            value: New value of the attribute.\n        \"\"\"\n        if name == \"dt\":\n            self.piecewise_resample.target_framerate = 1 / value\n            self.linear_interpolate.target_framerate = 1 / value\n        if name in [\"all_frames\", \"random_temporal_crop\"]:\n            self.temporal_crop.all_frames = value\n            self.temporal_crop.random = value\n        if name in [\"contrast_std\", \"brightness_std\"]:\n            self.jitter.contrast_std = value\n            self.jitter.brightness_std = value\n        if name == \"p_rot\":\n            self.rotate.p_rot = value\n        if name == \"p_flip\":\n            self.flip.p_flip = value\n        if name == \"gaussian_white_noise\":\n            self.noise.std = value\n        if name == \"gamma_std\":\n            self.gamma_correct.std = value\n\n    def set_augmentation_params(\n        self,\n        n_rot: Optional[int] = None,\n        flip_axis: Optional[int] = None,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma: Optional[float] = None,\n        start_frame: Optional[int] = None,\n        total_sequence_length: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Set augmentation callable parameters.\n\n        Info:\n            Called for each call of get_item.\n\n        Args:\n            n_rot: Number of rotations to apply.\n            flip_axis: Axis to flip over.\n            contrast_factor: Contrast factor for jitter augmentation.\n            brightness_factor: Brightness factor for jitter augmentation.\n            gaussian_white_noise: Standard deviation for noise augmentation.\n            gamma: Gamma value for gamma correction.\n            start_frame: Starting frame for temporal crop.\n            total_sequence_length: Total length of the sequence.\n        \"\"\"\n        if not self.fix_augmentation_params:\n            self.rotate.set_or_sample(n_rot)\n            self.flip.set_or_sample(flip_axis)\n            self.jitter.set_or_sample(contrast_factor, brightness_factor)\n            self.noise.set_or_sample(gaussian_white_noise)\n            self.gamma_correct.set_or_sample(gamma)\n            self.temporal_crop.set_or_sample(\n                start=start_frame, total_sequence_length=total_sequence_length\n            )\n\n    def get_item(self, key: int) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Return a dataset sample.\n\n        Args:\n            key: Index of the sample to retrieve.\n\n        Returns:\n            Dictionary containing the augmented sample data.\n        \"\"\"\n        return self.apply_augmentation(self.cached_sequences[key])\n\n    @contextmanager\n    def augmentation(self, abool: bool):\n        \"\"\"Context manager to turn augmentation on or off in a code block.\n\n        Args:\n            abool: Boolean value to set augmentation state.\n\n        Example:\n            ```python\n            with dataset.augmentation(True):\n                for i, data in enumerate(dataloader):\n                    ...  # all data is augmented\n            ```\n        \"\"\"\n        augmentations = [\n            \"temporal_crop\",\n            \"jitter\",\n            \"rotate\",\n            \"flip\",\n            \"noise\",\n            \"piecewise_resample\",\n            \"linear_interpolate\",\n            \"gamma_correct\",\n        ]\n        states = {key: getattr(self, key).augment for key in augmentations}\n        _augment = self.augment\n        try:\n            self.augment = abool\n            yield\n        finally:\n            self.augment = _augment\n            for key in augmentations:\n                getattr(self, key).augment = states[key]\n\n    @property\n    def augment(self) -&gt; bool:\n        \"\"\"Get the current augmentation state.\"\"\"\n        return self._augment\n\n    @augment.setter\n    def augment(self, value: bool) -&gt; None:\n        \"\"\"Set the augmentation state and update augmentation callables.\n\n        Args:\n            value: Boolean value to set augmentation state.\n        \"\"\"\n        self._augment = value\n        if not self._augmentations_are_initialized:\n            return\n        # note: random_temporal_crop can override augment=True\n        self.temporal_crop.random = self.random_temporal_crop if value else False\n        self.jitter.augment = value\n        self.rotate.augment = value\n        self.flip.augment = value\n        self.noise.augment = value\n        # note: these two are not affected by augment\n        self.piecewise_resample.augment = self.resampling\n        self.linear_interpolate.augment = self.interpolate\n        self.gamma_correct.augment = value\n\n    def apply_augmentation(\n        self,\n        data: Dict[str, torch.Tensor],\n        n_rot: Optional[int] = None,\n        flip_axis: Optional[int] = None,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma: Optional[float] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Apply augmentation to a sample from the dataset.\n\n        Args:\n            data: Dictionary containing the sample data.\n            n_rot: Number of rotations to apply.\n            flip_axis: Axis to flip over.\n            contrast_factor: Contrast factor for jitter augmentation.\n            brightness_factor: Brightness factor for jitter augmentation.\n            gaussian_white_noise: Standard deviation for noise augmentation.\n            gamma: Gamma value for gamma correction.\n\n        Returns:\n            Dictionary containing the augmented sample data.\n        \"\"\"\n\n        self.set_augmentation_params(\n            n_rot=n_rot,\n            flip_axis=flip_axis,\n            contrast_factor=contrast_factor,\n            brightness_factor=brightness_factor,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma=gamma,\n            start_frame=None,\n            total_sequence_length=data[\"lum\"].shape[0],\n        )\n\n        def transform_lum(lum):\n            return self.piecewise_resample(\n                self.rotate(\n                    self.flip(\n                        self.jitter(\n                            self.noise(self.temporal_crop(lum)),\n                        ),\n                    )\n                )\n            )\n\n        def transform_target(target):\n            if self.interpolate:\n                return self.linear_interpolate(\n                    self.rotate(self.flip(self.temporal_crop(target)))\n                )\n            return self.piecewise_resample(\n                self.rotate(self.flip(self.temporal_crop(target)))\n            )\n\n        return {\n            **{\"lum\": transform_lum(data[\"lum\"])},\n            **{\n                target: transform_target(data[target])\n                for target in self.tasks\n                if target in [\"flow\", \"depth\"]\n            },\n        }\n\n    def original_sequence_index(self, key: int) -&gt; int:\n        \"\"\"Get the original sequence index from an index of the split.\n\n        Args:\n            key: Index of the split.\n\n        Returns:\n            Original sequence index.\n\n        Raises:\n            ValueError: If the key is not found in splits.\n        \"\"\"\n        for index, splits in self.meta.sequence_index_to_splits.items():\n            if key in splits:\n                return index\n        raise ValueError(f\"key {key} not found in splits\")\n\n    def cartesian_sequence(\n        self,\n        key: int,\n        vertical_splits: Optional[int] = None,\n        outwidth: int = 716,\n        center_crop_fraction: Optional[float] = None,\n        sampling: slice = slice(1, None, None),\n    ) -&gt; np.ndarray:\n        \"\"\"Return the cartesian sequence of a fly eye rendered sequence.\n\n        Args:\n            key: Index of the sequence.\n            vertical_splits: Number of vertical splits to apply.\n            outwidth: Output width of the sequence.\n            center_crop_fraction: Fraction of the image to keep after cropping.\n            sampling: Slice object for sampling frames.\n\n        Returns:\n            Numpy array containing the cartesian sequence.\n        \"\"\"\n        # we want to retrieve the original scene which is possibly split\n        # into multiple ones\n        key = self.original_sequence_index(key)\n        lum_path = self.meta.lum_paths[key]\n        images = np.array([\n            sample_lum(path) for path in sorted(lum_path.iterdir())[sampling]\n        ])\n        return split(\n            images,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def cartesian_flow(\n        self,\n        key: int,\n        vertical_splits: Optional[int] = None,\n        outwidth: int = 417,\n        center_crop_fraction: Optional[float] = None,\n        sampling: slice = slice(None, None, None),\n    ) -&gt; np.ndarray:\n        \"\"\"Return the cartesian flow of a fly eye rendered flow.\n\n        Args:\n            key: Index of the sequence.\n            vertical_splits: Number of vertical splits to apply.\n            outwidth: Output width of the flow.\n            center_crop_fraction: Fraction of the image to keep after cropping.\n            sampling: Slice object for sampling frames.\n\n        Returns:\n            Numpy array containing the cartesian flow.\n        \"\"\"\n        key = self.original_sequence_index(key)\n        flow_path = self.meta.flow_paths[key]\n        flow = np.array([\n            sample_flow(path) for path in sorted(flow_path.iterdir())[sampling]\n        ])\n\n        return split(\n            flow,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def cartesian_depth(\n        self,\n        key: int,\n        vertical_splits: Optional[int] = None,\n        outwidth: int = 417,\n        center_crop_fraction: Optional[float] = None,\n        sampling: slice = slice(1, None, None),\n    ) -&gt; np.ndarray:\n        \"\"\"Return the cartesian depth of a fly eye rendered depth.\n\n        Args:\n            key: Index of the sequence.\n            vertical_splits: Number of vertical splits to apply.\n            outwidth: Output width of the depth.\n            center_crop_fraction: Fraction of the image to keep after cropping.\n            sampling: Slice object for sampling frames.\n\n        Returns:\n            Numpy array containing the cartesian depth.\n        \"\"\"\n        key = self.original_sequence_index(key)\n        flow_path = self.meta.depth_paths[key]\n        depth = np.array([\n            sample_depth(path) for path in sorted(flow_path.iterdir())[sampling]\n        ])\n\n        return split(\n            depth,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def original_train_and_validation_indices(self) -&gt; Tuple[List[int], List[int]]:\n        \"\"\"Get original training and validation indices for the dataloader.\n\n        Returns:\n            Tuple containing lists of train and validation indices.\n        \"\"\"\n        return original_train_and_validation_indices(self)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.augment","title":"augment  <code>property</code> <code>writable</code>","text":"<pre><code>augment\n</code></pre> <p>Get the current augmentation state.</p>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.init_cache","title":"init_cache","text":"<pre><code>init_cache()\n</code></pre> <p>Initialize the cache with preprocessed sequences.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def init_cache(self) -&gt; None:\n    \"\"\"Initialize the cache with preprocessed sequences.\"\"\"\n    self.cached_sequences = [\n        {\n            key: torch.tensor(val, dtype=torch.float32)\n            for key, val in self.rendered(seq_id).items()\n            if key in self.data_keys\n        }\n        for seq_id in range(len(self))\n    ]\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Custom attribute setter to handle special cases and update augmentation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to set.</p> required <code>value</code> <code>Any</code> <p>Value to set the attribute to.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If trying to change framerate or rendered initialization attributes.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Custom attribute setter to handle special cases and update augmentation.\n\n    Args:\n        name: Name of the attribute to set.\n        value: Value to set the attribute to.\n\n    Raises:\n        AttributeError: If trying to change framerate or rendered initialization\n            attributes.\n    \"\"\"\n    # some changes have no effect cause they are fixed, or set by the pre-rendering\n    if name == \"framerate\":\n        raise AttributeError(\"cannot change framerate\")\n    if hasattr(self, \"rendered\") and name in self.rendered.config:\n        raise AttributeError(\"cannot change attribute of rendered initialization\")\n    super().__setattr__(name, value)\n    # also update augmentation because it may already be initialized\n    if getattr(self, \"_augmentations_are_initialized\", False):\n        self.update_augmentation(name, value)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.init_augmentation","title":"init_augmentation","text":"<pre><code>init_augmentation()\n</code></pre> <p>Initialize augmentation callables.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def init_augmentation(self) -&gt; None:\n    \"\"\"Initialize augmentation callables.\"\"\"\n    self.temporal_crop = CropFrames(\n        self.n_frames, all_frames=self.all_frames, random=self.random_temporal_crop\n    )\n    self.jitter = ContrastBrightness(\n        contrast_std=self.contrast_std, brightness_std=self.brightness_std\n    )\n    self.rotate = HexRotate(self.extent, p_rot=self.p_rot)\n    self.flip = HexFlip(self.extent, p_flip=self.p_flip, flip_axes=self.flip_axes)\n    self.noise = PixelNoise(self.gaussian_white_noise)\n\n    self.piecewise_resample = Interpolate(\n        self.original_framerate, 1 / self.dt, mode=\"nearest-exact\"\n    )\n    self.linear_interpolate = Interpolate(\n        self.original_framerate,\n        1 / self.dt,\n        mode=\"linear\",\n    )\n    self.gamma_correct = GammaCorrection(1, self.gamma_std)\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.update_augmentation","title":"update_augmentation","text":"<pre><code>update_augmentation(name, value)\n</code></pre> <p>Update augmentation parameters based on attribute changes.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute that changed.</p> required <code>value</code> <code>Any</code> <p>New value of the attribute.</p> required Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def update_augmentation(self, name: str, value: Any) -&gt; None:\n    \"\"\"Update augmentation parameters based on attribute changes.\n\n    Args:\n        name: Name of the attribute that changed.\n        value: New value of the attribute.\n    \"\"\"\n    if name == \"dt\":\n        self.piecewise_resample.target_framerate = 1 / value\n        self.linear_interpolate.target_framerate = 1 / value\n    if name in [\"all_frames\", \"random_temporal_crop\"]:\n        self.temporal_crop.all_frames = value\n        self.temporal_crop.random = value\n    if name in [\"contrast_std\", \"brightness_std\"]:\n        self.jitter.contrast_std = value\n        self.jitter.brightness_std = value\n    if name == \"p_rot\":\n        self.rotate.p_rot = value\n    if name == \"p_flip\":\n        self.flip.p_flip = value\n    if name == \"gaussian_white_noise\":\n        self.noise.std = value\n    if name == \"gamma_std\":\n        self.gamma_correct.std = value\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.set_augmentation_params","title":"set_augmentation_params","text":"<pre><code>set_augmentation_params(n_rot=None, flip_axis=None, contrast_factor=None, brightness_factor=None, gaussian_white_noise=None, gamma=None, start_frame=None, total_sequence_length=None)\n</code></pre> <p>Set augmentation callable parameters.</p> Info <p>Called for each call of get_item.</p> <p>Parameters:</p> Name Type Description Default <code>n_rot</code> <code>Optional[int]</code> <p>Number of rotations to apply.</p> <code>None</code> <code>flip_axis</code> <code>Optional[int]</code> <p>Axis to flip over.</p> <code>None</code> <code>contrast_factor</code> <code>Optional[float]</code> <p>Contrast factor for jitter augmentation.</p> <code>None</code> <code>brightness_factor</code> <code>Optional[float]</code> <p>Brightness factor for jitter augmentation.</p> <code>None</code> <code>gaussian_white_noise</code> <code>Optional[float]</code> <p>Standard deviation for noise augmentation.</p> <code>None</code> <code>gamma</code> <code>Optional[float]</code> <p>Gamma value for gamma correction.</p> <code>None</code> <code>start_frame</code> <code>Optional[int]</code> <p>Starting frame for temporal crop.</p> <code>None</code> <code>total_sequence_length</code> <code>Optional[int]</code> <p>Total length of the sequence.</p> <code>None</code> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def set_augmentation_params(\n    self,\n    n_rot: Optional[int] = None,\n    flip_axis: Optional[int] = None,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n    gaussian_white_noise: Optional[float] = None,\n    gamma: Optional[float] = None,\n    start_frame: Optional[int] = None,\n    total_sequence_length: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Set augmentation callable parameters.\n\n    Info:\n        Called for each call of get_item.\n\n    Args:\n        n_rot: Number of rotations to apply.\n        flip_axis: Axis to flip over.\n        contrast_factor: Contrast factor for jitter augmentation.\n        brightness_factor: Brightness factor for jitter augmentation.\n        gaussian_white_noise: Standard deviation for noise augmentation.\n        gamma: Gamma value for gamma correction.\n        start_frame: Starting frame for temporal crop.\n        total_sequence_length: Total length of the sequence.\n    \"\"\"\n    if not self.fix_augmentation_params:\n        self.rotate.set_or_sample(n_rot)\n        self.flip.set_or_sample(flip_axis)\n        self.jitter.set_or_sample(contrast_factor, brightness_factor)\n        self.noise.set_or_sample(gaussian_white_noise)\n        self.gamma_correct.set_or_sample(gamma)\n        self.temporal_crop.set_or_sample(\n            start=start_frame, total_sequence_length=total_sequence_length\n        )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Return a dataset sample.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sample to retrieve.</p> required <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary containing the augmented sample data.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def get_item(self, key: int) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Return a dataset sample.\n\n    Args:\n        key: Index of the sample to retrieve.\n\n    Returns:\n        Dictionary containing the augmented sample data.\n    \"\"\"\n    return self.apply_augmentation(self.cached_sequences[key])\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.augmentation","title":"augmentation","text":"<pre><code>augmentation(abool)\n</code></pre> <p>Context manager to turn augmentation on or off in a code block.</p> <p>Parameters:</p> Name Type Description Default <code>abool</code> <code>bool</code> <p>Boolean value to set augmentation state.</p> required Example <pre><code>with dataset.augmentation(True):\n    for i, data in enumerate(dataloader):\n        ...  # all data is augmented\n</code></pre> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>@contextmanager\ndef augmentation(self, abool: bool):\n    \"\"\"Context manager to turn augmentation on or off in a code block.\n\n    Args:\n        abool: Boolean value to set augmentation state.\n\n    Example:\n        ```python\n        with dataset.augmentation(True):\n            for i, data in enumerate(dataloader):\n                ...  # all data is augmented\n        ```\n    \"\"\"\n    augmentations = [\n        \"temporal_crop\",\n        \"jitter\",\n        \"rotate\",\n        \"flip\",\n        \"noise\",\n        \"piecewise_resample\",\n        \"linear_interpolate\",\n        \"gamma_correct\",\n    ]\n    states = {key: getattr(self, key).augment for key in augmentations}\n    _augment = self.augment\n    try:\n        self.augment = abool\n        yield\n    finally:\n        self.augment = _augment\n        for key in augmentations:\n            getattr(self, key).augment = states[key]\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.apply_augmentation","title":"apply_augmentation","text":"<pre><code>apply_augmentation(data, n_rot=None, flip_axis=None, contrast_factor=None, brightness_factor=None, gaussian_white_noise=None, gamma=None)\n</code></pre> <p>Apply augmentation to a sample from the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Tensor]</code> <p>Dictionary containing the sample data.</p> required <code>n_rot</code> <code>Optional[int]</code> <p>Number of rotations to apply.</p> <code>None</code> <code>flip_axis</code> <code>Optional[int]</code> <p>Axis to flip over.</p> <code>None</code> <code>contrast_factor</code> <code>Optional[float]</code> <p>Contrast factor for jitter augmentation.</p> <code>None</code> <code>brightness_factor</code> <code>Optional[float]</code> <p>Brightness factor for jitter augmentation.</p> <code>None</code> <code>gaussian_white_noise</code> <code>Optional[float]</code> <p>Standard deviation for noise augmentation.</p> <code>None</code> <code>gamma</code> <code>Optional[float]</code> <p>Gamma value for gamma correction.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary containing the augmented sample data.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def apply_augmentation(\n    self,\n    data: Dict[str, torch.Tensor],\n    n_rot: Optional[int] = None,\n    flip_axis: Optional[int] = None,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n    gaussian_white_noise: Optional[float] = None,\n    gamma: Optional[float] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Apply augmentation to a sample from the dataset.\n\n    Args:\n        data: Dictionary containing the sample data.\n        n_rot: Number of rotations to apply.\n        flip_axis: Axis to flip over.\n        contrast_factor: Contrast factor for jitter augmentation.\n        brightness_factor: Brightness factor for jitter augmentation.\n        gaussian_white_noise: Standard deviation for noise augmentation.\n        gamma: Gamma value for gamma correction.\n\n    Returns:\n        Dictionary containing the augmented sample data.\n    \"\"\"\n\n    self.set_augmentation_params(\n        n_rot=n_rot,\n        flip_axis=flip_axis,\n        contrast_factor=contrast_factor,\n        brightness_factor=brightness_factor,\n        gaussian_white_noise=gaussian_white_noise,\n        gamma=gamma,\n        start_frame=None,\n        total_sequence_length=data[\"lum\"].shape[0],\n    )\n\n    def transform_lum(lum):\n        return self.piecewise_resample(\n            self.rotate(\n                self.flip(\n                    self.jitter(\n                        self.noise(self.temporal_crop(lum)),\n                    ),\n                )\n            )\n        )\n\n    def transform_target(target):\n        if self.interpolate:\n            return self.linear_interpolate(\n                self.rotate(self.flip(self.temporal_crop(target)))\n            )\n        return self.piecewise_resample(\n            self.rotate(self.flip(self.temporal_crop(target)))\n        )\n\n    return {\n        **{\"lum\": transform_lum(data[\"lum\"])},\n        **{\n            target: transform_target(data[target])\n            for target in self.tasks\n            if target in [\"flow\", \"depth\"]\n        },\n    }\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.original_sequence_index","title":"original_sequence_index","text":"<pre><code>original_sequence_index(key)\n</code></pre> <p>Get the original sequence index from an index of the split.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the split.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Original sequence index.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is not found in splits.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def original_sequence_index(self, key: int) -&gt; int:\n    \"\"\"Get the original sequence index from an index of the split.\n\n    Args:\n        key: Index of the split.\n\n    Returns:\n        Original sequence index.\n\n    Raises:\n        ValueError: If the key is not found in splits.\n    \"\"\"\n    for index, splits in self.meta.sequence_index_to_splits.items():\n        if key in splits:\n            return index\n    raise ValueError(f\"key {key} not found in splits\")\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.cartesian_sequence","title":"cartesian_sequence","text":"<pre><code>cartesian_sequence(key, vertical_splits=None, outwidth=716, center_crop_fraction=None, sampling=slice(1, None, None))\n</code></pre> <p>Return the cartesian sequence of a fly eye rendered sequence.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sequence.</p> required <code>vertical_splits</code> <code>Optional[int]</code> <p>Number of vertical splits to apply.</p> <code>None</code> <code>outwidth</code> <code>int</code> <p>Output width of the sequence.</p> <code>716</code> <code>center_crop_fraction</code> <code>Optional[float]</code> <p>Fraction of the image to keep after cropping.</p> <code>None</code> <code>sampling</code> <code>slice</code> <p>Slice object for sampling frames.</p> <code>slice(1, None, None)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array containing the cartesian sequence.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def cartesian_sequence(\n    self,\n    key: int,\n    vertical_splits: Optional[int] = None,\n    outwidth: int = 716,\n    center_crop_fraction: Optional[float] = None,\n    sampling: slice = slice(1, None, None),\n) -&gt; np.ndarray:\n    \"\"\"Return the cartesian sequence of a fly eye rendered sequence.\n\n    Args:\n        key: Index of the sequence.\n        vertical_splits: Number of vertical splits to apply.\n        outwidth: Output width of the sequence.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        sampling: Slice object for sampling frames.\n\n    Returns:\n        Numpy array containing the cartesian sequence.\n    \"\"\"\n    # we want to retrieve the original scene which is possibly split\n    # into multiple ones\n    key = self.original_sequence_index(key)\n    lum_path = self.meta.lum_paths[key]\n    images = np.array([\n        sample_lum(path) for path in sorted(lum_path.iterdir())[sampling]\n    ])\n    return split(\n        images,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.cartesian_flow","title":"cartesian_flow","text":"<pre><code>cartesian_flow(key, vertical_splits=None, outwidth=417, center_crop_fraction=None, sampling=slice(None, None, None))\n</code></pre> <p>Return the cartesian flow of a fly eye rendered flow.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sequence.</p> required <code>vertical_splits</code> <code>Optional[int]</code> <p>Number of vertical splits to apply.</p> <code>None</code> <code>outwidth</code> <code>int</code> <p>Output width of the flow.</p> <code>417</code> <code>center_crop_fraction</code> <code>Optional[float]</code> <p>Fraction of the image to keep after cropping.</p> <code>None</code> <code>sampling</code> <code>slice</code> <p>Slice object for sampling frames.</p> <code>slice(None, None, None)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array containing the cartesian flow.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def cartesian_flow(\n    self,\n    key: int,\n    vertical_splits: Optional[int] = None,\n    outwidth: int = 417,\n    center_crop_fraction: Optional[float] = None,\n    sampling: slice = slice(None, None, None),\n) -&gt; np.ndarray:\n    \"\"\"Return the cartesian flow of a fly eye rendered flow.\n\n    Args:\n        key: Index of the sequence.\n        vertical_splits: Number of vertical splits to apply.\n        outwidth: Output width of the flow.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        sampling: Slice object for sampling frames.\n\n    Returns:\n        Numpy array containing the cartesian flow.\n    \"\"\"\n    key = self.original_sequence_index(key)\n    flow_path = self.meta.flow_paths[key]\n    flow = np.array([\n        sample_flow(path) for path in sorted(flow_path.iterdir())[sampling]\n    ])\n\n    return split(\n        flow,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.cartesian_depth","title":"cartesian_depth","text":"<pre><code>cartesian_depth(key, vertical_splits=None, outwidth=417, center_crop_fraction=None, sampling=slice(1, None, None))\n</code></pre> <p>Return the cartesian depth of a fly eye rendered depth.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sequence.</p> required <code>vertical_splits</code> <code>Optional[int]</code> <p>Number of vertical splits to apply.</p> <code>None</code> <code>outwidth</code> <code>int</code> <p>Output width of the depth.</p> <code>417</code> <code>center_crop_fraction</code> <code>Optional[float]</code> <p>Fraction of the image to keep after cropping.</p> <code>None</code> <code>sampling</code> <code>slice</code> <p>Slice object for sampling frames.</p> <code>slice(1, None, None)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array containing the cartesian depth.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def cartesian_depth(\n    self,\n    key: int,\n    vertical_splits: Optional[int] = None,\n    outwidth: int = 417,\n    center_crop_fraction: Optional[float] = None,\n    sampling: slice = slice(1, None, None),\n) -&gt; np.ndarray:\n    \"\"\"Return the cartesian depth of a fly eye rendered depth.\n\n    Args:\n        key: Index of the sequence.\n        vertical_splits: Number of vertical splits to apply.\n        outwidth: Output width of the depth.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        sampling: Slice object for sampling frames.\n\n    Returns:\n        Numpy array containing the cartesian depth.\n    \"\"\"\n    key = self.original_sequence_index(key)\n    flow_path = self.meta.depth_paths[key]\n    depth = np.array([\n        sample_depth(path) for path in sorted(flow_path.iterdir())[sampling]\n    ])\n\n    return split(\n        depth,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/datasets/#flyvis.datasets.sintel.MultiTaskSintel.original_train_and_validation_indices","title":"original_train_and_validation_indices","text":"<pre><code>original_train_and_validation_indices()\n</code></pre> <p>Get original training and validation indices for the dataloader.</p> <p>Returns:</p> Type Description <code>Tuple[List[int], List[int]]</code> <p>Tuple containing lists of train and validation indices.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def original_train_and_validation_indices(self) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"Get original training and validation indices for the dataloader.\n\n    Returns:\n        Tuple containing lists of train and validation indices.\n    \"\"\"\n    return original_train_and_validation_indices(self)\n</code></pre>"},{"location":"reference/decoder/","title":"Decoder","text":""},{"location":"reference/decoder/#flyvis.task.decoder.ActivityDecoder","title":"flyvis.task.decoder.ActivityDecoder","text":"<p>               Bases: <code>Module</code></p> <p>Base class for decoding DMN activity.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory with output_cell_types.</p> required <p>Attributes:</p> Name Type Description <code>dvs_channels</code> <code>LayerActivity</code> <p>Dictionary of DVS channels.</p> <code>num_parameters</code> <code>NumberOfParams</code> <p>Number of parameters in the model.</p> <code>u</code> <code>Tensor</code> <p>u-coordinates of hexagonal grid.</p> <code>v</code> <code>Tensor</code> <p>v-coordinates of hexagonal grid.</p> <code>H</code> <code>int</code> <p>Height of the hexagonal grid.</p> <code>W</code> <code>int</code> <p>Width of the hexagonal grid.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>class ActivityDecoder(nn.Module):\n    \"\"\"\n    Base class for decoding DMN activity.\n\n    Args:\n        connectome: Connectome directory with output_cell_types.\n\n    Attributes:\n        dvs_channels (LayerActivity): Dictionary of DVS channels.\n        num_parameters (NumberOfParams): Number of parameters in the model.\n        u (torch.Tensor): u-coordinates of hexagonal grid.\n        v (torch.Tensor): v-coordinates of hexagonal grid.\n        H (int): Height of the hexagonal grid.\n        W (int): Width of the hexagonal grid.\n    \"\"\"\n\n    dvs_channels: Union[Dict[str, torch.Tensor], LayerActivity]\n\n    def __init__(self, connectome: ConnectomeFromAvgFilters):\n        super().__init__()\n        self.dvs_channels = LayerActivity(None, connectome, use_central=False)\n        self.num_parameters = n_params(self)\n        radius = connectome.config.extent\n        self.u, self.v = get_hex_coords(radius)\n        self.u -= self.u.min()\n        self.v -= self.v.min()\n        self.H, self.W = self.u.max() + 1, self.v.max() + 1\n\n    def forward(self, activity: torch.Tensor) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"\n        Forward pass of the ActivityDecoder.\n\n        Args:\n            activity: Tensor of shape (n_samples, n_frames, n_cells).\n\n        Returns:\n            Dictionary of tensors with shape\n            (n_samples, n_frames, output_cell_types, n_hexals).\n        \"\"\"\n        self.dvs_channels.update(activity)\n        return self.dvs_channels\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.ActivityDecoder.forward","title":"forward","text":"<pre><code>forward(activity)\n</code></pre> <p>Forward pass of the ActivityDecoder.</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>Tensor</code> <p>Tensor of shape (n_samples, n_frames, n_cells).</p> required <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary of tensors with shape</p> <code>Dict[str, Tensor]</code> <p>(n_samples, n_frames, output_cell_types, n_hexals).</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>def forward(self, activity: torch.Tensor) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"\n    Forward pass of the ActivityDecoder.\n\n    Args:\n        activity: Tensor of shape (n_samples, n_frames, n_cells).\n\n    Returns:\n        Dictionary of tensors with shape\n        (n_samples, n_frames, output_cell_types, n_hexals).\n    \"\"\"\n    self.dvs_channels.update(activity)\n    return self.dvs_channels\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.DecoderGAVP","title":"flyvis.task.decoder.DecoderGAVP","text":"<p>               Bases: <code>ActivityDecoder</code></p> <p>Fully convolutional decoder with optional global average pooling.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory.</p> required <code>shape</code> <code>List[int]</code> <p>List of channel sizes for each layer.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolutional kernel.</p> required <code>p_dropout</code> <code>float</code> <p>Dropout probability.</p> <code>0.5</code> <code>batch_norm</code> <code>bool</code> <p>Whether to use batch normalization.</p> <code>True</code> <code>n_out_features</code> <code>Optional[int]</code> <p>Number of output features.</p> <code>None</code> <code>const_weight</code> <code>Optional[float]</code> <p>Constant value for weight initialization.</p> <code>None</code> <code>normalize_last</code> <code>bool</code> <p>Whether to normalize the last layer.</p> <code>True</code> <code>activation</code> <code>str</code> <p>Activation function to use.</p> <code>'Softplus'</code> <p>Attributes:</p> Name Type Description <code>_out_channels</code> <p>Number of output channels before reshaping.</p> <code>out_channels</code> <p>Total number of output channels.</p> <code>n_out_features</code> <p>Number of output features.</p> <code>base</code> <p>Base convolutional layers.</p> <code>decoder</code> <p>Decoder convolutional layers.</p> <code>head</code> <p>Head layers for global average pooling.</p> <code>normalize_last</code> <p>Whether to normalize the last layer.</p> <code>num_parameters</code> <p>Number of parameters in the model.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>class DecoderGAVP(ActivityDecoder):\n    \"\"\"\n    Fully convolutional decoder with optional global average pooling.\n\n    Args:\n        connectome: Connectome directory.\n        shape: List of channel sizes for each layer.\n        kernel_size: Size of the convolutional kernel.\n        p_dropout: Dropout probability.\n        batch_norm: Whether to use batch normalization.\n        n_out_features: Number of output features.\n        const_weight: Constant value for weight initialization.\n        normalize_last: Whether to normalize the last layer.\n        activation: Activation function to use.\n\n    Attributes:\n        _out_channels: Number of output channels before reshaping.\n        out_channels: Total number of output channels.\n        n_out_features: Number of output features.\n        base: Base convolutional layers.\n        decoder: Decoder convolutional layers.\n        head: Head layers for global average pooling.\n        normalize_last: Whether to normalize the last layer.\n        num_parameters: Number of parameters in the model.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: ConnectomeFromAvgFilters,\n        shape: List[int],\n        kernel_size: int,\n        p_dropout: float = 0.5,\n        batch_norm: bool = True,\n        n_out_features: Optional[int] = None,\n        const_weight: Optional[float] = None,\n        normalize_last: bool = True,\n        activation: str = \"Softplus\",\n    ):\n        super().__init__(connectome)\n        p = int((kernel_size - 1) / 2)\n        in_channels = len(connectome.output_cell_types)\n        out_channels = shape[-1]\n        self._out_channels = out_channels\n        self.out_channels = (\n            out_channels * n_out_features if n_out_features is not None else out_channels\n        )\n        self.n_out_features = n_out_features\n\n        self.base = []\n        for c in shape[:-1]:\n            if c == 0:\n                continue\n            self.base.append(\n                Conv2dHexSpace(\n                    in_channels,\n                    c,\n                    kernel_size,\n                    const_weight=const_weight,\n                    padding=p,\n                )\n            )\n            if batch_norm:\n                self.base.append(nn.BatchNorm2d(c))\n            self.base.append(getattr(nn, activation)())\n            if p_dropout:\n                self.base.append(nn.Dropout(p_dropout))\n            in_channels = c\n        self.base = nn.Sequential(*self.base)\n\n        self.decoder = []\n        if len(self.base) == 0 and batch_norm:\n            self.decoder.append(nn.BatchNorm2d(in_channels))\n        self.decoder.append(\n            Conv2dHexSpace(\n                in_channels,\n                self.out_channels + 1 if normalize_last else self.out_channels,\n                kernel_size,\n                const_weight=const_weight,\n                padding=p,\n            )\n        )\n        self.decoder = nn.Sequential(*self.decoder)\n\n        self.n_out_features = n_out_features\n        self.head = []\n        if n_out_features is not None:\n            self.head.append(GlobalAvgPool())\n        self.head = nn.Sequential(*self.head)\n\n        self.normalize_last = normalize_last\n\n        self.num_parameters = n_params(self)\n        logging.info(f\"Initialized decoder with {self.num_parameters} parameters.\")\n        logging.info(repr(self))\n\n    def forward(self, activity: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the DecoderGAVP.\n\n        Args:\n            activity: Input activity tensor.\n\n        Returns:\n            Decoded output tensor.\n        \"\"\"\n        self.dvs_channels.update(activity)\n        # Ensure that the outputs of the dvs-model are rectified potentials.\n        x = nnf.relu(self.dvs_channels.output)\n\n        # (n_frames, #samples, #outputneurons, n_hexals)\n        n_samples, n_frames, in_channels, n_hexals = x.shape\n\n        # Store hexals in square map.\n        # (n_frames, #samples, #outputneurons, H, W)\n        x_map = torch.zeros([n_samples, n_frames, in_channels, self.H, self.W])\n        x_map[:, :, :, self.u, self.v] = x\n\n        # Concatenate actual batch dimension with the frame dimension.\n        # torch.flatten(x_map, 0, 1)  # (#samples*n_frames, #outputneurons, H, W)\n        x_map = x_map.view(-1, in_channels, self.H, self.W)\n\n        # Run decoder.\n        # (n_frames*#samples, out_channels + 1, H, W)\n        out = self.decoder(self.base(x_map))\n\n        if self.normalize_last:\n            # Do some normalization with the additional channel.\n            # (n_frames*#samples, out_channels, H, W)\n            out = out[:, : self.out_channels] / (\n                nnf.softplus(out[:, self.out_channels :]) + 1\n            )\n\n        # Bring back into shape: # (#samples, n_frames, out_channels, n_hexals)\n        out = out.view(n_samples, n_frames, self.out_channels, self.H, self.W)[\n            :, :, :, self.u, self.v\n        ]\n\n        if self.n_out_features is not None:\n            out = self.head(out).view(\n                n_samples, n_frames, self._out_channels, self.n_out_features\n            )\n\n        return out\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.DecoderGAVP.forward","title":"forward","text":"<pre><code>forward(activity)\n</code></pre> <p>Forward pass of the DecoderGAVP.</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>Tensor</code> <p>Input activity tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Decoded output tensor.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>def forward(self, activity: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the DecoderGAVP.\n\n    Args:\n        activity: Input activity tensor.\n\n    Returns:\n        Decoded output tensor.\n    \"\"\"\n    self.dvs_channels.update(activity)\n    # Ensure that the outputs of the dvs-model are rectified potentials.\n    x = nnf.relu(self.dvs_channels.output)\n\n    # (n_frames, #samples, #outputneurons, n_hexals)\n    n_samples, n_frames, in_channels, n_hexals = x.shape\n\n    # Store hexals in square map.\n    # (n_frames, #samples, #outputneurons, H, W)\n    x_map = torch.zeros([n_samples, n_frames, in_channels, self.H, self.W])\n    x_map[:, :, :, self.u, self.v] = x\n\n    # Concatenate actual batch dimension with the frame dimension.\n    # torch.flatten(x_map, 0, 1)  # (#samples*n_frames, #outputneurons, H, W)\n    x_map = x_map.view(-1, in_channels, self.H, self.W)\n\n    # Run decoder.\n    # (n_frames*#samples, out_channels + 1, H, W)\n    out = self.decoder(self.base(x_map))\n\n    if self.normalize_last:\n        # Do some normalization with the additional channel.\n        # (n_frames*#samples, out_channels, H, W)\n        out = out[:, : self.out_channels] / (\n            nnf.softplus(out[:, self.out_channels :]) + 1\n        )\n\n    # Bring back into shape: # (#samples, n_frames, out_channels, n_hexals)\n    out = out.view(n_samples, n_frames, self.out_channels, self.H, self.W)[\n        :, :, :, self.u, self.v\n    ]\n\n    if self.n_out_features is not None:\n        out = self.head(out).view(\n            n_samples, n_frames, self._out_channels, self.n_out_features\n        )\n\n    return out\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.init_decoder","title":"flyvis.task.decoder.init_decoder","text":"<pre><code>init_decoder(decoder_config, connectome)\n</code></pre> <p>Initialize a decoder based on the provided configuration.</p> <p>Parameters:</p> Name Type Description Default <code>decoder_config</code> <code>Namespace</code> <p>Configuration for the decoder.</p> required <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory.</p> required <p>Returns:</p> Type Description <code>Module</code> <p>Initialized decoder module.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>def init_decoder(\n    decoder_config: Namespace, connectome: ConnectomeFromAvgFilters\n) -&gt; nn.Module:\n    \"\"\"\n    Initialize a decoder based on the provided configuration.\n\n    Args:\n        decoder_config: Configuration for the decoder.\n        connectome: Connectome directory.\n\n    Returns:\n        Initialized decoder module.\n    \"\"\"\n    decoder_config = decoder_config.deepcopy()\n    _type = decoder_config.pop(\"type\")\n    decoder_type = globals()[_type]\n    decoder_config.update(dict(connectome=connectome))\n    return decoder_type(**decoder_config)\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.Conv2dHexSpace","title":"flyvis.task.decoder.Conv2dHexSpace","text":"<p>               Bases: <code>Conv2dConstWeight</code></p> <p>Convolution with regularly, hexagonally shaped filters (in cartesian map storage).</p> <p>Reference to map storage: https://www.redblobgames.com/grids/hexagons/#map-storage</p> Info <p>kernel_size must be odd!</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolutional kernel.</p> required <code>const_weight</code> <code>Optional[float]</code> <p>Optional constant value for weight initialization. If None, the standard PyTorch initialization is used.</p> <code>0.001</code> <code>stride</code> <code>int</code> <p>Stride of the convolution.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding added to input.</p> <code>0</code> <code>**kwargs</code> <p>Additional keyword arguments for Conv2d.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>mask</code> <p>Mask for hexagonal convolution.</p> <code>_filter_to_hex</code> <p>Whether to apply hexagonal filter.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>class Conv2dHexSpace(Conv2dConstWeight):\n    \"\"\"\n    Convolution with regularly, hexagonally shaped filters (in cartesian map storage).\n\n    Reference to map storage:\n    https://www.redblobgames.com/grids/hexagons/#map-storage\n\n    Info:\n        kernel_size must be odd!\n\n    Args:\n        in_channels: Number of input channels.\n        out_channels: Number of output channels.\n        kernel_size: Size of the convolutional kernel.\n        const_weight: Optional constant value for weight initialization.\n            If None, the standard PyTorch initialization is used.\n        stride: Stride of the convolution.\n        padding: Padding added to input.\n        **kwargs: Additional keyword arguments for Conv2d.\n\n    Attributes:\n        mask: Mask for hexagonal convolution.\n        _filter_to_hex: Whether to apply hexagonal filter.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int,\n        const_weight: Optional[float] = 1e-3,\n        stride: int = 1,\n        padding: int = 0,\n        **kwargs,\n    ):\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            const_weight,\n            stride=stride,\n            padding=padding,\n            **kwargs,\n        )\n\n        if not kernel_size % 2:\n            raise ValueError(f\"{kernel_size} is even. Must be odd.\")\n        if kernel_size &gt; 1:\n            u, v = get_hex_coords(kernel_size // 2)\n            u -= u.min()\n            v -= v.min()\n            mask = np.zeros(tuple(self.weight.shape))\n            mask[:, :, u, v] = 1\n            self.mask = torch.tensor(mask, device=\"cpu\")\n            self.weight.data.mul_(self.mask.to(device))\n            self._filter_to_hex = True\n        else:\n            self._filter_to_hex = False\n\n    def filter_to_hex(self):\n        \"\"\"Apply hexagonal filter to weights.\"\"\"\n        self.weight.data.mul_(self.mask.to(device))\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass of the Conv2dHexSpace layer.\n\n        Args:\n            x: Input tensor.\n\n        Returns:\n            Output tensor after hexagonal convolution.\n        \"\"\"\n        if self._filter_to_hex:\n            self.filter_to_hex()\n        return super().forward(x)\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.Conv2dHexSpace.filter_to_hex","title":"filter_to_hex","text":"<pre><code>filter_to_hex()\n</code></pre> <p>Apply hexagonal filter to weights.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>def filter_to_hex(self):\n    \"\"\"Apply hexagonal filter to weights.\"\"\"\n    self.weight.data.mul_(self.mask.to(device))\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.Conv2dHexSpace.forward","title":"forward","text":"<pre><code>forward(x)\n</code></pre> <p>Forward pass of the Conv2dHexSpace layer.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor after hexagonal convolution.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass of the Conv2dHexSpace layer.\n\n    Args:\n        x: Input tensor.\n\n    Returns:\n        Output tensor after hexagonal convolution.\n    \"\"\"\n    if self._filter_to_hex:\n        self.filter_to_hex()\n    return super().forward(x)\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.Conv2dConstWeight","title":"flyvis.task.decoder.Conv2dConstWeight","text":"<p>               Bases: <code>Conv2d</code></p> <p>PyTorch\u2019s Conv2d layer with optional constant weight initialization.</p> <p>Parameters:</p> Name Type Description Default <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the convolutional kernel.</p> required <code>const_weight</code> <code>Optional[float]</code> <p>Optional constant value for weight initialization. If None, the standard PyTorch initialization is used.</p> <code>None</code> <code>stride</code> <code>int</code> <p>Stride of the convolution.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding added to input.</p> <code>0</code> <code>**kwargs</code> <p>Additional keyword arguments for Conv2d.</p> <code>{}</code> Source code in <code>flyvis/task/decoder.py</code> <pre><code>class Conv2dConstWeight(nn.Conv2d):\n    \"\"\"\n    PyTorch's Conv2d layer with optional constant weight initialization.\n\n    Args:\n        in_channels: Number of input channels.\n        out_channels: Number of output channels.\n        kernel_size: Size of the convolutional kernel.\n        const_weight: Optional constant value for weight initialization.\n            If None, the standard PyTorch initialization is used.\n        stride: Stride of the convolution.\n        padding: Padding added to input.\n        **kwargs: Additional keyword arguments for Conv2d.\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels: int,\n        out_channels: int,\n        kernel_size: int,\n        const_weight: Optional[float] = None,\n        stride: int = 1,\n        padding: int = 0,\n        **kwargs,\n    ):\n        super().__init__(\n            in_channels,\n            out_channels,\n            kernel_size,\n            stride=stride,\n            padding=padding,\n            **kwargs,\n        )\n        if const_weight is not None and self.weight is not None:\n            self.weight.data.fill_(const_weight)\n        if const_weight is not None and self.bias is not None:\n            self.bias.data.fill_(const_weight)\n</code></pre>"},{"location":"reference/decoder/#flyvis.task.decoder.GlobalAvgPool","title":"flyvis.task.decoder.GlobalAvgPool","text":"<p>               Bases: <code>Module</code></p> <p>Returns the average over the last dimension.</p> Source code in <code>flyvis/task/decoder.py</code> <pre><code>class GlobalAvgPool(nn.Module):\n    \"\"\"Returns the average over the last dimension.\"\"\"\n\n    def forward(self, x):\n        return x.mean(dim=-1)\n</code></pre>"},{"location":"reference/ensemble_clustering/","title":"Ensemble Clustering","text":""},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.compute_umap_and_clustering","title":"flyvis.analysis.clustering.compute_umap_and_clustering","text":"<pre><code>compute_umap_and_clustering(ensemble, cell_type, embedding_kwargs=None, gm_kwargs=None, subdir='umap_and_clustering')\n</code></pre> <p>Compute UMAP embedding and Gaussian Mixture clustering of responses.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <code>EnsembleView</code> <p>EnsembleView object.</p> required <code>cell_type</code> <code>str</code> <p>Type of cell to analyze.</p> required <code>embedding_kwargs</code> <code>Optional[Dict]</code> <p>UMAP embedding parameters.</p> <code>None</code> <code>gm_kwargs</code> <code>Optional[Dict]</code> <p>Gaussian Mixture clustering parameters.</p> <code>None</code> <code>subdir</code> <code>str</code> <p>Subdirectory for storing results.</p> <code>'umap_and_clustering'</code> <p>Returns:</p> Type Description <code>GaussianMixtureClustering</code> <p>GaussianMixtureClustering object.</p> Note <p>Results are cached to disk for faster subsequent access.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def compute_umap_and_clustering(\n    ensemble: \"flyvis.network.EnsembleView\",\n    cell_type: str,\n    embedding_kwargs: Optional[Dict] = None,\n    gm_kwargs: Optional[Dict] = None,\n    subdir: str = \"umap_and_clustering\",\n) -&gt; GaussianMixtureClustering:\n    \"\"\"\n    Compute UMAP embedding and Gaussian Mixture clustering of responses.\n\n    Args:\n        ensemble: EnsembleView object.\n        cell_type: Type of cell to analyze.\n        embedding_kwargs: UMAP embedding parameters.\n        gm_kwargs: Gaussian Mixture clustering parameters.\n        subdir: Subdirectory for storing results.\n\n    Returns:\n        GaussianMixtureClustering object.\n\n    Note:\n        Results are cached to disk for faster subsequent access.\n    \"\"\"\n    if embedding_kwargs is None:\n        embedding_kwargs = {\n            \"min_dist\": 0.105,\n            \"spread\": 9.0,\n            \"n_neighbors\": 5,\n            \"random_state\": 42,\n            \"n_epochs\": 1500,\n        }\n    if gm_kwargs is None:\n        gm_kwargs = {\n            \"range_n_clusters\": [2, 3, 3, 4, 5],\n            \"n_init\": 100,\n            \"max_iter\": 1000,\n            \"random_state\": 42,\n            \"tol\": 0.001,\n        }\n\n    destination = ensemble.path / subdir\n\n    def load_from_disk():\n        with open((destination / cell_type).with_suffix(\".pickle\"), \"rb\") as f:\n            embedding_and_clustering = pickle.load(f)\n\n        logging.info(\"Loaded %s embedding and clustering from %s\", cell_type, destination)\n        return embedding_and_clustering\n\n    if (destination / cell_type).with_suffix(\".pickle\").exists():\n        return load_from_disk()\n\n    def create_embedding_object(responses):\n        central_responses = CentralActivity(\n            responses['responses'].values, ensemble[0].connectome, keepref=True\n        )\n        embeddings = EnsembleEmbedding(central_responses)\n        return embeddings\n\n    responses = naturalistic_stimuli_responses(ensemble)\n    embeddings = create_embedding_object(responses)\n\n    embedding = embeddings.from_cell_type(cell_type, embedding_kwargs=embedding_kwargs)\n    embedding_and_clustering = embedding.cluster.gaussian_mixture(**gm_kwargs)\n    return embedding_and_clustering\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.umap_embedding","title":"flyvis.analysis.clustering.umap_embedding","text":"<pre><code>umap_embedding(X, n_neighbors=5, min_dist=0.12, spread=9.0, random_state=42, n_components=2, metric='correlation', n_epochs=1500, **kwargs)\n</code></pre> <p>Perform UMAP embedding on input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Input data with shape (n_samples, n_features).</p> required <code>n_neighbors</code> <code>int</code> <p>Number of neighbors to consider for each point.</p> <code>5</code> <code>min_dist</code> <code>float</code> <p>Minimum distance between points in the embedding space.</p> <code>0.12</code> <code>spread</code> <code>float</code> <p>Determines how spread out all embedded points are overall.</p> <code>9.0</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>n_components</code> <code>int</code> <p>Number of dimensions in the embedding space.</p> <code>2</code> <code>metric</code> <code>str</code> <p>Distance metric to use.</p> <code>'correlation'</code> <code>n_epochs</code> <code>int</code> <p>Number of training epochs for embedding optimization.</p> <code>1500</code> <code>**kwargs</code> <p>Additional keyword arguments for UMAP.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A tuple containing:</p> <code>ndarray</code> <ul> <li>embedding: The UMAP embedding.</li> </ul> <code>UMAP</code> <ul> <li>mask: Boolean mask for valid samples.</li> </ul> <code>Tuple[ndarray, ndarray, UMAP]</code> <ul> <li>reducer: The fitted UMAP object.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_components is too large relative to sample size.</p> Note <p>This function handles reshaping of input data and removes constant rows.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def umap_embedding(\n    X: np.ndarray,\n    n_neighbors: int = 5,\n    min_dist: float = 0.12,\n    spread: float = 9.0,\n    random_state: int = 42,\n    n_components: int = 2,\n    metric: str = \"correlation\",\n    n_epochs: int = 1500,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, np.ndarray, UMAP]:\n    \"\"\"\n    Perform UMAP embedding on input data.\n\n    Args:\n        X: Input data with shape (n_samples, n_features).\n        n_neighbors: Number of neighbors to consider for each point.\n        min_dist: Minimum distance between points in the embedding space.\n        spread: Determines how spread out all embedded points are overall.\n        random_state: Random seed for reproducibility.\n        n_components: Number of dimensions in the embedding space.\n        metric: Distance metric to use.\n        n_epochs: Number of training epochs for embedding optimization.\n        **kwargs: Additional keyword arguments for UMAP.\n\n    Returns:\n        A tuple containing:\n        - embedding: The UMAP embedding.\n        - mask: Boolean mask for valid samples.\n        - reducer: The fitted UMAP object.\n\n    Raises:\n        ValueError: If n_components is too large relative to sample size.\n\n    Note:\n        This function handles reshaping of input data and removes constant rows.\n    \"\"\"\n    # umap import would slow down whole library import\n    from umap import UMAP\n    from umap.utils import disconnected_vertices\n\n    if n_components &gt; X.shape[0] - 2:\n        raise ValueError(\n            \"number of components must be 2 smaller than sample size. \"\n            \"See: https://github.com/lmcinnes/umap/issues/201\"\n        )\n\n    if len(X.shape) &gt; 2:\n        shape = X.shape\n        X = X.reshape(X.shape[0], -1)\n        logging.info(\"reshaped X from %s to %s\", shape, X.shape)\n\n    embedding = np.ones([X.shape[0], n_components]) * np.nan\n    # umap doesn't like contant rows\n    mask = ~np.isclose(X.std(axis=1), 0)\n    X = X[mask]\n    reducer = UMAP(\n        n_neighbors=n_neighbors,\n        min_dist=min_dist,\n        random_state=random_state,\n        n_components=n_components,\n        metric=metric,\n        spread=spread,\n        n_epochs=n_epochs,\n        **kwargs,\n    )\n    _embedding = reducer.fit_transform(X)\n\n    # gaussian mixture doesn't like nans through disconnected vertices in umap\n    connected_vertices_mask = ~disconnected_vertices(reducer)\n    mask[mask] = mask[mask] &amp; connected_vertices_mask\n    embedding[mask] = _embedding[connected_vertices_mask]\n    return embedding, mask, reducer\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.GaussianMixtureClustering","title":"flyvis.analysis.clustering.GaussianMixtureClustering  <code>dataclass</code>","text":"<p>Gaussian Mixture Clustering of the embeddings.</p> <p>Attributes:</p> Name Type Description <code>embedding</code> <code>Embedding</code> <p>The embedding to cluster.</p> <code>range_n_clusters</code> <code>Iterable[int]</code> <p>Range of number of clusters to try.</p> <code>n_init</code> <code>int</code> <p>Number of initializations for GMM.</p> <code>max_iter</code> <code>int</code> <p>Maximum number of iterations for GMM.</p> <code>random_state</code> <code>int</code> <p>Random state for reproducibility.</p> <code>labels</code> <code>NDArray</code> <p>Cluster labels.</p> <code>gm</code> <code>object</code> <p>Fitted GaussianMixture object.</p> <code>scores</code> <code>list</code> <p>Scores for each number of clusters.</p> <code>n_clusters</code> <code>list</code> <p>Number of clusters tried.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>@dataclass\nclass GaussianMixtureClustering:\n    \"\"\"\n    Gaussian Mixture Clustering of the embeddings.\n\n    Attributes:\n        embedding (Embedding): The embedding to cluster.\n        range_n_clusters (Iterable[int]): Range of number of clusters to try.\n        n_init (int): Number of initializations for GMM.\n        max_iter (int): Maximum number of iterations for GMM.\n        random_state (int): Random state for reproducibility.\n        labels (npt.NDArray): Cluster labels.\n        gm (object): Fitted GaussianMixture object.\n        scores (list): Scores for each number of clusters.\n        n_clusters (list): Number of clusters tried.\n    \"\"\"\n\n    embedding: Embedding = None\n    range_n_clusters: Iterable[int] = None\n    n_init: int = 1\n    max_iter: int = 1000\n    random_state: int = 0\n    labels: npt.NDArray = None\n    gm: object = None\n    scores: list = None\n    n_clusters: list = None\n\n    def __call__(\n        self,\n        range_n_clusters: Iterable[int] = None,\n        n_init: int = 1,\n        max_iter: int = 1000,\n        random_state: int = 0,\n        **kwargs,\n    ) -&gt; \"GaussianMixtureClustering\":\n        \"\"\"\n        Perform Gaussian Mixture clustering.\n\n        Args:\n            range_n_clusters: Range of number of clusters to try.\n            n_init: Number of initializations for GMM.\n            max_iter: Maximum number of iterations for GMM.\n            random_state: Random state for reproducibility.\n            **kwargs: Additional arguments for gaussian_mixture function.\n\n        Returns:\n            Self with updated clustering results.\n        \"\"\"\n        self.labels, self.gm, self.scores, self.n_clusters = gaussian_mixture(\n            self.embedding.embedding,\n            self.embedding.mask,\n            range_n_clusters=range_n_clusters,\n            n_init=n_init,\n            max_iter=max_iter,\n            random_state=random_state,\n            **kwargs,\n        )\n        self.range_n_clusters = range_n_clusters\n        self.n_init = n_init\n        self.max_iter = max_iter\n        self.random_state = random_state\n        self.kwargs = kwargs\n        return self\n\n    def task_error_sort_labels(self, task_error: npt.NDArray, mode: str = \"mean\") -&gt; None:\n        \"\"\"\n        Sort cluster labels based on task error.\n\n        Args:\n            task_error: Array of task errors.\n            mode: Method to compute task error ('mean', 'min', or 'median').\n        \"\"\"\n        self.labels = task_error_sort_labels(task_error, self.labels, mode=mode)\n\n    def plot(\n        self,\n        task_error: npt.NDArray = None,\n        colors: npt.NDArray = None,\n        annotate: bool = True,\n        annotate_scores: bool = False,\n        fig: Figure = None,\n        ax: Axes = None,\n        figsize: tuple = None,\n        plot_mode: str = \"paper\",\n        fontsize: int = 5,\n        **kwargs,\n    ) -&gt; \"EmbeddingPlot\":\n        \"\"\"\n        Plot the clustering results.\n\n        Args:\n            task_error: Array of task errors.\n            colors: Colors for data points.\n            annotate: Whether to annotate clusters.\n            annotate_scores: Whether to annotate BIC scores.\n            fig: Existing figure to plot on.\n            ax: Existing axes to plot on.\n            figsize: Size of the figure.\n            plot_mode: Mode for plotting ('paper', 'small', or 'large').\n            fontsize: Font size for annotations.\n            **kwargs: Additional arguments for plot_embedding function.\n\n        Returns:\n            An EmbeddingPlot object.\n\n        Raises:\n            AssertionError: If the embedding is not 2-dimensional.\n        \"\"\"\n        if self.embedding.embedding.shape[1] != 2:\n            raise AssertionError(\"Embedding must be 2-dimensional for plotting\")\n        if figsize is None:\n            figsize = [0.94, 2.38]\n        fig, ax = plot_embedding(\n            self.embedding.embedding,\n            colors=colors,\n            task_error=task_error,\n            labels=self.labels,\n            gm=self.gm,\n            mask=self.embedding.mask,\n            fit_gaussians=True,\n            annotate=annotate,\n            title=\"\",\n            fig=fig,\n            ax=ax,\n            mode=plot_mode,\n            figsize=figsize,\n            fontsize=fontsize,\n            range_n_clusters=self.range_n_clusters,\n            n_init_gaussian_mixture=self.n_init,\n            gm_kwargs=self.kwargs,\n            **kwargs,\n        )\n        if annotate_scores:\n            ax.annotate(\n                \"BIC: {:.2f}\".format(np.min(self.scores)),\n                xy=(ax.get_xlim()[0], ax.get_ylim()[1]),\n                ha=\"left\",\n                va=\"top\",\n                fontsize=fontsize,\n            )\n        return EmbeddingPlot(fig, ax, None, None, self.gm.n_components, self)\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.GaussianMixtureClustering.__call__","title":"__call__","text":"<pre><code>__call__(range_n_clusters=None, n_init=1, max_iter=1000, random_state=0, **kwargs)\n</code></pre> <p>Perform Gaussian Mixture clustering.</p> <p>Parameters:</p> Name Type Description Default <code>range_n_clusters</code> <code>Iterable[int]</code> <p>Range of number of clusters to try.</p> <code>None</code> <code>n_init</code> <code>int</code> <p>Number of initializations for GMM.</p> <code>1</code> <code>max_iter</code> <code>int</code> <p>Maximum number of iterations for GMM.</p> <code>1000</code> <code>random_state</code> <code>int</code> <p>Random state for reproducibility.</p> <code>0</code> <code>**kwargs</code> <p>Additional arguments for gaussian_mixture function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GaussianMixtureClustering</code> <p>Self with updated clustering results.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def __call__(\n    self,\n    range_n_clusters: Iterable[int] = None,\n    n_init: int = 1,\n    max_iter: int = 1000,\n    random_state: int = 0,\n    **kwargs,\n) -&gt; \"GaussianMixtureClustering\":\n    \"\"\"\n    Perform Gaussian Mixture clustering.\n\n    Args:\n        range_n_clusters: Range of number of clusters to try.\n        n_init: Number of initializations for GMM.\n        max_iter: Maximum number of iterations for GMM.\n        random_state: Random state for reproducibility.\n        **kwargs: Additional arguments for gaussian_mixture function.\n\n    Returns:\n        Self with updated clustering results.\n    \"\"\"\n    self.labels, self.gm, self.scores, self.n_clusters = gaussian_mixture(\n        self.embedding.embedding,\n        self.embedding.mask,\n        range_n_clusters=range_n_clusters,\n        n_init=n_init,\n        max_iter=max_iter,\n        random_state=random_state,\n        **kwargs,\n    )\n    self.range_n_clusters = range_n_clusters\n    self.n_init = n_init\n    self.max_iter = max_iter\n    self.random_state = random_state\n    self.kwargs = kwargs\n    return self\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.GaussianMixtureClustering.task_error_sort_labels","title":"task_error_sort_labels","text":"<pre><code>task_error_sort_labels(task_error, mode='mean')\n</code></pre> <p>Sort cluster labels based on task error.</p> <p>Parameters:</p> Name Type Description Default <code>task_error</code> <code>NDArray</code> <p>Array of task errors.</p> required <code>mode</code> <code>str</code> <p>Method to compute task error (\u2018mean\u2019, \u2018min\u2019, or \u2018median\u2019).</p> <code>'mean'</code> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def task_error_sort_labels(self, task_error: npt.NDArray, mode: str = \"mean\") -&gt; None:\n    \"\"\"\n    Sort cluster labels based on task error.\n\n    Args:\n        task_error: Array of task errors.\n        mode: Method to compute task error ('mean', 'min', or 'median').\n    \"\"\"\n    self.labels = task_error_sort_labels(task_error, self.labels, mode=mode)\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.GaussianMixtureClustering.plot","title":"plot","text":"<pre><code>plot(task_error=None, colors=None, annotate=True, annotate_scores=False, fig=None, ax=None, figsize=None, plot_mode='paper', fontsize=5, **kwargs)\n</code></pre> <p>Plot the clustering results.</p> <p>Parameters:</p> Name Type Description Default <code>task_error</code> <code>NDArray</code> <p>Array of task errors.</p> <code>None</code> <code>colors</code> <code>NDArray</code> <p>Colors for data points.</p> <code>None</code> <code>annotate</code> <code>bool</code> <p>Whether to annotate clusters.</p> <code>True</code> <code>annotate_scores</code> <code>bool</code> <p>Whether to annotate BIC scores.</p> <code>False</code> <code>fig</code> <code>Figure</code> <p>Existing figure to plot on.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Size of the figure.</p> <code>None</code> <code>plot_mode</code> <code>str</code> <p>Mode for plotting (\u2018paper\u2019, \u2018small\u2019, or \u2018large\u2019).</p> <code>'paper'</code> <code>fontsize</code> <code>int</code> <p>Font size for annotations.</p> <code>5</code> <code>**kwargs</code> <p>Additional arguments for plot_embedding function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>EmbeddingPlot</code> <p>An EmbeddingPlot object.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the embedding is not 2-dimensional.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def plot(\n    self,\n    task_error: npt.NDArray = None,\n    colors: npt.NDArray = None,\n    annotate: bool = True,\n    annotate_scores: bool = False,\n    fig: Figure = None,\n    ax: Axes = None,\n    figsize: tuple = None,\n    plot_mode: str = \"paper\",\n    fontsize: int = 5,\n    **kwargs,\n) -&gt; \"EmbeddingPlot\":\n    \"\"\"\n    Plot the clustering results.\n\n    Args:\n        task_error: Array of task errors.\n        colors: Colors for data points.\n        annotate: Whether to annotate clusters.\n        annotate_scores: Whether to annotate BIC scores.\n        fig: Existing figure to plot on.\n        ax: Existing axes to plot on.\n        figsize: Size of the figure.\n        plot_mode: Mode for plotting ('paper', 'small', or 'large').\n        fontsize: Font size for annotations.\n        **kwargs: Additional arguments for plot_embedding function.\n\n    Returns:\n        An EmbeddingPlot object.\n\n    Raises:\n        AssertionError: If the embedding is not 2-dimensional.\n    \"\"\"\n    if self.embedding.embedding.shape[1] != 2:\n        raise AssertionError(\"Embedding must be 2-dimensional for plotting\")\n    if figsize is None:\n        figsize = [0.94, 2.38]\n    fig, ax = plot_embedding(\n        self.embedding.embedding,\n        colors=colors,\n        task_error=task_error,\n        labels=self.labels,\n        gm=self.gm,\n        mask=self.embedding.mask,\n        fit_gaussians=True,\n        annotate=annotate,\n        title=\"\",\n        fig=fig,\n        ax=ax,\n        mode=plot_mode,\n        figsize=figsize,\n        fontsize=fontsize,\n        range_n_clusters=self.range_n_clusters,\n        n_init_gaussian_mixture=self.n_init,\n        gm_kwargs=self.kwargs,\n        **kwargs,\n    )\n    if annotate_scores:\n        ax.annotate(\n            \"BIC: {:.2f}\".format(np.min(self.scores)),\n            xy=(ax.get_xlim()[0], ax.get_ylim()[1]),\n            ha=\"left\",\n            va=\"top\",\n            fontsize=fontsize,\n        )\n    return EmbeddingPlot(fig, ax, None, None, self.gm.n_components, self)\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.EnsembleEmbedding","title":"flyvis.analysis.clustering.EnsembleEmbedding","text":"<p>Embedding of the ensemble responses.</p> <p>Args: responses (CentralActivity): CentralActivity object</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>class EnsembleEmbedding:\n    \"\"\"Embedding of the ensemble responses.\n\n    Args: responses (CentralActivity): CentralActivity object\n    \"\"\"\n\n    def __init__(self, responses: CentralActivity):\n        self.responses = responses\n\n    def from_cell_type(\n        self,\n        cell_type,\n        embedding_kwargs=None,\n    ) -&gt; Embedding:\n        \"\"\"Umap Embedding of the responses of a specific cell type.\"\"\"\n\n        embedding_kwargs = embedding_kwargs or {}\n        return Embedding(*umap_embedding(self.responses[cell_type], **embedding_kwargs))\n\n    def __call__(\n        self,\n        arg: Union[str, Iterable],\n        embedding_kwargs=None,\n    ):\n        if isinstance(arg, str):\n            return self.from_cell_type(arg, embedding_kwargs)\n        else:\n            raise ValueError(\"arg\")\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.EnsembleEmbedding.from_cell_type","title":"from_cell_type","text":"<pre><code>from_cell_type(cell_type, embedding_kwargs=None)\n</code></pre> <p>Umap Embedding of the responses of a specific cell type.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def from_cell_type(\n    self,\n    cell_type,\n    embedding_kwargs=None,\n) -&gt; Embedding:\n    \"\"\"Umap Embedding of the responses of a specific cell type.\"\"\"\n\n    embedding_kwargs = embedding_kwargs or {}\n    return Embedding(*umap_embedding(self.responses[cell_type], **embedding_kwargs))\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.Embedding","title":"flyvis.analysis.clustering.Embedding  <code>dataclass</code>","text":"<p>Embedding of the ensemble responses.</p> <p>Attributes:</p> Name Type Description <code>embedding</code> <code>NDArray</code> <p>The embedded data.</p> <code>mask</code> <code>NDArray</code> <p>Mask for valid data points.</p> <code>reducer</code> <code>object</code> <p>The reduction object used for embedding.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>@dataclass\nclass Embedding:\n    \"\"\"\n    Embedding of the ensemble responses.\n\n    Attributes:\n        embedding (npt.NDArray): The embedded data.\n        mask (npt.NDArray): Mask for valid data points.\n        reducer (object): The reduction object used for embedding.\n    \"\"\"\n\n    embedding: npt.NDArray = None\n    mask: npt.NDArray = None\n    reducer: object = None\n\n    @property\n    def cluster(self) -&gt; \"Clustering\":\n        \"\"\"Returns a Clustering object for this embedding.\"\"\"\n        return Clustering(self)\n\n    @property\n    def embedding(self) -&gt; npt.NDArray:  # noqa: F811\n        \"\"\"Returns the embedded data.\"\"\"\n        return getattr(self, \"_embedding\", None)\n\n    @embedding.setter\n    def embedding(self, value: npt.NDArray) -&gt; None:\n        \"\"\"\n        Sets the embedding and scales it to range (0, 1).\n\n        Args:\n            value: The embedding array to set.\n        \"\"\"\n        self._embedding, self.minmaxscaler = scale_tensor(value)\n\n    def plot(\n        self,\n        fig: Figure = None,\n        ax: Axes = None,\n        figsize: tuple = None,\n        plot_mode: str = \"paper\",\n        fontsize: int = 5,\n        colors: npt.NDArray = None,\n        **kwargs,\n    ) -&gt; tuple[Figure, Axes]:\n        \"\"\"\n        Plot the embedding.\n\n        Args:\n            fig: Existing figure to plot on.\n            ax: Existing axes to plot on.\n            figsize: Size of the figure.\n            plot_mode: Mode for plotting ('paper', 'small', or 'large').\n            fontsize: Font size for annotations.\n            colors: Colors for data points.\n            **kwargs: Additional arguments passed to plot_embedding.\n\n        Returns:\n            A tuple containing the figure and axes objects.\n\n        Raises:\n            AssertionError: If the embedding is not 2-dimensional.\n        \"\"\"\n        if self.embedding.shape[1] != 2:\n            raise AssertionError(\"Embedding must be 2-dimensional for plotting\")\n        if figsize is None:\n            figsize = [0.94, 2.38]\n        return plot_embedding(\n            self.embedding,\n            colors=colors,\n            task_error=None,\n            labels=None,\n            mask=self.mask,\n            fit_gaussians=False,\n            annotate=False,\n            title=\"\",\n            fig=fig,\n            ax=ax,\n            mode=plot_mode,\n            figsize=figsize,\n            fontsize=fontsize,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.Embedding.cluster","title":"cluster  <code>property</code>","text":"<pre><code>cluster\n</code></pre> <p>Returns a Clustering object for this embedding.</p>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.Embedding.embedding","title":"embedding  <code>property</code> <code>writable</code>","text":"<pre><code>embedding\n</code></pre> <p>Returns the embedded data.</p>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.Embedding.plot","title":"plot","text":"<pre><code>plot(fig=None, ax=None, figsize=None, plot_mode='paper', fontsize=5, colors=None, **kwargs)\n</code></pre> <p>Plot the embedding.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Existing figure to plot on.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes to plot on.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Size of the figure.</p> <code>None</code> <code>plot_mode</code> <code>str</code> <p>Mode for plotting (\u2018paper\u2019, \u2018small\u2019, or \u2018large\u2019).</p> <code>'paper'</code> <code>fontsize</code> <code>int</code> <p>Font size for annotations.</p> <code>5</code> <code>colors</code> <code>NDArray</code> <p>Colors for data points.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to plot_embedding.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Figure, Axes]</code> <p>A tuple containing the figure and axes objects.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the embedding is not 2-dimensional.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>def plot(\n    self,\n    fig: Figure = None,\n    ax: Axes = None,\n    figsize: tuple = None,\n    plot_mode: str = \"paper\",\n    fontsize: int = 5,\n    colors: npt.NDArray = None,\n    **kwargs,\n) -&gt; tuple[Figure, Axes]:\n    \"\"\"\n    Plot the embedding.\n\n    Args:\n        fig: Existing figure to plot on.\n        ax: Existing axes to plot on.\n        figsize: Size of the figure.\n        plot_mode: Mode for plotting ('paper', 'small', or 'large').\n        fontsize: Font size for annotations.\n        colors: Colors for data points.\n        **kwargs: Additional arguments passed to plot_embedding.\n\n    Returns:\n        A tuple containing the figure and axes objects.\n\n    Raises:\n        AssertionError: If the embedding is not 2-dimensional.\n    \"\"\"\n    if self.embedding.shape[1] != 2:\n        raise AssertionError(\"Embedding must be 2-dimensional for plotting\")\n    if figsize is None:\n        figsize = [0.94, 2.38]\n    return plot_embedding(\n        self.embedding,\n        colors=colors,\n        task_error=None,\n        labels=None,\n        mask=self.mask,\n        fit_gaussians=False,\n        annotate=False,\n        title=\"\",\n        fig=fig,\n        ax=ax,\n        mode=plot_mode,\n        figsize=figsize,\n        fontsize=fontsize,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.Clustering","title":"flyvis.analysis.clustering.Clustering  <code>dataclass</code>","text":"<p>Clustering of the embedding.</p> <p>Attributes:</p> Name Type Description <code>embedding</code> <code>Embedding</code> <p>The embedding to be clustered.</p> Source code in <code>flyvis/analysis/clustering.py</code> <pre><code>@dataclass\nclass Clustering:\n    \"\"\"Clustering of the embedding.\n\n    Attributes:\n        embedding (Embedding): The embedding to be clustered.\n    \"\"\"\n\n    embedding: Embedding = None\n\n    @property\n    def gaussian_mixture(self) -&gt; GaussianMixtureClustering:\n        \"\"\"Create a GaussianMixtureClustering object for the embedding.\n\n        Returns:\n            GaussianMixtureClustering: A clustering object for Gaussian mixture models.\n        \"\"\"\n        return GaussianMixtureClustering(self.embedding)\n</code></pre>"},{"location":"reference/ensemble_clustering/#flyvis.analysis.clustering.Clustering.gaussian_mixture","title":"gaussian_mixture  <code>property</code>","text":"<pre><code>gaussian_mixture\n</code></pre> <p>Create a GaussianMixtureClustering object for the embedding.</p> <p>Returns:</p> Name Type Description <code>GaussianMixtureClustering</code> <code>GaussianMixtureClustering</code> <p>A clustering object for Gaussian mixture models.</p>"},{"location":"reference/ensemble_view/","title":"EnsembleView","text":""},{"location":"reference/ensemble_view/#flyvis.network.directories.EnsembleDir","title":"flyvis.network.directories.EnsembleDir","text":"<p>               Bases: <code>Directory</code></p> <p>Contains many NetworkDirs.</p> Source code in <code>flyvis/network/directories.py</code> <pre><code>@root(flyvis.results_dir)\nclass EnsembleDir(Directory):\n    \"\"\"Contains many NetworkDirs.\"\"\"\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView","title":"flyvis.network.EnsembleView","text":"<p>               Bases: <code>Ensemble</code></p> <p>A view of an ensemble of trained networks.</p> <p>This class extends the Ensemble class with visualization and analysis methods.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path, Iterable, EnsembleDir, Ensemble]</code> <p>Path to the ensemble directory or an existing Ensemble object.</p> required <code>network_class</code> <code>Module</code> <p>The network class to use for instantiation.</p> <code>Network</code> <code>root_dir</code> <code>Path</code> <p>Root directory for results.</p> <code>results_dir</code> <code>connectome_getter</code> <code>Callable</code> <p>Function to get the connectome.</p> <code>get_avgfilt_connectome</code> <code>checkpoint_mapper</code> <code>Callable</code> <p>Function to resolve checkpoints.</p> <code>resolve_checkpoints</code> <code>best_checkpoint_fn</code> <code>Callable</code> <p>Function to select the best checkpoint.</p> <code>best_checkpoint_default_fn</code> <code>best_checkpoint_fn_kwargs</code> <code>dict</code> <p>Keyword arguments for best_checkpoint_fn.</p> <code>{'validation_subdir': 'validation', 'loss_file_name': 'epe'}</code> <code>recover_fn</code> <code>Callable</code> <p>Function to recover the network.</p> <code>recover_network</code> <code>try_sort</code> <code>bool</code> <p>Whether to try sorting the ensemble.</p> <code>False</code> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>class EnsembleView(Ensemble):\n    \"\"\"A view of an ensemble of trained networks.\n\n    This class extends the Ensemble class with visualization and analysis methods.\n\n    Args:\n        path: Path to the ensemble directory or an existing Ensemble object.\n        network_class: The network class to use for instantiation.\n        root_dir: Root directory for results.\n        connectome_getter: Function to get the connectome.\n        checkpoint_mapper: Function to resolve checkpoints.\n        best_checkpoint_fn: Function to select the best checkpoint.\n        best_checkpoint_fn_kwargs: Keyword arguments for best_checkpoint_fn.\n        recover_fn: Function to recover the network.\n        try_sort: Whether to try sorting the ensemble.\n\n    Attributes:\n        Inherits all attributes from the Ensemble class.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Union[str, Path, Iterable, EnsembleDir, Ensemble],\n        network_class: nn.Module = Network,\n        root_dir: Path = flyvis.results_dir,\n        connectome_getter: Callable = get_avgfilt_connectome,\n        checkpoint_mapper: Callable = resolve_checkpoints,\n        best_checkpoint_fn: Callable = best_checkpoint_default_fn,\n        best_checkpoint_fn_kwargs: dict = {\n            \"validation_subdir\": \"validation\",\n            \"loss_file_name\": \"epe\",\n        },\n        recover_fn: Callable = recover_network,\n        try_sort: bool = False,\n    ):\n        init_args = (\n            path,\n            network_class,\n            root_dir,\n            connectome_getter,\n            checkpoint_mapper,\n            best_checkpoint_fn,\n            best_checkpoint_fn_kwargs,\n            recover_fn,\n            try_sort,\n        )\n        if isinstance(path, Ensemble):\n            init_args = path._init_args\n        super().__init__(*init_args)\n\n    @wraps(plots.loss_curves)\n    def training_loss(self, **kwargs) -&gt; Tuple[plt.Figure, plt.Axes]:\n        \"\"\"Plot training loss curves for the ensemble.\n\n        Args:\n            **kwargs: Additional keyword arguments to pass to plots.loss_curves.\n\n        Returns:\n            A tuple containing the matplotlib Figure and Axes objects.\n        \"\"\"\n        task_error = self.task_error()\n        losses = np.array([nv.dir.loss[:] for nv in self.values()])\n        return plots.loss_curves(\n            losses,\n            cbar=True,\n            colors=task_error.colors,\n            cmap=task_error.cmap,\n            norm=task_error.norm,\n            xlabel=\"iterations\",\n            ylabel=\"training loss\",\n            **kwargs,\n        )\n\n    @wraps(plots.loss_curves)\n    def validation_loss(\n        self,\n        validation_subdir: Optional[str] = None,\n        loss_file_name: Optional[str] = None,\n        **kwargs,\n    ) -&gt; Tuple[plt.Figure, plt.Axes]:\n        \"\"\"Plot validation loss curves for the ensemble.\n\n        Args:\n            validation_subdir: Subdirectory containing validation data.\n            loss_file_name: Name of the loss file.\n            **kwargs: Additional keyword arguments to pass to plots.loss_curves.\n\n        Returns:\n            A tuple containing the matplotlib Figure and Axes objects.\n        \"\"\"\n        task_error = self.task_error()\n        losses = self.validation_losses(validation_subdir, loss_file_name)\n        return plots.loss_curves(\n            losses,\n            cbar=True,\n            colors=task_error.colors,\n            cmap=task_error.cmap,\n            norm=task_error.norm,\n            xlabel=\"checkpoints\",\n            ylabel=\"validation loss\",\n            **kwargs,\n        )\n\n    @wraps(plots.histogram)\n    def task_error_histogram(self, **kwargs) -&gt; Tuple[plt.Figure, plt.Axes]:\n        \"\"\"Plot a histogram of the validation losses of the ensemble.\n\n        Args:\n            **kwargs: Additional keyword arguments to pass to plots.histogram.\n\n        Returns:\n            A tuple containing the matplotlib Figure and Axes objects.\n        \"\"\"\n        losses = self.min_validation_losses()\n        return plots.histogram(\n            losses, xlabel=\"task error\", ylabel=\"number models\", **kwargs\n        )\n\n    @wraps(plots.violins)\n    def node_parameters(\n        self, key: str, max_per_ax: int = 34, **kwargs\n    ) -&gt; Tuple[plt.Figure, List[plt.Axes]]:\n        \"\"\"Plot violin plots of node parameters for the ensemble.\n\n        Args:\n            key: The parameter key to plot.\n            max_per_ax: Maximum number of violins per axis.\n            **kwargs: Additional keyword arguments to pass to plots.violins.\n\n        Returns:\n            A tuple containing the matplotlib Figure and a list of Axes objects.\n        \"\"\"\n        parameters = self.parameters()[f\"nodes_{key}\"]\n        parameter_keys = self.parameter_keys()[f\"nodes_{key}\"]\n        return plots.violins(\n            parameter_keys, parameters, ylabel=key, max_per_ax=max_per_ax, **kwargs\n        )\n\n    @wraps(plots.violins)\n    def edge_parameters(\n        self, key: str, max_per_ax: int = 120, **kwargs\n    ) -&gt; Tuple[plt.Figure, List[plt.Axes]]:\n        \"\"\"Plot violin plots of edge parameters for the ensemble.\n\n        Args:\n            key: The parameter key to plot.\n            max_per_ax: Maximum number of violins per axis.\n            **kwargs: Additional keyword arguments to pass to plots.violins.\n\n        Returns:\n            A tuple containing the matplotlib Figure and a list of Axes objects.\n        \"\"\"\n        parameters = self.parameters()[f\"edges_{key}\"]\n        parameter_keys = self.parameter_keys()[f\"edges_{key}\"]\n        variable_names = np.array([\n            f\"{source}-&gt;{target}\" for source, target in parameter_keys\n        ])\n        return plots.violins(\n            variable_names,\n            variable_values=parameters,\n            ylabel=key,\n            max_per_ax=max_per_ax,\n            **kwargs,\n        )\n\n    @wraps(plots.heatmap)\n    def dead_or_alive(self, **kwargs) -&gt; Tuple[plt.Figure, plt.Axes]:\n        \"\"\"Plot a heatmap of dead cells in the ensemble.\n\n        Args:\n            **kwargs: Additional keyword arguments to pass to plots.heatmap.\n\n        Returns:\n            A tuple containing the matplotlib Figure and Axes objects.\n        \"\"\"\n        responses = self.naturalistic_stimuli_responses()\n        dead_count = (responses['responses'].values &lt; 0).all(axis=(1, 2))\n        return plots.heatmap(\n            dead_count,\n            ylabels=np.arange(len(self)),\n            xlabels=responses.cell_type.values,\n            size_scale=15,\n            cbar=False,\n            **kwargs,\n        )\n\n    @wraps(plot_fris)\n    def flash_response_index(\n        self, cell_types: Optional[List[str]] = None, **kwargs\n    ) -&gt; Tuple[plt.Figure, plt.Axes]:\n        \"\"\"Plot the flash response indices of the ensemble.\n\n        Args:\n            cell_types: List of cell types to include. If None, all cell types are used.\n            **kwargs: Additional keyword arguments to pass to plot_fris.\n\n        Returns:\n            A tuple containing the matplotlib Figure and Axes objects.\n        \"\"\"\n        responses = self.flash_responses()\n        fris = flash_response_index(responses, radius=6)\n        if cell_types is not None:\n            fris = fris.custom.where(cell_type=cell_types)\n        else:\n            cell_types = fris.cell_type.values\n        task_error = self.task_error()\n        best_index = np.argmin(task_error.values)\n        return plot_fris(\n            fris.values,\n            cell_types,\n            scatter_best=True,\n            scatter_best_index=best_index,\n            scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n            **kwargs,\n        )\n\n    @wraps(dsi_violins_on_and_off)\n    def direction_selectivity_index(\n        self, **kwargs\n    ) -&gt; Tuple[plt.Figure, Tuple[plt.Axes, plt.Axes]]:\n        \"\"\"Plot the direction selectivity indices of the ensemble.\n\n        Args:\n            **kwargs: Additional keyword arguments to pass to plot_dsis.\n\n        Returns:\n            A tuple containing the matplotlib Figure and a tuple of Axes objects.\n        \"\"\"\n        responses = self.moving_edge_responses()\n        dsis = direction_selectivity_index(responses)\n        task_error = self.task_error()\n        best_index = np.argmin(task_error.values)\n        return dsi_violins_on_and_off(\n            dsis,\n            responses.cell_type,\n            bold_output_type_labels=False,\n            figsize=[10, 1.2],\n            color_known_types=True,\n            fontsize=6,\n            scatter_best_index=best_index,\n            scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.training_loss","title":"training_loss","text":"<pre><code>training_loss(**kwargs)\n</code></pre> <p>Plot training loss curves for the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to pass to plots.loss_curves.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the matplotlib Figure and Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plots.loss_curves)\ndef training_loss(self, **kwargs) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"Plot training loss curves for the ensemble.\n\n    Args:\n        **kwargs: Additional keyword arguments to pass to plots.loss_curves.\n\n    Returns:\n        A tuple containing the matplotlib Figure and Axes objects.\n    \"\"\"\n    task_error = self.task_error()\n    losses = np.array([nv.dir.loss[:] for nv in self.values()])\n    return plots.loss_curves(\n        losses,\n        cbar=True,\n        colors=task_error.colors,\n        cmap=task_error.cmap,\n        norm=task_error.norm,\n        xlabel=\"iterations\",\n        ylabel=\"training loss\",\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.validation_loss","title":"validation_loss","text":"<pre><code>validation_loss(validation_subdir=None, loss_file_name=None, **kwargs)\n</code></pre> <p>Plot validation loss curves for the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>validation_subdir</code> <code>Optional[str]</code> <p>Subdirectory containing validation data.</p> <code>None</code> <code>loss_file_name</code> <code>Optional[str]</code> <p>Name of the loss file.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to plots.loss_curves.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the matplotlib Figure and Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plots.loss_curves)\ndef validation_loss(\n    self,\n    validation_subdir: Optional[str] = None,\n    loss_file_name: Optional[str] = None,\n    **kwargs,\n) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"Plot validation loss curves for the ensemble.\n\n    Args:\n        validation_subdir: Subdirectory containing validation data.\n        loss_file_name: Name of the loss file.\n        **kwargs: Additional keyword arguments to pass to plots.loss_curves.\n\n    Returns:\n        A tuple containing the matplotlib Figure and Axes objects.\n    \"\"\"\n    task_error = self.task_error()\n    losses = self.validation_losses(validation_subdir, loss_file_name)\n    return plots.loss_curves(\n        losses,\n        cbar=True,\n        colors=task_error.colors,\n        cmap=task_error.cmap,\n        norm=task_error.norm,\n        xlabel=\"checkpoints\",\n        ylabel=\"validation loss\",\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.task_error_histogram","title":"task_error_histogram","text":"<pre><code>task_error_histogram(**kwargs)\n</code></pre> <p>Plot a histogram of the validation losses of the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to pass to plots.histogram.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the matplotlib Figure and Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plots.histogram)\ndef task_error_histogram(self, **kwargs) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"Plot a histogram of the validation losses of the ensemble.\n\n    Args:\n        **kwargs: Additional keyword arguments to pass to plots.histogram.\n\n    Returns:\n        A tuple containing the matplotlib Figure and Axes objects.\n    \"\"\"\n    losses = self.min_validation_losses()\n    return plots.histogram(\n        losses, xlabel=\"task error\", ylabel=\"number models\", **kwargs\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.node_parameters","title":"node_parameters","text":"<pre><code>node_parameters(key, max_per_ax=34, **kwargs)\n</code></pre> <p>Plot violin plots of node parameters for the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The parameter key to plot.</p> required <code>max_per_ax</code> <code>int</code> <p>Maximum number of violins per axis.</p> <code>34</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to plots.violins.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, List[Axes]]</code> <p>A tuple containing the matplotlib Figure and a list of Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plots.violins)\ndef node_parameters(\n    self, key: str, max_per_ax: int = 34, **kwargs\n) -&gt; Tuple[plt.Figure, List[plt.Axes]]:\n    \"\"\"Plot violin plots of node parameters for the ensemble.\n\n    Args:\n        key: The parameter key to plot.\n        max_per_ax: Maximum number of violins per axis.\n        **kwargs: Additional keyword arguments to pass to plots.violins.\n\n    Returns:\n        A tuple containing the matplotlib Figure and a list of Axes objects.\n    \"\"\"\n    parameters = self.parameters()[f\"nodes_{key}\"]\n    parameter_keys = self.parameter_keys()[f\"nodes_{key}\"]\n    return plots.violins(\n        parameter_keys, parameters, ylabel=key, max_per_ax=max_per_ax, **kwargs\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.edge_parameters","title":"edge_parameters","text":"<pre><code>edge_parameters(key, max_per_ax=120, **kwargs)\n</code></pre> <p>Plot violin plots of edge parameters for the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The parameter key to plot.</p> required <code>max_per_ax</code> <code>int</code> <p>Maximum number of violins per axis.</p> <code>120</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to plots.violins.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, List[Axes]]</code> <p>A tuple containing the matplotlib Figure and a list of Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plots.violins)\ndef edge_parameters(\n    self, key: str, max_per_ax: int = 120, **kwargs\n) -&gt; Tuple[plt.Figure, List[plt.Axes]]:\n    \"\"\"Plot violin plots of edge parameters for the ensemble.\n\n    Args:\n        key: The parameter key to plot.\n        max_per_ax: Maximum number of violins per axis.\n        **kwargs: Additional keyword arguments to pass to plots.violins.\n\n    Returns:\n        A tuple containing the matplotlib Figure and a list of Axes objects.\n    \"\"\"\n    parameters = self.parameters()[f\"edges_{key}\"]\n    parameter_keys = self.parameter_keys()[f\"edges_{key}\"]\n    variable_names = np.array([\n        f\"{source}-&gt;{target}\" for source, target in parameter_keys\n    ])\n    return plots.violins(\n        variable_names,\n        variable_values=parameters,\n        ylabel=key,\n        max_per_ax=max_per_ax,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.dead_or_alive","title":"dead_or_alive","text":"<pre><code>dead_or_alive(**kwargs)\n</code></pre> <p>Plot a heatmap of dead cells in the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to pass to plots.heatmap.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the matplotlib Figure and Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plots.heatmap)\ndef dead_or_alive(self, **kwargs) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"Plot a heatmap of dead cells in the ensemble.\n\n    Args:\n        **kwargs: Additional keyword arguments to pass to plots.heatmap.\n\n    Returns:\n        A tuple containing the matplotlib Figure and Axes objects.\n    \"\"\"\n    responses = self.naturalistic_stimuli_responses()\n    dead_count = (responses['responses'].values &lt; 0).all(axis=(1, 2))\n    return plots.heatmap(\n        dead_count,\n        ylabels=np.arange(len(self)),\n        xlabels=responses.cell_type.values,\n        size_scale=15,\n        cbar=False,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.flash_response_index","title":"flash_response_index","text":"<pre><code>flash_response_index(cell_types=None, **kwargs)\n</code></pre> <p>Plot the flash response indices of the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>cell_types</code> <code>Optional[List[str]]</code> <p>List of cell types to include. If None, all cell types are used.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to plot_fris.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the matplotlib Figure and Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(plot_fris)\ndef flash_response_index(\n    self, cell_types: Optional[List[str]] = None, **kwargs\n) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"Plot the flash response indices of the ensemble.\n\n    Args:\n        cell_types: List of cell types to include. If None, all cell types are used.\n        **kwargs: Additional keyword arguments to pass to plot_fris.\n\n    Returns:\n        A tuple containing the matplotlib Figure and Axes objects.\n    \"\"\"\n    responses = self.flash_responses()\n    fris = flash_response_index(responses, radius=6)\n    if cell_types is not None:\n        fris = fris.custom.where(cell_type=cell_types)\n    else:\n        cell_types = fris.cell_type.values\n    task_error = self.task_error()\n    best_index = np.argmin(task_error.values)\n    return plot_fris(\n        fris.values,\n        cell_types,\n        scatter_best=True,\n        scatter_best_index=best_index,\n        scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.EnsembleView.direction_selectivity_index","title":"direction_selectivity_index","text":"<pre><code>direction_selectivity_index(**kwargs)\n</code></pre> <p>Plot the direction selectivity indices of the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to pass to plot_dsis.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Tuple[Axes, Axes]]</code> <p>A tuple containing the matplotlib Figure and a tuple of Axes objects.</p> Source code in <code>flyvis/network/ensemble_view.py</code> <pre><code>@wraps(dsi_violins_on_and_off)\ndef direction_selectivity_index(\n    self, **kwargs\n) -&gt; Tuple[plt.Figure, Tuple[plt.Axes, plt.Axes]]:\n    \"\"\"Plot the direction selectivity indices of the ensemble.\n\n    Args:\n        **kwargs: Additional keyword arguments to pass to plot_dsis.\n\n    Returns:\n        A tuple containing the matplotlib Figure and a tuple of Axes objects.\n    \"\"\"\n    responses = self.moving_edge_responses()\n    dsis = direction_selectivity_index(responses)\n    task_error = self.task_error()\n    best_index = np.argmin(task_error.values)\n    return dsi_violins_on_and_off(\n        dsis,\n        responses.cell_type,\n        bold_output_type_labels=False,\n        figsize=[10, 1.2],\n        color_known_types=True,\n        fontsize=6,\n        scatter_best_index=best_index,\n        scatter_best_color=cm.get_cmap(\"Blues\")(1.0),\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble","title":"flyvis.network.Ensemble","text":"<p>               Bases: <code>dict</code></p> <p>Dictionary to a collection of trained networks.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path, Iterable, 'EnsembleDir']</code> <p>Path to ensemble directory or list of paths to model directories. Can be a single string, then assumes the path is the root directory as configured by datamate.</p> required <code>network_class</code> <code>Module</code> <p>Class to use for initializing networks.</p> <code>Network</code> <code>root_dir</code> <code>Path</code> <p>Root directory for model paths.</p> <code>results_dir</code> <code>connectome_getter</code> <code>Callable</code> <p>Function to get the connectome.</p> <code>get_avgfilt_connectome</code> <code>checkpoint_mapper</code> <code>Callable</code> <p>Function to map checkpoints.</p> <code>resolve_checkpoints</code> <code>best_checkpoint_fn</code> <code>Callable</code> <p>Function to determine best checkpoint.</p> <code>best_checkpoint_default_fn</code> <code>best_checkpoint_fn_kwargs</code> <code>dict</code> <p>Kwargs for best_checkpoint_fn.</p> <code>{'validation_subdir': 'validation', 'loss_file_name': 'epe'}</code> <code>recover_fn</code> <code>Callable</code> <p>Function to recover network.</p> <code>recover_network</code> <code>try_sort</code> <code>bool</code> <p>Whether to try to sort the ensemble by validation error.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>names</code> <code>List[str]</code> <p>List of model names.</p> <code>name</code> <code>str</code> <p>Ensemble name.</p> <code>path</code> <code>Path</code> <p>Path to ensemble directory.</p> <code>model_paths</code> <code>List[Path]</code> <p>List of paths to model directories.</p> <code>dir</code> <code>EnsembleDir</code> <p>Directory object for ensemble directory.</p> Note <p>The ensemble is a dynamic dictionary, so you can access the networks in the ensemble by name or index. For example, to access the first network simply do: <pre><code>ensemble[0]\n</code></pre> or <pre><code>ensemble['flow/000/0000']\n</code></pre> Slice to create a subset of the ensemble: <pre><code>ensemble[0:2]\n</code></pre></p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>class Ensemble(dict):\n    \"\"\"Dictionary to a collection of trained networks.\n\n    Args:\n        path: Path to ensemble directory or list of paths to model directories.\n            Can be a single string, then assumes the path is the root directory\n            as configured by datamate.\n        network_class: Class to use for initializing networks.\n        root_dir: Root directory for model paths.\n        connectome_getter: Function to get the connectome.\n        checkpoint_mapper: Function to map checkpoints.\n        best_checkpoint_fn: Function to determine best checkpoint.\n        best_checkpoint_fn_kwargs: Kwargs for best_checkpoint_fn.\n        recover_fn: Function to recover network.\n        try_sort: Whether to try to sort the ensemble by validation error.\n\n    Attributes:\n        names (List[str]): List of model names.\n        name (str): Ensemble name.\n        path (Path): Path to ensemble directory.\n        model_paths (List[Path]): List of paths to model directories.\n        dir (EnsembleDir): Directory object for ensemble directory.\n\n    Note:\n        The ensemble is a dynamic dictionary, so you can access the networks\n        in the ensemble by name or index. For example, to access the first network\n        simply do:\n        ```python\n        ensemble[0]\n        ```\n        or\n        ```python\n        ensemble['flow/000/0000']\n        ```\n        Slice to create a subset of the ensemble:\n        ```python\n        ensemble[0:2]\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Union[str, Path, Iterable, \"EnsembleDir\"],\n        network_class: nn.Module = Network,\n        root_dir: Path = flyvis.results_dir,\n        connectome_getter: Callable = get_avgfilt_connectome,\n        checkpoint_mapper: Callable = resolve_checkpoints,\n        best_checkpoint_fn: Callable = best_checkpoint_default_fn,\n        best_checkpoint_fn_kwargs: dict = {\n            \"validation_subdir\": \"validation\",\n            \"loss_file_name\": \"epe\",\n        },\n        recover_fn: Callable = recover_network,\n        try_sort: bool = False,\n    ):\n        if isinstance(path, EnsembleDir):\n            path = path.path\n            self.model_paths, self.path = model_paths_from_parent(path)\n            self.dir = path\n        elif isinstance(path, Path):\n            self.model_paths, self.path = model_paths_from_parent(path)\n            self.dir = EnsembleDir(self.path)\n        elif isinstance(path, str):\n            self.dir = EnsembleDir(path)\n            self.model_paths, self.path = model_paths_from_parent(self.dir.path)\n        elif isinstance(path, Iterable):\n            self.model_paths, self.path = model_paths_from_names_or_paths(path, root_dir)\n            self.dir = EnsembleDir(self.path)\n        else:\n            raise TypeError(\n                f\"Unsupported path type: {type(path)}. \"\n                \"Expected EnsembleDir, str, PathLike, or Iterable.\"\n            )\n\n        self.names, self.name = model_path_names(self.model_paths)\n        self.in_context = False\n\n        self._names = []\n        self.model_index = []\n        # Initialize pointers to model directories.\n        for i, name in tqdm(\n            enumerate(self.names), desc=\"Loading ensemble\", total=len(self.names)\n        ):\n            try:\n                with all_logging_disabled():\n                    self[name] = NetworkView(\n                        NetworkDir(self.model_paths[i]),\n                        network_class=network_class,\n                        root_dir=root_dir,\n                        connectome_getter=connectome_getter,\n                        checkpoint_mapper=checkpoint_mapper,\n                        best_checkpoint_fn=best_checkpoint_fn,\n                        best_checkpoint_fn_kwargs=best_checkpoint_fn_kwargs,\n                        recover_fn=recover_fn,\n                    )\n                    self._names.append(name)\n            except AttributeError as e:\n                logging.warning(f\"Failed to load {name}: {e}\")\n        self._broken = list(set(self.names) - set(self._names))\n        self.names = self._names\n        self.model_index = np.arange(len(self.names))\n        logging.info(f\"Loaded {len(self)} networks.\")\n\n        if try_sort:\n            self.sort()\n\n        self._init_args = (\n            path,\n            network_class,\n            root_dir,\n            connectome_getter,\n            checkpoint_mapper,\n            best_checkpoint_fn,\n            best_checkpoint_fn_kwargs,\n            recover_fn,\n            try_sort,\n        )\n        self.connectome = self[next(iter(self))].connectome\n        self.cache = FIFOCache(maxsize=3)\n\n    def __getitem__(\n        self, key: Union[str, int, slice, NDArray, list]\n    ) -&gt; Union[NetworkView, \"Ensemble\"]:\n        \"\"\"Get item from the ensemble.\n\n        Args:\n            key: Key to access the ensemble.\n                Can be a string, int, slice, NDArray, or list.\n\n        Returns:\n            NetworkView or Ensemble: The requested item or subset of the ensemble.\n\n        Raises:\n            ValueError: If the key is invalid.\n        \"\"\"\n        if isinstance(key, (int, np.integer)):\n            return dict.__getitem__(self, self.names[key])\n        elif isinstance(key, slice):\n            return self.__class__(self.names[key])\n        elif isinstance(key, (np.ndarray, list)):\n            return self.__class__(np.array(self.names)[key])\n        elif key in self.names:\n            return dict.__getitem__(self, key)\n        else:\n            raise ValueError(f\"{key}\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the Ensemble.\"\"\"\n        return f\"{self.__class__.__name__}({self.path})\"\n\n    def __dir__(self) -&gt; List[str]:\n        \"\"\"Return a list of attributes for the Ensemble.\"\"\"\n        return list({*dict.__dir__(self), *dict.__iter__(self)})\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of networks in the Ensemble.\"\"\"\n        return len(self.names)\n\n    def __iter__(self) -&gt; Iterator[str]:\n        \"\"\"Iterate over the names of the networks in the Ensemble.\"\"\"\n        yield from self.names\n\n    def items(self) -&gt; Iterator[Tuple[str, NetworkView]]:\n        \"\"\"Return an iterator over the (name, NetworkView) pairs in the Ensemble.\"\"\"\n        return iter((k, self[k]) for k in self)\n\n    def keys(self) -&gt; List[str]:\n        \"\"\"Return a list of network names in the Ensemble.\"\"\"\n        return list(self)\n\n    def values(self) -&gt; List[NetworkView]:\n        \"\"\"Return a list of NetworkViews in the Ensemble.\"\"\"\n        return [self[k] for k in self]\n\n    def _clear_cache(self) -&gt; None:\n        \"\"\"Clear the cache of the Ensemble.\"\"\"\n        self.cache = {}\n\n    def _clear_memory(self) -&gt; None:\n        \"\"\"Clear the memory of all NetworkViews in the Ensemble.\"\"\"\n        for nv in self.values():\n            nv._clear_memory()\n\n    def check_configs_match(self) -&gt; bool:\n        \"\"\"Check if the configurations of the networks in the ensemble match.\n\n        Returns:\n            bool: True if all configurations match, False otherwise.\n        \"\"\"\n        config0 = self[0].dir.config\n        for i in range(1, len(self)):\n            diff = config0.diff(self[i].dir.config, name1=\"first\", name2=\"second\").first\n            if diff and not (len(diff) == 1 and \"network_name\" in diff[0]):\n                logging.warning(\n                    \"%(first)s differs from %(second)s. Diff is %(diff)s.\",\n                    {\"first\": self[0].name, \"second\": self[i].name, \"diff\": diff},\n                )\n                return False\n        return True\n\n    def yield_networks(self) -&gt; Generator[Network, None, None]:\n        \"\"\"Yield initialized networks from the ensemble.\n\n        Yields:\n            Network: Initialized network from the ensemble.\n        \"\"\"\n        network = self[0].init_network()\n        yield network\n        for network_view in self.values()[1:]:\n            yield network_view.init_network(network=network)\n\n    def yield_decoders(self) -&gt; Generator[nn.Module, None, None]:\n        \"\"\"Yield initialized decoders from the ensemble.\n\n        Yields:\n            nn.Module: Initialized decoder from the ensemble.\n        \"\"\"\n        assert self.check_configs_match(), \"configurations do not match\"\n        decoder = self[0].init_decoder()\n        for network_view in self.values():\n            yield network_view.init_decoder(decoder=decoder)\n\n    def simulate(\n        self, movie_input: torch.Tensor, dt: float, fade_in: bool = True\n    ) -&gt; Generator[np.ndarray, None, None]:\n        \"\"\"Simulate the ensemble activity from movie input.\n\n        Args:\n            movie_input: Tensor with shape (batch_size, n_frames, 1, hexals).\n            dt: Integration time constant. Warns if dt &gt; 1/50.\n            fade_in: Whether to use `network.fade_in_state` to compute the initial\n                state. Defaults to True. If False, uses the\n                `network.steady_state` after 1s of grey input.\n\n        Yields:\n            np.ndarray: Response of each individual network.\n\n        Note:\n            Simulates across batch_size in parallel, which can easily lead to OOM for\n            large batch sizes.\n        \"\"\"\n        for network in tqdm(\n            self.yield_networks(),\n            desc=\"Simulating network\",\n            total=len(self.names),\n        ):\n            yield (\n                network.simulate(\n                    movie_input,\n                    dt,\n                    initial_state=(\n                        network.fade_in_state(1.0, dt, movie_input[:, 0])\n                        if fade_in\n                        else \"auto\"\n                    ),\n                )\n                .cpu()\n                .numpy()\n            )\n\n    def simulate_from_dataset(\n        self,\n        dataset,\n        dt: float,\n        indices: Iterable[int] = None,\n        t_pre: float = 1.0,\n        t_fade_in: float = 0.0,\n        default_stim_key: str = \"lum\",\n        batch_size: int = 1,\n        central_cell_only: bool = True,\n    ) -&gt; Generator[np.ndarray, None, None]:\n        \"\"\"Simulate the ensemble activity from a dataset.\n\n        Args:\n            dataset: Dataset to simulate from.\n            dt: Integration time constant.\n            indices: Indices of stimuli to simulate. Defaults to None (all stimuli).\n            t_pre: Time before stimulus onset. Defaults to 1.0.\n            t_fade_in: Fade-in time. Defaults to 0.0.\n            default_stim_key: Default stimulus key. Defaults to \"lum\".\n            batch_size: Batch size for simulation. Defaults to 1.\n            central_cell_only: Whether to return only central cells. Defaults to True.\n\n        Yields:\n            np.ndarray: Simulated responses for each network.\n        \"\"\"\n        if central_cell_only:\n            central_cells_index = self[0].connectome.central_cells_index[:]\n\n        progress_bar = tqdm(desc=\"Simulating network\", total=len(self.names))\n\n        for network in self.yield_networks():\n\n            def handle_network(network: Network):\n                for _, resp in network.stimulus_response(\n                    dataset,\n                    dt=dt,\n                    indices=indices,\n                    t_pre=t_pre,\n                    t_fade_in=t_fade_in,\n                    default_stim_key=default_stim_key,\n                    batch_size=batch_size,\n                ):\n                    if central_cell_only:\n                        yield resp[:, :, central_cells_index]\n                    else:\n                        yield resp\n\n            r = np.stack(list(handle_network(network)))\n            yield r.reshape(-1, r.shape[-2], r.shape[-1])\n\n            progress_bar.update(1)\n        progress_bar.close()\n\n    def decode(\n        self, movie_input: torch.Tensor, dt: float\n    ) -&gt; Generator[np.ndarray, None, None]:\n        \"\"\"Decode the ensemble responses with the ensemble decoders.\n\n        Args:\n            movie_input: Input movie tensor.\n            dt: Integration time constant.\n\n        Yields:\n            np.ndarray: Decoded responses for each network.\n        \"\"\"\n        responses = torch.tensor(list(self.simulate(movie_input, dt)))\n        for i, decoder in enumerate(self.yield_decoders()):\n            with simulation(decoder):\n                yield decoder(responses[i]).cpu().numpy()\n\n    def validation_file(\n        self,\n        validation_subdir: Optional[str] = None,\n        loss_file_name: Optional[str] = None,\n    ) -&gt; Tuple[str, str]:\n        \"\"\"Return the validation file for each network in the ensemble.\n\n        Args:\n            validation_subdir: Subdirectory for validation files. Defaults to None.\n            loss_file_name: Name of the loss file. Defaults to None.\n\n        Returns:\n            Tuple[str, str]: Validation subdirectory and loss file name.\n        \"\"\"\n        network_view0 = self[0]\n        if validation_subdir is None:\n            validation_subdir = network_view0.best_checkpoint_fn_kwargs.get(\n                \"validation_subdir\"\n            )\n        if loss_file_name is None:\n            loss_file_name = network_view0.best_checkpoint_fn_kwargs.get(\"loss_file_name\")\n\n        return validation_subdir, loss_file_name\n\n    def sort(\n        self,\n        validation_subdir: Optional[str] = None,\n        loss_file_name: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Sort the ensemble by validation loss.\n\n        Args:\n            validation_subdir: Subdirectory for validation files. Defaults to None.\n            loss_file_name: Name of the loss file. Defaults to None.\n        \"\"\"\n        try:\n            self.names = sorted(\n                self.keys(),\n                key=lambda key: dict(\n                    zip(\n                        self.keys(),\n                        self.min_validation_losses(validation_subdir, loss_file_name),\n                    )\n                )[key],\n                reverse=False,\n            )\n        except Exception as e:\n            logging.info(f\"sorting failed: {e}\")\n\n    def argsort(\n        self,\n        validation_subdir: Optional[str] = None,\n        loss_file_name: Optional[str] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the indices that would sort the ensemble by validation loss.\n\n        Args:\n            validation_subdir: Subdirectory for validation files. Defaults to None.\n            loss_file_name: Name of the loss file. Defaults to None.\n\n        Returns:\n            np.ndarray: Indices that would sort the ensemble.\n        \"\"\"\n        return np.argsort(\n            self.min_validation_losses(\n                *self.validation_file(validation_subdir, loss_file_name)\n            )\n        )\n\n    def zorder(\n        self,\n        validation_subdir: Optional[str] = None,\n        loss_file_name: Optional[str] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the z-order of the ensemble based on validation loss.\n\n        Args:\n            validation_subdir: Subdirectory for validation files. Defaults to None.\n            loss_file_name: Name of the loss file. Defaults to None.\n\n        Returns:\n            np.ndarray: Z-order of the ensemble.\n        \"\"\"\n        return len(self) - self.argsort(validation_subdir, loss_file_name).argsort()\n\n    @context_aware_cache(context=lambda self: (self.names))\n    def validation_losses(\n        self, subdir: Optional[str] = None, file: Optional[str] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Return a list of validation losses for each network in the ensemble.\n\n        Args:\n            subdir: Subdirectory for validation files. Defaults to None.\n            file: Name of the loss file. Defaults to None.\n\n        Returns:\n            np.ndarray: Validation losses for each network.\n        \"\"\"\n        subdir, file = self.validation_file(subdir, file)\n        losses = np.array([nv.dir[subdir][file][()] for nv in self.values()])\n        return losses\n\n    def min_validation_losses(\n        self, subdir: Optional[str] = None, file: Optional[str] = None\n    ) -&gt; np.ndarray:\n        \"\"\"Return the minimum validation loss of the ensemble.\n\n        Args:\n            subdir: Subdirectory for validation files. Defaults to None.\n            file: Name of the loss file. Defaults to None.\n\n        Returns:\n            np.ndarray: Minimum validation losses for each network.\n        \"\"\"\n        losses = self.validation_losses(subdir, file)\n        if losses.ndim == 1:\n            return losses\n        return np.min(losses, axis=1)\n\n    @contextmanager\n    def rank_by_validation_error(self, reverse: bool = False):\n        \"\"\"Temporarily sort the ensemble based on validation error.\n\n        Args:\n            reverse: Whether to sort in descending order. Defaults to False.\n\n        Yields:\n            None\n        \"\"\"\n        _names = deepcopy(self.names)\n\n        try:\n            self.names = sorted(\n                self.keys(),\n                key=lambda key: dict(zip(self.keys(), self.min_validation_losses()))[key],\n                reverse=reverse,\n            )\n        except Exception as e:\n            logging.info(f\"sorting failed: {e}\")\n        try:\n            yield\n        finally:\n            self.names = list(_names)\n\n    @contextmanager\n    def ratio(self, best: Optional[float] = None, worst: Optional[float] = None):\n        \"\"\"Temporarily filter the ensemble by a ratio of best or worst performing models.\n\n        Args:\n            best: Ratio of best performing models to keep. Defaults to None.\n            worst: Ratio of worst performing models to keep. Defaults to None.\n\n        Yields:\n            None\n\n        Raises:\n            ValueError: If best and worst sum to more than 1.\n        \"\"\"\n        # no-op\n        if best is None and worst is None:\n            yield\n            return\n\n        _names = tuple(self.names)\n        _model_index = tuple(self.model_index)\n\n        with self.rank_by_validation_error():\n            if best is not None and worst is not None and best + worst &gt; 1:\n                raise ValueError(\"best and worst must add up to 1\")\n\n            if best is not None or worst is not None:\n                _context_best_names, _context_worst_names = [], []\n                if best is not None:\n                    _context_best_names = list(self.names[: int(best * len(self))])\n                    self._best_ratio = best\n                else:\n                    self._best_ratio = 0\n                if worst is not None:\n                    _context_worst_names = list(self.names[-int(worst * len(self)) :])\n                    self._worst_ratio = worst\n                else:\n                    self._worst_ratio = 0\n\n                in_context_names = [*_context_best_names, *_context_worst_names]\n\n                if in_context_names:  # to prevent an empty index\n                    self.model_index = np.array([\n                        i\n                        for i, name in zip(_model_index, _names)\n                        if name in in_context_names\n                    ])\n                self.names = in_context_names\n                self.in_context = True\n            try:\n                yield\n            finally:\n                self.names = list(_names)\n                self.model_index = _model_index\n                self._best_ratio = 0.5\n                self._worst_ratio = 0.5\n                self.in_context = False\n\n    @contextmanager\n    def select_items(self, indices: List[int]):\n        \"\"\"Temporarily filter the ensemble by a list of indices.\n\n        Args:\n            indices: List of indices to select.\n\n        Yields:\n            None\n\n        Raises:\n            ValueError: If indices are invalid.\n        \"\"\"\n        # no-op\n        try:\n            if indices is None:\n                yield\n                return\n            _names = tuple(self.names)\n            _model_index = tuple(self.model_index)\n            self._names = _names\n\n            if isinstance(indices, (int, np.integer, slice)):\n                in_context_names = self.names[indices]\n            elif isinstance(indices, (list, np.ndarray)):\n                if np.array(indices).dtype == np.array(self.names).dtype:\n                    in_context_names = indices\n                elif np.array(indices).dtype == np.int_:\n                    in_context_names = np.array(self.names)[indices]\n                else:\n                    raise ValueError(f\"{indices}\")\n            else:\n                raise ValueError(f\"{indices}\")\n            self.model_index = np.array([\n                i for i, name in zip(_model_index, _names) if name in in_context_names\n            ])\n            self.names = in_context_names\n            self.in_context = True\n            yield\n        finally:\n            self.names = list(_names)\n            self.model_index = list(_model_index)\n            self.in_context = False\n\n    def task_error(\n        self,\n        cmap: Union[str, Colormap] = \"Blues_r\",\n        truncate: Optional[Dict[str, Union[float, int]]] = None,\n        vmin: Optional[float] = None,\n        vmax: Optional[float] = None,\n    ) -&gt; \"TaskError\":\n        \"\"\"Return a TaskError object for the ensemble.\n\n        Args:\n            cmap: Colormap to use. Defaults to \"Blues_r\".\n            truncate: Dictionary to truncate the colormap. Defaults to None.\n            vmin: Minimum value for normalization. Defaults to None.\n            vmax: Maximum value for normalization. Defaults to None.\n\n        Returns:\n            TaskError: Object containing validation losses, colors, colormap, norm,\n                and scalar mapper.\n        \"\"\"\n        error = self.min_validation_losses()\n\n        if truncate is None:\n            # truncate because the maxval would be white with the default colormap\n            # which would be invisible on a white background\n            truncate = {\"minval\": 0.0, \"maxval\": 0.9, \"n\": 256}\n        cmap = cm.get_cmap(cmap) if isinstance(cmap, str) else cmap\n        cmap = plots.plt_utils.truncate_colormap(cmap, **truncate)\n        sm, norm = plots.plt_utils.get_scalarmapper(\n            cmap=cmap,\n            vmin=vmin or np.min(error),\n            vmax=vmax or np.max(error),\n        )\n        colors = sm.to_rgba(np.array(error))\n\n        return TaskError(error, colors, cmap, norm, sm)\n\n    def parameters(self) -&gt; Dict[str, np.ndarray]:\n        \"\"\"Return the parameters of the ensemble.\n\n        Returns:\n            Dict[str, np.ndarray]: Dictionary of parameter arrays.\n        \"\"\"\n        network_params = {}\n        for network_view in self.values():\n            chkpt_params = torch.load(network_view.network('best').checkpoint)\n            for key, val in chkpt_params[\"network\"].items():\n                if key not in network_params:\n                    network_params[key] = []\n                network_params[key].append(val.cpu().numpy())\n        for key, val in network_params.items():\n            network_params[key] = np.array(val)\n        return network_params\n\n    def parameter_keys(self) -&gt; Dict[str, List[str]]:\n        \"\"\"Return the keys of the parameters of the ensemble.\n\n        Returns:\n            Dict[str, List[str]]: Dictionary of parameter keys.\n        \"\"\"\n        self.check_configs_match()\n        network_view = self[0]\n        config = network_view.dir.config.network\n\n        parameter_keys = {}\n        for param_name, param_config in config.node_config.items():\n            param = forward_subclass(\n                Parameter,\n                config={\n                    \"type\": param_config.type,\n                    \"param_config\": param_config,\n                    \"connectome\": network_view.connectome,\n                },\n            )\n            parameter_keys[f\"nodes_{param_name}\"] = param.keys\n        for param_name, param_config in config.edge_config.items():\n            param = forward_subclass(\n                Parameter,\n                config={\n                    \"type\": param_config.type,\n                    \"param_config\": param_config,\n                    \"connectome\": network_view.connectome,\n                },\n            )\n            parameter_keys[f\"edges_{param_name}\"] = param.keys\n        return parameter_keys\n\n    @wraps(stimulus_responses.flash_responses)\n    @context_aware_cache(context=lambda self: (self.names))\n    def flash_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate flash responses.\"\"\"\n        return stimulus_responses.flash_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.moving_edge_responses)\n    @context_aware_cache(context=lambda self: (self.names))\n    def moving_edge_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate moving edge responses.\"\"\"\n        return stimulus_responses.moving_edge_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.moving_bar_responses)\n    @context_aware_cache(context=lambda self: (self.names))\n    def moving_bar_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate moving bar responses.\"\"\"\n        return stimulus_responses.moving_bar_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.naturalistic_stimuli_responses)\n    @context_aware_cache(context=lambda self: (self.names))\n    def naturalistic_stimuli_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate naturalistic stimuli responses.\"\"\"\n        return stimulus_responses.naturalistic_stimuli_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.central_impulses_responses)\n    @context_aware_cache(context=lambda self: (self.names))\n    def central_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate central ommatidium impulses responses.\"\"\"\n        return stimulus_responses.central_impulses_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.spatial_impulses_responses)\n    @context_aware_cache(context=lambda self: (self.names))\n    def spatial_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate spatial ommatidium impulses responses.\"\"\"\n        return stimulus_responses.spatial_impulses_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses_currents.moving_edge_currents)\n    @context_aware_cache(context=lambda self: (self.names))\n    def moving_edge_currents(\n        self, *args, **kwargs\n    ) -&gt; List[stimulus_responses_currents.ExperimentData]:\n        \"\"\"Generate moving edge currents.\"\"\"\n        return stimulus_responses_currents.moving_edge_currents(self, *args, **kwargs)\n\n    @context_aware_cache\n    def clustering(self, cell_type) -&gt; GaussianMixtureClustering:\n        \"\"\"Return the clustering of the ensemble for a given cell type.\n\n        Args:\n            cell_type: The cell type to cluster.\n\n        Returns:\n            GaussianMixtureClustering: Clustering object for the given cell type.\n\n        Raises:\n            ValueError: If clustering is not available in context.\n        \"\"\"\n        if self.in_context:\n            raise ValueError(\"clustering is not available in context\")\n\n        if (\n            not self.dir.umap_and_clustering\n            or not self.dir.umap_and_clustering[cell_type]\n        ):\n            return compute_umap_and_clustering(self, cell_type)\n\n        path = self.dir.umap_and_clustering[f\"{cell_type}.pickle\"]\n        with open(path, \"rb\") as file:\n            clustering = pickle.load(file)\n\n        return clustering\n\n    def cluster_indices(self, cell_type: str) -&gt; Dict[int, NDArray[int]]:\n        \"\"\"Clusters from responses to naturalistic stimuli of the given cell type.\n\n        Args:\n            cell_type: The cell type to return the clusters for.\n\n        Returns:\n            Dict[int, NDArray[int]]: Keys are the cluster ids and the values are the\n            model indices in the ensemble.\n\n        Example:\n            ```python\n            ensemble = Ensemble(\"path/to/ensemble\")\n            cluster_indices = ensemble.cluster_indices(\"T4a\")\n            first_cluster = ensemble[cluster_indices[0]]\n            ```\n\n        Raises:\n            ValueError: If stored clustering does not match ensemble.\n        \"\"\"\n        clustering = self.clustering(cell_type)\n        cluster_indices = get_cluster_to_indices(\n            clustering.embedding.mask,\n            clustering.labels,\n            task_error=self.task_error(),\n        )\n\n        _models = sorted(np.concatenate(list(cluster_indices.values())))\n        if len(_models) != clustering.embedding.mask.sum() or len(_models) &gt; len(self):\n            raise ValueError(\"stored clustering does not match ensemble\")\n\n        return cluster_indices\n\n    def responses_norm(self, rectified: bool = False) -&gt; np.ndarray:\n        \"\"\"Compute the norm of responses to naturalistic stimuli.\n\n        Args:\n            rectified: Whether to rectify responses before computing norm.\n\n        Returns:\n            np.ndarray: Norm of responses for each network.\n        \"\"\"\n        response_set = self.naturalistic_stimuli_responses()\n        responses = response_set['responses'].values\n\n        def compute_norm(X, rectified=True):\n            \"\"\"Computes a normalization constant for stimulus\n                responses per cell hypothesis, i.e. cell_type independent values.\n\n            Args:\n                X: (n_stimuli, n_frames, n_cell_types)\n            \"\"\"\n            if rectified:\n                X = np.maximum(X, 0)\n            n_models, n_samples, n_frames, n_cell_types = X.shape\n\n            # replace NaNs with 0\n            X[np.isnan(X)] = 0\n\n            return (\n                1\n                / np.sqrt(n_samples * n_frames)\n                * np.linalg.norm(\n                    X,\n                    axis=(1, 2),\n                    keepdims=True,\n                )\n            )\n\n        return np.take(\n            compute_norm(responses, rectified=rectified), self.model_index, axis=0\n        )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Get item from the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Union[str, int, slice, NDArray, list]</code> <p>Key to access the ensemble. Can be a string, int, slice, NDArray, or list.</p> required <p>Returns:</p> Type Description <code>Union[NetworkView, 'Ensemble']</code> <p>NetworkView or Ensemble: The requested item or subset of the ensemble.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is invalid.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def __getitem__(\n    self, key: Union[str, int, slice, NDArray, list]\n) -&gt; Union[NetworkView, \"Ensemble\"]:\n    \"\"\"Get item from the ensemble.\n\n    Args:\n        key: Key to access the ensemble.\n            Can be a string, int, slice, NDArray, or list.\n\n    Returns:\n        NetworkView or Ensemble: The requested item or subset of the ensemble.\n\n    Raises:\n        ValueError: If the key is invalid.\n    \"\"\"\n    if isinstance(key, (int, np.integer)):\n        return dict.__getitem__(self, self.names[key])\n    elif isinstance(key, slice):\n        return self.__class__(self.names[key])\n    elif isinstance(key, (np.ndarray, list)):\n        return self.__class__(np.array(self.names)[key])\n    elif key in self.names:\n        return dict.__getitem__(self, key)\n    else:\n        raise ValueError(f\"{key}\")\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Return a string representation of the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the Ensemble.\"\"\"\n    return f\"{self.__class__.__name__}({self.path})\"\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.__dir__","title":"__dir__","text":"<pre><code>__dir__()\n</code></pre> <p>Return a list of attributes for the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def __dir__(self) -&gt; List[str]:\n    \"\"\"Return a list of attributes for the Ensemble.\"\"\"\n    return list({*dict.__dir__(self), *dict.__iter__(self)})\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Return the number of networks in the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of networks in the Ensemble.\"\"\"\n    return len(self.names)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.__iter__","title":"__iter__","text":"<pre><code>__iter__()\n</code></pre> <p>Iterate over the names of the networks in the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def __iter__(self) -&gt; Iterator[str]:\n    \"\"\"Iterate over the names of the networks in the Ensemble.\"\"\"\n    yield from self.names\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.items","title":"items","text":"<pre><code>items()\n</code></pre> <p>Return an iterator over the (name, NetworkView) pairs in the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def items(self) -&gt; Iterator[Tuple[str, NetworkView]]:\n    \"\"\"Return an iterator over the (name, NetworkView) pairs in the Ensemble.\"\"\"\n    return iter((k, self[k]) for k in self)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.keys","title":"keys","text":"<pre><code>keys()\n</code></pre> <p>Return a list of network names in the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def keys(self) -&gt; List[str]:\n    \"\"\"Return a list of network names in the Ensemble.\"\"\"\n    return list(self)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.values","title":"values","text":"<pre><code>values()\n</code></pre> <p>Return a list of NetworkViews in the Ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def values(self) -&gt; List[NetworkView]:\n    \"\"\"Return a list of NetworkViews in the Ensemble.\"\"\"\n    return [self[k] for k in self]\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.check_configs_match","title":"check_configs_match","text":"<pre><code>check_configs_match()\n</code></pre> <p>Check if the configurations of the networks in the ensemble match.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if all configurations match, False otherwise.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def check_configs_match(self) -&gt; bool:\n    \"\"\"Check if the configurations of the networks in the ensemble match.\n\n    Returns:\n        bool: True if all configurations match, False otherwise.\n    \"\"\"\n    config0 = self[0].dir.config\n    for i in range(1, len(self)):\n        diff = config0.diff(self[i].dir.config, name1=\"first\", name2=\"second\").first\n        if diff and not (len(diff) == 1 and \"network_name\" in diff[0]):\n            logging.warning(\n                \"%(first)s differs from %(second)s. Diff is %(diff)s.\",\n                {\"first\": self[0].name, \"second\": self[i].name, \"diff\": diff},\n            )\n            return False\n    return True\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.yield_networks","title":"yield_networks","text":"<pre><code>yield_networks()\n</code></pre> <p>Yield initialized networks from the ensemble.</p> <p>Yields:</p> Name Type Description <code>Network</code> <code>Network</code> <p>Initialized network from the ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def yield_networks(self) -&gt; Generator[Network, None, None]:\n    \"\"\"Yield initialized networks from the ensemble.\n\n    Yields:\n        Network: Initialized network from the ensemble.\n    \"\"\"\n    network = self[0].init_network()\n    yield network\n    for network_view in self.values()[1:]:\n        yield network_view.init_network(network=network)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.yield_decoders","title":"yield_decoders","text":"<pre><code>yield_decoders()\n</code></pre> <p>Yield initialized decoders from the ensemble.</p> <p>Yields:</p> Type Description <code>Module</code> <p>nn.Module: Initialized decoder from the ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def yield_decoders(self) -&gt; Generator[nn.Module, None, None]:\n    \"\"\"Yield initialized decoders from the ensemble.\n\n    Yields:\n        nn.Module: Initialized decoder from the ensemble.\n    \"\"\"\n    assert self.check_configs_match(), \"configurations do not match\"\n    decoder = self[0].init_decoder()\n    for network_view in self.values():\n        yield network_view.init_decoder(decoder=decoder)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.simulate","title":"simulate","text":"<pre><code>simulate(movie_input, dt, fade_in=True)\n</code></pre> <p>Simulate the ensemble activity from movie input.</p> <p>Parameters:</p> Name Type Description Default <code>movie_input</code> <code>Tensor</code> <p>Tensor with shape (batch_size, n_frames, 1, hexals).</p> required <code>dt</code> <code>float</code> <p>Integration time constant. Warns if dt &gt; 1/50.</p> required <code>fade_in</code> <code>bool</code> <p>Whether to use <code>network.fade_in_state</code> to compute the initial state. Defaults to True. If False, uses the <code>network.steady_state</code> after 1s of grey input.</p> <code>True</code> <p>Yields:</p> Type Description <code>ndarray</code> <p>np.ndarray: Response of each individual network.</p> Note <p>Simulates across batch_size in parallel, which can easily lead to OOM for large batch sizes.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def simulate(\n    self, movie_input: torch.Tensor, dt: float, fade_in: bool = True\n) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"Simulate the ensemble activity from movie input.\n\n    Args:\n        movie_input: Tensor with shape (batch_size, n_frames, 1, hexals).\n        dt: Integration time constant. Warns if dt &gt; 1/50.\n        fade_in: Whether to use `network.fade_in_state` to compute the initial\n            state. Defaults to True. If False, uses the\n            `network.steady_state` after 1s of grey input.\n\n    Yields:\n        np.ndarray: Response of each individual network.\n\n    Note:\n        Simulates across batch_size in parallel, which can easily lead to OOM for\n        large batch sizes.\n    \"\"\"\n    for network in tqdm(\n        self.yield_networks(),\n        desc=\"Simulating network\",\n        total=len(self.names),\n    ):\n        yield (\n            network.simulate(\n                movie_input,\n                dt,\n                initial_state=(\n                    network.fade_in_state(1.0, dt, movie_input[:, 0])\n                    if fade_in\n                    else \"auto\"\n                ),\n            )\n            .cpu()\n            .numpy()\n        )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.simulate_from_dataset","title":"simulate_from_dataset","text":"<pre><code>simulate_from_dataset(dataset, dt, indices=None, t_pre=1.0, t_fade_in=0.0, default_stim_key='lum', batch_size=1, central_cell_only=True)\n</code></pre> <p>Simulate the ensemble activity from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <p>Dataset to simulate from.</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <code>indices</code> <code>Iterable[int]</code> <p>Indices of stimuli to simulate. Defaults to None (all stimuli).</p> <code>None</code> <code>t_pre</code> <code>float</code> <p>Time before stimulus onset. Defaults to 1.0.</p> <code>1.0</code> <code>t_fade_in</code> <code>float</code> <p>Fade-in time. Defaults to 0.0.</p> <code>0.0</code> <code>default_stim_key</code> <code>str</code> <p>Default stimulus key. Defaults to \u201clum\u201d.</p> <code>'lum'</code> <code>batch_size</code> <code>int</code> <p>Batch size for simulation. Defaults to 1.</p> <code>1</code> <code>central_cell_only</code> <code>bool</code> <p>Whether to return only central cells. Defaults to True.</p> <code>True</code> <p>Yields:</p> Type Description <code>ndarray</code> <p>np.ndarray: Simulated responses for each network.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def simulate_from_dataset(\n    self,\n    dataset,\n    dt: float,\n    indices: Iterable[int] = None,\n    t_pre: float = 1.0,\n    t_fade_in: float = 0.0,\n    default_stim_key: str = \"lum\",\n    batch_size: int = 1,\n    central_cell_only: bool = True,\n) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"Simulate the ensemble activity from a dataset.\n\n    Args:\n        dataset: Dataset to simulate from.\n        dt: Integration time constant.\n        indices: Indices of stimuli to simulate. Defaults to None (all stimuli).\n        t_pre: Time before stimulus onset. Defaults to 1.0.\n        t_fade_in: Fade-in time. Defaults to 0.0.\n        default_stim_key: Default stimulus key. Defaults to \"lum\".\n        batch_size: Batch size for simulation. Defaults to 1.\n        central_cell_only: Whether to return only central cells. Defaults to True.\n\n    Yields:\n        np.ndarray: Simulated responses for each network.\n    \"\"\"\n    if central_cell_only:\n        central_cells_index = self[0].connectome.central_cells_index[:]\n\n    progress_bar = tqdm(desc=\"Simulating network\", total=len(self.names))\n\n    for network in self.yield_networks():\n\n        def handle_network(network: Network):\n            for _, resp in network.stimulus_response(\n                dataset,\n                dt=dt,\n                indices=indices,\n                t_pre=t_pre,\n                t_fade_in=t_fade_in,\n                default_stim_key=default_stim_key,\n                batch_size=batch_size,\n            ):\n                if central_cell_only:\n                    yield resp[:, :, central_cells_index]\n                else:\n                    yield resp\n\n        r = np.stack(list(handle_network(network)))\n        yield r.reshape(-1, r.shape[-2], r.shape[-1])\n\n        progress_bar.update(1)\n    progress_bar.close()\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.decode","title":"decode","text":"<pre><code>decode(movie_input, dt)\n</code></pre> <p>Decode the ensemble responses with the ensemble decoders.</p> <p>Parameters:</p> Name Type Description Default <code>movie_input</code> <code>Tensor</code> <p>Input movie tensor.</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <p>Yields:</p> Type Description <code>ndarray</code> <p>np.ndarray: Decoded responses for each network.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def decode(\n    self, movie_input: torch.Tensor, dt: float\n) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"Decode the ensemble responses with the ensemble decoders.\n\n    Args:\n        movie_input: Input movie tensor.\n        dt: Integration time constant.\n\n    Yields:\n        np.ndarray: Decoded responses for each network.\n    \"\"\"\n    responses = torch.tensor(list(self.simulate(movie_input, dt)))\n    for i, decoder in enumerate(self.yield_decoders()):\n        with simulation(decoder):\n            yield decoder(responses[i]).cpu().numpy()\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.validation_file","title":"validation_file","text":"<pre><code>validation_file(validation_subdir=None, loss_file_name=None)\n</code></pre> <p>Return the validation file for each network in the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>validation_subdir</code> <code>Optional[str]</code> <p>Subdirectory for validation files. Defaults to None.</p> <code>None</code> <code>loss_file_name</code> <code>Optional[str]</code> <p>Name of the loss file. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[str, str]</code> <p>Tuple[str, str]: Validation subdirectory and loss file name.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def validation_file(\n    self,\n    validation_subdir: Optional[str] = None,\n    loss_file_name: Optional[str] = None,\n) -&gt; Tuple[str, str]:\n    \"\"\"Return the validation file for each network in the ensemble.\n\n    Args:\n        validation_subdir: Subdirectory for validation files. Defaults to None.\n        loss_file_name: Name of the loss file. Defaults to None.\n\n    Returns:\n        Tuple[str, str]: Validation subdirectory and loss file name.\n    \"\"\"\n    network_view0 = self[0]\n    if validation_subdir is None:\n        validation_subdir = network_view0.best_checkpoint_fn_kwargs.get(\n            \"validation_subdir\"\n        )\n    if loss_file_name is None:\n        loss_file_name = network_view0.best_checkpoint_fn_kwargs.get(\"loss_file_name\")\n\n    return validation_subdir, loss_file_name\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.sort","title":"sort","text":"<pre><code>sort(validation_subdir=None, loss_file_name=None)\n</code></pre> <p>Sort the ensemble by validation loss.</p> <p>Parameters:</p> Name Type Description Default <code>validation_subdir</code> <code>Optional[str]</code> <p>Subdirectory for validation files. Defaults to None.</p> <code>None</code> <code>loss_file_name</code> <code>Optional[str]</code> <p>Name of the loss file. Defaults to None.</p> <code>None</code> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def sort(\n    self,\n    validation_subdir: Optional[str] = None,\n    loss_file_name: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Sort the ensemble by validation loss.\n\n    Args:\n        validation_subdir: Subdirectory for validation files. Defaults to None.\n        loss_file_name: Name of the loss file. Defaults to None.\n    \"\"\"\n    try:\n        self.names = sorted(\n            self.keys(),\n            key=lambda key: dict(\n                zip(\n                    self.keys(),\n                    self.min_validation_losses(validation_subdir, loss_file_name),\n                )\n            )[key],\n            reverse=False,\n        )\n    except Exception as e:\n        logging.info(f\"sorting failed: {e}\")\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.argsort","title":"argsort","text":"<pre><code>argsort(validation_subdir=None, loss_file_name=None)\n</code></pre> <p>Return the indices that would sort the ensemble by validation loss.</p> <p>Parameters:</p> Name Type Description Default <code>validation_subdir</code> <code>Optional[str]</code> <p>Subdirectory for validation files. Defaults to None.</p> <code>None</code> <code>loss_file_name</code> <code>Optional[str]</code> <p>Name of the loss file. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Indices that would sort the ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def argsort(\n    self,\n    validation_subdir: Optional[str] = None,\n    loss_file_name: Optional[str] = None,\n) -&gt; np.ndarray:\n    \"\"\"Return the indices that would sort the ensemble by validation loss.\n\n    Args:\n        validation_subdir: Subdirectory for validation files. Defaults to None.\n        loss_file_name: Name of the loss file. Defaults to None.\n\n    Returns:\n        np.ndarray: Indices that would sort the ensemble.\n    \"\"\"\n    return np.argsort(\n        self.min_validation_losses(\n            *self.validation_file(validation_subdir, loss_file_name)\n        )\n    )\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.zorder","title":"zorder","text":"<pre><code>zorder(validation_subdir=None, loss_file_name=None)\n</code></pre> <p>Return the z-order of the ensemble based on validation loss.</p> <p>Parameters:</p> Name Type Description Default <code>validation_subdir</code> <code>Optional[str]</code> <p>Subdirectory for validation files. Defaults to None.</p> <code>None</code> <code>loss_file_name</code> <code>Optional[str]</code> <p>Name of the loss file. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Z-order of the ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def zorder(\n    self,\n    validation_subdir: Optional[str] = None,\n    loss_file_name: Optional[str] = None,\n) -&gt; np.ndarray:\n    \"\"\"Return the z-order of the ensemble based on validation loss.\n\n    Args:\n        validation_subdir: Subdirectory for validation files. Defaults to None.\n        loss_file_name: Name of the loss file. Defaults to None.\n\n    Returns:\n        np.ndarray: Z-order of the ensemble.\n    \"\"\"\n    return len(self) - self.argsort(validation_subdir, loss_file_name).argsort()\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.validation_losses","title":"validation_losses","text":"<pre><code>validation_losses(subdir=None, file=None)\n</code></pre> <p>Return a list of validation losses for each network in the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>subdir</code> <code>Optional[str]</code> <p>Subdirectory for validation files. Defaults to None.</p> <code>None</code> <code>file</code> <code>Optional[str]</code> <p>Name of the loss file. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Validation losses for each network.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@context_aware_cache(context=lambda self: (self.names))\ndef validation_losses(\n    self, subdir: Optional[str] = None, file: Optional[str] = None\n) -&gt; np.ndarray:\n    \"\"\"Return a list of validation losses for each network in the ensemble.\n\n    Args:\n        subdir: Subdirectory for validation files. Defaults to None.\n        file: Name of the loss file. Defaults to None.\n\n    Returns:\n        np.ndarray: Validation losses for each network.\n    \"\"\"\n    subdir, file = self.validation_file(subdir, file)\n    losses = np.array([nv.dir[subdir][file][()] for nv in self.values()])\n    return losses\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.min_validation_losses","title":"min_validation_losses","text":"<pre><code>min_validation_losses(subdir=None, file=None)\n</code></pre> <p>Return the minimum validation loss of the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>subdir</code> <code>Optional[str]</code> <p>Subdirectory for validation files. Defaults to None.</p> <code>None</code> <code>file</code> <code>Optional[str]</code> <p>Name of the loss file. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Minimum validation losses for each network.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def min_validation_losses(\n    self, subdir: Optional[str] = None, file: Optional[str] = None\n) -&gt; np.ndarray:\n    \"\"\"Return the minimum validation loss of the ensemble.\n\n    Args:\n        subdir: Subdirectory for validation files. Defaults to None.\n        file: Name of the loss file. Defaults to None.\n\n    Returns:\n        np.ndarray: Minimum validation losses for each network.\n    \"\"\"\n    losses = self.validation_losses(subdir, file)\n    if losses.ndim == 1:\n        return losses\n    return np.min(losses, axis=1)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.rank_by_validation_error","title":"rank_by_validation_error","text":"<pre><code>rank_by_validation_error(reverse=False)\n</code></pre> <p>Temporarily sort the ensemble based on validation error.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>Whether to sort in descending order. Defaults to False.</p> <code>False</code> <p>Yields:</p> Type Description <p>None</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@contextmanager\ndef rank_by_validation_error(self, reverse: bool = False):\n    \"\"\"Temporarily sort the ensemble based on validation error.\n\n    Args:\n        reverse: Whether to sort in descending order. Defaults to False.\n\n    Yields:\n        None\n    \"\"\"\n    _names = deepcopy(self.names)\n\n    try:\n        self.names = sorted(\n            self.keys(),\n            key=lambda key: dict(zip(self.keys(), self.min_validation_losses()))[key],\n            reverse=reverse,\n        )\n    except Exception as e:\n        logging.info(f\"sorting failed: {e}\")\n    try:\n        yield\n    finally:\n        self.names = list(_names)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.ratio","title":"ratio","text":"<pre><code>ratio(best=None, worst=None)\n</code></pre> <p>Temporarily filter the ensemble by a ratio of best or worst performing models.</p> <p>Parameters:</p> Name Type Description Default <code>best</code> <code>Optional[float]</code> <p>Ratio of best performing models to keep. Defaults to None.</p> <code>None</code> <code>worst</code> <code>Optional[float]</code> <p>Ratio of worst performing models to keep. Defaults to None.</p> <code>None</code> <p>Yields:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If best and worst sum to more than 1.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@contextmanager\ndef ratio(self, best: Optional[float] = None, worst: Optional[float] = None):\n    \"\"\"Temporarily filter the ensemble by a ratio of best or worst performing models.\n\n    Args:\n        best: Ratio of best performing models to keep. Defaults to None.\n        worst: Ratio of worst performing models to keep. Defaults to None.\n\n    Yields:\n        None\n\n    Raises:\n        ValueError: If best and worst sum to more than 1.\n    \"\"\"\n    # no-op\n    if best is None and worst is None:\n        yield\n        return\n\n    _names = tuple(self.names)\n    _model_index = tuple(self.model_index)\n\n    with self.rank_by_validation_error():\n        if best is not None and worst is not None and best + worst &gt; 1:\n            raise ValueError(\"best and worst must add up to 1\")\n\n        if best is not None or worst is not None:\n            _context_best_names, _context_worst_names = [], []\n            if best is not None:\n                _context_best_names = list(self.names[: int(best * len(self))])\n                self._best_ratio = best\n            else:\n                self._best_ratio = 0\n            if worst is not None:\n                _context_worst_names = list(self.names[-int(worst * len(self)) :])\n                self._worst_ratio = worst\n            else:\n                self._worst_ratio = 0\n\n            in_context_names = [*_context_best_names, *_context_worst_names]\n\n            if in_context_names:  # to prevent an empty index\n                self.model_index = np.array([\n                    i\n                    for i, name in zip(_model_index, _names)\n                    if name in in_context_names\n                ])\n            self.names = in_context_names\n            self.in_context = True\n        try:\n            yield\n        finally:\n            self.names = list(_names)\n            self.model_index = _model_index\n            self._best_ratio = 0.5\n            self._worst_ratio = 0.5\n            self.in_context = False\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.select_items","title":"select_items","text":"<pre><code>select_items(indices)\n</code></pre> <p>Temporarily filter the ensemble by a list of indices.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>List[int]</code> <p>List of indices to select.</p> required <p>Yields:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If indices are invalid.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@contextmanager\ndef select_items(self, indices: List[int]):\n    \"\"\"Temporarily filter the ensemble by a list of indices.\n\n    Args:\n        indices: List of indices to select.\n\n    Yields:\n        None\n\n    Raises:\n        ValueError: If indices are invalid.\n    \"\"\"\n    # no-op\n    try:\n        if indices is None:\n            yield\n            return\n        _names = tuple(self.names)\n        _model_index = tuple(self.model_index)\n        self._names = _names\n\n        if isinstance(indices, (int, np.integer, slice)):\n            in_context_names = self.names[indices]\n        elif isinstance(indices, (list, np.ndarray)):\n            if np.array(indices).dtype == np.array(self.names).dtype:\n                in_context_names = indices\n            elif np.array(indices).dtype == np.int_:\n                in_context_names = np.array(self.names)[indices]\n            else:\n                raise ValueError(f\"{indices}\")\n        else:\n            raise ValueError(f\"{indices}\")\n        self.model_index = np.array([\n            i for i, name in zip(_model_index, _names) if name in in_context_names\n        ])\n        self.names = in_context_names\n        self.in_context = True\n        yield\n    finally:\n        self.names = list(_names)\n        self.model_index = list(_model_index)\n        self.in_context = False\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.task_error","title":"task_error","text":"<pre><code>task_error(cmap='Blues_r', truncate=None, vmin=None, vmax=None)\n</code></pre> <p>Return a TaskError object for the ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>cmap</code> <code>Union[str, Colormap]</code> <p>Colormap to use. Defaults to \u201cBlues_r\u201d.</p> <code>'Blues_r'</code> <code>truncate</code> <code>Optional[Dict[str, Union[float, int]]]</code> <p>Dictionary to truncate the colormap. Defaults to None.</p> <code>None</code> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for normalization. Defaults to None.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for normalization. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>TaskError</code> <code>'TaskError'</code> <p>Object containing validation losses, colors, colormap, norm, and scalar mapper.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def task_error(\n    self,\n    cmap: Union[str, Colormap] = \"Blues_r\",\n    truncate: Optional[Dict[str, Union[float, int]]] = None,\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n) -&gt; \"TaskError\":\n    \"\"\"Return a TaskError object for the ensemble.\n\n    Args:\n        cmap: Colormap to use. Defaults to \"Blues_r\".\n        truncate: Dictionary to truncate the colormap. Defaults to None.\n        vmin: Minimum value for normalization. Defaults to None.\n        vmax: Maximum value for normalization. Defaults to None.\n\n    Returns:\n        TaskError: Object containing validation losses, colors, colormap, norm,\n            and scalar mapper.\n    \"\"\"\n    error = self.min_validation_losses()\n\n    if truncate is None:\n        # truncate because the maxval would be white with the default colormap\n        # which would be invisible on a white background\n        truncate = {\"minval\": 0.0, \"maxval\": 0.9, \"n\": 256}\n    cmap = cm.get_cmap(cmap) if isinstance(cmap, str) else cmap\n    cmap = plots.plt_utils.truncate_colormap(cmap, **truncate)\n    sm, norm = plots.plt_utils.get_scalarmapper(\n        cmap=cmap,\n        vmin=vmin or np.min(error),\n        vmax=vmax or np.max(error),\n    )\n    colors = sm.to_rgba(np.array(error))\n\n    return TaskError(error, colors, cmap, norm, sm)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.parameters","title":"parameters","text":"<pre><code>parameters()\n</code></pre> <p>Return the parameters of the ensemble.</p> <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dict[str, np.ndarray]: Dictionary of parameter arrays.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def parameters(self) -&gt; Dict[str, np.ndarray]:\n    \"\"\"Return the parameters of the ensemble.\n\n    Returns:\n        Dict[str, np.ndarray]: Dictionary of parameter arrays.\n    \"\"\"\n    network_params = {}\n    for network_view in self.values():\n        chkpt_params = torch.load(network_view.network('best').checkpoint)\n        for key, val in chkpt_params[\"network\"].items():\n            if key not in network_params:\n                network_params[key] = []\n            network_params[key].append(val.cpu().numpy())\n    for key, val in network_params.items():\n        network_params[key] = np.array(val)\n    return network_params\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.parameter_keys","title":"parameter_keys","text":"<pre><code>parameter_keys()\n</code></pre> <p>Return the keys of the parameters of the ensemble.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: Dictionary of parameter keys.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def parameter_keys(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Return the keys of the parameters of the ensemble.\n\n    Returns:\n        Dict[str, List[str]]: Dictionary of parameter keys.\n    \"\"\"\n    self.check_configs_match()\n    network_view = self[0]\n    config = network_view.dir.config.network\n\n    parameter_keys = {}\n    for param_name, param_config in config.node_config.items():\n        param = forward_subclass(\n            Parameter,\n            config={\n                \"type\": param_config.type,\n                \"param_config\": param_config,\n                \"connectome\": network_view.connectome,\n            },\n        )\n        parameter_keys[f\"nodes_{param_name}\"] = param.keys\n    for param_name, param_config in config.edge_config.items():\n        param = forward_subclass(\n            Parameter,\n            config={\n                \"type\": param_config.type,\n                \"param_config\": param_config,\n                \"connectome\": network_view.connectome,\n            },\n        )\n        parameter_keys[f\"edges_{param_name}\"] = param.keys\n    return parameter_keys\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.flash_responses","title":"flash_responses","text":"<pre><code>flash_responses(*args, **kwargs)\n</code></pre> <p>Generate flash responses.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses.flash_responses)\n@context_aware_cache(context=lambda self: (self.names))\ndef flash_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate flash responses.\"\"\"\n    return stimulus_responses.flash_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.moving_edge_responses","title":"moving_edge_responses","text":"<pre><code>moving_edge_responses(*args, **kwargs)\n</code></pre> <p>Generate moving edge responses.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses.moving_edge_responses)\n@context_aware_cache(context=lambda self: (self.names))\ndef moving_edge_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate moving edge responses.\"\"\"\n    return stimulus_responses.moving_edge_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.moving_bar_responses","title":"moving_bar_responses","text":"<pre><code>moving_bar_responses(*args, **kwargs)\n</code></pre> <p>Generate moving bar responses.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses.moving_bar_responses)\n@context_aware_cache(context=lambda self: (self.names))\ndef moving_bar_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate moving bar responses.\"\"\"\n    return stimulus_responses.moving_bar_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.naturalistic_stimuli_responses","title":"naturalistic_stimuli_responses","text":"<pre><code>naturalistic_stimuli_responses(*args, **kwargs)\n</code></pre> <p>Generate naturalistic stimuli responses.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses.naturalistic_stimuli_responses)\n@context_aware_cache(context=lambda self: (self.names))\ndef naturalistic_stimuli_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate naturalistic stimuli responses.\"\"\"\n    return stimulus_responses.naturalistic_stimuli_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.central_impulses_responses","title":"central_impulses_responses","text":"<pre><code>central_impulses_responses(*args, **kwargs)\n</code></pre> <p>Generate central ommatidium impulses responses.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses.central_impulses_responses)\n@context_aware_cache(context=lambda self: (self.names))\ndef central_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate central ommatidium impulses responses.\"\"\"\n    return stimulus_responses.central_impulses_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.spatial_impulses_responses","title":"spatial_impulses_responses","text":"<pre><code>spatial_impulses_responses(*args, **kwargs)\n</code></pre> <p>Generate spatial ommatidium impulses responses.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses.spatial_impulses_responses)\n@context_aware_cache(context=lambda self: (self.names))\ndef spatial_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate spatial ommatidium impulses responses.\"\"\"\n    return stimulus_responses.spatial_impulses_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.moving_edge_currents","title":"moving_edge_currents","text":"<pre><code>moving_edge_currents(*args, **kwargs)\n</code></pre> <p>Generate moving edge currents.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@wraps(stimulus_responses_currents.moving_edge_currents)\n@context_aware_cache(context=lambda self: (self.names))\ndef moving_edge_currents(\n    self, *args, **kwargs\n) -&gt; List[stimulus_responses_currents.ExperimentData]:\n    \"\"\"Generate moving edge currents.\"\"\"\n    return stimulus_responses_currents.moving_edge_currents(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.clustering","title":"clustering","text":"<pre><code>clustering(cell_type)\n</code></pre> <p>Return the clustering of the ensemble for a given cell type.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <p>The cell type to cluster.</p> required <p>Returns:</p> Name Type Description <code>GaussianMixtureClustering</code> <code>GaussianMixtureClustering</code> <p>Clustering object for the given cell type.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If clustering is not available in context.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>@context_aware_cache\ndef clustering(self, cell_type) -&gt; GaussianMixtureClustering:\n    \"\"\"Return the clustering of the ensemble for a given cell type.\n\n    Args:\n        cell_type: The cell type to cluster.\n\n    Returns:\n        GaussianMixtureClustering: Clustering object for the given cell type.\n\n    Raises:\n        ValueError: If clustering is not available in context.\n    \"\"\"\n    if self.in_context:\n        raise ValueError(\"clustering is not available in context\")\n\n    if (\n        not self.dir.umap_and_clustering\n        or not self.dir.umap_and_clustering[cell_type]\n    ):\n        return compute_umap_and_clustering(self, cell_type)\n\n    path = self.dir.umap_and_clustering[f\"{cell_type}.pickle\"]\n    with open(path, \"rb\") as file:\n        clustering = pickle.load(file)\n\n    return clustering\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.cluster_indices","title":"cluster_indices","text":"<pre><code>cluster_indices(cell_type)\n</code></pre> <p>Clusters from responses to naturalistic stimuli of the given cell type.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>The cell type to return the clusters for.</p> required <p>Returns:</p> Type Description <code>Dict[int, NDArray[int]]</code> <p>Dict[int, NDArray[int]]: Keys are the cluster ids and the values are the</p> <code>Dict[int, NDArray[int]]</code> <p>model indices in the ensemble.</p> Example <pre><code>ensemble = Ensemble(\"path/to/ensemble\")\ncluster_indices = ensemble.cluster_indices(\"T4a\")\nfirst_cluster = ensemble[cluster_indices[0]]\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If stored clustering does not match ensemble.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def cluster_indices(self, cell_type: str) -&gt; Dict[int, NDArray[int]]:\n    \"\"\"Clusters from responses to naturalistic stimuli of the given cell type.\n\n    Args:\n        cell_type: The cell type to return the clusters for.\n\n    Returns:\n        Dict[int, NDArray[int]]: Keys are the cluster ids and the values are the\n        model indices in the ensemble.\n\n    Example:\n        ```python\n        ensemble = Ensemble(\"path/to/ensemble\")\n        cluster_indices = ensemble.cluster_indices(\"T4a\")\n        first_cluster = ensemble[cluster_indices[0]]\n        ```\n\n    Raises:\n        ValueError: If stored clustering does not match ensemble.\n    \"\"\"\n    clustering = self.clustering(cell_type)\n    cluster_indices = get_cluster_to_indices(\n        clustering.embedding.mask,\n        clustering.labels,\n        task_error=self.task_error(),\n    )\n\n    _models = sorted(np.concatenate(list(cluster_indices.values())))\n    if len(_models) != clustering.embedding.mask.sum() or len(_models) &gt; len(self):\n        raise ValueError(\"stored clustering does not match ensemble\")\n\n    return cluster_indices\n</code></pre>"},{"location":"reference/ensemble_view/#flyvis.network.Ensemble.responses_norm","title":"responses_norm","text":"<pre><code>responses_norm(rectified=False)\n</code></pre> <p>Compute the norm of responses to naturalistic stimuli.</p> <p>Parameters:</p> Name Type Description Default <code>rectified</code> <code>bool</code> <p>Whether to rectify responses before computing norm.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Norm of responses for each network.</p> Source code in <code>flyvis/network/ensemble.py</code> <pre><code>def responses_norm(self, rectified: bool = False) -&gt; np.ndarray:\n    \"\"\"Compute the norm of responses to naturalistic stimuli.\n\n    Args:\n        rectified: Whether to rectify responses before computing norm.\n\n    Returns:\n        np.ndarray: Norm of responses for each network.\n    \"\"\"\n    response_set = self.naturalistic_stimuli_responses()\n    responses = response_set['responses'].values\n\n    def compute_norm(X, rectified=True):\n        \"\"\"Computes a normalization constant for stimulus\n            responses per cell hypothesis, i.e. cell_type independent values.\n\n        Args:\n            X: (n_stimuli, n_frames, n_cell_types)\n        \"\"\"\n        if rectified:\n            X = np.maximum(X, 0)\n        n_models, n_samples, n_frames, n_cell_types = X.shape\n\n        # replace NaNs with 0\n        X[np.isnan(X)] = 0\n\n        return (\n            1\n            / np.sqrt(n_samples * n_frames)\n            * np.linalg.norm(\n                X,\n                axis=(1, 2),\n                keepdims=True,\n            )\n        )\n\n    return np.take(\n        compute_norm(responses, rectified=rectified), self.model_index, axis=0\n    )\n</code></pre>"},{"location":"reference/flash_responses/","title":"Flash responses","text":""},{"location":"reference/flash_responses/#rendering","title":"Rendering","text":""},{"location":"reference/flash_responses/#flyvis.datasets.flashes.RenderedFlashes","title":"flyvis.datasets.flashes.RenderedFlashes","text":"<p>               Bases: <code>Directory</code></p> <p>Render a directory with flashes for the Flashes dataset.</p> <p>Parameters:</p> Name Type Description Default <code>boxfilter</code> <code>Dict[str, int]</code> <p>Parameters for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>dynamic_range</code> <code>List[float]</code> <p>Range of intensities. E.g. [0, 1] renders flashes with decrement 0.5-&gt;0 and increment 0.5-&gt;1.</p> <code>[0, 1]</code> <code>t_stim</code> <code>float</code> <p>Duration of the stimulus.</p> <code>1.0</code> <code>t_pre</code> <code>float</code> <p>Duration of the grey stimulus.</p> <code>1.0</code> <code>dt</code> <code>float</code> <p>Timesteps.</p> <code>1 / 200</code> <code>radius</code> <code>List[int]</code> <p>Radius of the stimulus.</p> <code>[-1, 6]</code> <code>alternations</code> <code>Tuple[int, ...]</code> <p>Sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> <code>(0, 1, 0)</code> <p>Attributes:</p> Name Type Description <code>flashes</code> <code>ArrayFile</code> <p>Array containing rendered flash sequences.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>@root(renderings_dir)\nclass RenderedFlashes(Directory):\n    \"\"\"Render a directory with flashes for the Flashes dataset.\n\n    Args:\n        boxfilter: Parameters for the BoxEye filter.\n        dynamic_range: Range of intensities. E.g. [0, 1] renders flashes\n            with decrement 0.5-&gt;0 and increment 0.5-&gt;1.\n        t_stim: Duration of the stimulus.\n        t_pre: Duration of the grey stimulus.\n        dt: Timesteps.\n        radius: Radius of the stimulus.\n        alternations: Sequence of alternations between lower or upper intensity and\n            baseline of the dynamic range.\n\n    Attributes:\n        flashes (ArrayFile): Array containing rendered flash sequences.\n    \"\"\"\n\n    def __init__(\n        self,\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        dynamic_range: List[float] = [0, 1],\n        t_stim: float = 1.0,\n        t_pre: float = 1.0,\n        dt: float = 1 / 200,\n        radius: List[int] = [-1, 6],\n        alternations: Tuple[int, ...] = (0, 1, 0),\n    ):\n        boxfilter = BoxEye(**boxfilter)\n        n_ommatidia = len(boxfilter.receptor_centers)\n        dynamic_range = np.array(dynamic_range)\n        baseline = 2 * (dynamic_range.sum() / 2,)\n\n        intensity = dynamic_range.copy()\n        values = np.array(list(zip(baseline, intensity)))\n        samples = dict(v=values, r=radius)\n        values = list(product(*(v for v in samples.values())))\n        sequence = []  # samples, #frames, width, height\n        for (baseline, intensity), rad in tqdm(values, desc=\"Flashes\"):\n            sequence.append(\n                render_flash(\n                    n_ommatidia,\n                    intensity,\n                    baseline,\n                    t_stim,\n                    t_pre,\n                    dt,\n                    alternations,\n                    rad,\n                )\n            )\n\n        self.flashes = np.array(sequence)\n</code></pre>"},{"location":"reference/flash_responses/#datasets","title":"Datasets","text":""},{"location":"reference/flash_responses/#flyvis.datasets.flashes.Flashes","title":"flyvis.datasets.flashes.Flashes","text":"<p>               Bases: <code>SequenceDataset</code></p> <p>Flashes dataset.</p> <p>Parameters:</p> Name Type Description Default <code>boxfilter</code> <code>Dict[str, int]</code> <p>Parameters for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>dynamic_range</code> <code>List[float]</code> <p>Range of intensities. E.g. [0, 1] renders flashes with decrement 0.5-&gt;0 and increment 0.5-&gt;1.</p> <code>[0, 1]</code> <code>t_stim</code> <code>float</code> <p>Duration of the stimulus.</p> <code>1.0</code> <code>t_pre</code> <code>float</code> <p>Duration of the grey stimulus.</p> <code>1.0</code> <code>dt</code> <code>float</code> <p>Timesteps.</p> <code>1 / 200</code> <code>radius</code> <code>List[int]</code> <p>Radius of the stimulus.</p> <code>[-1, 6]</code> <code>alternations</code> <code>Tuple[int, ...]</code> <p>Sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> <code>(0, 1, 0)</code> <p>Attributes:</p> Name Type Description <code>dt</code> <code>Union[float, None]</code> <p>Timestep.</p> <code>t_post</code> <code>float</code> <p>Post-stimulus time.</p> <code>flashes_dir</code> <p>Directory containing rendered flashes.</p> <code>config</code> <p>Configuration object.</p> <code>baseline</code> <p>Baseline intensity.</p> <code>arg_df</code> <p>DataFrame containing flash parameters.</p> Note <p>Zero alternation is the prestimulus and baseline. One alternation is the central stimulus. Has to start with zero alternation. <code>t_pre</code> is the duration of the prestimulus and <code>t_stim</code> is the duration of the stimulus.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>class Flashes(SequenceDataset):\n    \"\"\"Flashes dataset.\n\n    Args:\n        boxfilter: Parameters for the BoxEye filter.\n        dynamic_range: Range of intensities. E.g. [0, 1] renders flashes\n            with decrement 0.5-&gt;0 and increment 0.5-&gt;1.\n        t_stim: Duration of the stimulus.\n        t_pre: Duration of the grey stimulus.\n        dt: Timesteps.\n        radius: Radius of the stimulus.\n        alternations: Sequence of alternations between lower or upper intensity and\n            baseline of the dynamic range.\n\n    Attributes:\n        dt: Timestep.\n        t_post: Post-stimulus time.\n        flashes_dir: Directory containing rendered flashes.\n        config: Configuration object.\n        baseline: Baseline intensity.\n        arg_df: DataFrame containing flash parameters.\n\n    Note:\n        Zero alternation is the prestimulus and baseline. One alternation is the\n        central stimulus. Has to start with zero alternation. `t_pre` is the\n        duration of the prestimulus and `t_stim` is the duration of the stimulus.\n    \"\"\"\n\n    dt: Union[float, None] = None\n    t_post: float = 0.0\n\n    def __init__(\n        self,\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        dynamic_range: List[float] = [0, 1],\n        t_stim: float = 1.0,\n        t_pre: float = 1.0,\n        dt: float = 1 / 200,\n        radius: List[int] = [-1, 6],\n        alternations: Tuple[int, ...] = (0, 1, 0),\n    ):\n        assert alternations[0] == 0, \"First alternation must be 0.\"\n        self.flashes_dir = RenderedFlashes(\n            boxfilter=boxfilter,\n            dynamic_range=dynamic_range,\n            t_stim=t_stim,\n            t_pre=t_pre,\n            dt=dt,\n            radius=radius,\n            alternations=alternations,\n        )\n        self.config = self.flashes_dir.config\n        baseline = 2 * (sum(dynamic_range) / 2,)\n        intensity = dynamic_range.copy()\n\n        params = [\n            (p[0][0], p[0][1], p[1])\n            for p in list(product(zip(baseline, intensity), radius))\n        ]\n        self.baseline = baseline[0]\n        self.arg_df = pd.DataFrame(params, columns=[\"baseline\", \"intensity\", \"radius\"])\n\n        self.dt = dt\n\n    @property\n    def t_pre(self) -&gt; float:\n        \"\"\"Duration of the prestimulus and zero alternation.\"\"\"\n        return self.config.t_pre\n\n    @property\n    def t_stim(self) -&gt; float:\n        \"\"\"Duration of the one alternation.\"\"\"\n        return self.config.t_stim\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Index the dataset.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Flash sequence at the given index.\n        \"\"\"\n        return torch.Tensor(self.flashes_dir.flashes[key])\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the dataset.\"\"\"\n        return f\"Flashes dataset. Parametrization: \\n{self.arg_df}\"\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.flashes.Flashes.t_pre","title":"t_pre  <code>property</code>","text":"<pre><code>t_pre\n</code></pre> <p>Duration of the prestimulus and zero alternation.</p>"},{"location":"reference/flash_responses/#flyvis.datasets.flashes.Flashes.t_stim","title":"t_stim  <code>property</code>","text":"<pre><code>t_stim\n</code></pre> <p>Duration of the one alternation.</p>"},{"location":"reference/flash_responses/#flyvis.datasets.flashes.Flashes.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Index the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Flash sequence at the given index.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Index the dataset.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Flash sequence at the given index.\n    \"\"\"\n    return torch.Tensor(self.flashes_dir.flashes[key])\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.flashes.Flashes.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Return a string representation of the dataset.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the dataset.\"\"\"\n    return f\"Flashes dataset. Parametrization: \\n{self.arg_df}\"\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.flashes.render_flash","title":"flyvis.datasets.flashes.render_flash","text":"<pre><code>render_flash(n_ommatidia, intensity, baseline, t_stim, t_pre, dt, alternations, radius)\n</code></pre> <p>Generate a sequence of flashes on a hexagonal lattice.</p> <p>Parameters:</p> Name Type Description Default <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> required <code>intensity</code> <code>float</code> <p>Intensity of the flash.</p> required <code>baseline</code> <code>float</code> <p>Intensity of the baseline.</p> required <code>t_stim</code> <code>float</code> <p>Duration of the stimulus.</p> required <code>t_pre</code> <code>float</code> <p>Duration of the grey stimulus.</p> required <code>dt</code> <code>float</code> <p>Timesteps.</p> required <code>alternations</code> <code>Tuple[int, ...]</code> <p>Sequence of alternations between lower or upper intensity and baseline of the dynamic range.</p> required <code>radius</code> <code>int</code> <p>Radius of the stimulus.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Generated flash sequence.</p> Source code in <code>flyvis/datasets/flashes.py</code> <pre><code>def render_flash(\n    n_ommatidia: int,\n    intensity: float,\n    baseline: float,\n    t_stim: float,\n    t_pre: float,\n    dt: float,\n    alternations: Tuple[int, ...],\n    radius: int,\n) -&gt; np.ndarray:\n    \"\"\"Generate a sequence of flashes on a hexagonal lattice.\n\n    Args:\n        n_ommatidia: Number of ommatidia.\n        intensity: Intensity of the flash.\n        baseline: Intensity of the baseline.\n        t_stim: Duration of the stimulus.\n        t_pre: Duration of the grey stimulus.\n        dt: Timesteps.\n        alternations: Sequence of alternations between lower or upper intensity\n            and baseline of the dynamic range.\n        radius: Radius of the stimulus.\n\n    Returns:\n        Generated flash sequence.\n    \"\"\"\n    stimulus = torch.ones(n_ommatidia)[None] * baseline\n\n    if radius != -1:\n        ring = HexLattice.filled_circle(\n            radius=radius, center=Hexal(0, 0, 0), as_lattice=True\n        )\n        coordinate_index = ring.where(1)\n    else:\n        coordinate_index = np.arange(n_ommatidia)\n\n    stimulus[:, coordinate_index] = intensity\n\n    on = resample(stimulus, t_stim, dt)\n    off = resample(torch.ones(n_ommatidia)[None] * baseline, t_pre, dt)\n\n    whole_stimulus = []\n    for switch in alternations:\n        if switch == 0:\n            whole_stimulus.append(off)\n        elif switch == 1:\n            whole_stimulus.append(on)\n    return torch.cat(whole_stimulus, dim=0).cpu().numpy()\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.Dots","title":"flyvis.datasets.dots.Dots","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Render flashes aka dots per ommatidia.</p> Note <p>Renders directly in receptor space, does not use BoxEye or HexEye as eye-model.</p> <p>Parameters:</p> Name Type Description Default <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>max_extent</code> <code>int</code> <p>Maximum extent of the stimulus.</p> <code>15</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>1 / 200</code> <code>t_impulse</code> <code>Optional[float]</code> <p>Impulse duration.</p> <code>None</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>Literal['sustained', 'impulse']</code> <p>Stimulus mode (\u2018sustained\u2019 or \u2018impulse\u2019).</p> <code>'sustained'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> <p>Attributes:</p> Name Type Description <code>dt</code> <code>Optional[float]</code> <p>Time step.</p> <code>arg_df</code> <code>Optional[DataFrame]</code> <p>DataFrame containing stimulus parameters.</p> <code>config</code> <p>Namespace containing configuration parameters.</p> <code>t_stim</code> <p>Stimulus duration.</p> <code>n_ommatidia</code> <p>Number of ommatidia.</p> <code>offsets</code> <p>Array of ommatidia offsets.</p> <code>u</code> <p>U-coordinates of the hexagonal grid.</p> <code>v</code> <p>V-coordinates of the hexagonal grid.</p> <code>extent_condition</code> <p>Boolean mask for the extent condition.</p> <code>max_extent</code> <p>Maximum extent of the stimulus.</p> <code>bg_intensity</code> <p>Background intensity.</p> <code>intensities</code> <p>List of stimulus intensities.</p> <code>device</code> <p>Torch device for computations.</p> <code>mode</code> <p>Stimulus mode (\u2018sustained\u2019 or \u2018impulse\u2019).</p> <code>params</code> <p>List of stimulus parameters.</p> <code>t_impulse</code> <p>Impulse duration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dot_column_radius is greater than max_extent.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>class Dots(StimulusDataset):\n    \"\"\"\n    Render flashes aka dots per ommatidia.\n\n    Note:\n        Renders directly in receptor space, does not use BoxEye or HexEye as eye-model.\n\n    Args:\n        dot_column_radius: Radius of the dot column.\n        max_extent: Maximum extent of the stimulus.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        t_impulse: Impulse duration.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode ('sustained' or 'impulse').\n        device: Torch device for computations.\n\n    Attributes:\n        dt: Time step.\n        arg_df: DataFrame containing stimulus parameters.\n        config: Namespace containing configuration parameters.\n        t_stim: Stimulus duration.\n        n_ommatidia: Number of ommatidia.\n        offsets: Array of ommatidia offsets.\n        u: U-coordinates of the hexagonal grid.\n        v: V-coordinates of the hexagonal grid.\n        extent_condition: Boolean mask for the extent condition.\n        max_extent: Maximum extent of the stimulus.\n        bg_intensity: Background intensity.\n        intensities: List of stimulus intensities.\n        device: Torch device for computations.\n        mode: Stimulus mode ('sustained' or 'impulse').\n        params: List of stimulus parameters.\n        t_impulse: Impulse duration.\n\n    Raises:\n        ValueError: If dot_column_radius is greater than max_extent.\n    \"\"\"\n\n    dt: Optional[float] = None\n    arg_df: Optional[pd.DataFrame] = None\n\n    def __init__(\n        self,\n        dot_column_radius: int = 0,\n        max_extent: int = 15,\n        bg_intensity: float = 0.5,\n        t_stim: float = 5,\n        dt: float = 1 / 200,\n        t_impulse: Optional[float] = None,\n        n_ommatidia: int = 721,\n        t_pre: float = 2.0,\n        t_post: float = 0,\n        intensity: float = 1,\n        mode: Literal[\"sustained\", \"impulse\"] = \"sustained\",\n        device: torch.device = flyvis.device,\n    ):\n        if dot_column_radius &gt; max_extent:\n            raise ValueError(\"dot_column_radius must be smaller than max_extent\")\n        self.config = Namespace(\n            dot_column_radius=dot_column_radius,\n            max_extent=max_extent,\n            bg_intensity=bg_intensity,\n            t_stim=t_stim,\n            dt=dt,\n            n_ommatidia=n_ommatidia,\n            t_pre=t_pre,\n            t_post=t_post,\n            intensity=intensity,\n            mode=mode,\n            t_impulse=t_impulse,\n        )\n\n        self.t_stim = t_stim\n        self.t_pre = t_pre\n        self.t_post = t_post\n\n        self.n_ommatidia = n_ommatidia\n        self.offsets = np.arange(self.n_ommatidia)\n\n        u, v = hex_utils.get_hex_coords(hex_utils.get_hextent(n_ommatidia))\n        extent_condition = (\n            (-max_extent &lt;= u)\n            &amp; (u &lt;= max_extent)\n            &amp; (-max_extent &lt;= v)\n            &amp; (v &lt;= max_extent)\n            &amp; (-max_extent &lt;= u + v)\n            &amp; (u + v &lt;= max_extent)\n        )\n        self.u = u[extent_condition]\n        self.v = v[extent_condition]\n        # self.offsets = self.offsets[extent_condition]\n        self.extent_condition = extent_condition\n\n        # to have multi column dots at every location, construct coordinate_indices\n        # for each central column\n        coordinate_indices = []\n        for u, v in zip(self.u, self.v):\n            ring = HexLattice.filled_circle(\n                radius=dot_column_radius, center=Hexal(u, v, 0), as_lattice=True\n            )\n            # mask = np.array([~np.isnan(h.value) for h in h1])\n            coordinate_indices.append(self.offsets[ring.where(1)])\n\n        self.max_extent = max_extent\n        self.bg_intensity = bg_intensity\n\n        self.intensities = [2 * bg_intensity - intensity, intensity]\n        self.device = device\n        self.mode = mode\n\n        self.params = [\n            (*p[0], p[-1])\n            for p in list(\n                product(\n                    zip(self.u, self.v, self.offsets, coordinate_indices),\n                    self.intensities,\n                )\n            )\n        ]\n\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\"u\", \"v\", \"offset\", \"coordinate_index\", \"intensity\"],\n        )\n\n        self.dt = dt\n        self.t_impulse = t_impulse or self.dt\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a specific key.\n\n        Args:\n            key: Index of the parameters to retrieve.\n\n        Returns:\n            Array of parameters for the given key.\n        \"\"\"\n        return self.arg_df.iloc[key].values\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get a stimulus item for a specific key.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Tensor representing the stimulus sequence.\n        \"\"\"\n        # create maps with background value\n        _dot = (\n            torch.ones(self.n_ommatidia, device=self.device)[None, None]\n            * self.bg_intensity\n        )\n        # fill at the ommatitdium at offset with intensity\n        _, _, _, coordinate_index, intensity = self._params(key)\n        _dot[:, :, coordinate_index] = torch.tensor(intensity, device=self.device).float()\n\n        # repeat for stustained stimulus\n        if self.mode == \"sustained\":\n            sequence = resample(_dot, self.t_stim, self.dt, dim=1, device=self.device)\n\n        elif self.mode == \"impulse\":\n            # pad remaining stimulus duration i.e. self.t_stim - self.dt with\n            # background intensity\n            if self.t_impulse == self.dt:\n                sequence = pad(\n                    _dot,\n                    self.t_stim,\n                    self.dt,\n                    mode=\"end\",\n                    fill=self.bg_intensity,\n                )\n            # first resample for t_impulse/dt then pad remaining stimulus\n            # duration, i.e. t_stim - t_impulse with background intensity\n            else:\n                sequence = resample(\n                    _dot, self.t_impulse, self.dt, dim=1, device=self.device\n                )\n                sequence = pad(\n                    sequence,\n                    self.t_stim,\n                    self.dt,\n                    mode=\"end\",\n                    fill=self.bg_intensity,\n                )\n\n        # pad with pre stimulus background\n        sequence = pad(\n            sequence,\n            self.t_stim + self.t_pre,\n            self.dt,\n            mode=\"start\",\n            fill=self.bg_intensity,\n        )\n        # pad with post stimulus background\n        sequence = pad(\n            sequence,\n            self.t_stim + self.t_pre + self.t_post,\n            self.dt,\n            mode=\"end\",\n            fill=self.bg_intensity,\n        )\n        return sequence.squeeze()\n\n    def get_stimulus_index(self, u: float, v: float, intensity: float) -&gt; int:\n        \"\"\"Get sequence ID from given arguments.\n\n        Args:\n            u: U-coordinate.\n            v: V-coordinate.\n            intensity: Stimulus intensity.\n\n        Returns:\n            Sequence ID.\n        \"\"\"\n        return StimulusDataset.get_stimulus_index(self, locals())\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.Dots.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get a stimulus item for a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor representing the stimulus sequence.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get a stimulus item for a specific key.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Tensor representing the stimulus sequence.\n    \"\"\"\n    # create maps with background value\n    _dot = (\n        torch.ones(self.n_ommatidia, device=self.device)[None, None]\n        * self.bg_intensity\n    )\n    # fill at the ommatitdium at offset with intensity\n    _, _, _, coordinate_index, intensity = self._params(key)\n    _dot[:, :, coordinate_index] = torch.tensor(intensity, device=self.device).float()\n\n    # repeat for stustained stimulus\n    if self.mode == \"sustained\":\n        sequence = resample(_dot, self.t_stim, self.dt, dim=1, device=self.device)\n\n    elif self.mode == \"impulse\":\n        # pad remaining stimulus duration i.e. self.t_stim - self.dt with\n        # background intensity\n        if self.t_impulse == self.dt:\n            sequence = pad(\n                _dot,\n                self.t_stim,\n                self.dt,\n                mode=\"end\",\n                fill=self.bg_intensity,\n            )\n        # first resample for t_impulse/dt then pad remaining stimulus\n        # duration, i.e. t_stim - t_impulse with background intensity\n        else:\n            sequence = resample(\n                _dot, self.t_impulse, self.dt, dim=1, device=self.device\n            )\n            sequence = pad(\n                sequence,\n                self.t_stim,\n                self.dt,\n                mode=\"end\",\n                fill=self.bg_intensity,\n            )\n\n    # pad with pre stimulus background\n    sequence = pad(\n        sequence,\n        self.t_stim + self.t_pre,\n        self.dt,\n        mode=\"start\",\n        fill=self.bg_intensity,\n    )\n    # pad with post stimulus background\n    sequence = pad(\n        sequence,\n        self.t_stim + self.t_pre + self.t_post,\n        self.dt,\n        mode=\"end\",\n        fill=self.bg_intensity,\n    )\n    return sequence.squeeze()\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.Dots.get_stimulus_index","title":"get_stimulus_index","text":"<pre><code>get_stimulus_index(u, v, intensity)\n</code></pre> <p>Get sequence ID from given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>float</code> <p>U-coordinate.</p> required <code>v</code> <code>float</code> <p>V-coordinate.</p> required <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Sequence ID.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_stimulus_index(self, u: float, v: float, intensity: float) -&gt; int:\n    \"\"\"Get sequence ID from given arguments.\n\n    Args:\n        u: U-coordinate.\n        v: V-coordinate.\n        intensity: Stimulus intensity.\n\n    Returns:\n        Sequence ID.\n    \"\"\"\n    return StimulusDataset.get_stimulus_index(self, locals())\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.CentralImpulses","title":"flyvis.datasets.dots.CentralImpulses","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Flashes at the center of the visual field for temporal receptive field mapping.</p> <p>Parameters:</p> Name Type Description Default <code>impulse_durations</code> <code>List[float]</code> <p>List of impulse durations.</p> <code>[0.005, 0.02, 0.05, 0.1, 0.2, 0.3]</code> <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>0.005</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Stimulus mode.</p> <code>'impulse'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> <p>Attributes:</p> Name Type Description <code>arg_df</code> <code>Optional[DataFrame]</code> <p>DataFrame containing stimulus parameters.</p> <code>dt</code> <code>Optional[float]</code> <p>Time step.</p> <code>dots</code> <p>Instance of the Dots class.</p> <code>impulse_durations</code> <p>List of impulse durations.</p> <code>config</code> <p>Configuration namespace.</p> <code>params</code> <p>List of stimulus parameters.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>class CentralImpulses(StimulusDataset):\n    \"\"\"Flashes at the center of the visual field for temporal receptive field mapping.\n\n    Args:\n        impulse_durations: List of impulse durations.\n        dot_column_radius: Radius of the dot column.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode.\n        device: Torch device for computations.\n\n    Attributes:\n        arg_df: DataFrame containing stimulus parameters.\n        dt: Time step.\n        dots: Instance of the Dots class.\n        impulse_durations: List of impulse durations.\n        config: Configuration namespace.\n        params: List of stimulus parameters.\n    \"\"\"\n\n    arg_df: Optional[pd.DataFrame] = None\n    dt: Optional[float] = None\n\n    def __init__(\n        self,\n        impulse_durations: List[float] = [5e-3, 20e-3, 50e-3, 100e-3, 200e-3, 300e-3],\n        dot_column_radius: int = 0,\n        bg_intensity: float = 0.5,\n        t_stim: float = 5,\n        dt: float = 0.005,\n        n_ommatidia: int = 721,\n        t_pre: float = 2.0,\n        t_post: float = 0,\n        intensity: float = 1,\n        mode: str = \"impulse\",\n        device: torch.device = flyvis.device,\n    ):\n        \"\"\"Initialize the CentralImpulses dataset.\n\n        Args:\n            impulse_durations: List of impulse durations.\n            dot_column_radius: Radius of the dot column.\n            bg_intensity: Background intensity.\n            t_stim: Stimulus duration.\n            dt: Time step.\n            n_ommatidia: Number of ommatidia.\n            t_pre: Pre-stimulus duration.\n            t_post: Post-stimulus duration.\n            intensity: Stimulus intensity.\n            mode: Stimulus mode.\n            device: Torch device for computations.\n        \"\"\"\n        self.dots = Dots(\n            dot_column_radius=dot_column_radius,\n            max_extent=dot_column_radius,\n            bg_intensity=bg_intensity,\n            t_stim=t_stim,\n            dt=dt,\n            n_ommatidia=n_ommatidia,\n            t_pre=t_pre,\n            t_post=t_post,\n            intensity=intensity,\n            mode=mode,\n            device=device,\n        )\n        self.impulse_durations = impulse_durations\n        self.config = self.dots.config\n        self.config.update(impulse_durations=impulse_durations)\n        self.params = [\n            (*p[0], p[1])\n            for p in product(self.dots.arg_df.values.tolist(), impulse_durations)\n        ]\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\n                \"u\",\n                \"v\",\n                \"offset\",\n                \"coordinate_index\",\n                \"intensity\",\n                \"t_impulse\",\n            ],\n        )\n        self.dt = dt\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a specific key.\n\n        Args:\n            key: Index of the parameters to retrieve.\n\n        Returns:\n            Array of parameters for the given key.\n        \"\"\"\n        return self.arg_df.iloc[key].values\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get a stimulus item for a specific key.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Tensor representing the stimulus sequence.\n        \"\"\"\n        u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n        self.dots.t_impulse = t_impulse\n        return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n\n    @property\n    def t_pre(self) -&gt; float:\n        \"\"\"Get pre-stimulus duration.\"\"\"\n        return self.dots.t_pre\n\n    @property\n    def t_post(self) -&gt; float:\n        \"\"\"Get post-stimulus duration.\"\"\"\n        return self.dots.t_post\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Get string representation of the dataset.\"\"\"\n        return repr(self.arg_df)\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.CentralImpulses.t_pre","title":"t_pre  <code>property</code>","text":"<pre><code>t_pre\n</code></pre> <p>Get pre-stimulus duration.</p>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.CentralImpulses.t_post","title":"t_post  <code>property</code>","text":"<pre><code>t_post\n</code></pre> <p>Get post-stimulus duration.</p>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.CentralImpulses.__init__","title":"__init__","text":"<pre><code>__init__(impulse_durations=[0.005, 0.02, 0.05, 0.1, 0.2, 0.3], dot_column_radius=0, bg_intensity=0.5, t_stim=5, dt=0.005, n_ommatidia=721, t_pre=2.0, t_post=0, intensity=1, mode='impulse', device=flyvis.device)\n</code></pre> <p>Initialize the CentralImpulses dataset.</p> <p>Parameters:</p> Name Type Description Default <code>impulse_durations</code> <code>List[float]</code> <p>List of impulse durations.</p> <code>[0.005, 0.02, 0.05, 0.1, 0.2, 0.3]</code> <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>0.005</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Stimulus mode.</p> <code>'impulse'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def __init__(\n    self,\n    impulse_durations: List[float] = [5e-3, 20e-3, 50e-3, 100e-3, 200e-3, 300e-3],\n    dot_column_radius: int = 0,\n    bg_intensity: float = 0.5,\n    t_stim: float = 5,\n    dt: float = 0.005,\n    n_ommatidia: int = 721,\n    t_pre: float = 2.0,\n    t_post: float = 0,\n    intensity: float = 1,\n    mode: str = \"impulse\",\n    device: torch.device = flyvis.device,\n):\n    \"\"\"Initialize the CentralImpulses dataset.\n\n    Args:\n        impulse_durations: List of impulse durations.\n        dot_column_radius: Radius of the dot column.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode.\n        device: Torch device for computations.\n    \"\"\"\n    self.dots = Dots(\n        dot_column_radius=dot_column_radius,\n        max_extent=dot_column_radius,\n        bg_intensity=bg_intensity,\n        t_stim=t_stim,\n        dt=dt,\n        n_ommatidia=n_ommatidia,\n        t_pre=t_pre,\n        t_post=t_post,\n        intensity=intensity,\n        mode=mode,\n        device=device,\n    )\n    self.impulse_durations = impulse_durations\n    self.config = self.dots.config\n    self.config.update(impulse_durations=impulse_durations)\n    self.params = [\n        (*p[0], p[1])\n        for p in product(self.dots.arg_df.values.tolist(), impulse_durations)\n    ]\n    self.arg_df = pd.DataFrame(\n        self.params,\n        columns=[\n            \"u\",\n            \"v\",\n            \"offset\",\n            \"coordinate_index\",\n            \"intensity\",\n            \"t_impulse\",\n        ],\n    )\n    self.dt = dt\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.CentralImpulses.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get a stimulus item for a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor representing the stimulus sequence.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get a stimulus item for a specific key.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Tensor representing the stimulus sequence.\n    \"\"\"\n    u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n    self.dots.t_impulse = t_impulse\n    return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.CentralImpulses.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Get string representation of the dataset.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Get string representation of the dataset.\"\"\"\n    return repr(self.arg_df)\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.SpatialImpulses","title":"flyvis.datasets.dots.SpatialImpulses","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Spatial flashes for spatial receptive field mapping.</p> <p>Parameters:</p> Name Type Description Default <code>impulse_durations</code> <code>List[float]</code> <p>List of impulse durations.</p> <code>[0.005, 0.02]</code> <code>max_extent</code> <code>int</code> <p>Maximum extent of the stimulus.</p> <code>4</code> <code>dot_column_radius</code> <code>int</code> <p>Radius of the dot column.</p> <code>0</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>5</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>0.005</code> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia.</p> <code>721</code> <code>t_pre</code> <code>float</code> <p>Pre-stimulus duration.</p> <code>2.0</code> <code>t_post</code> <code>float</code> <p>Post-stimulus duration.</p> <code>0</code> <code>intensity</code> <code>float</code> <p>Stimulus intensity.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Stimulus mode.</p> <code>'impulse'</code> <code>device</code> <code>device</code> <p>Torch device for computations.</p> <code>device</code> <p>Attributes:</p> Name Type Description <code>arg_df</code> <code>Optional[DataFrame]</code> <p>DataFrame containing stimulus parameters.</p> <code>dt</code> <code>Optional[float]</code> <p>Time step.</p> <code>dots</code> <p>Instance of the Dots class.</p> <code>impulse_durations</code> <p>List of impulse durations.</p> <code>config</code> <p>Configuration namespace.</p> <code>params</code> <p>List of stimulus parameters.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>class SpatialImpulses(StimulusDataset):\n    \"\"\"Spatial flashes for spatial receptive field mapping.\n\n    Args:\n        impulse_durations: List of impulse durations.\n        max_extent: Maximum extent of the stimulus.\n        dot_column_radius: Radius of the dot column.\n        bg_intensity: Background intensity.\n        t_stim: Stimulus duration.\n        dt: Time step.\n        n_ommatidia: Number of ommatidia.\n        t_pre: Pre-stimulus duration.\n        t_post: Post-stimulus duration.\n        intensity: Stimulus intensity.\n        mode: Stimulus mode.\n        device: Torch device for computations.\n\n    Attributes:\n        arg_df: DataFrame containing stimulus parameters.\n        dt: Time step.\n        dots: Instance of the Dots class.\n        impulse_durations: List of impulse durations.\n        config: Configuration namespace.\n        params: List of stimulus parameters.\n    \"\"\"\n\n    arg_df: Optional[pd.DataFrame] = None\n    dt: Optional[float] = None\n\n    def __init__(\n        self,\n        impulse_durations: List[float] = [5e-3, 20e-3],\n        max_extent: int = 4,\n        dot_column_radius: int = 0,\n        bg_intensity: float = 0.5,\n        t_stim: float = 5,\n        dt: float = 0.005,\n        n_ommatidia: int = 721,\n        t_pre: float = 2.0,\n        t_post: float = 0,\n        intensity: float = 1,\n        mode: str = \"impulse\",\n        device: torch.device = flyvis.device,\n    ):\n        self.dots = Dots(\n            dot_column_radius=dot_column_radius,\n            max_extent=max_extent,\n            bg_intensity=bg_intensity,\n            t_stim=t_stim,\n            dt=dt,\n            n_ommatidia=n_ommatidia,\n            t_pre=t_pre,\n            t_post=t_post,\n            intensity=intensity,\n            mode=mode,\n            device=device,\n        )\n        self.dt = dt\n        self.impulse_durations = impulse_durations\n\n        self.config = self.dots.config\n        self.config.update(impulse_durations=impulse_durations)\n\n        self.params = [\n            (*p[0], p[1])\n            for p in product(self.dots.arg_df.values.tolist(), impulse_durations)\n        ]\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\n                \"u\",\n                \"v\",\n                \"offset\",\n                \"coordinate_index\",\n                \"intensity\",\n                \"t_impulse\",\n            ],\n        )\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a specific key.\n\n        Args:\n            key: Index of the parameters to retrieve.\n\n        Returns:\n            Array of parameters for the given key.\n        \"\"\"\n        return self.arg_df.iloc[key].values\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get a stimulus item for a specific key.\n\n        Args:\n            key: Index of the item to retrieve.\n\n        Returns:\n            Tensor representing the stimulus sequence.\n        \"\"\"\n        u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n        self.dots.t_impulse = t_impulse\n        return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Get string representation of the dataset.\"\"\"\n        return repr(self.arg_df)\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.SpatialImpulses.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get a stimulus item for a specific key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor representing the stimulus sequence.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get a stimulus item for a specific key.\n\n    Args:\n        key: Index of the item to retrieve.\n\n    Returns:\n        Tensor representing the stimulus sequence.\n    \"\"\"\n    u, v, offset, coordinate_index, intensity, t_impulse = self._params(key)\n    self.dots.t_impulse = t_impulse\n    return self.dots[self.dots.get_stimulus_index(u, v, intensity)]\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.datasets.dots.SpatialImpulses.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Get string representation of the dataset.</p> Source code in <code>flyvis/datasets/dots.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Get string representation of the dataset.\"\"\"\n    return repr(self.arg_df)\n</code></pre>"},{"location":"reference/flash_responses/#analysis","title":"Analysis","text":""},{"location":"reference/flash_responses/#flyvis.analysis.flash_responses","title":"flyvis.analysis.flash_responses","text":"<p>Analysis of responses to flash stimuli.</p> Info <p>Relies on xarray dataset format defined in <code>flyvis.analysis.stimulus_responses</code>.</p>"},{"location":"reference/flash_responses/#flyvis.analysis.flash_responses.flash_response_index","title":"flash_response_index","text":"<pre><code>flash_response_index(self, radius, on_intensity=1.0, off_intensity=0.0, nonnegative=True)\n</code></pre> <p>Compute the Flash Response Index (FRI) using xarray methods.</p> <p>Parameters:</p> Name Type Description Default <code>self</code> <code>DataArray</code> <p>The input DataArray containing response data.</p> required <code>radius</code> <code>float</code> <p>The radius value to select data for.</p> required <code>on_intensity</code> <code>float</code> <p>The intensity value for the \u2018on\u2019 state.</p> <code>1.0</code> <code>off_intensity</code> <code>float</code> <p>The intensity value for the \u2018off\u2019 state.</p> <code>0.0</code> <code>nonnegative</code> <code>bool</code> <p>If True, applies a nonnegative constraint to the data.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>xr.DataArray: The computed Flash Response Index.</p> Note <p>Ensures that the stimulus configuration is correct for FRI computation.</p> Source code in <code>flyvis/analysis/flash_responses.py</code> <pre><code>def flash_response_index(\n    self: xr.DataArray,\n    radius: float,\n    on_intensity: float = 1.0,\n    off_intensity: float = 0.0,\n    nonnegative: bool = True,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute the Flash Response Index (FRI) using xarray methods.\n\n    Args:\n        self: The input DataArray containing response data.\n        radius: The radius value to select data for.\n        on_intensity: The intensity value for the 'on' state.\n        off_intensity: The intensity value for the 'off' state.\n        nonnegative: If True, applies a nonnegative constraint to the data.\n\n    Returns:\n        xr.DataArray: The computed Flash Response Index.\n\n    Note:\n        Ensures that the stimulus configuration is correct for FRI computation.\n    \"\"\"\n\n    # Ensure that the stimulus configuration is correct for FRI computation\n    assert tuple(self.attrs['config']['alternations']) == (0, 1, 0)\n\n    responses = self['responses']\n\n    # Select the time window for the stimulus response using query\n    time_query = (\n        f\"{-self.attrs['config']['dt']} &lt;= time &lt;= {self.attrs['config']['t_stim']}\"\n    )\n    stim_response = responses.query(frame=time_query)\n\n    # Select the data for the given radius\n    stim_response = stim_response.query(sample=f'radius=={radius}')\n\n    # Apply nonnegative constraint if required\n    if nonnegative:\n        minimum = stim_response.min(dim=['frame', 'sample'])\n        stim_response += np.abs(minimum)\n\n    # Select the response data for on and off intensities\n    r_on = stim_response.query(sample=f'intensity=={on_intensity}')\n    r_off = stim_response.query(sample=f'intensity=={off_intensity}')\n\n    # Compute the peak responses by finding the maximum along the 'frame' dimension\n    on_peak = r_on.max(dim='frame')\n    off_peak = r_off.max(dim='frame')\n\n    # Drop the 'sample' coordinate to avoid broadcasting issues\n    on_peak = on_peak.drop('sample')\n    off_peak = off_peak.drop('sample')\n\n    # Compute the Flash Response Index (FRI)\n    fri = on_peak - off_peak\n    fri /= on_peak + off_peak + np.array([1e-16])\n\n    # Optionally, you can drop NaN values after computation\n    return fri.dropna(dim='sample', how='any')\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.analysis.flash_responses.fri_correlation_to_known","title":"fri_correlation_to_known","text":"<pre><code>fri_correlation_to_known(fris)\n</code></pre> <p>Compute the correlation of the FRI to known cell type tunings.</p> <p>Parameters:</p> Name Type Description Default <code>fris</code> <code>DataArray</code> <p>DataArray containing Flash Response Index values.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>xr.DataArray: Correlation of FRIs to known cell type tunings.</p> Source code in <code>flyvis/analysis/flash_responses.py</code> <pre><code>def fri_correlation_to_known(fris: xr.DataArray) -&gt; xr.DataArray:\n    \"\"\"\n    Compute the correlation of the FRI to known cell type tunings.\n\n    Args:\n        fris: DataArray containing Flash Response Index values.\n\n    Returns:\n        xr.DataArray: Correlation of FRIs to known cell type tunings.\n    \"\"\"\n    known_preferred_contrasts = {\n        k: v for k, v in groundtruth_utils.polarity.items() if v != 0\n    }\n    known_cell_types = list(known_preferred_contrasts.keys())\n    groundtruth = list(known_preferred_contrasts.values())\n\n    index = np.array([\n        np.where(nt == fris.cell_type)[0].item() for i, nt in enumerate(known_cell_types)\n    ])\n    fris = fris.isel(neuron=index)\n    groundtruth = xr.DataArray(\n        data=groundtruth,\n        dims=[\"neuron\"],\n    )\n    return xr.corr(fris, groundtruth, dim=\"neuron\")\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.analysis.flash_responses.plot_fris","title":"plot_fris","text":"<pre><code>plot_fris(fris, cell_types, scatter_best=False, scatter_all=True, bold_output_type_labels=True, output_cell_types=None, known_first=True, sorted_type_list=None, figsize=[10, 1], cmap=plt.cm.Greys_r, ylim=(-1, 1), color_known_types=True, fontsize=6, colors=None, color='b', showmeans=False, showmedians=True, scatter_edge_width=0.5, scatter_best_edge_width=0.75, scatter_edge_color='none', scatter_face_color='k', scatter_alpha=0.35, scatter_best_alpha=1.0, scatter_all_marker='o', scatter_best_index=None, scatter_best_marker='o', scatter_best_color=None, mean_median_linewidth=1.5, mean_median_bar_length=1.0, violin_alpha=0.3, **kwargs)\n</code></pre> <p>Plot flash response indices (FRIs) for the given cell types with violins.</p> <p>Parameters:</p> Name Type Description Default <code>fris</code> <code>ndarray</code> <p>Array of FRI values (n_random_variables, n_groups, n_samples).</p> required <code>cell_types</code> <code>ndarray</code> <p>Array of cell type labels, corresponding to the first axis (n_random_variables) of <code>fris</code>.</p> required <code>scatter_best</code> <code>bool</code> <p>If True, scatter the best points.</p> <code>False</code> <code>scatter_all</code> <code>bool</code> <p>If True, scatter all points.</p> <code>True</code> <code>bold_output_type_labels</code> <code>bool</code> <p>If True, bold the output type labels.</p> <code>True</code> <code>output_cell_types</code> <code>Optional[List[str]]</code> <p>List of cell types to bold in the output.</p> <code>None</code> <code>known_first</code> <code>bool</code> <p>If True, sort known cell types first.</p> <code>True</code> <code>sorted_type_list</code> <code>Optional[List[str]]</code> <p>List of cell types to sort by.</p> <code>None</code> <code>figsize</code> <code>List[int]</code> <p>Figure size as [width, height].</p> <code>[10, 1]</code> <code>cmap</code> <code>cm</code> <p>Colormap for the plot.</p> <code>Greys_r</code> <code>ylim</code> <code>Tuple[float, float]</code> <p>Y-axis limits as (min, max).</p> <code>(-1, 1)</code> <code>color_known_types</code> <code>bool</code> <p>If True, color known cell type labels.</p> <code>True</code> <code>fontsize</code> <code>int</code> <p>Font size for labels.</p> <code>6</code> <code>colors</code> <code>Optional[List[str]]</code> <p>List of colors for the violins.</p> <code>None</code> <code>color</code> <code>str</code> <p>Single color for all violins if cmap is None.</p> <code>'b'</code> <code>showmeans</code> <code>bool</code> <p>If True, show means on the violins.</p> <code>False</code> <code>showmedians</code> <code>bool</code> <p>If True, show medians on the violins.</p> <code>True</code> <code>scatter_edge_width</code> <code>float</code> <p>Width of scatter point edges.</p> <code>0.5</code> <code>scatter_best_edge_width</code> <code>float</code> <p>Width of best scatter point edges.</p> <code>0.75</code> <code>scatter_edge_color</code> <code>str</code> <p>Color of scatter point edges.</p> <code>'none'</code> <code>scatter_face_color</code> <code>str</code> <p>Color of scatter point faces.</p> <code>'k'</code> <code>scatter_alpha</code> <code>float</code> <p>Alpha value for scatter points.</p> <code>0.35</code> <code>scatter_best_alpha</code> <code>float</code> <p>Alpha value for best scatter points.</p> <code>1.0</code> <code>scatter_all_marker</code> <code>str</code> <p>Marker style for all scatter points.</p> <code>'o'</code> <code>scatter_best_index</code> <code>Optional[int]</code> <p>Index of the best scatter point.</p> <code>None</code> <code>scatter_best_marker</code> <code>str</code> <p>Marker style for the best scatter point.</p> <code>'o'</code> <code>scatter_best_color</code> <code>Optional[str]</code> <p>Color of the best scatter point.</p> <code>None</code> <code>mean_median_linewidth</code> <code>float</code> <p>Line width for mean/median lines.</p> <code>1.5</code> <code>mean_median_bar_length</code> <code>float</code> <p>Length of mean/median bars.</p> <code>1.0</code> <code>violin_alpha</code> <code>float</code> <p>Alpha value for violin plots.</p> <code>0.3</code> <code>**kwargs</code> <p>Additional keyword arguments for violin_groups.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>Tuple containing the Figure and Axes objects.</p> Source code in <code>flyvis/analysis/flash_responses.py</code> <pre><code>def plot_fris(\n    fris: np.ndarray,\n    cell_types: np.ndarray,\n    scatter_best: bool = False,\n    scatter_all: bool = True,\n    bold_output_type_labels: bool = True,\n    output_cell_types: Optional[List[str]] = None,\n    known_first: bool = True,\n    sorted_type_list: Optional[List[str]] = None,\n    figsize: List[int] = [10, 1],\n    cmap: plt.cm = plt.cm.Greys_r,\n    ylim: Tuple[float, float] = (-1, 1),\n    color_known_types: bool = True,\n    fontsize: int = 6,\n    colors: Optional[List[str]] = None,\n    color: str = \"b\",\n    showmeans: bool = False,\n    showmedians: bool = True,\n    scatter_edge_width: float = 0.5,\n    scatter_best_edge_width: float = 0.75,\n    scatter_edge_color: str = \"none\",\n    scatter_face_color: str = \"k\",\n    scatter_alpha: float = 0.35,\n    scatter_best_alpha: float = 1.0,\n    scatter_all_marker: str = \"o\",\n    scatter_best_index: Optional[int] = None,\n    scatter_best_marker: str = \"o\",\n    scatter_best_color: Optional[str] = None,\n    mean_median_linewidth: float = 1.5,\n    mean_median_bar_length: float = 1.0,\n    violin_alpha: float = 0.3,\n    **kwargs,\n) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"\n    Plot flash response indices (FRIs) for the given cell types with violins.\n\n    Args:\n        fris: Array of FRI values (n_random_variables, n_groups, n_samples).\n        cell_types: Array of cell type labels, corresponding to the first axis\n            (n_random_variables) of `fris`.\n        scatter_best: If True, scatter the best points.\n        scatter_all: If True, scatter all points.\n        bold_output_type_labels: If True, bold the output type labels.\n        output_cell_types: List of cell types to bold in the output.\n        known_first: If True, sort known cell types first.\n        sorted_type_list: List of cell types to sort by.\n        figsize: Figure size as [width, height].\n        cmap: Colormap for the plot.\n        ylim: Y-axis limits as (min, max).\n        color_known_types: If True, color known cell type labels.\n        fontsize: Font size for labels.\n        colors: List of colors for the violins.\n        color: Single color for all violins if cmap is None.\n        showmeans: If True, show means on the violins.\n        showmedians: If True, show medians on the violins.\n        scatter_edge_width: Width of scatter point edges.\n        scatter_best_edge_width: Width of best scatter point edges.\n        scatter_edge_color: Color of scatter point edges.\n        scatter_face_color: Color of scatter point faces.\n        scatter_alpha: Alpha value for scatter points.\n        scatter_best_alpha: Alpha value for best scatter points.\n        scatter_all_marker: Marker style for all scatter points.\n        scatter_best_index: Index of the best scatter point.\n        scatter_best_marker: Marker style for the best scatter point.\n        scatter_best_color: Color of the best scatter point.\n        mean_median_linewidth: Line width for mean/median lines.\n        mean_median_bar_length: Length of mean/median bars.\n        violin_alpha: Alpha value for violin plots.\n        **kwargs: Additional keyword arguments for violin_groups.\n\n    Returns:\n        Tuple containing the Figure and Axes objects.\n    \"\"\"\n    # Process FRIs data\n    if len(fris.shape) != 3:\n        fris = fris[:, None]\n    if fris.shape[0] != len(cell_types):\n        fris = np.transpose(fris, (2, 1, 0))\n\n    # Sort cell types\n    if sorted_type_list is not None:\n        fris = nodes_edges_utils.sort_by_mapping_lists(\n            cell_types, sorted_type_list, fris, axis=0\n        )\n        cell_types = np.array(sorted_type_list)\n    if known_first:\n        _cell_types = nodes_edges_utils.nodes_list_sorting_on_off_unknown(cell_types)\n        fris = nodes_edges_utils.sort_by_mapping_lists(\n            cell_types, _cell_types, fris, axis=0\n        )\n        cell_types = np.array(_cell_types)\n\n    # Set colors\n    if colors is not None:\n        pass\n    elif cmap is not None:\n        colors = None\n    elif color is not None:\n        cmap = None\n        colors = (color,)\n\n    # Create violin plot\n    fig, ax, colors = violin_groups(\n        fris,\n        cell_types[:],\n        rotation=90,\n        scatter=False,\n        cmap=cmap,\n        colors=colors,\n        fontsize=fontsize,\n        figsize=figsize,\n        width=0.7,\n        showmeans=showmeans,\n        showmedians=showmedians,\n        mean_median_linewidth=mean_median_linewidth,\n        mean_median_bar_length=mean_median_bar_length,\n        violin_alpha=violin_alpha,\n        **kwargs,\n    )\n\n    # Add scatter points if necessary\n    if fris.shape[1] == 1:\n        plt_utils.scatter_on_violins_with_best(\n            fris.T.squeeze(),\n            ax,\n            scatter_best,\n            scatter_all,\n            best_index=scatter_best_index,\n            linewidth=scatter_edge_width,\n            best_linewidth=scatter_best_edge_width,\n            edgecolor=scatter_edge_color,\n            facecolor=scatter_face_color,\n            all_scatter_alpha=scatter_alpha,\n            best_scatter_alpha=scatter_best_alpha,\n            all_marker=scatter_all_marker,\n            best_marker=scatter_best_marker,\n            best_color=scatter_best_color,\n        )\n\n    # Customize plot appearance\n    ax.grid(False)\n    if bold_output_type_labels and output_cell_types is not None:\n        plt_utils.boldify_labels(output_cell_types, ax)\n    ax.set_ylim(*ylim)\n    plt_utils.trim_axis(ax)\n    plt_utils.set_spine_tick_params(\n        ax,\n        tickwidth=0.5,\n        ticklength=3,\n        ticklabelpad=2,\n        spinewidth=0.5,\n    )\n    if color_known_types:\n        ax = flash_response_color_labels(ax)\n    ax.hlines(\n        0,\n        min(ax.get_xticks()),\n        max(ax.get_xticks()),\n        linewidth=0.25,\n        color=\"k\",\n        zorder=0,\n    )\n    ax.set_yticks(np.arange(-1.0, 1.5, 0.5))\n\n    return fig, ax\n</code></pre>"},{"location":"reference/flash_responses/#flyvis.analysis.flash_responses.flash_response_color_labels","title":"flash_response_color_labels","text":"<pre><code>flash_response_color_labels(ax)\n</code></pre> <p>Color the labels of ON and OFF cells in the plot.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The matplotlib Axes object to modify.</p> required <p>Returns:</p> Type Description <code>Axes</code> <p>The modified matplotlib Axes object.</p> Source code in <code>flyvis/analysis/flash_responses.py</code> <pre><code>def flash_response_color_labels(ax: plt.Axes) -&gt; plt.Axes:\n    \"\"\"\n    Color the labels of ON and OFF cells in the plot.\n\n    Args:\n        ax: The matplotlib Axes object to modify.\n\n    Returns:\n        The modified matplotlib Axes object.\n    \"\"\"\n    on = [key for key, value in groundtruth_utils.polarity.items() if value == 1]\n    off = [key for key, value in groundtruth_utils.polarity.items() if value == -1]\n    plt_utils.color_labels(on, ON_FR, ax)\n    plt_utils.color_labels(off, OFF_FR, ax)\n    return ax\n</code></pre>"},{"location":"reference/hydra_default_config/","title":"Configuration System","text":"<p><code>flyvis</code> uses Hydra for configuration management of network and training. The configuration system is organized hierarchically, allowing for modular configuration of different components.</p>"},{"location":"reference/hydra_default_config/#configuration-components","title":"Configuration Components","text":""},{"location":"reference/hydra_default_config/#configuration-components_1","title":"Configuration Components","text":""},{"location":"reference/hydra_default_config/#network-configuration","title":"Network Configuration","text":"<ul> <li><code>network/</code>: Core network architecture and parameters</li> <li><code>connectome/</code>: Neural connectivity specification</li> <li><code>dynamics/</code>: Neural dynamics parameters</li> <li><code>edge_config/</code>: Synapse-related configurations (sign, strength, count)</li> <li><code>node_config/</code>: Neuron-related configurations (bias, time constants)</li> <li><code>stimulus_config/</code>: Input stimulus parameters</li> </ul>"},{"location":"reference/hydra_default_config/#training-configuration","title":"Training Configuration","text":"<ul> <li><code>optim/</code>: Optimization parameters</li> <li><code>penalizer/</code>: Loss function penalties</li> <li><code>scheduler/</code>: Learning rate scheduling</li> <li><code>task/</code>: Task-specific settings and parameters</li> </ul>"},{"location":"reference/hydra_default_config/#top-level-configuration","title":"Top-level Configuration","text":"<ul> <li><code>solver.yaml</code>: Training loop parameters</li> </ul>"},{"location":"reference/hydra_default_config/#default-configuration-structure","title":"Default Configuration Structure","text":"<p>The default configuration is structured as follows:</p> <pre><code>config\n\u251c\u2500\u2500 network                         # Network configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 connectome                  # Connectome configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 connectome.yaml         # Default connectome configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dynamics                    # Dynamics configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dynamics.yaml           # Default dynamics configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 edge_config                 # Edge configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 edge_config.yaml        # Default edge configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sign                    # Signaling configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sign.yaml           # Default signaling configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 syn_count               # Synaptic count configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 syn_count.yaml      # Default synaptic count configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 syn_strength            # Synaptic strength configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 syn_strength.yaml   # Default synaptic strength configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 network.yaml                # Default network configuration\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 node_config                 # Node configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bias                    # Bias configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bias.yaml           # Default bias configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 node_config.yaml        # Default node configuration\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 time_const              # Time constant configurations\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 time_const.yaml     # Default time constant configuration\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 stimulus_config             # Stimulus configuration\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 stimulus_config.yaml    # Default stimulus configuration\n\u251c\u2500\u2500 optim                           # Optimizer configuration\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 optim.yaml                  # Default optimizer configuration\n\u251c\u2500\u2500 penalizer                       # Penalizer configuration\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 penalizer.yaml              # Default penalizer configuration\n\u251c\u2500\u2500 scheduler                       # Scheduler configuration\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scheduler.yaml              # Default scheduler configuration\n\u251c\u2500\u2500 solver.yaml                     # Default solver configuration\n\u2514\u2500\u2500 task                            # Task configuration\n    \u2514\u2500\u2500 task.yaml                   # Default task configuration\n\n15 directories, 16 files\n</code></pre>"},{"location":"reference/hydra_default_config/#customizing-configurations","title":"Customizing Configurations","text":""},{"location":"reference/hydra_default_config/#overriding-default-parameters","title":"Overriding Default Parameters","text":"<p>For quick parameter changes you can use hydra command-line overrides.</p> <pre><code># Example: Change the scale of the synaptic strength to 0.5\nflyvis train-single network.edge_config.syn_strength.scale=0.5 ensemble_and_network_id=0042/007 task_name=flow\n\n# Example: Add a custom parameter to an existing config\nflyvis train-single +network.edge_config.syn_strength.custom_param=100 ensemble_and_network_id=0042/007 task_name=flow\n</code></pre> <p>More information on hydra command-line overrides can be found here.</p>"},{"location":"reference/hydra_default_config/#using-custom-configurations","title":"Using Custom Configurations","text":"<p>In many situations you will want to create custom configuration files, to either break the existing config structure for new code or to keep track of different sets of parameters.</p> <p>This particularly applies when installing <code>flyvis</code> as a package instead of using the developer mode, where one can directly modify the source code configuration.</p> <p>To create and maintain your own configuration files proceed as follows:</p> <ol> <li> <p>Initialize a local config directory:</p> <pre><code># Copy the default config structure into flyvis_config\nflyvis init-config\n</code></pre> </li> <li> <p>Create your custom configurations in the generated <code>flyvis_config</code> directory.</p> </li> <li> <p>Use your custom configs:</p> <pre><code># Using the full custom config directory\nflyvis train-single --config-path $(pwd)/flyvis_config [other options]\n\n# Using a specific custom config\nflyvis train-single network/edge_config/syn_strength=custom_syn_strength --config-dir $(pwd)/flyvis_config\n</code></pre> <p>Notice that <code>config-path</code> overrides the entire default config directory, while <code>config-dir</code> only adds another search path for resolving configs.</p> <p>Important: It is recommended to use different file names than the defaults. This is because for partial usage with <code>config-dir</code> hydra resolves the config names in the default config directory first. I.e., your changes reflected in files of the same name in the custom config directory might not have the intended effect. E.g., name your config file <code>custom_syn_strength.yaml</code> instead of <code>syn_strength.yaml</code>.</p> </li> </ol> <p>More information on hydra configuration can be found here.</p>"},{"location":"reference/moving_stimulus_responses/","title":"Moving Stimulus Responses","text":""},{"location":"reference/moving_stimulus_responses/#rendering","title":"Rendering","text":""},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.RenderedOffsets","title":"flyvis.datasets.moving_bar.RenderedOffsets","text":"<p>               Bases: <code>Directory</code></p> <p>Rendered offsets for the moving bar stimulus.</p> <p>This class precomputes the offsets for moving bar (edge) stimuli and stores them in a directory. At runtime, the offsets are resampled to efficiently generate stimuli with different durations and temporal resolutions.</p> <p>Parameters:</p> Name Type Description Default <code>offsets</code> <code>list[int]</code> <p>List of offset values.</p> <code>list(range(-10, 11))</code> <code>angles</code> <code>list[int]</code> <p>List of angle values in degrees.</p> <code>[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]</code> <code>widths</code> <code>list[int]</code> <p>List of width values.</p> <code>[1, 2, 4]</code> <code>intensities</code> <code>list[int]</code> <p>List of intensity values.</p> <code>[0, 1]</code> <code>led_width</code> <code>float</code> <p>Width of LED in radians.</p> <code>radians(2.25)</code> <code>height</code> <code>float</code> <p>Height of the bar in radians.</p> <code>radians(2.25) * 9</code> <code>n_bars</code> <code>int</code> <p>Number of bars.</p> <code>1</code> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>0.5</code> <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of the bar in radians.</p> <code>radians(90)</code> <p>Attributes:</p> Name Type Description <code>offsets</code> <code>ArrayFile</code> <p>Rendered offsets for different stimulus parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>@root(renderings_dir)\nclass RenderedOffsets(Directory):\n    \"\"\"Rendered offsets for the moving bar stimulus.\n\n    This class precomputes the offsets for moving bar (edge) stimuli and stores them\n    in a directory. At runtime, the offsets are resampled to efficiently generate\n    stimuli with different durations and temporal resolutions.\n\n    Args:\n        offsets: List of offset values.\n        angles: List of angle values in degrees.\n        widths: List of width values.\n        intensities: List of intensity values.\n        led_width: Width of LED in radians.\n        height: Height of the bar in radians.\n        n_bars: Number of bars.\n        bg_intensity: Background intensity.\n        bar_loc_horizontal: Horizontal location of the bar in radians.\n\n    Attributes:\n        offsets (ArrayFile): Rendered offsets for different stimulus parameters.\n    \"\"\"\n\n    def __init__(\n        self,\n        offsets: list[int] = list(range(-10, 11)),\n        angles: list[int] = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n        widths: list[int] = [1, 2, 4],\n        intensities: list[int] = [0, 1],\n        led_width: float = np.radians(2.25),\n        height: float = np.radians(2.25) * 9,\n        n_bars: int = 1,\n        bg_intensity: float = 0.5,\n        bar_loc_horizontal: float = np.radians(90),\n    ):\n        eye = HexEye(721, 25)\n\n        params = list(product(angles, widths, intensities))\n\n        sequences = {}\n        _tqdm = tqdm(total=len(params), desc=\"building stimuli\")\n        for angle in angles:\n            for width in widths:\n                for intensity in intensities:\n                    offset_bars = eye.render_offset_bars(\n                        bar_width_rad=width * led_width,\n                        bar_height_rad=height,\n                        n_bars=n_bars,\n                        offsets=np.array(offsets) * led_width,\n                        bar_intensity=intensity,\n                        bg_intensity=bg_intensity,\n                        moving_angle=angle,\n                        bar_loc_horizontal=bar_loc_horizontal,\n                    )\n                    sequences[(angle, width, intensity)] = offset_bars\n                    _tqdm.update()\n\n        _tqdm.close()\n        self.offsets = torch.stack([sequences[p] for p in params]).cpu().numpy()\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#datasets","title":"Datasets","text":""},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar","title":"flyvis.datasets.moving_bar.MovingBar","text":"<p>               Bases: <code>StimulusDataset</code></p> <p>Moving bar stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>widths</code> <code>list[int]</code> <p>Width of the bar in half ommatidia.</p> <code>[1, 2, 4]</code> <code>offsets</code> <code>tuple[int, int]</code> <p>First and last offset to the central column in half ommatidia.</p> <code>(-10, 11)</code> <code>intensities</code> <code>list[float]</code> <p>Intensity of the bar.</p> <code>[0, 1]</code> <code>speeds</code> <code>list[float]</code> <p>Speed of the bar in half ommatidia per second.</p> <code>[2.4, 4.8, 9.7, 13, 19, 25]</code> <code>height</code> <code>int</code> <p>Height of the bar in half ommatidia.</p> <code>9</code> <code>dt</code> <code>float</code> <p>Time step in seconds.</p> <code>1 / 200</code> <code>device</code> <code>str</code> <p>Device to store the stimulus.</p> <code>device</code> <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of the bar in radians from left to right of image plane. np.radians(90) is the center.</p> <code>radians(90)</code> <code>post_pad_mode</code> <code>Literal['continue', 'value', 'reflect']</code> <p>Padding mode after the stimulus. One of \u2018continue\u2019, \u2018value\u2019, \u2018reflect\u2019. If \u2018value\u2019 the padding is filled with <code>bg_intensity</code>.</p> <code>'value'</code> <code>t_pre</code> <code>float</code> <p>Time before the stimulus in seconds.</p> <code>1.0</code> <code>t_post</code> <code>float</code> <p>Time after the stimulus in seconds.</p> <code>1.0</code> <code>build_stim_on_init</code> <code>bool</code> <p>Build the stimulus on initialization.</p> <code>True</code> <code>shuffle_offsets</code> <code>bool</code> <p>Shuffle the offsets to remove spatio-temporal correlation.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Seed for the random state.</p> <code>0</code> <code>angles</code> <code>list[int]</code> <p>List of angles in degrees.</p> <code>[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]</code> <p>Attributes:</p> Name Type Description <code>config</code> <code>Namespace</code> <p>Configuration parameters.</p> <code>omm_width</code> <code>float</code> <p>Width of ommatidium in radians.</p> <code>led_width</code> <code>float</code> <p>Width of LED in radians.</p> <code>angles</code> <code>ndarray</code> <p>Array of angles in degrees.</p> <code>widths</code> <code>ndarray</code> <p>Array of widths in half ommatidia.</p> <code>offsets</code> <code>ndarray</code> <p>Array of offsets in half ommatidia.</p> <code>intensities</code> <code>ndarray</code> <p>Array of intensities.</p> <code>speeds</code> <code>ndarray</code> <p>Array of speeds in half ommatidia per second.</p> <code>bg_intensity</code> <code>float</code> <p>Background intensity.</p> <code>n_bars</code> <code>int</code> <p>Number of bars.</p> <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of bar in radians.</p> <code>t_stim</code> <code>ndarray</code> <p>Stimulation times for each speed.</p> <code>t_stim_max</code> <code>float</code> <p>Maximum stimulation time.</p> <code>height</code> <code>float</code> <p>Height of bar in radians.</p> <code>post_pad_mode</code> <code>str</code> <p>Padding mode after the stimulus.</p> <code>arg_df</code> <code>DataFrame</code> <p>DataFrame of stimulus parameters.</p> <code>arg_group_df</code> <code>DataFrame</code> <p>Grouped DataFrame of stimulus parameters.</p> <code>device</code> <code>str</code> <p>Device for storing stimuli.</p> <code>shuffle_offsets</code> <code>bool</code> <p>Whether to shuffle offsets.</p> <code>randomstate</code> <code>RandomState</code> <p>Random state for shuffling.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>class MovingBar(StimulusDataset):\n    \"\"\"Moving bar stimulus.\n\n    Args:\n        widths: Width of the bar in half ommatidia.\n        offsets: First and last offset to the central column in half ommatidia.\n        intensities: Intensity of the bar.\n        speeds: Speed of the bar in half ommatidia per second.\n        height: Height of the bar in half ommatidia.\n        dt: Time step in seconds.\n        device: Device to store the stimulus.\n        bar_loc_horizontal: Horizontal location of the bar in radians from left to\n            right of image plane. np.radians(90) is the center.\n        post_pad_mode: Padding mode after the stimulus. One of 'continue', 'value',\n            'reflect'. If 'value' the padding is filled with `bg_intensity`.\n        t_pre: Time before the stimulus in seconds.\n        t_post: Time after the stimulus in seconds.\n        build_stim_on_init: Build the stimulus on initialization.\n        shuffle_offsets: Shuffle the offsets to remove spatio-temporal correlation.\n        seed: Seed for the random state.\n        angles: List of angles in degrees.\n\n    Attributes:\n        config (Namespace): Configuration parameters.\n        omm_width (float): Width of ommatidium in radians.\n        led_width (float): Width of LED in radians.\n        angles (np.ndarray): Array of angles in degrees.\n        widths (np.ndarray): Array of widths in half ommatidia.\n        offsets (np.ndarray): Array of offsets in half ommatidia.\n        intensities (np.ndarray): Array of intensities.\n        speeds (np.ndarray): Array of speeds in half ommatidia per second.\n        bg_intensity (float): Background intensity.\n        n_bars (int): Number of bars.\n        bar_loc_horizontal (float): Horizontal location of bar in radians.\n        t_stim (np.ndarray): Stimulation times for each speed.\n        t_stim_max (float): Maximum stimulation time.\n        height (float): Height of bar in radians.\n        post_pad_mode (str): Padding mode after the stimulus.\n        arg_df (pd.DataFrame): DataFrame of stimulus parameters.\n        arg_group_df (pd.DataFrame): Grouped DataFrame of stimulus parameters.\n        device (str): Device for storing stimuli.\n        shuffle_offsets (bool): Whether to shuffle offsets.\n        randomstate (np.random.RandomState): Random state for shuffling.\n    \"\"\"\n\n    arg_df: pd.DataFrame = None\n\n    def __init__(\n        self,\n        widths: list[int] = [1, 2, 4],\n        offsets: tuple[int, int] = (-10, 11),\n        intensities: list[float] = [0, 1],\n        speeds: list[float] = [2.4, 4.8, 9.7, 13, 19, 25],\n        height: int = 9,\n        dt: float = 1 / 200,\n        device: str = flyvis.device,\n        bar_loc_horizontal: float = np.radians(90),\n        post_pad_mode: Literal[\"continue\", \"value\", \"reflect\"] = \"value\",\n        t_pre: float = 1.0,\n        t_post: float = 1.0,\n        build_stim_on_init: bool = True,\n        shuffle_offsets: bool = False,\n        seed: int = 0,\n        angles: list[int] = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n    ) -&gt; None:\n        super().__init__()\n        # HexEye parameter\n        self.omm_width = np.radians(5.8)  # radians(5.8 degree)\n\n        # Monitor parameter\n        self.led_width = np.radians(2.25)  # Gruntman et al. 2018\n\n        _locals = locals()\n        self.config = Namespace({\n            arg: _locals[arg]\n            for arg in [\n                \"widths\",\n                \"offsets\",\n                \"intensities\",\n                \"speeds\",\n                \"height\",\n                \"bar_loc_horizontal\",\n                \"shuffle_offsets\",\n                \"post_pad_mode\",\n                \"t_pre\",\n                \"t_post\",\n                \"dt\",\n                \"angles\",\n            ]\n        })\n\n        # Stim parameter\n        self.angles = np.array(angles)\n        self.widths = np.array(widths)  # half ommatidia\n        if len(offsets) == 2:\n            self.offsets = np.arange(*offsets)  # half ommatidia\n        else:\n            assert (\n                np.mean(offsets[1:] - offsets[:-1]) == 1\n            )  # t_stim assumes spacing of 1 corresponding to 2.25 deg\n            self.offsets = offsets\n        self.intensities = np.array(intensities)\n        self.speeds = np.array(speeds)\n        self.bg_intensity = 0.5\n        self.n_bars = 1\n        self.bar_loc_horizontal = bar_loc_horizontal\n\n        self.t_stim = (len(self.offsets) * self.led_width) / (\n            self.speeds * self.omm_width\n        )\n        self.t_stim_max = np.max(self.t_stim)\n\n        self._speed_to_t_stim = dict(zip(self.speeds, self.t_stim))\n\n        self.height = self.led_width * height\n\n        self.post_pad_mode = post_pad_mode\n        self._t_pre = t_pre\n        self._t_post = t_post\n\n        params = [\n            (*p[:-1], *p[-1])\n            for p in list(\n                product(\n                    self.angles,\n                    self.widths,\n                    self.intensities,\n                    zip(self.t_stim, self.speeds),\n                )\n            )\n        ]\n        self.arg_df = pd.DataFrame(\n            params, columns=[\"angle\", \"width\", \"intensity\", \"t_stim\", \"speed\"]\n        )\n\n        self.arg_group_df = self.arg_df.groupby(\n            [\"angle\", \"width\", \"intensity\"], sort=False, as_index=False\n        ).all()\n\n        self.device = device\n        self.shuffle_offsets = shuffle_offsets\n        self.randomstate = None\n        if self.shuffle_offsets:\n            self.randomstate = np.random.RandomState(seed=seed)\n\n        self._dt = dt\n\n        self._built = False\n        if build_stim_on_init:\n            self._build()\n            self._resample()\n            self._built = True\n\n    @property\n    def dt(self) -&gt; float:\n        \"\"\"Time step in seconds.\"\"\"\n        return getattr(self, \"_dt\", None)\n\n    @dt.setter\n    def dt(self, value: float) -&gt; None:\n        if self._dt == value:\n            self._dt = value\n            if self._built:\n                self._resample()\n            return\n        logging.warning(\n            \"Cannot override dt=%s because responses with dt=%s are initialized. \"\n            \"Keeping dt=%s.\",\n            value,\n            self._dt,\n            self._dt,\n        )\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"{self.__class__.__name__}\\n\"\n            + \"Config:\\n\"\n            + repr(self.config)\n            + \"Stimulus parameter:\\n\"\n            + repr(self.arg_df)\n        )\n\n    @property\n    def t_pre(self) -&gt; float:\n        \"\"\"Time before stimulus onset in seconds.\"\"\"\n        return self._t_pre\n\n    @property\n    def t_post(self) -&gt; float:\n        \"\"\"Time after stimulus offset in seconds.\"\"\"\n        return self._t_post\n\n    def _build(self) -&gt; None:\n        \"\"\"Build the stimulus.\"\"\"\n        self.wrap = RenderedOffsets(\n            dict(\n                angles=self.angles,\n                widths=self.widths,\n                intensities=self.intensities,\n                offsets=self.offsets,\n                led_width=self.led_width,\n                height=self.height,\n                n_bars=self.n_bars,\n                bg_intensity=self.bg_intensity,\n                bar_loc_horizontal=self.bar_loc_horizontal,\n            )\n        )\n\n        self._offsets = torch.tensor(self.wrap.offsets[:], device=self.device)\n        self._built = True\n\n    def _resample(self) -&gt; None:\n        \"\"\"Resample the stimulus at runtime.\"\"\"\n        # resampling at runtime to allow for changing dt and to save GB of\n        # storage.\n        self.sequences = {}\n        self.indices = {}\n        for t, speed in zip(self.t_stim, self.speeds):\n            sequence, indices = resample(\n                self._offsets,\n                t,\n                self.dt,\n                dim=1,\n                device=self.device,\n                return_indices=True,\n            )\n            if self.shuffle_offsets:\n                # breakpoint()\n                sequence = shuffle(sequence, self.randomstate)\n            sequence = pad(\n                sequence,\n                t + self.t_pre,\n                self.dt,\n                mode=\"start\",\n                fill=self.bg_intensity,\n            )\n            sequence = pad(\n                sequence,\n                t + self.t_pre + self.t_post,\n                self.dt,\n                mode=\"end\",\n                pad_mode=self.post_pad_mode,\n                fill=self.bg_intensity,\n            )\n            # Because we fix the distance that the bar moves but vary speeds we\n            # have different stimulation times. To make all sequences equal\n            # length for storing them in a single tensor, we pad them with nans\n            # based on the maximal stimulation time (slowest speed). The nans\n            # can later be removed before processing the traces.\n            sequence = pad(\n                sequence,\n                self.t_stim_max + self.t_pre + self.t_post,\n                self.dt,\n                mode=\"end\",\n                fill=np.nan,\n            )\n            self.sequences[speed] = sequence\n            self.indices[speed] = indices\n\n    def _key(self, angle: float, width: float, intensity: float, speed: float) -&gt; int:\n        \"\"\"Get the key for a specific stimulus configuration.\"\"\"\n        try:\n            return self.arg_df.query(\n                f\"angle=={angle}\"\n                f\" &amp; width=={width}\"\n                f\" &amp; intensity == {intensity}\"\n                f\" &amp; speed == {speed}\"\n            ).index.values.item()\n        except ValueError:\n            raise ValueError(\n                f\"angle: {angle}, width: {width}, intensity: {intensity}, \"\n                f\"speed: {speed} invalid.\"\n            ) from None\n\n    def get_sequence_id_from_arguments(\n        self, angle: float, width: float, intensity: float, speed: float\n    ) -&gt; int:\n        \"\"\"Get sequence ID from stimulus arguments.\"\"\"\n        return self.get_stimulus_index(locals())\n\n    def _params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get parameters for a given key.\"\"\"\n        return self.arg_df.iloc[key].values\n\n    def _group_key(self, angle: float, width: float, intensity: float) -&gt; int:\n        \"\"\"Get group key for a specific stimulus configuration.\"\"\"\n        return self.arg_group_df.query(\n            f\"angle=={angle}\" f\" &amp; width=={width}\" f\" &amp; intensity == {intensity}\"\n        ).index.values.item()\n\n    def _group_params(self, key: int) -&gt; np.ndarray:\n        \"\"\"Get group parameters for a given key.\"\"\"\n        return self.arg_group_df.iloc[key].values\n\n    def get(\n        self, angle: float, width: float, intensity: float, speed: float\n    ) -&gt; torch.Tensor:\n        \"\"\"Get stimulus for specific parameters.\"\"\"\n        key = self._key(angle, width, intensity, speed)\n        return self[key]\n\n    def get_item(self, key: int) -&gt; torch.Tensor:\n        \"\"\"Get stimulus for a specific key.\"\"\"\n        angle, width, intensity, _, speed = self._params(key)\n        return self.sequences[speed][self._group_key(angle, width, intensity)]\n\n    def mask(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n        t_stim: Optional[float] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Create a mask for specific stimulus parameters.\"\"\"\n        # 22x faster than df.query\n        values = self.arg_df.values\n\n        def iterparam(param, name, axis, and_condition):\n            condition = np.zeros(len(values)).astype(bool)\n            if isinstance(param, Iterable):\n                for p in param:\n                    _new = values.take(axis, axis=1) == p\n                    assert any(_new), f\"{name} {p} not in dataset.\"\n                    condition = np.logical_or(condition, _new)\n            else:\n                _new = values.take(axis, axis=1) == param\n                assert any(_new), f\"{name} {param} not in dataset.\"\n                condition = np.logical_or(condition, _new)\n            return condition &amp; and_condition\n\n        condition = np.ones(len(values)).astype(bool)\n        if angle is not None:\n            condition = iterparam(angle, \"angle\", 0, condition)\n        if width is not None:\n            condition = iterparam(width, \"width\", 1, condition)\n        if intensity is not None:\n            condition = iterparam(intensity, \"intensity\", 2, condition)\n        if t_stim is not None:\n            condition = iterparam(t_stim, \"t_stim\", 3, condition)\n        if speed is not None:\n            condition = iterparam(speed, \"speed\", 4, condition)\n        return condition\n\n    @property\n    def time(self) -&gt; np.ndarray:\n        \"\"\"Time array for the stimulus.\"\"\"\n        return np.arange(-self.t_pre, self.t_stim_max + self.t_post - self.dt, self.dt)\n\n    def stimulus(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n        pre_stim: bool = True,\n        post_stim: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Get stimulus for specific parameters.\n\n        Args:\n            angle: Angle of the bar.\n            width: Width of the bar.\n            intensity: Intensity of the bar.\n            speed: Speed of the bar.\n            pre_stim: Include pre-stimulus period.\n            post_stim: Include post-stimulus period.\n\n        Returns:\n            Stimulus array.\n        \"\"\"\n        key = self._key(angle, width, intensity, speed)\n        stim = self[key][:, 360].cpu().numpy()\n        if not post_stim:\n            stim = filter_post([stim], self.t_post, self.dt).squeeze()\n        if not pre_stim:\n            stim = filter_pre(stim[None], self.t_pre, self.dt).squeeze()\n        return stim\n\n    def stimulus_parameters(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n    ) -&gt; tuple[list, ...]:\n        \"\"\"Get stimulus parameters.\"\"\"\n\n        def _number_to_list(*args):\n            returns = tuple()\n            for arg in args:\n                if isinstance(arg, Number):\n                    returns += ([arg],)\n                else:\n                    returns += (arg,)\n            return returns\n\n        angle, width, speed, intensity = _number_to_list(angle, width, speed, intensity)\n        angle = angle or self.angles\n        width = width or self.widths\n        intensity = intensity or self.intensities\n        speed = speed or self.speeds\n        return angle, width, intensity, speed\n\n    def sample_shape(\n        self,\n        angle: Optional[float] = None,\n        width: Optional[float] = None,\n        intensity: Optional[float] = None,\n        speed: Optional[float] = None,\n    ) -&gt; tuple[int, ...]:\n        \"\"\"Get shape of stimulus sample for given parameters.\"\"\"\n        if isinstance(angle, Number):\n            angle = [angle]\n        if isinstance(width, Number):\n            width = [width]\n        if isinstance(speed, Number):\n            speed = [speed]\n        if isinstance(intensity, Number):\n            intensity = [intensity]\n        angle = angle or self.angles\n        width = width or self.widths\n        intensity = intensity or self.intensities\n        speed = speed or self.speeds\n        return (\n            len(angle),\n            len(width),\n            len(intensity),\n            len(speed),\n        )\n\n    def time_to_center(self, speed: float) -&gt; float:\n        \"\"\"Calculate time for bar to reach center at given speed.\"\"\"\n        # Note: time = distance / velocity, i.e.\n        #     time = (n_leds * led_width) / (speed * omm_width)\n        #     with speed in ommatidia / s.\n        return np.abs(self.config.offsets[0]) * self.led_width / (speed * self.omm_width)\n\n    def get_time_with_origin_at_onset(self) -&gt; np.ndarray:\n        \"\"\"Get time array with origin at stimulus onset.\"\"\"\n        return np.linspace(\n            -self.t_pre,\n            self.t_stim_max - self.t_pre + self.t_post,\n            int(self.t_stim_max / self.dt)\n            + int(self.t_post / self.dt)\n            + int(self.t_pre / self.dt),\n        )\n\n    def get_time_with_origin_at_center(self, speed: float) -&gt; np.ndarray:\n        \"\"\"Get time array with origin where bar reaches central column.\"\"\"\n        time_to_center = self.time_to_center(speed)\n        n_steps = (\n            int(self.t_stim_max / self.dt)\n            + int(self.t_post / self.dt)\n            + int(self.t_pre / self.dt)\n        )\n        return np.linspace(\n            -(self.t_pre + time_to_center),\n            n_steps * self.dt - (self.t_pre + time_to_center),\n            n_steps,\n        )\n\n    def stimulus_cartoon(\n        self,\n        angle: float,\n        width: float,\n        intensity: float,\n        speed: float,\n        time_after_stimulus_onset: float = 0.5,\n        fig: Optional[plt.Figure] = None,\n        ax: Optional[plt.Axes] = None,\n        facecolor: str = \"#000000\",\n        cmap: Colormap = plt.cm.bone,\n        alpha: float = 0.5,\n        vmin: float = 0,\n        vmax: float = 1,\n        edgecolor: str = \"none\",\n        central_hex_color: str = \"#2f7cb9\",\n        **kwargs,\n    ) -&gt; tuple[plt.Figure, plt.Axes]:\n        \"\"\"Create a cartoon representation of the stimulus.\"\"\"\n        fig, ax = init_plot(fig=fig, ax=ax)\n\n        time = (\n            np.arange(\n                0,\n                self.t_pre + self.t_stim_max + self.t_post - self.dt,\n                self.dt,\n            )\n            - self.t_pre\n        )\n        index = np.argmin(np.abs(time - time_after_stimulus_onset))\n\n        fig, ax, _ = quick_hex_scatter(\n            self.get(angle=angle, width=width, speed=speed, intensity=intensity)\n            .cpu()\n            .numpy()[index],\n            vmin=vmin,\n            vmax=vmax,\n            cbar=False,\n            figsize=[1, 1],\n            max_extent=5,\n            fig=fig,\n            ax=ax,\n            cmap=cmap,\n            alpha=alpha,\n            edgecolor=edgecolor,\n            **kwargs,\n        )\n        rotation = np.array([\n            [\n                np.cos(np.radians(angle - 90)),\n                -np.sin(np.radians(angle - 90)),\n            ],\n            [\n                np.sin(np.radians(angle - 90)),\n                np.cos(np.radians(angle - 90)),\n            ],\n        ])\n        x = rotation @ np.array([0, -5])\n        dx = rotation @ np.array([0, 1])\n        ax.arrow(\n            *x,\n            *dx,\n            facecolor=facecolor,\n            width=0.75,\n            head_length=2.5,\n            edgecolor=\"k\",\n            linewidth=0.25,\n        )\n        _hex = RegularPolygon(\n            (0, 0),\n            numVertices=6,\n            radius=1,\n            linewidth=1,\n            orientation=np.radians(30),\n            edgecolor=central_hex_color,\n            facecolor=central_hex_color,\n            alpha=1,\n            ls=\"-\",\n        )\n        ax.add_patch(_hex)\n\n        return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.dt","title":"dt  <code>property</code> <code>writable</code>","text":"<pre><code>dt\n</code></pre> <p>Time step in seconds.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.t_pre","title":"t_pre  <code>property</code>","text":"<pre><code>t_pre\n</code></pre> <p>Time before stimulus onset in seconds.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.t_post","title":"t_post  <code>property</code>","text":"<pre><code>t_post\n</code></pre> <p>Time after stimulus offset in seconds.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.time","title":"time  <code>property</code>","text":"<pre><code>time\n</code></pre> <p>Time array for the stimulus.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.get_sequence_id_from_arguments","title":"get_sequence_id_from_arguments","text":"<pre><code>get_sequence_id_from_arguments(angle, width, intensity, speed)\n</code></pre> <p>Get sequence ID from stimulus arguments.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_sequence_id_from_arguments(\n    self, angle: float, width: float, intensity: float, speed: float\n) -&gt; int:\n    \"\"\"Get sequence ID from stimulus arguments.\"\"\"\n    return self.get_stimulus_index(locals())\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.get","title":"get","text":"<pre><code>get(angle, width, intensity, speed)\n</code></pre> <p>Get stimulus for specific parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get(\n    self, angle: float, width: float, intensity: float, speed: float\n) -&gt; torch.Tensor:\n    \"\"\"Get stimulus for specific parameters.\"\"\"\n    key = self._key(angle, width, intensity, speed)\n    return self[key]\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Get stimulus for a specific key.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_item(self, key: int) -&gt; torch.Tensor:\n    \"\"\"Get stimulus for a specific key.\"\"\"\n    angle, width, intensity, _, speed = self._params(key)\n    return self.sequences[speed][self._group_key(angle, width, intensity)]\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.mask","title":"mask","text":"<pre><code>mask(angle=None, width=None, intensity=None, speed=None, t_stim=None)\n</code></pre> <p>Create a mask for specific stimulus parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def mask(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n    t_stim: Optional[float] = None,\n) -&gt; np.ndarray:\n    \"\"\"Create a mask for specific stimulus parameters.\"\"\"\n    # 22x faster than df.query\n    values = self.arg_df.values\n\n    def iterparam(param, name, axis, and_condition):\n        condition = np.zeros(len(values)).astype(bool)\n        if isinstance(param, Iterable):\n            for p in param:\n                _new = values.take(axis, axis=1) == p\n                assert any(_new), f\"{name} {p} not in dataset.\"\n                condition = np.logical_or(condition, _new)\n        else:\n            _new = values.take(axis, axis=1) == param\n            assert any(_new), f\"{name} {param} not in dataset.\"\n            condition = np.logical_or(condition, _new)\n        return condition &amp; and_condition\n\n    condition = np.ones(len(values)).astype(bool)\n    if angle is not None:\n        condition = iterparam(angle, \"angle\", 0, condition)\n    if width is not None:\n        condition = iterparam(width, \"width\", 1, condition)\n    if intensity is not None:\n        condition = iterparam(intensity, \"intensity\", 2, condition)\n    if t_stim is not None:\n        condition = iterparam(t_stim, \"t_stim\", 3, condition)\n    if speed is not None:\n        condition = iterparam(speed, \"speed\", 4, condition)\n    return condition\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.stimulus","title":"stimulus","text":"<pre><code>stimulus(angle=None, width=None, intensity=None, speed=None, pre_stim=True, post_stim=True)\n</code></pre> <p>Get stimulus for specific parameters.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>Optional[float]</code> <p>Angle of the bar.</p> <code>None</code> <code>width</code> <code>Optional[float]</code> <p>Width of the bar.</p> <code>None</code> <code>intensity</code> <code>Optional[float]</code> <p>Intensity of the bar.</p> <code>None</code> <code>speed</code> <code>Optional[float]</code> <p>Speed of the bar.</p> <code>None</code> <code>pre_stim</code> <code>bool</code> <p>Include pre-stimulus period.</p> <code>True</code> <code>post_stim</code> <code>bool</code> <p>Include post-stimulus period.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Stimulus array.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def stimulus(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n    pre_stim: bool = True,\n    post_stim: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Get stimulus for specific parameters.\n\n    Args:\n        angle: Angle of the bar.\n        width: Width of the bar.\n        intensity: Intensity of the bar.\n        speed: Speed of the bar.\n        pre_stim: Include pre-stimulus period.\n        post_stim: Include post-stimulus period.\n\n    Returns:\n        Stimulus array.\n    \"\"\"\n    key = self._key(angle, width, intensity, speed)\n    stim = self[key][:, 360].cpu().numpy()\n    if not post_stim:\n        stim = filter_post([stim], self.t_post, self.dt).squeeze()\n    if not pre_stim:\n        stim = filter_pre(stim[None], self.t_pre, self.dt).squeeze()\n    return stim\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.stimulus_parameters","title":"stimulus_parameters","text":"<pre><code>stimulus_parameters(angle=None, width=None, intensity=None, speed=None)\n</code></pre> <p>Get stimulus parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def stimulus_parameters(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n) -&gt; tuple[list, ...]:\n    \"\"\"Get stimulus parameters.\"\"\"\n\n    def _number_to_list(*args):\n        returns = tuple()\n        for arg in args:\n            if isinstance(arg, Number):\n                returns += ([arg],)\n            else:\n                returns += (arg,)\n        return returns\n\n    angle, width, speed, intensity = _number_to_list(angle, width, speed, intensity)\n    angle = angle or self.angles\n    width = width or self.widths\n    intensity = intensity or self.intensities\n    speed = speed or self.speeds\n    return angle, width, intensity, speed\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.sample_shape","title":"sample_shape","text":"<pre><code>sample_shape(angle=None, width=None, intensity=None, speed=None)\n</code></pre> <p>Get shape of stimulus sample for given parameters.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def sample_shape(\n    self,\n    angle: Optional[float] = None,\n    width: Optional[float] = None,\n    intensity: Optional[float] = None,\n    speed: Optional[float] = None,\n) -&gt; tuple[int, ...]:\n    \"\"\"Get shape of stimulus sample for given parameters.\"\"\"\n    if isinstance(angle, Number):\n        angle = [angle]\n    if isinstance(width, Number):\n        width = [width]\n    if isinstance(speed, Number):\n        speed = [speed]\n    if isinstance(intensity, Number):\n        intensity = [intensity]\n    angle = angle or self.angles\n    width = width or self.widths\n    intensity = intensity or self.intensities\n    speed = speed or self.speeds\n    return (\n        len(angle),\n        len(width),\n        len(intensity),\n        len(speed),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.time_to_center","title":"time_to_center","text":"<pre><code>time_to_center(speed)\n</code></pre> <p>Calculate time for bar to reach center at given speed.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def time_to_center(self, speed: float) -&gt; float:\n    \"\"\"Calculate time for bar to reach center at given speed.\"\"\"\n    # Note: time = distance / velocity, i.e.\n    #     time = (n_leds * led_width) / (speed * omm_width)\n    #     with speed in ommatidia / s.\n    return np.abs(self.config.offsets[0]) * self.led_width / (speed * self.omm_width)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.get_time_with_origin_at_onset","title":"get_time_with_origin_at_onset","text":"<pre><code>get_time_with_origin_at_onset()\n</code></pre> <p>Get time array with origin at stimulus onset.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_time_with_origin_at_onset(self) -&gt; np.ndarray:\n    \"\"\"Get time array with origin at stimulus onset.\"\"\"\n    return np.linspace(\n        -self.t_pre,\n        self.t_stim_max - self.t_pre + self.t_post,\n        int(self.t_stim_max / self.dt)\n        + int(self.t_post / self.dt)\n        + int(self.t_pre / self.dt),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.get_time_with_origin_at_center","title":"get_time_with_origin_at_center","text":"<pre><code>get_time_with_origin_at_center(speed)\n</code></pre> <p>Get time array with origin where bar reaches central column.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def get_time_with_origin_at_center(self, speed: float) -&gt; np.ndarray:\n    \"\"\"Get time array with origin where bar reaches central column.\"\"\"\n    time_to_center = self.time_to_center(speed)\n    n_steps = (\n        int(self.t_stim_max / self.dt)\n        + int(self.t_post / self.dt)\n        + int(self.t_pre / self.dt)\n    )\n    return np.linspace(\n        -(self.t_pre + time_to_center),\n        n_steps * self.dt - (self.t_pre + time_to_center),\n        n_steps,\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingBar.stimulus_cartoon","title":"stimulus_cartoon","text":"<pre><code>stimulus_cartoon(angle, width, intensity, speed, time_after_stimulus_onset=0.5, fig=None, ax=None, facecolor='#000000', cmap=plt.cm.bone, alpha=0.5, vmin=0, vmax=1, edgecolor='none', central_hex_color='#2f7cb9', **kwargs)\n</code></pre> <p>Create a cartoon representation of the stimulus.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>def stimulus_cartoon(\n    self,\n    angle: float,\n    width: float,\n    intensity: float,\n    speed: float,\n    time_after_stimulus_onset: float = 0.5,\n    fig: Optional[plt.Figure] = None,\n    ax: Optional[plt.Axes] = None,\n    facecolor: str = \"#000000\",\n    cmap: Colormap = plt.cm.bone,\n    alpha: float = 0.5,\n    vmin: float = 0,\n    vmax: float = 1,\n    edgecolor: str = \"none\",\n    central_hex_color: str = \"#2f7cb9\",\n    **kwargs,\n) -&gt; tuple[plt.Figure, plt.Axes]:\n    \"\"\"Create a cartoon representation of the stimulus.\"\"\"\n    fig, ax = init_plot(fig=fig, ax=ax)\n\n    time = (\n        np.arange(\n            0,\n            self.t_pre + self.t_stim_max + self.t_post - self.dt,\n            self.dt,\n        )\n        - self.t_pre\n    )\n    index = np.argmin(np.abs(time - time_after_stimulus_onset))\n\n    fig, ax, _ = quick_hex_scatter(\n        self.get(angle=angle, width=width, speed=speed, intensity=intensity)\n        .cpu()\n        .numpy()[index],\n        vmin=vmin,\n        vmax=vmax,\n        cbar=False,\n        figsize=[1, 1],\n        max_extent=5,\n        fig=fig,\n        ax=ax,\n        cmap=cmap,\n        alpha=alpha,\n        edgecolor=edgecolor,\n        **kwargs,\n    )\n    rotation = np.array([\n        [\n            np.cos(np.radians(angle - 90)),\n            -np.sin(np.radians(angle - 90)),\n        ],\n        [\n            np.sin(np.radians(angle - 90)),\n            np.cos(np.radians(angle - 90)),\n        ],\n    ])\n    x = rotation @ np.array([0, -5])\n    dx = rotation @ np.array([0, 1])\n    ax.arrow(\n        *x,\n        *dx,\n        facecolor=facecolor,\n        width=0.75,\n        head_length=2.5,\n        edgecolor=\"k\",\n        linewidth=0.25,\n    )\n    _hex = RegularPolygon(\n        (0, 0),\n        numVertices=6,\n        radius=1,\n        linewidth=1,\n        orientation=np.radians(30),\n        edgecolor=central_hex_color,\n        facecolor=central_hex_color,\n        alpha=1,\n        ls=\"-\",\n    )\n    ax.add_patch(_hex)\n\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.datasets.moving_bar.MovingEdge","title":"flyvis.datasets.moving_bar.MovingEdge","text":"<p>               Bases: <code>MovingBar</code></p> <p>Moving edge stimulus.</p> <p>This class creates a moving edge stimulus by using a very wide bar.</p> <p>Parameters:</p> Name Type Description Default <code>offsets</code> <code>tuple[int, int]</code> <p>First and last offset to the central column in half ommatidia.</p> <code>(-10, 11)</code> <code>intensities</code> <code>list[float]</code> <p>Intensity of the edge.</p> <code>[0, 1]</code> <code>speeds</code> <code>list[float]</code> <p>Speed of the edge in half ommatidia per second.</p> <code>[2.4, 4.8, 9.7, 13, 19, 25]</code> <code>height</code> <code>int</code> <p>Height of the edge in half ommatidia.</p> <code>9</code> <code>dt</code> <code>float</code> <p>Time step in seconds.</p> <code>1 / 200</code> <code>device</code> <code>str</code> <p>Device to store the stimulus.</p> <code>device</code> <code>post_pad_mode</code> <code>Literal['continue', 'value', 'reflect']</code> <p>Padding mode after the stimulus.</p> <code>'continue'</code> <code>t_pre</code> <code>float</code> <p>Time before the stimulus in seconds.</p> <code>1.0</code> <code>t_post</code> <code>float</code> <p>Time after the stimulus in seconds.</p> <code>1.0</code> <code>build_stim_on_init</code> <code>bool</code> <p>Build the stimulus on initialization.</p> <code>True</code> <code>shuffle_offsets</code> <code>bool</code> <p>Shuffle the offsets to remove spatio-temporal correlation.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Seed for the random state.</p> <code>0</code> <code>angles</code> <code>list[int]</code> <p>List of angles in degrees.</p> <code>[0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]</code> Note <p>This class uses a very wide bar (width=80) under the hood to render an edge stimulus.</p> Source code in <code>flyvis/datasets/moving_bar.py</code> <pre><code>class MovingEdge(MovingBar):\n    \"\"\"Moving edge stimulus.\n\n    This class creates a moving edge stimulus by using a very wide bar.\n\n    Args:\n        offsets: First and last offset to the central column in half ommatidia.\n        intensities: Intensity of the edge.\n        speeds: Speed of the edge in half ommatidia per second.\n        height: Height of the edge in half ommatidia.\n        dt: Time step in seconds.\n        device: Device to store the stimulus.\n        post_pad_mode: Padding mode after the stimulus.\n        t_pre: Time before the stimulus in seconds.\n        t_post: Time after the stimulus in seconds.\n        build_stim_on_init: Build the stimulus on initialization.\n        shuffle_offsets: Shuffle the offsets to remove spatio-temporal correlation.\n        seed: Seed for the random state.\n        angles: List of angles in degrees.\n\n    Note:\n        This class uses a very wide bar (width=80) under the hood to render an\n        edge stimulus.\n    \"\"\"\n\n    def __init__(\n        self,\n        offsets: tuple[int, int] = (-10, 11),\n        intensities: list[float] = [0, 1],\n        speeds: list[float] = [2.4, 4.8, 9.7, 13, 19, 25],\n        height: int = 9,\n        dt: float = 1 / 200,\n        device: str = flyvis.device,\n        post_pad_mode: Literal[\"continue\", \"value\", \"reflect\"] = \"continue\",\n        t_pre: float = 1.0,\n        t_post: float = 1.0,\n        build_stim_on_init: bool = True,\n        shuffle_offsets: bool = False,\n        seed: int = 0,\n        angles: list[int] = [0, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330],\n        **kwargs,\n    ) -&gt; None:\n        super().__init__(\n            widths=[80],\n            offsets=offsets,\n            intensities=intensities,\n            speeds=speeds,\n            height=height,\n            dt=dt,\n            device=device,\n            bar_loc_horizontal=np.radians(0),\n            post_pad_mode=post_pad_mode,\n            t_pre=t_pre,\n            t_post=t_post,\n            build_stim_on_init=build_stim_on_init,\n            shuffle_offsets=shuffle_offsets,\n            seed=seed,\n            angles=angles,\n        )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#response-analysis","title":"Response Analysis","text":""},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses","title":"flyvis.analysis.moving_bar_responses","text":"<p>Analysis of responses to moving edges or bars.</p> Info <p>Relies on xarray dataset format defined in <code>flyvis.analysis.stimulus_responses</code>.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.peak_responses","title":"peak_responses","text":"<pre><code>peak_responses(dataset, norm=None, from_degree=None, to_degree=None)\n</code></pre> <p>Compute peak responses from rectified voltages, optionally normalized.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset containing \u2018responses\u2019 and necessary coordinates.</p> required <code>norm</code> <code>DataArray</code> <p>Normalization array.</p> <code>None</code> <code>from_degree</code> <code>float</code> <p>Starting degree for masking.</p> <code>None</code> <code>to_degree</code> <code>float</code> <p>Ending degree for masking.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Peak responses with reshaped and transposed dimensions.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def peak_responses(\n    dataset: xr.Dataset,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute peak responses from rectified voltages, optionally normalized.\n\n    Args:\n        dataset: Input dataset containing 'responses' and necessary coordinates.\n        norm: Normalization array.\n        from_degree: Starting degree for masking.\n        to_degree: Ending degree for masking.\n\n    Returns:\n        Peak responses with reshaped and transposed dimensions.\n    \"\"\"\n    config = dataset.attrs['config']\n    from_degree = from_degree if from_degree is not None else config['offsets'][0] * 2.25\n    to_degree = to_degree if to_degree is not None else (config['offsets'][1] - 1) * 2.25\n\n    # Generate time masks\n    masks = get_time_masks(\n        dataset, from_column=from_degree / 5.8, to_column=to_degree / 5.8\n    )\n\n    # Apply masks to responses and rectify\n    responses = dataset['responses']\n    masked = responses.where(masks, other=0)\n    rectified = masked.clip(min=0)  # Rectify: max(0, response)\n\n    # Normalize if provided\n    if norm is not None:\n        rectified = rectified / norm\n\n    # Compute peak (maximum over 'frame')\n    peak = rectified.max(dim='frame')\n    return peak\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.get_time_masks","title":"get_time_masks","text":"<pre><code>get_time_masks(dataset, from_column=-1.5, to_column=1.5)\n</code></pre> <p>Generate time masks for each sample based on speed and column range.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset containing \u2018speed\u2019 and \u2018time\u2019 coordinates.</p> required <code>from_column</code> <code>float</code> <p>Start of the column range.</p> <code>-1.5</code> <code>to_column</code> <code>float</code> <p>End of the column range.</p> <code>1.5</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Boolean mask with dimensions (\u2018sample\u2019, \u2018frame\u2019).</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def get_time_masks(\n    dataset: xr.Dataset, from_column: float = -1.5, to_column: float = 1.5\n) -&gt; xr.DataArray:\n    \"\"\"\n    Generate time masks for each sample based on speed and column range.\n\n    Args:\n        dataset: Input dataset containing 'speed' and 'time' coordinates.\n        from_column: Start of the column range.\n        to_column: End of the column range.\n\n    Returns:\n        Boolean mask with dimensions ('sample', 'frame').\n    \"\"\"\n    speeds = dataset['speed'].values\n    unique_speeds = np.unique(speeds)\n    config = dataset.attrs['config']\n    start, end = config['offsets']\n    times = dataset['time'].values\n\n    # Precompute masks for unique speeds\n    mask_dict = {}\n    for speed in unique_speeds:\n        t_start, t_end = time_window(\n            speed, from_column=from_column, to_column=to_column, start=start, end=end\n        )\n        mask_dict[speed] = mask_between_seconds(t_start, t_end, times)\n\n    # Map masks to each sample based on its speed\n    masks = np.array([mask_dict[speed] for speed in speeds])\n\n    # Create a DataArray for the masks\n    mask_da = xr.DataArray(\n        data=masks,\n        dims=('sample', 'frame'),\n        coords={'sample': dataset['sample'], 'frame': dataset['frame']},\n    )\n\n    return mask_da\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.peak_responses_angular","title":"peak_responses_angular","text":"<pre><code>peak_responses_angular(dataset, norm=None, from_degree=None, to_degree=None)\n</code></pre> <p>Compute peak responses and make them complex over angles.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required <code>norm</code> <code>DataArray</code> <p>Normalization array.</p> <code>None</code> <code>from_degree</code> <code>float</code> <p>Starting degree for masking.</p> <code>None</code> <code>to_degree</code> <code>float</code> <p>Ending degree for masking.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Complex-valued peak responses.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def peak_responses_angular(\n    dataset: xr.Dataset,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute peak responses and make them complex over angles.\n\n    Args:\n        dataset: Input dataset.\n        norm: Normalization array.\n        from_degree: Starting degree for masking.\n        to_degree: Ending degree for masking.\n\n    Returns:\n        Complex-valued peak responses.\n    \"\"\"\n    peak = peak_responses(\n        dataset, norm=norm, from_degree=from_degree, to_degree=to_degree\n    )\n\n    # Make complex over angles\n    angles = peak['angle'].values\n    radians = np.deg2rad(angles)\n    # Expand dimensions to match broadcasting\n    radians = radians[np.newaxis, :, np.newaxis]\n    complex_peak = peak * np.exp(1j * radians)\n\n    return complex_peak\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.direction_selectivity_index","title":"direction_selectivity_index","text":"<pre><code>direction_selectivity_index(dataset, average=True, norm=None, from_degree=None, to_degree=None)\n</code></pre> <p>Compute Direction Selectivity Index (DSI).</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required <code>average</code> <code>bool</code> <p>Whether to average over \u2018width\u2019 and \u2018speed\u2019.</p> <code>True</code> <code>norm</code> <code>DataArray</code> <p>Normalization array.</p> <code>None</code> <code>from_degree</code> <code>float</code> <p>Starting degree for masking.</p> <code>None</code> <code>to_degree</code> <code>float</code> <p>Ending degree for masking.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Direction Selectivity Index.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def direction_selectivity_index(\n    dataset: xr.Dataset,\n    average: bool = True,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute Direction Selectivity Index (DSI).\n\n    Args:\n        dataset: Input dataset.\n        average: Whether to average over 'width' and 'speed'.\n        norm: Normalization array.\n        from_degree: Starting degree for masking.\n        to_degree: Ending degree for masking.\n\n    Returns:\n        Direction Selectivity Index.\n    \"\"\"\n    view = peak_responses_angular(\n        dataset, norm=norm, from_degree=from_degree, to_degree=to_degree\n    )\n    view = view.set_index(sample=[\"angle\", \"width\", \"intensity\", \"speed\"]).unstack(\n        \"sample\"\n    )\n\n    # Compute vector sum over 'angle'\n    vector_sum = view.sum(dim='angle')\n    vector_length = np.abs(vector_sum)\n\n    # Normalization: sum of absolute responses\n    normalization = np.abs(view).sum(dim='angle').max(dim='intensity')\n    dsi = vector_length / (normalization + 1e-15)\n\n    if average:\n        # Average over 'width' and 'speed'\n        dsi = dsi.mean(dim=['width', 'speed'])\n\n    return dsi.squeeze()\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.prepare_dsi_data","title":"prepare_dsi_data","text":"<pre><code>prepare_dsi_data(dsis, cell_types, sorted_type_list, known_on_off_first, sort_descending)\n</code></pre> <p>Prepare DSI data for plotting.</p> <p>Parameters:</p> Name Type Description Default <code>dsis</code> <p>Array of DSI values.</p> required <code>cell_types</code> <p>Array of cell type labels.</p> required <code>sorted_type_list</code> <p>List of cell types in desired order.</p> required <code>known_on_off_first</code> <p>Whether to sort known ON/OFF types first.</p> required <code>sort_descending</code> <p>Whether to sort DSIs in descending order.</p> required <p>Returns:</p> Type Description <p>Tuple of prepared DSIs and cell types.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def prepare_dsi_data(\n    dsis, cell_types, sorted_type_list, known_on_off_first, sort_descending\n):\n    \"\"\"\n    Prepare DSI data for plotting.\n\n    Args:\n        dsis: Array of DSI values.\n        cell_types: Array of cell type labels.\n        sorted_type_list: List of cell types in desired order.\n        known_on_off_first: Whether to sort known ON/OFF types first.\n        sort_descending: Whether to sort DSIs in descending order.\n\n    Returns:\n        Tuple of prepared DSIs and cell types.\n    \"\"\"\n    if known_on_off_first:\n        sorted_type_list = nodes_edges_utils.nodes_list_sorting_on_off_unknown(cell_types)\n\n    if sorted_type_list is not None:\n        dsis = nodes_edges_utils.sort_by_mapping_lists(\n            cell_types, sorted_type_list, dsis, axis=0\n        )\n        cell_types = np.array(sorted_type_list)\n\n    if sort_descending:\n        medians = np.median(dsis, axis=(-2, -1))\n        index = np.argsort(medians)[::-1]\n        dsis = dsis[index]\n        cell_types = cell_types[index]\n\n    return dsis, cell_types\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.dsi_violins","title":"dsi_violins","text":"<pre><code>dsi_violins(dsis, cell_types, scatter_best=False, scatter_all=True, cmap=None, colors=None, color='b', figsize=[10, 1], fontsize=6, showmeans=False, showmedians=True, sorted_type_list=None, sort_descending=False, known_on_off_first=True, scatter_kwargs={}, **kwargs)\n</code></pre> <p>Create violin plots for Direction Selectivity Index (DSI) data.</p> <p>Parameters:</p> Name Type Description Default <code>dsis</code> <p>Array of DSI values.</p> required <code>cell_types</code> <p>Array of cell type labels.</p> required <code>scatter_best</code> <p>Whether to scatter the best points.</p> <code>False</code> <code>scatter_all</code> <p>Whether to scatter all points.</p> <code>True</code> <code>cmap</code> <p>Colormap for the violins.</p> <code>None</code> <code>colors</code> <p>Specific colors for the violins.</p> <code>None</code> <code>color</code> <p>Default color if colors is None and cmap is None.</p> <code>'b'</code> <code>figsize</code> <p>Figure size.</p> <code>[10, 1]</code> <code>fontsize</code> <p>Font size for labels.</p> <code>6</code> <code>showmeans</code> <p>Whether to show means on violins.</p> <code>False</code> <code>showmedians</code> <p>Whether to show medians on violins.</p> <code>True</code> <code>sorted_type_list</code> <p>List of cell types in desired order.</p> <code>None</code> <code>sort_descending</code> <p>Whether to sort DSIs in descending order.</p> <code>False</code> <code>known_on_off_first</code> <p>Whether to sort known ON/OFF types first.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments for violin_groups.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Tuple of (figure, axis, colors, prepared DSIs)</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def dsi_violins(\n    dsis,\n    cell_types,\n    scatter_best=False,\n    scatter_all=True,\n    cmap=None,\n    colors=None,\n    color=\"b\",\n    figsize=[10, 1],\n    fontsize=6,\n    showmeans=False,\n    showmedians=True,\n    sorted_type_list=None,\n    sort_descending=False,\n    known_on_off_first=True,\n    scatter_kwargs={},\n    **kwargs,\n):\n    \"\"\"\n    Create violin plots for Direction Selectivity Index (DSI) data.\n\n    Args:\n        dsis: Array of DSI values.\n        cell_types: Array of cell type labels.\n        scatter_best: Whether to scatter the best points.\n        scatter_all: Whether to scatter all points.\n        cmap: Colormap for the violins.\n        colors: Specific colors for the violins.\n        color: Default color if colors is None and cmap is None.\n        figsize: Figure size.\n        fontsize: Font size for labels.\n        showmeans: Whether to show means on violins.\n        showmedians: Whether to show medians on violins.\n        sorted_type_list: List of cell types in desired order.\n        sort_descending: Whether to sort DSIs in descending order.\n        known_on_off_first: Whether to sort known ON/OFF types first.\n        **kwargs: Additional keyword arguments for violin_groups.\n\n    Returns:\n        Tuple of (figure, axis, colors, prepared DSIs)\n    \"\"\"\n    dsis, cell_types = prepare_dsi_data(\n        dsis, cell_types, sorted_type_list, known_on_off_first, sort_descending\n    )\n\n    if len(dsis.shape) == 1:\n        dsis = dsis[None, None, :]\n    elif len(dsis.shape) == 2:\n        dsis = dsis[:, None]\n\n    if colors is None and cmap is None and color is not None:\n        colors = (color,)\n\n    fig, ax, colors = violin_groups(\n        dsis,\n        cell_types[:],\n        rotation=90,\n        scatter=False,\n        cmap=cmap,\n        colors=colors,\n        fontsize=fontsize,\n        figsize=figsize,\n        width=0.7,\n        showmeans=showmeans,\n        showmedians=showmedians,\n        **kwargs,\n    )\n\n    if dsis.shape[1] == 1:\n        plt_utils.scatter_on_violins_with_best(\n            dsis.T.squeeze(), ax, scatter_best, scatter_all, **scatter_kwargs\n        )\n\n    return fig, ax, colors, dsis\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.dsi_violins_on_and_off","title":"dsi_violins_on_and_off","text":"<pre><code>dsi_violins_on_and_off(dsis, cell_types, scatter_best=False, scatter_all=True, bold_output_type_labels=False, output_cell_types=None, known_on_off_first=True, sorted_type_list=None, figsize=[10, 1], ylim=(0, 1), color_known_types=True, fontsize=6, fig=None, axes=None, **kwargs)\n</code></pre> <p>Plot Direction Selectivity Index (DSI) for ON and OFF intensities.</p> <p>Parameters:</p> Name Type Description Default <code>dsis</code> <code>DataArray</code> <p>DataArray of DSI values.</p> required <code>cell_types</code> <code>DataArray</code> <p>DataArray of cell type labels.</p> required <code>scatter_best</code> <p>Whether to scatter the best points.</p> <code>False</code> <code>scatter_all</code> <p>Whether to scatter all points.</p> <code>True</code> <code>bold_output_type_labels</code> <p>Whether to bold output type labels.</p> <code>False</code> <code>output_cell_types</code> <p>Cell types to output.</p> <code>None</code> <code>known_on_off_first</code> <p>Whether to sort known ON/OFF types first.</p> <code>True</code> <code>sorted_type_list</code> <p>List of cell types in desired order.</p> <code>None</code> <code>figsize</code> <p>Figure size.</p> <code>[10, 1]</code> <code>ylim</code> <p>Y-axis limits.</p> <code>(0, 1)</code> <code>color_known_types</code> <p>Whether to color known cell types.</p> <code>True</code> <code>fontsize</code> <p>Font size for labels.</p> <code>6</code> <code>fig</code> <p>Existing figure to use.</p> <code>None</code> <code>axes</code> <p>Existing axes to use.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for dsi_violins.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Tuple of (figure, (ax1, ax2))</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def dsi_violins_on_and_off(\n    dsis: xr.DataArray,\n    cell_types: xr.DataArray,\n    scatter_best=False,\n    scatter_all=True,\n    bold_output_type_labels=False,\n    output_cell_types=None,\n    known_on_off_first=True,\n    sorted_type_list=None,\n    figsize=[10, 1],\n    ylim=(0, 1),\n    color_known_types=True,\n    fontsize=6,\n    fig=None,\n    axes=None,\n    **kwargs,\n):\n    \"\"\"\n    Plot Direction Selectivity Index (DSI) for ON and OFF intensities.\n\n    Args:\n        dsis: DataArray of DSI values.\n        cell_types: DataArray of cell type labels.\n        scatter_best: Whether to scatter the best points.\n        scatter_all: Whether to scatter all points.\n        bold_output_type_labels: Whether to bold output type labels.\n        output_cell_types: Cell types to output.\n        known_on_off_first: Whether to sort known ON/OFF types first.\n        sorted_type_list: List of cell types in desired order.\n        figsize: Figure size.\n        ylim: Y-axis limits.\n        color_known_types: Whether to color known cell types.\n        fontsize: Font size for labels.\n        fig: Existing figure to use.\n        axes: Existing axes to use.\n        **kwargs: Additional keyword arguments for dsi_violins.\n\n    Returns:\n        Tuple of (figure, (ax1, ax2))\n    \"\"\"\n    if len(dsis.shape) == 2:\n        dsis = dsis[None, :]\n\n    if fig is None or axes is None:\n        fig, axes = plt.subplots(2, 1, figsize=figsize, sharex=True)\n        plt_utils.rm_spines(axes[0], spines=(\"bottom\",))\n\n    for i, intensity in enumerate([1, 0]):\n        color = ON if intensity == 1 else OFF\n        _, ax, *_ = dsi_violins(\n            dsis=dsis.sel(intensity=intensity).values.T,\n            cell_types=cell_types.values,\n            color=color,\n            fig=fig,\n            ax=axes[i],\n            fontsize=fontsize,\n            sorted_type_list=sorted_type_list,\n            scatter_best=scatter_best,\n            scatter_all=scatter_all,\n            known_on_off_first=known_on_off_first,\n            **kwargs,\n        )\n\n        ax.grid(False)\n        ax.set_ylim(*ylim)\n        plt_utils.trim_axis(ax)\n        plt_utils.set_spine_tick_params(\n            ax, tickwidth=0.5, ticklength=3, ticklabelpad=2, spinewidth=0.5\n        )\n\n        if bold_output_type_labels:\n            plt_utils.boldify_labels(output_cell_types, ax)\n\n        if color_known_types:\n            plt_utils.color_labels([\"T4a\", \"T4b\", \"T4c\", \"T4d\"], ON, ax)\n            plt_utils.color_labels([\"T5a\", \"T5b\", \"T5c\", \"T5d\"], OFF, ax)\n\n    # axes[0].set_xticks([])\n    axes[0].set_yticks(np.arange(0, 1.2, 0.5))\n    axes[1].set_yticks(np.arange(0, 1.2, 0.5))\n    axes[1].invert_yaxis()\n\n    return fig, axes\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.dsi_correlation_to_known","title":"dsi_correlation_to_known","text":"<pre><code>dsi_correlation_to_known(dsis, max_aggregate_dims=('intensity'))\n</code></pre> <p>Compute the correlation between predicted DSIs and known DSIs.</p> <p>Parameters:</p> Name Type Description Default <code>dsis</code> <code>DataArray</code> <p>DataArray containing DSIs for ON and OFF intensities. Should have dimensions including \u2018intensity\u2019 and \u2018neuron\u2019, and a coordinate \u2018cell_type\u2019.</p> required <code>max_aggregate_dims</code> <p>Dimensions to max-aggregate before computing correlation.</p> <code>('intensity')</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Correlation between predicted and known DSIs.</p> Note <p>Known DSIs are binary (0 or 1) based on whether the cell type is known to be motion-tuned.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def dsi_correlation_to_known(\n    dsis: xr.DataArray, max_aggregate_dims=(\"intensity\",)\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute the correlation between predicted DSIs and known DSIs.\n\n    Args:\n        dsis: DataArray containing DSIs for ON and OFF intensities.\n            Should have dimensions including 'intensity' and 'neuron',\n            and a coordinate 'cell_type'.\n        max_aggregate_dims: Dimensions to max-aggregate before computing correlation.\n\n    Returns:\n        Correlation between predicted and known DSIs.\n\n    Note:\n        Known DSIs are binary (0 or 1) based on whether the cell type\n        is known to be motion-tuned.\n    \"\"\"\n    # Ensure the 'intensity' dimension has length 2\n    assert dsis.sizes['intensity'] == 2, \"Dimension 'intensity' should have length 2\"\n\n    # Retrieve ground truth motion tuning information\n    motion_tuning = groundtruth_utils.motion_tuning\n    known_dsi_types = groundtruth_utils.known_dsi_types\n\n    # Select dsis for known cell types\n    dsis_for_known = dsis.where(dsis['cell_type'].isin(known_dsi_types), drop=True).max(\n        dim=max_aggregate_dims\n    )\n\n    # Construct ground truth motion tuning array\n    groundtruth_mt = xr.DataArray(\n        [\n            1.0 if ct in motion_tuning else 0.0\n            for ct in dsis_for_known['cell_type'].values\n        ],\n        coords={'neuron': dsis_for_known['neuron']},\n        dims=['neuron'],\n    )\n\n    # Compute correlation along 'neuron' dimension\n    corr_dsi = xr.corr(dsis_for_known, groundtruth_mt, dim='neuron')\n\n    return corr_dsi\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.correlation_to_known_tuning_curves","title":"correlation_to_known_tuning_curves","text":"<pre><code>correlation_to_known_tuning_curves(dataset, absmax=False)\n</code></pre> <p>Compute correlation between predicted and known tuning curves.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required <code>absmax</code> <code>bool</code> <p>If True, maximize magnitude of correlation regardless of sign.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Correlation values for each cell type.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def correlation_to_known_tuning_curves(\n    dataset: xr.Dataset, absmax: bool = False\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute correlation between predicted and known tuning curves.\n\n    Args:\n        dataset: Input dataset.\n        absmax: If True, maximize magnitude of correlation regardless of sign.\n\n    Returns:\n        Correlation values for each cell type.\n    \"\"\"\n    tuning = peak_responses(dataset)\n    gt_tuning = get_known_tuning_curves(\n        [\"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\"], np.arange(0, 360, 30)\n    )\n\n    tuning = (\n        tuning.set_index(sample=[\"angle\", \"intensity\", \"width\", \"speed\"])\n        .unstack(\"sample\")\n        .fillna(0.0)\n        .custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\"])\n    )\n\n    # reset the neuron axis to make it compatible with the ground truth tuning curves\n    tuning[\"neuron\"] = np.arange(tuning.coords[\"neuron\"].size)\n\n    correlation = xr.corr(tuning, gt_tuning, dim=\"angle\")\n    correlation = correlation.fillna(0.0)\n    if absmax:\n        # take speed and width that maximize the magnitude of the correlation, regardless\n        # of the sign\n        argmax = np.abs(correlation).argmax(dim=(\"speed\", \"width\"))\n    else:\n        # take speed and width that maximize the correlation as an experimentalist\n        # would do\n        argmax = correlation.argmax(dim=(\"speed\", \"width\"))\n    correlation = correlation.isel(argmax)\n    return correlation\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.get_known_tuning_curves","title":"get_known_tuning_curves","text":"<pre><code>get_known_tuning_curves(cell_types, angles)\n</code></pre> <p>Retrieve ground truth tuning curves for specified cell types.</p> <p>Parameters:</p> Name Type Description Default <code>cell_types</code> <code>List[str]</code> <p>List of cell type names.</p> required <code>angles</code> <code>ndarray</code> <p>Array of angles to interpolate curves to.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>DataArray of interpolated ground truth tuning curves.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def get_known_tuning_curves(cell_types: List[str], angles: np.ndarray) -&gt; xr.DataArray:\n    \"\"\"\n    Retrieve ground truth tuning curves for specified cell types.\n\n    Args:\n        cell_types: List of cell type names.\n        angles: Array of angles to interpolate curves to.\n\n    Returns:\n        DataArray of interpolated ground truth tuning curves.\n    \"\"\"\n    gt_angles = np.arange(0, 360, 30)\n    tuning_curves = []\n\n    for cell_type in cell_types:\n        gt_tuning = groundtruth_utils.tuning_curves[cell_type]\n        interp_func = interp1d(\n            gt_angles, gt_tuning, kind='cubic', fill_value=\"extrapolate\"\n        )\n        gt_tuning = interp_func(angles)\n        tuning_curves.append(gt_tuning)\n\n    dataset = xr.DataArray(\n        np.array(tuning_curves),\n        dims=['neuron', 'angle'],\n        coords={'cell_type': (\"neuron\", cell_types), 'angle': angles},\n    )\n\n    return dataset\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.preferred_direction","title":"preferred_direction","text":"<pre><code>preferred_direction(dataset, average=True, norm=None, from_degree=None, to_degree=None)\n</code></pre> <p>Compute the preferred direction based on peak responses.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required <code>average</code> <code>bool</code> <p>Whether to average over certain dimensions.</p> <code>True</code> <code>norm</code> <code>DataArray</code> <p>Normalization array.</p> <code>None</code> <code>from_degree</code> <code>float</code> <p>Starting degree for masking.</p> <code>None</code> <code>to_degree</code> <code>float</code> <p>Ending degree for masking.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Preferred direction angles in radians.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def preferred_direction(\n    dataset: xr.Dataset,\n    average: bool = True,\n    norm: xr.DataArray = None,\n    from_degree: float = None,\n    to_degree: float = None,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Compute the preferred direction based on peak responses.\n\n    Args:\n        dataset: Input dataset.\n        average: Whether to average over certain dimensions.\n        norm: Normalization array.\n        from_degree: Starting degree for masking.\n        to_degree: Ending degree for masking.\n\n    Returns:\n        Preferred direction angles in radians.\n    \"\"\"\n    view = peak_responses_angular(\n        dataset, norm=norm, from_degree=from_degree, to_degree=to_degree\n    )\n    view = view.set_index(sample=[\"angle\", \"width\", \"intensity\", \"speed\"]).unstack(\n        \"sample\"\n    )\n\n    # Compute vector sum over 'angle'\n    vector_sum = view.sum(dim='angle')\n    theta_pref = np.angle(vector_sum)\n\n    if average:\n        # Sum over 'width' and 'speed' before computing angle\n        vector_sum = view.sum(dim=['width', 'speed', 'angle'])\n        theta_pref = np.angle(vector_sum)\n\n    vector_sum.data = theta_pref\n    return vector_sum\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.angular_distance_to_known","title":"angular_distance_to_known","text":"<pre><code>angular_distance_to_known(pds)\n</code></pre> <p>Compute angular distance between predicted and known preferred directions for T4/T5.</p> <p>Parameters:</p> Name Type Description Default <code>pds</code> <code>DataArray</code> <p>Preferred directions for cells.</p> required <p>Returns:</p> Type Description <code>DataArray</code> <p>Angular distances to known preferred directions.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def angular_distance_to_known(pds: xr.DataArray) -&gt; xr.DataArray:\n    \"\"\"\n    Compute angular distance between predicted and known preferred directions for T4/T5.\n\n    Args:\n        pds: Preferred directions for cells.\n\n    Returns:\n        Angular distances to known preferred directions.\n    \"\"\"\n    t4s = pds.custom.where(cell_type=[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], intensity=1)\n    t4_distances = angular_distances(t4s, np.array([np.pi, 0, np.pi / 2, 3 * np.pi / 2]))\n    t5s = pds.custom.where(cell_type=[\"T5a\", \"T5b\", \"T5c\", \"T5d\"], intensity=0)\n    t5_distances = angular_distances(t5s, np.array([np.pi, 0, np.pi / 2, 3 * np.pi / 2]))\n    # concatenate both xarrays again in the neuron dimension, drop intensity\n    return xr.concat(\n        [t4_distances.drop('intensity'), t5_distances.drop('intensity')], dim='neuron'\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.angular_distances","title":"angular_distances","text":"<pre><code>angular_distances(x, y, upper=np.pi)\n</code></pre> <p>Compute angular distances between two sets of angles.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataArray</code> <p>First set of angles.</p> required <code>y</code> <code>array</code> <p>Second set of angles.</p> required <code>upper</code> <code>float</code> <p>Upper bound for distance calculation.</p> <code>pi</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Angular distances.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def angular_distances(x: xr.DataArray, y: np.array, upper: float = np.pi) -&gt; xr.DataArray:\n    \"\"\"\n    Compute angular distances between two sets of angles.\n\n    Args:\n        x: First set of angles.\n        y: Second set of angles.\n        upper: Upper bound for distance calculation.\n\n    Returns:\n        Angular distances.\n    \"\"\"\n    assert x.neuron.size == len(y)\n    y_da = xr.DataArray(y, dims=['neuron'], coords={'neuron': x.coords['neuron']})\n\n    result = xr.apply_ufunc(\n        simple_angle_distance,\n        x,\n        y_da,\n        input_core_dims=[['neuron'], ['neuron']],\n        output_core_dims=[['neuron']],\n        vectorize=True,\n        kwargs={'upper': upper},\n    )\n\n    return result\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.simple_angle_distance","title":"simple_angle_distance","text":"<pre><code>simple_angle_distance(a, b, upper=np.pi)\n</code></pre> <p>Calculate element-wise angle distance between 0 and pi radians.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>First set of angles in radians.</p> required <code>b</code> <code>ndarray</code> <p>Second set of angles in radians.</p> required <code>upper</code> <code>float</code> <p>Upper bound for distance calculation.</p> <code>pi</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Distance between 0 and pi radians.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def simple_angle_distance(\n    a: np.ndarray, b: np.ndarray, upper: float = np.pi\n) -&gt; np.ndarray:\n    \"\"\"\n    Calculate element-wise angle distance between 0 and pi radians.\n\n    Args:\n        a: First set of angles in radians.\n        b: Second set of angles in radians.\n        upper: Upper bound for distance calculation.\n\n    Returns:\n        Distance between 0 and pi radians.\n    \"\"\"\n    a = np.atleast_1d(a)\n    b = np.atleast_1d(b)\n\n    # make all angles positive between 0 and 2 * pi\n    a = a % (2 * np.pi)\n    b = b % (2 * np.pi)\n\n    y = np.zeros_like(a)\n    # subtract the smaller angle from the larger one\n    mask = a &gt;= b\n    y[mask] = a[mask] - b[mask]\n    y[~mask] = b[~mask] - a[~mask]\n\n    # map distances between pi and 2 pi to 0 and pi\n    y[y &gt; np.pi] = 2 * np.pi - y[y &gt; np.pi]\n\n    # map distances between 0 and pi to 0 and upper\n    return y / np.pi * upper\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.plot_angular_tuning","title":"plot_angular_tuning","text":"<pre><code>plot_angular_tuning(dataset, cell_type, intensity, figsize=(1, 1), fontsize=5, linewidth=1, anglepad=-7, xlabelpad=-1, groundtruth=True, groundtruth_linewidth=1.0, fig=None, ax=None, peak_responses_da=None, weighted_average=None, average_models=False, colors=None, zorder=0, **kwargs)\n</code></pre> <p>Plot angular tuning for a specific cell type and intensity.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required <code>cell_type</code> <code>int</code> <p>Neuron index to plot.</p> required <code>intensity</code> <code>int</code> <p>Intensity level (0 or 1).</p> required <code>figsize</code> <code>Tuple[float, float]</code> <p>Figure size.</p> <code>(1, 1)</code> <code>fontsize</code> <code>int</code> <p>Font size.</p> <code>5</code> <code>linewidth</code> <code>float</code> <p>Line width.</p> <code>1</code> <code>anglepad</code> <code>float</code> <p>Angle padding.</p> <code>-7</code> <code>xlabelpad</code> <code>float</code> <p>X-label padding.</p> <code>-1</code> <code>groundtruth</code> <code>bool</code> <p>Whether to plot ground truth.</p> <code>True</code> <code>groundtruth_linewidth</code> <code>float</code> <p>Line width for ground truth.</p> <code>1.0</code> <code>fig</code> <code>Figure</code> <p>Existing figure.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axes.</p> <code>None</code> <code>peak_responses_da</code> <code>DataArray</code> <p>Precomputed peak responses.</p> <code>None</code> <code>weighted_average</code> <code>DataArray</code> <p>Weights for averaging models.</p> <code>None</code> <code>average_models</code> <code>bool</code> <p>Whether to average across models.</p> <code>False</code> <code>colors</code> <code>str</code> <p>Color for the plot.</p> <code>None</code> <code>zorder</code> <code>Union[int, Iterable]</code> <p>Z-order for plotting.</p> <code>0</code> <code>**kwargs</code> <p>Additional keyword arguments for plotting.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>The figure and axes objects.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def plot_angular_tuning(\n    dataset: xr.Dataset,\n    cell_type: int,\n    intensity: int,\n    figsize: Tuple[float, float] = (1, 1),\n    fontsize: int = 5,\n    linewidth: float = 1,\n    anglepad: float = -7,\n    xlabelpad: float = -1,\n    groundtruth: bool = True,\n    groundtruth_linewidth: float = 1.0,\n    fig: plt.Figure = None,\n    ax: plt.Axes = None,\n    peak_responses_da: xr.DataArray = None,\n    weighted_average: xr.DataArray = None,\n    average_models: bool = False,\n    colors: str = None,\n    zorder: Union[int, Iterable] = 0,\n    **kwargs,\n) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"\n    Plot angular tuning for a specific cell type and intensity.\n\n    Args:\n        dataset: Input dataset.\n        cell_type: Neuron index to plot.\n        intensity: Intensity level (0 or 1).\n        figsize: Figure size.\n        fontsize: Font size.\n        linewidth: Line width.\n        anglepad: Angle padding.\n        xlabelpad: X-label padding.\n        groundtruth: Whether to plot ground truth.\n        groundtruth_linewidth: Line width for ground truth.\n        fig: Existing figure.\n        ax: Existing axes.\n        peak_responses_da: Precomputed peak responses.\n        weighted_average: Weights for averaging models.\n        average_models: Whether to average across models.\n        colors: Color for the plot.\n        zorder: Z-order for plotting.\n        **kwargs: Additional keyword arguments for plotting.\n\n    Returns:\n        The figure and axes objects.\n    \"\"\"\n    if peak_responses_da is None:\n        peak_responses_da = peak_responses(dataset)\n\n    peak_responses_da = peak_responses_da.set_index(\n        sample=[\"angle\", \"width\", \"intensity\", \"speed\"]\n    ).unstack(\"sample\")\n\n    # Select the specific cell type\n    peak = peak_responses_da.custom.where(cell_type=cell_type, intensity=intensity)\n\n    # Squeeze irrelevant dimensions\n    # peak = peak.squeeze(dim=['width', 'intensity', 'speed'], drop=True)\n\n    # Average over speeds\n    average_tuning = peak.mean(dim=('speed', 'width'))\n\n    # Average over models if specified\n    if average_models and weighted_average is not None:\n        average_tuning = average_tuning.weighted(weighted_average).mean(dim='network_id')\n    elif average_models:\n        average_tuning = average_tuning.mean(dim='network_id')\n\n    color = (ON if intensity == 1 else OFF) if colors is None else colors\n\n    average_tuning = average_tuning / average_tuning.max()\n\n    angles = average_tuning['angle'].values\n    fig, ax = polar(\n        angles,\n        average_tuning.data.squeeze().T,\n        figsize=figsize,\n        fontsize=fontsize,\n        linewidth=linewidth,\n        anglepad=anglepad,\n        xlabelpad=xlabelpad,\n        color=color,\n        fig=fig,\n        ax=ax,\n        zorder=zorder,\n        **kwargs,\n    )\n\n    if groundtruth and cell_type in groundtruth_utils.tuning_curves:\n        r_gt = np.array(groundtruth_utils.tuning_curves[cell_type])\n        r_gt = r_gt / np.max(np.abs(r_gt))\n        theta_gt = np.arange(0, 360, 360 / len(r_gt))\n        polar(\n            theta_gt,\n            r_gt,\n            figsize=figsize,\n            fontsize=fontsize,\n            linewidth=groundtruth_linewidth,\n            anglepad=anglepad,\n            xlabelpad=xlabelpad,\n            color=\"k\",\n            fig=fig,\n            ax=ax,\n            # **kwargs,\n        )\n\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.plot_T4_tuning","title":"plot_T4_tuning","text":"<pre><code>plot_T4_tuning(dataset)\n</code></pre> <p>Plot tuning curves for T4 cells.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def plot_T4_tuning(dataset: xr.Dataset) -&gt; None:\n    \"\"\"\n    Plot tuning curves for T4 cells.\n\n    Args:\n        dataset: Input dataset.\n    \"\"\"\n    fig, axes, _ = plt_utils.get_axis_grid(\n        range(4),\n        projection=\"polar\",\n        aspect_ratio=4,\n        figsize=[2.95, 0.83],\n        wspace=0.25,\n    )\n    for i, cell_type in enumerate([\"T4a\", \"T4b\", \"T4c\", \"T4d\"]):\n        plot_angular_tuning(\n            dataset,\n            cell_type,\n            intensity=1,\n            fig=fig,\n            ax=axes[i],\n            groundtruth=True,\n            aggregate_models=\"mean\",\n            linewidth=1.0,\n        )\n        axes[i].set_xlabel(cell_type)\n\n    for ax in axes:\n        ax.xaxis.label.set_fontsize(5)\n        [i.set_linewidth(0.5) for i in ax.spines.values()]\n        ax.grid(True, linewidth=0.5)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.plot_T5_tuning","title":"plot_T5_tuning","text":"<pre><code>plot_T5_tuning(dataset)\n</code></pre> <p>Plot tuning curves for T5 cells.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Input dataset.</p> required Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def plot_T5_tuning(dataset: xr.Dataset) -&gt; None:\n    \"\"\"\n    Plot tuning curves for T5 cells.\n\n    Args:\n        dataset: Input dataset.\n    \"\"\"\n    fig, axes, _ = plt_utils.get_axis_grid(\n        range(4),\n        projection=\"polar\",\n        aspect_ratio=4,\n        figsize=[2.95, 0.83],\n        wspace=0.25,\n    )\n    for i, cell_type in enumerate([\"T5a\", \"T5b\", \"T5c\", \"T5d\"]):\n        plot_angular_tuning(\n            dataset,\n            cell_type,\n            intensity=0,\n            fig=fig,\n            ax=axes[i],\n            groundtruth=True,\n            aggregate_models=\"mean\",\n            linewidth=1.0,\n        )\n        axes[i].set_xlabel(cell_type)\n\n    for ax in axes:\n        ax.xaxis.label.set_fontsize(5)\n        [i.set_linewidth(0.5) for i in ax.spines.values()]\n        ax.grid(True, linewidth=0.5)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.mask_between_seconds","title":"mask_between_seconds","text":"<pre><code>mask_between_seconds(t_start, t_end, time=None, t_pre=None, t_stim=None, t_post=None, dt=None)\n</code></pre> <p>Create a boolean mask for time values between t_start and t_end.</p> <p>Parameters:</p> Name Type Description Default <code>t_start</code> <code>float</code> <p>Start time for the mask.</p> required <code>t_end</code> <code>float</code> <p>End time for the mask.</p> required <code>time</code> <code>ndarray</code> <p>Array of time values. If None, it will be generated using other parameters.</p> <code>None</code> <code>t_pre</code> <code>float</code> <p>Time before stimulus onset.</p> <code>None</code> <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> <code>None</code> <code>t_post</code> <code>float</code> <p>Time after stimulus offset.</p> <code>None</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean mask array.</p> Note <p>If \u2018time\u2019 is not provided, it will be generated using t_pre, t_stim, t_post, and dt.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def mask_between_seconds(\n    t_start: float,\n    t_end: float,\n    time: np.ndarray = None,\n    t_pre: float = None,\n    t_stim: float = None,\n    t_post: float = None,\n    dt: float = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Create a boolean mask for time values between t_start and t_end.\n\n    Args:\n        t_start: Start time for the mask.\n        t_end: End time for the mask.\n        time: Array of time values. If None, it will be generated using other parameters.\n        t_pre: Time before stimulus onset.\n        t_stim: Stimulus duration.\n        t_post: Time after stimulus offset.\n        dt: Time step.\n\n    Returns:\n        Boolean mask array.\n\n    Note:\n        If 'time' is not provided, it will be generated using t_pre, t_stim, t_post,\n        and dt.\n    \"\"\"\n    time = time if time is not None else np.arange(-t_pre, t_stim + t_post - dt, dt)\n    return (time &gt;= t_start) &amp; (time &lt;= t_end)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_bar_responses.time_window","title":"time_window","text":"<pre><code>time_window(speed, from_column=-1.5, to_column=1.5, start=-10, end=11)\n</code></pre> <p>Calculate start and end time when the bar passes from_column to to_column.</p> <p>Parameters:</p> Name Type Description Default <code>speed</code> <code>float</code> <p>Speed in columns/s (5.8deg/s).</p> required <code>from_column</code> <code>float</code> <p>Starting column in 5.8deg units.</p> <code>-1.5</code> <code>to_column</code> <code>float</code> <p>Ending column in 5.8deg units.</p> <code>1.5</code> <code>start</code> <code>float</code> <p>Starting position in LED units (2.25deg).</p> <code>-10</code> <code>end</code> <code>float</code> <p>Ending position in LED units (2.25deg).</p> <code>11</code> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple containing start and end times.</p> Note <p>The function adjusts the to_column by adding a single LED width (2.25 deg) to make it symmetric around the central column.</p> Source code in <code>flyvis/analysis/moving_bar_responses.py</code> <pre><code>def time_window(\n    speed: float,\n    from_column: float = -1.5,\n    to_column: float = 1.5,\n    start: float = -10,\n    end: float = 11,\n) -&gt; tuple[float, float]:\n    \"\"\"\n    Calculate start and end time when the bar passes from_column to to_column.\n\n    Args:\n        speed: Speed in columns/s (5.8deg/s).\n        from_column: Starting column in 5.8deg units.\n        to_column: Ending column in 5.8deg units.\n        start: Starting position in LED units (2.25deg).\n        end: Ending position in LED units (2.25deg).\n\n    Returns:\n        Tuple containing start and end times.\n\n    Note:\n        The function adjusts the to_column by adding a single LED width (2.25 deg)\n        to make it symmetric around the central column.\n    \"\"\"\n    start_in_columns = start * 2.25 / 5.8  # in 5.8deg\n    end_in_columns = end * 2.25 / 5.8  # in 5.8deg\n\n    # Make it symmetric around the central column by adding a single LED width\n    to_column += 2.25 / 5.8\n\n    assert abs(start_in_columns) &gt;= abs(from_column)\n    assert abs(end_in_columns) &gt;= abs(to_column)\n\n    # Calculate when the edge is at the from_column\n    t_start = (abs(start_in_columns) - abs(from_column)) / speed\n    # Calculate when it's at the to_column\n    t_end = t_start + (to_column - from_column) / speed\n    return t_start, t_end\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#current-analysis","title":"Current Analysis","text":""},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView","title":"flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView","text":"<p>Represents a view of moving edge currents for analysis and visualization.</p> <p>This class provides methods for analyzing and visualizing currents and responses related to moving edge stimuli in neural simulations.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <p>The ensemble of models.</p> required <code>target_type</code> <code>str</code> <p>The type of target cell.</p> required <code>exp_data</code> <code>List[ExperimentData]</code> <p>Experimental data.</p> required <code>arg_df</code> <code>DataFrame | None</code> <p>DataFrame containing stimulus arguments.</p> <code>None</code> <code>currents</code> <code>Namespace | None</code> <p>Currents for each source type.</p> <code>None</code> <code>rfs</code> <code>ReceptiveFields | None</code> <p>Receptive fields for the target cells.</p> <code>None</code> <code>time</code> <code>ndarray | None</code> <p>Time array for the simulation.</p> <code>None</code> <code>responses</code> <code>ndarray | None</code> <p>Responses of the target cells.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>target_type</code> <p>The type of target cell.</p> <code>ensemble</code> <p>The ensemble of models.</p> <code>config</code> <p>Configuration settings.</p> <code>arg_df</code> <p>DataFrame containing stimulus arguments.</p> <code>rfs</code> <p>Receptive fields for the target cells.</p> <code>exp_data</code> <p>Experimental data.</p> <code>source_types</code> <p>Types of source cells.</p> <code>time</code> <p>Time array for the simulation.</p> <code>currents</code> <p>Currents for each source type.</p> <code>responses</code> <p>Responses of the target cells.</p> Note <p>This class is intended to be updated to use xarray datasets in the future.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>class MovingEdgeCurrentView:\n    \"\"\"Represents a view of moving edge currents for analysis and visualization.\n\n    This class provides methods for analyzing and visualizing currents and responses\n    related to moving edge stimuli in neural simulations.\n\n    Args:\n        ensemble: The ensemble of models.\n        target_type: The type of target cell.\n        exp_data: Experimental data.\n        arg_df: DataFrame containing stimulus arguments.\n        currents: Currents for each source type.\n        rfs: Receptive fields for the target cells.\n        time: Time array for the simulation.\n        responses: Responses of the target cells.\n\n    Attributes:\n        target_type: The type of target cell.\n        ensemble: The ensemble of models.\n        config: Configuration settings.\n        arg_df: DataFrame containing stimulus arguments.\n        rfs: Receptive fields for the target cells.\n        exp_data: Experimental data.\n        source_types: Types of source cells.\n        time: Time array for the simulation.\n        currents: Currents for each source type.\n        responses: Responses of the target cells.\n\n    Note:\n        This class is intended to be updated to use xarray datasets in the future.\n    \"\"\"\n\n    def __init__(\n        self,\n        ensemble,\n        target_type: str,\n        exp_data: List[ExperimentData],\n        arg_df: pd.DataFrame | None = None,\n        currents: Namespace | None = None,\n        rfs: ReceptiveFields | None = None,\n        time: np.ndarray | None = None,\n        responses: np.ndarray | None = None,\n    ):\n        self.target_type = target_type\n        self.ensemble = ensemble\n        self.config = exp_data[0].config\n        if arg_df is None:\n            self.arg_df = MovingEdge(**exp_data[0].config).arg_df\n        else:\n            self.arg_df = arg_df\n        self.rfs = rfs or reset_index(\n            ReceptiveFields(target_type, ensemble[0].connectome.edges.to_df())\n        )\n        self.exp_data = exp_data\n        self.source_types = self.rfs.source_types\n        self.time = time\n        self.init_currents(currents)\n        self.init_time(time)\n        self.init_responses(responses)\n\n    def init_currents(self, currents: Namespace | None) -&gt; None:\n        \"\"\"Initialize the currents for each source type.\n\n        Args:\n            currents: Currents for each source type.\n        \"\"\"\n        if currents is not None:\n            self.currents = currents\n            return\n        self.currents = Namespace()\n        for source_type in self.rfs.source_types:\n            # (on/off, n_models, n_angles, n_timesteps, n_input_cells)\n            self.currents[source_type] = np.array(\n                [\n                    np.array(exp.target_data[self.target_type].source_data[source_type])\n                    for exp in self.exp_data\n                ],\n            )\n\n    def init_responses(self, responses: np.ndarray | None) -&gt; None:\n        \"\"\"Initialize the responses of the target cells.\n\n        Args:\n            responses: Responses of the target cells.\n        \"\"\"\n        if responses is not None:\n            self.responses = responses\n            return\n        # (on/off, n_models, n_angles, n_timesteps)\n        self.responses = np.array(\n            [\n                np.array(exp.target_data[self.target_type].activity_central)\n                for exp in self.exp_data\n            ],\n        )\n\n    def init_time(self, time: np.ndarray | None) -&gt; None:\n        \"\"\"Initialize the time array for the simulation.\n\n        Args:\n            time: Time array for the simulation.\n        \"\"\"\n        if time is not None:\n            self.time = time\n            return\n        self.time = self.time or (\n            np.arange(0, next(iter(self.currents.values())).shape[-2]) * self.config.dt\n            - self.config.t_pre\n        )\n\n    @property\n    def on(self) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Return a view of the ON responses.\"\"\"\n        on_index = get_stimulus_index(self.arg_df, intensity=0)\n        arg_df = self.arg_df.iloc[on_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=on_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=on_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    @property\n    def off(self) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Return a view of the OFF responses.\"\"\"\n        off_index = get_stimulus_index(self.arg_df, intensity=0)\n        arg_df = self.arg_df.iloc[off_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=off_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=off_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    def divide_by_given_norm(self, norm: CellTypeArray) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Divide currents and responses by a given norm.\n\n        Args:\n            norm: The norm to divide by.\n\n        Returns:\n            A new view with normalized currents and responses.\n\n        Raises:\n            ValueError: If norm is not a CellTypeArray.\n        \"\"\"\n        if not isinstance(norm, CellTypeArray):\n            raise ValueError\n\n        response_dims = np.arange(len(self.responses.shape))\n        response_norm = np.expand_dims(\n            norm[self.target_type].squeeze(), list(set(response_dims) - set([0]))\n        )\n\n        # divide the responses by the norm\n        new_responses = self.responses[:] / response_norm\n\n        # note: we also divide by the norm of the target cell type\n\n        currents_dims = np.arange(len(next(iter(self.currents.values())).shape))\n\n        currents_norm = np.expand_dims(\n            norm[self.target_type].squeeze(), list(set(currents_dims) - set([0]))\n        )\n\n        # divide the currents by the norm\n        new_currents = Namespace({\n            cell_type: c / currents_norm for cell_type, c in self.currents.items()\n        })\n        return self.view(currents=new_currents, responses=new_responses)\n\n    def at_contrast(self, contrast: float) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Create a new view filtered by contrast.\n\n        Args:\n            contrast: The contrast value to filter by.\n\n        Returns:\n            A new view with data filtered by the specified contrast.\n        \"\"\"\n        contrast_index = get_stimulus_index(self.arg_df, intensity=contrast)\n        arg_df = self.arg_df.iloc[contrast_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=contrast_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=contrast_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    def at_angle(self, angle: float) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Create a new view filtered by angle.\n\n        Args:\n            angle: The angle value to filter by.\n\n        Returns:\n            A new view with data filtered by the specified angle.\n        \"\"\"\n        angle_index = get_stimulus_index(self.arg_df, angle=angle)\n        arg_df = self.arg_df.iloc[angle_index]\n        return self.view(\n            Namespace({\n                cell_type: np.take(c, indices=angle_index, axis=1)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=np.take(self.responses, indices=angle_index, axis=1),\n            arg_df=arg_df,\n        )\n\n    def at_position(\n        self, u: float | None = None, v: float | None = None, central: bool = True\n    ) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Create a new view filtered by position.\n\n        Args:\n            u: The u-coordinate.\n            v: The v-coordinate.\n            central: Whether to use central position.\n\n        Returns:\n            A new view with data filtered by the specified position.\n        \"\"\"\n        rfs = at_position(self.rfs, u, v, central)\n        currents = Namespace({\n            cell_type: c[:, :, :, :, rfs[cell_type].index]\n            for cell_type, c in self.currents.items()\n        })\n        return self.view(currents, rfs=rfs)\n\n    def between_seconds(self, t_start: float, t_end: float) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Create a new view filtered by time range.\n\n        Args:\n            t_start: Start time in seconds.\n            t_end: End time in seconds.\n\n        Returns:\n            A new view with data filtered by the specified time range.\n        \"\"\"\n        slice = np.where((self.time &gt;= t_start) &amp; (self.time &lt; t_end))[0]\n        newview = self[:, :, slice, :]\n        newview.time = self.time[slice]\n        newview.responses = self.responses[:, :, slice]\n        return newview\n\n    def model_selection(self, mask: np.ndarray) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Create a new view with selected models.\n\n        Args:\n            mask: Boolean mask for model selection.\n\n        Returns:\n            A new view with selected models.\n        \"\"\"\n        return self[mask, :, :, :]\n\n    def __getattr__(self, key):\n        return self.__getitem__(key)\n\n    def __getitem__(self, key) -&gt; Union[\"MovingEdgeCurrentView\", Any]:\n        # e.g. view.C3\n        if isinstance(key, str) and key in self.source_types:\n            return self.view(Namespace({key: self.currents[key]}))\n        # e.g. view[\"C3\", 0, 0, 0]\n        elif (\n            isinstance(key, Iterable)\n            and isinstance(key[0], str)\n            and key[0] in self.source_types\n            and len(key[1:]) == self.shape\n        ):\n            return self.view(self.currents[key[0]][key[1:]])\n        # e.g. view[index, :, :, :]\n        elif isinstance(key, Iterable) and len(key) == len(self.shape):\n            return self.view(\n                Namespace({cell_type: c[key] for cell_type, c in self.currents.items()}),\n                responses=self.responses[key[:-1]],\n            )\n        # view[:]\n        elif key == slice(None):\n            if len(self.currents) == 1:\n                return next(iter(self.currents.values()))\n            return self.currents\n        return object.__getattribute__(self, key)\n\n    def __repr__(self):\n        cv = {ct: v.shape for ct, v in self.currents.items()}\n        formatted_cv = \",\\n        \".join(\n            f\"'{ct}': Array(shape={v})\" for ct, v in cv.items()\n        )\n        return (\n            f\"{self.__class__.__name__}(\\n\"\n            f\"    ensemble={self.ensemble.name},\\n\"\n            f\"    target_type={self.target_type},\\n\"\n            f\"    currents={{\\n        {formatted_cv}\\n    }},\\n\"\n            f\"    rfs={self.rfs}\\n\"\n            f\")\"\n        )\n\n    @property\n    def shape(self):\n        return next(iter(self.currents.values())).shape\n\n    def sorting(self, average_over_models: bool = True, mode: str = \"all\") -&gt; np.ndarray:\n        \"\"\"Sort cell types based on their contributions.\n\n        Args:\n            average_over_models: Whether to average over models.\n            mode: Sorting mode (\"all\", \"excitatory\", or \"inhibitory\").\n\n        Returns:\n            Sorted array of cell types.\n\n        Raises:\n            ValueError: If an invalid mode is provided.\n        \"\"\"\n        summed = self if len(self.shape) == 4 else self.sum_over_cells()\n        signs = self.signs()\n        if average_over_models:\n            absmax = {\n                k: v * signs[k]\n                for k, v in valmap(\n                    lambda v: np.nanmax(\n                        np.abs(np.nanmean(v, axis=1, keepdims=True)),\n                        axis=(0, 2, 3),\n                    ),\n                    summed[:],\n                ).items()\n            }\n        else:\n            # summing over on/off, angles and time to sort -- results in n_models sortings\n            absmax = {\n                k: v * signs[k]\n                for k, v in valmap(\n                    lambda v: np.nanmax(np.abs(v), axis=(0, 2, 3)), summed[:]\n                ).items()\n            }\n        cell_types = np.array(list(absmax.keys()))\n        values = np.array(list(absmax.values()))\n        sorting = np.argsort(values, axis=0).T\n        #         if average_over_models:\n        #             # add extra dimension here for the next operation\n        #             sorting = sorting[None]\n        self.sorted_cell_types = cell_types[sorting[:, ::-1]]\n\n        # return all excitatory and inhibitory from most excitatory to most inhibitory\n        if mode == \"all\":\n            return self.sorted_cell_types\n        # from most excitatory to least excitatory\n        elif mode == \"excitatory\":\n            assert average_over_models\n            return np.array([\n                cell_type\n                for cell_type in self.sorted_cell_types[0]\n                if signs[cell_type] == 1\n            ])\n        # from most inhibitory to least inhibitory\n        elif mode == \"inhibitory\":\n            assert average_over_models\n            return np.array([\n                cell_type\n                for cell_type in self.sorted_cell_types[0][::-1]\n                if signs[cell_type] == -1\n            ])\n        else:\n            raise ValueError(f\"mode {mode}\")\n\n    def filter_cell_types_by_contribution(\n        self,\n        bins: int = 3,\n        cut_off_edge: int = 1,\n        mode: str = \"above_cut_off\",\n        statistic: Callable = np.max,\n    ) -&gt; np.ndarray:\n        \"\"\"Filter cell types based on their contribution.\n\n        Args:\n            bins: Number of bins for contribution levels.\n            cut_off_edge: Edge index for cut-off.\n            mode: Filtering mode (\"above_cut_off\" or \"below_cut_off\").\n            statistic: Function to compute the statistic.\n\n        Returns:\n            Filtered array of cell types.\n\n        Raises:\n            ValueError: If an invalid mode is provided.\n\n        Info:\n            In principle, chunks the y-axis of the current plots into excitatory and\n            inhibitory parts and each of the parts into bins. All cell types with currents\n            above or below, depending on the mode, the specified bin edge are discarded.\n        \"\"\"\n        sorting = self.sorting()[0]\n        signs = self.signs()\n        currents = self.sum_over_cells().currents\n\n        filtered_cell_types = []\n        for sign in [1, -1]:\n            # compute the std over all inputs\n            values = {\n                cell_type: statistic(np.abs(currents[cell_type][:]))\n                for cell_type in sorting\n                if signs[cell_type] == sign\n            }\n            # bin into three bins\n            # ala (low contribution, medium contribution, high contribution)\n            counts, bins = np.histogram(list(values.values()), bins=bins)\n            cut_off_value = bins[cut_off_edge]\n            if mode == \"above_cut_off\":\n                filtered_cell_types.extend(\n                    list(valfilter(lambda v, cut_off=cut_off_value: v &gt;= cut_off, values))\n                )\n            elif mode == \"below_cut_off\":\n                filtered_cell_types.extend(\n                    list(valfilter(lambda v, cut_off=cut_off_value: v &lt; cut_off, values))\n                )\n            else:\n                raise ValueError(f\"mode {mode}\")\n        return np.array(filtered_cell_types)\n\n    def filter_source_types(\n        self,\n        hide_source_types: str | list | None,\n        bins: int,\n        edge: int,\n        mode: str,\n        statistic: Callable = np.max,\n    ) -&gt; np.ndarray:\n        \"\"\"Filter source types based on various criteria.\n\n        Args:\n            hide_source_types: Source types to hide or \"auto\".\n            bins: Number of bins for contribution levels.\n            edge: Edge index for cut-off.\n            mode: Filtering mode.\n            statistic: Function to compute the statistic.\n\n        Returns:\n            Filtered array of source types.\n        \"\"\"\n        source_types = self.sorting()[0]\n        if isinstance(hide_source_types, str) and hide_source_types == \"auto\":\n            hide_source_types = self.filter_cell_types_by_contribution(\n                bins=bins, cut_off_edge=edge, mode=mode, statistic=statistic\n            )\n\n        if hide_source_types is not None:\n            source_types = np.array([\n                source_type\n                for source_type in source_types\n                if source_type not in hide_source_types\n            ])\n        return source_types\n\n    def signs(self) -&gt; dict[str, float]:\n        \"\"\"Compute the signs of receptive fields for each source type.\n\n        Returns:\n            Dictionary of signs for each source type.\n        \"\"\"\n        return {ct: np.mean(self.rfs[ct].sign) for ct in self.rfs.source_types}\n\n    def sum_over_cells(self) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"Sum currents over cells.\n\n        Returns:\n            A new view with currents summed over cells.\n        \"\"\"\n        return self.view(\n            Namespace({\n                cell_type: c.sum(axis=-1) for cell_type, c in self.currents.items()\n            }),\n        )\n\n    def plot_spatial_contribution(\n        self,\n        source_type: str,\n        t_start: float,\n        t_end: float,\n        mode: str = \"peak\",\n        title: str = \"{source_type} :\u2192\",\n        fig: plt.Figure | None = None,\n        ax: plt.Axes | None = None,\n        max_extent: float | None = None,\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"Plot the spatial contribution of a source type.\n\n        Args:\n            source_type: The source type to plot.\n            t_start: Start time for the plot.\n            t_end: End time for the plot.\n            mode: Mode for calculating values (\"peak\", \"mean\", or \"std\").\n            title: Title format string for the plot.\n            fig: Existing figure to use.\n            ax: Existing axes to use.\n            max_extent: Maximum extent of the spatial filter.\n            **kwargs: Additional keyword arguments for plt_utils.kernel.\n\n        Returns:\n            Axes object containing the plot.\n        \"\"\"\n        current_view = kwargs.get(\"current_view\") or (\n            self.between_seconds(t_start, t_end)  # .at_contrast(contrast).at_angle(angle)\n        )\n\n        vmin = kwargs.get(\"vmin\") or (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        current.mean(axis=(0, 1, 2)).min()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        vmax = kwargs.get(\"vmax\") or (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        current.mean(axis=(0, 1, 2)).max()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        u, v = current_view.rfs[source_type][[\"source_u\", \"source_v\"]].values.T\n        # average over models\n        # (1, n_models, 1, n_timesteps, n_models) -&gt; (n_timesteps, n_models)\n        # import pdb\n\n        # pdb.set_trace()\n        values = current_view[source_type][:].mean(axis=(0, 1))\n        if mode == \"peak\":\n            values = values[\n                np.argmax(np.abs(values), axis=0), np.arange(values.shape[-1])\n            ]\n        elif mode == \"mean\":\n            values = np.mean(values, axis=0)\n        elif mode == \"std\":\n            signs = self.signs()\n            values = signs[source_type] * np.std(values, axis=0)\n        fig, ax, _ = plots.kernel(\n            u,\n            v,\n            values,\n            fill=True,\n            max_extent=max_extent or current_view.rfs.max_extent,\n            label=title.format(source_type=source_type),\n            labelxy=\"auto\",\n            strict_sign=False,\n            fig=fig,\n            ax=ax,\n            **kwargs,\n        )\n        (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n        ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n        ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n\n    def plot_spatial_contribution_grid(\n        self,\n        t_start: float,\n        t_end: float,\n        max_extent: float = 3,\n        mode: str = \"peak\",\n        title: str = \"{source_type} :\u2192\",\n        fig: plt.Figure | None = None,\n        axes: np.ndarray[plt.Axes] | None = None,\n        fontsize: float = 5,\n        edgewidth: float = 0.125,\n        title_y: float = 0.8,\n        max_figure_height_cm: float = 9.271,\n        panel_height_cm: float | str = \"auto\",\n        max_figure_width_cm: float = 2.54,\n        panel_width_cm: float = 2.54,\n        annotate: bool = False,\n        cbar: bool = False,\n        hide_source_types: str | list | None = \"auto\",\n        hide_source_types_bins: int = 5,\n        hide_source_types_cut_off_edge: int = 1,\n        hide_source_types_mode: str = \"below_cut_off\",\n        max_axes: int | None = None,\n        **kwargs,\n    ) -&gt; tuple[\n        plt.Figure,\n        np.ndarray[plt.Axes],\n        tuple[plt.Colorbar, plt.Colormap, plt.Normalize, float, float],\n    ]:\n        \"\"\"Plot a grid of spatial contributions for different source types.\n\n        Args:\n            t_start: Start time for the plot.\n            t_end: End time for the plot.\n            max_extent: Maximum extent of the spatial filter.\n            mode: Mode for calculating values (\"peak\", \"mean\", or \"std\").\n            title: Title format string for each subplot.\n            fig: Existing figure to use.\n            axes: Existing axes to use.\n            fontsize: Font size for labels and titles.\n            edgewidth: Width of edges in the plot.\n            title_y: Y-position of the title.\n            max_figure_height_cm: Maximum figure height in centimeters.\n            panel_height_cm: Height of each panel in centimeters.\n            max_figure_width_cm: Maximum figure width in centimeters.\n            panel_width_cm: Width of each panel in centimeters.\n            annotate: Whether to annotate the plots.\n            cbar: Whether to add a colorbar.\n            hide_source_types: Source types to hide or \"auto\".\n            hide_source_types_bins: Number of bins for auto-hiding.\n            hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n            hide_source_types_mode: Mode for auto-hiding source types.\n            max_axes: Maximum number of axes to create.\n            **kwargs: Additional keyword arguments for plot_spatial_contribution.\n\n        Returns:\n            Figure, axes, and colorbar information (cbar, cmap, norm, vmin, vmax).\n        \"\"\"\n        current_view = self.between_seconds(t_start, t_end)\n\n        vmin = (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        current.mean(axis=(0, 1, 2)).min()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 10\n            )\n            / 10\n        )\n\n        vmax = (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        current.mean(axis=(0, 1, 2)).max()\n                        for current in list(current_view[:].values())\n                    ),\n                )\n                * 10\n            )\n            / 10\n        )\n\n        source_types = self.filter_source_types(\n            hide_source_types,\n            bins=hide_source_types_bins,\n            edge=hide_source_types_cut_off_edge,\n            mode=hide_source_types_mode,\n        )\n\n        if fig is None and axes is None:\n            figsize = figsize_from_n_items(\n                max_axes or len(source_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=(\n                    max_figure_height_cm / (max_axes or len(source_types))\n                    if panel_height_cm == \"auto\"\n                    else panel_height_cm\n                ),\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=max_axes or len(source_types), hspace=0.1, wspace=0\n            )\n            if max_axes is not None and len(source_types) &lt; max_axes:\n                for ax in np.array(axes).flatten():\n                    if isinstance(ax, Axes):\n                        ax.axis(\"off\")\n\n        for i, source_type in enumerate(source_types):\n            self.plot_spatial_contribution(\n                source_type,\n                #                 contrast,\n                #                 angle,\n                t_start,\n                t_end,\n                mode=mode,\n                title=title,\n                fontsize=fontsize,\n                edgewidth=edgewidth,\n                title_y=title_y,\n                fig=fig,\n                ax=axes[i],\n                current_view=current_view,\n                vmin=vmin,\n                vmax=vmax,\n                annotate=annotate,\n                cbar=False,\n                max_extent=max_extent or current_view.rfs.max_extent,\n                **kwargs,\n            )\n\n        cmap = plt.cm.seismic\n        norm = plt_utils.get_norm(vmin=vmin, vmax=vmax, midpoint=0)\n        if cbar:\n            cbar = plt_utils.add_colorbar_to_fig(\n                fig,\n                width=0.01,\n                height=0.25,\n                fontsize=fontsize,\n                cmap=cmap,\n                norm=norm,\n                label=f\"{mode} input currents\",\n                n_ticks=4,\n                n_decimals=1,\n            )\n        return fig, axes, (cbar, cmap, norm, vmin, vmax)\n\n    def plot_spatial_filter(\n        self,\n        source_type: str,\n        title: str = \"{source_type} :\u2192\",\n        fig: plt.Figure | None = None,\n        ax: plt.Axes | None = None,\n        max_extent: float | None = None,\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"Plot the spatial filter for a given source type.\n\n        Args:\n            source_type: The source type to plot.\n            title: Title format string for the plot.\n            fig: Existing figure to use.\n            ax: Existing axes to use.\n            max_extent: Maximum extent of the spatial filter.\n            **kwargs: Additional keyword arguments for plt_utils.kernel.\n\n        Returns:\n            Axes object containing the plot.\n        \"\"\"\n        filter = self.rfs\n\n        def filter_values(rf):\n            return (rf.n_syn * rf.sign).values\n\n        vmin = kwargs.pop(\"vmin\", None) or (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        min(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        vmax = kwargs.pop(\"vmax\", None) or (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        max(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        u, v = filter[source_type][[\"source_u\", \"source_v\"]].values.T\n        # average over models\n        # (1, n_models, 1, n_timesteps, n_models) -&gt; (n_timesteps, n_models)\n        values = filter_values(filter[source_type])\n\n        label = title.format(source_type=source_type)\n        fig, ax, _ = plt_utils.kernel(\n            u,\n            v,\n            values,\n            fill=True,\n            max_extent=max_extent or filter.max_extent,\n            label=label,\n            labelxy=\"auto\",\n            strict_sign=False,\n            fig=fig,\n            ax=ax,\n            vmin=vmin,\n            vmax=vmax,\n            **kwargs,\n        )\n        (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n        ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n        ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n        return ax\n\n    def plot_spatial_filter_grid(\n        self,\n        title: str = \"{source_type} :\u2192\",\n        fig: plt.Figure | None = None,\n        axes: np.ndarray[plt.Axes] | None = None,\n        max_extent: float | None = None,\n        fontsize: float = 5,\n        edgewidth: float = 0.125,\n        title_y: float = 0.8,\n        max_figure_height_cm: float = 9.271,\n        panel_height_cm: float | str = \"auto\",\n        max_figure_width_cm: float = 2.54,\n        panel_width_cm: float = 2.54,\n        annotate: bool = False,\n        cbar: bool = False,\n        hide_source_types: str | list | None = \"auto\",\n        hide_source_types_bins: int = 5,\n        hide_source_types_cut_off_edge: int = 1,\n        hide_source_types_mode: str = \"below_cut_off\",\n        max_axes: int | None = None,\n        wspace: float = 0.0,\n        hspace: float = 0.1,\n        **kwargs,\n    ) -&gt; tuple[\n        plt.Figure,\n        np.ndarray[plt.Axes],\n        tuple[plt.Colorbar, plt.Colormap, plt.Normalize, float, float],\n    ]:\n        \"\"\"Plot a grid of spatial filters for different source types.\n\n        Args:\n            title: Title format string for each subplot.\n            fig: Existing figure to use.\n            axes: Existing axes to use.\n            max_extent: Maximum extent of the spatial filter.\n            fontsize: Font size for labels and titles.\n            edgewidth: Width of edges in the plot.\n            title_y: Y-position of the title.\n            max_figure_height_cm: Maximum figure height in centimeters.\n            panel_height_cm: Height of each panel in centimeters.\n            max_figure_width_cm: Maximum figure width in centimeters.\n            panel_width_cm: Width of each panel in centimeters.\n            annotate: Whether to annotate the plots.\n            cbar: Whether to add a colorbar.\n            hide_source_types: Source types to hide or \"auto\".\n            hide_source_types_bins: Number of bins for auto-hiding.\n            hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n            hide_source_types_mode: Mode for auto-hiding source types.\n            max_axes: Maximum number of axes to create.\n            wspace: Width space between subplots.\n            hspace: Height space between subplots.\n            **kwargs: Additional keyword arguments for plot_spatial_filter.\n\n        Returns:\n            Figure, axes, and colorbar information (cbar, cmap, norm, vmin, vmax).\n        \"\"\"\n        filter = self.rfs\n\n        def filter_values(rf):\n            return (rf.n_syn * rf.sign).values\n\n        vmin = kwargs.pop(\"vmin\", None) or (\n            np.floor(\n                min(\n                    0,\n                    min(\n                        min(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        vmax = kwargs.pop(\"vmax\", None) or (\n            np.ceil(\n                max(\n                    0,\n                    max(\n                        max(filter_values(filter[source_type]))\n                        for source_type in self.source_types\n                    ),\n                )\n                * 100\n            )\n            / 100\n        )\n\n        source_types = self.filter_source_types(\n            hide_source_types,\n            bins=hide_source_types_bins,\n            edge=hide_source_types_cut_off_edge,\n            mode=hide_source_types_mode,\n        )\n\n        if fig is None and axes is None:\n            figsize = figsize_from_n_items(\n                max_axes or len(source_types),\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=(\n                    max_figure_height_cm / (max_axes or len(source_types))\n                    if panel_height_cm == \"auto\"\n                    else panel_height_cm\n                ),\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(\n                unmask_n=max_axes or len(source_types), hspace=hspace, wspace=wspace\n            )\n            if max_axes is not None and len(source_types) &lt; max_axes:\n                for ax in np.array(axes).flatten():\n                    if isinstance(ax, Axes):\n                        ax.axis(\"off\")\n\n        for i, source_type in enumerate(source_types):\n            self.plot_spatial_filter(\n                source_type,\n                title=title,\n                fontsize=fontsize,\n                edgewidth=edgewidth,\n                title_y=title_y,\n                fig=fig,\n                ax=axes[i],\n                vmin=vmin,\n                vmax=vmax,\n                annotate=annotate,\n                cbar=False,\n                max_extent=max_extent or filter.max_extent,\n                **kwargs,\n            )\n\n        cmap = plt.cm.seismic\n        norm = plt_utils.get_norm(vmin=vmin, vmax=vmax, midpoint=0)\n        if cbar:\n            cbar = plt_utils.add_colorbar_to_fig(\n                fig,\n                width=0.01,\n                height=0.25,\n                fontsize=fontsize,\n                cmap=cmap,\n                norm=norm,\n                label=\"spatial filters\",\n                n_ticks=4,\n                n_decimals=1,\n            )\n        return fig, axes, (cbar, cmap, norm, vmin, vmax)\n\n    def view(\n        self,\n        currents: Namespace,\n        rfs: ReceptiveFields | None = None,\n        time: np.ndarray | None = None,\n        responses: np.ndarray | None = None,\n        arg_df: pd.DataFrame | None = None,\n    ) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"\n        Create a new view with the given currents, rfs, time, responses, and arg_df.\n\n        Args:\n            currents: Currents for each source type.\n            rfs: Receptive fields for the target cells.\n            time: Time array for the simulation.\n            responses: Responses of the target cells.\n            arg_df: DataFrame containing stimulus arguments.\n\n        Returns:\n            A new view with the given data.\n        \"\"\"\n        arg_df = arg_df.reset_index(drop=True) if arg_df is not None else self.arg_df\n        return MovingEdgeCurrentView(\n            self.ensemble,\n            self.target_type,\n            self.exp_data,\n            arg_df,\n            currents,\n            rfs if rfs is not None else self.rfs,\n            time if time is not None else self.time,\n            responses if responses is not None else self.responses,\n        )\n\n    def subtract_baseline(self) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"\n        Create a new view with baseline subtracted from the currents and responses.\n\n        Returns:\n            A new view with baseline subtracted data.\n        \"\"\"\n        return self.view(\n            Namespace({\n                cell_type: c - np.take(c, [0], -2)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=self.responses - np.take(self.responses, [0], -1),\n        )\n\n    def subtract_mean(self) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"\n        Create a new view with mean subtracted from the currents and responses.\n\n        Returns:\n            A new view with mean subtracted data.\n        \"\"\"\n        return self.view(\n            Namespace({\n                cell_type: c - np.mean(c, -2, keepdims=True)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=self.responses - np.mean(self.responses, -1, keepdims=True),\n        )\n\n    def standardize(self) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"\n        Create a new view with standardized currents and responses.\n\n        Returns:\n            A new view with standardized data.\n        \"\"\"\n        return self.view(\n            Namespace({\n                cell_type: (c - np.mean(c, -2, keepdims=True))\n                / (np.std(c, -2, keepdims=True) + 1e-15)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=(self.responses - np.mean(self.responses, -1, keepdims=True))\n            / (np.std(self.responses, -1, keepdims=True) + 1e-15),\n        )\n\n    def standardize_over_time_and_pd_nd(\n        self, t_start: float, t_end: float, pd: float\n    ) -&gt; \"MovingEdgeCurrentView\":\n        \"\"\"\n        Create a new view with standardized currents and responses over time and PD/ND.\n\n        Args:\n            t_start: Start time for standardization.\n            t_end: End time for standardization.\n            pd: Preferred direction for standardization.\n\n        Returns:\n            A new view with standardized data.\n        \"\"\"\n        temp = self.between_seconds(t_start, t_end).at_angle([pd, (pd - 180) % 360])\n        return self.view(\n            Namespace({\n                cell_type: (\n                    c - np.mean(temp.currents[cell_type], (-2, -3), keepdims=True)\n                )\n                / (np.std(temp.currents[cell_type], (-2, -3), keepdims=True) + 1e-15)\n                for cell_type, c in self.currents.items()\n            }),\n            responses=(self.responses - np.mean(temp.responses, (-1, -2), keepdims=True))\n            / (np.std(temp.responses, (-1, -2), keepdims=True) + 1e-15),\n        )\n\n    def init_colors(self, source_types: list[str]) -&gt; None:\n        \"\"\"\n        Initialize colors for source types.\n\n        Args:\n            source_types: List of source types.\n        \"\"\"\n        signs = self.signs()\n        signs = {cell_type: signs[cell_type] for cell_type in source_types}\n        signs_reversed = {cell_type: signs[cell_type] for cell_type in source_types[::-1]}\n        n_exc = len([v for v in signs.values() if v == 1])\n        n_inh = len([v for v in signs.values() if v == -1])\n        exc_colors_pd = cmap_iter(\n            truncate_colormap(plt.cm.RdBu, minval=0.05, maxval=0.45, n=n_exc)\n        )\n        inh_cmap_pd = cmap_iter(\n            truncate_colormap(plt.cm.RdBu_r, minval=0.05, maxval=0.45, n=n_inh)\n        )\n        exc_colors_nd = cmap_iter(\n            truncate_colormap(plt.cm.BrBG_r, minval=0.05, maxval=0.45, n=n_exc)\n        )\n        inh_cmap_nd = cmap_iter(\n            truncate_colormap(plt.cm.BrBG, minval=0.05, maxval=0.45, n=n_inh)\n        )\n        colors_pd = {}\n        colors_nd = {}\n        for _, (cell_type, sign) in enumerate(signs.items()):\n            if sign == 1:\n                # take the first half of the RdBu colormap, i.e. red\n                colors_pd[cell_type] = next(exc_colors_pd)\n                colors_nd[cell_type] = next(exc_colors_nd)\n\n        for _, (cell_type, sign) in enumerate(signs_reversed.items()):\n            if sign == -1:\n                # take the second half of the RdBu colormap, i.e. blue\n                colors_pd[cell_type] = next(inh_cmap_pd)\n                colors_nd[cell_type] = next(inh_cmap_nd)\n        self.colors_pd = colors_pd\n        self.colors_nd = colors_nd\n\n    def color(self, source_type: str, pd: bool = True) -&gt; tuple[float, float, float]:\n        \"\"\"\n        Get the color for a given source type.\n\n        Args:\n            source_type: The source type.\n            pd: Whether to use PD or ND colors.\n\n        Returns:\n            The color as an RGB tuple.\n        \"\"\"\n        if pd:\n            return self.colors_pd[source_type]\n        return self.colors_nd[source_type]\n\n    def zorder(\n        self,\n        source_types: list[str],\n        source_type: str,\n        start_exc: int = 1000,\n        start_inh: int = 1000,\n    ) -&gt; int:\n        \"\"\"\n        Get the z-order for a given source type.\n\n        Args:\n            source_types: List of source types.\n            source_type: The source type.\n            start_exc: Starting z-order for excitatory cells.\n            start_inh: Starting z-order for inhibitory cells.\n\n        Returns:\n            The z-order for the given source type.\n        \"\"\"\n        signs = self.signs()\n        signs_reversed = {cell_type: signs[cell_type] for cell_type in source_types[::-1]}\n\n        z_order = start_exc\n        for _, (cell_type, sign) in enumerate(signs.items()):\n            if sign == 1:\n                if cell_type == source_type:\n                    return z_order\n                z_order -= 10\n\n        z_order = start_inh\n        for _, (cell_type, sign) in enumerate(signs_reversed.items()):\n            if sign == -1:\n                if cell_type == source_type:\n                    return z_order\n                z_order -= 10\n\n    def ylims(\n        self, source_types: list[str] | None = None, offset: float = 0.02\n    ) -&gt; dict[str, tuple[float, float]]:\n        \"\"\"\n        Get the y-limits for temporal contributions summed over cells.\n\n        Args:\n            source_types: List of source types to consider.\n            offset: Offset for the y-limits.\n\n        Returns:\n            Y-limits for the given source types or all source types.\n        \"\"\"\n        if source_types is not None:\n            return {\n                cell_type: plt_utils.get_lims(c, offset)\n                for cell_type, c in self.sum_over_cells().currents.items()\n                if cell_type in source_types\n            }\n        return plt_utils.get_lims(list(self.sum_over_cells().currents.values()), offset)\n\n    def plot_response(\n        self,\n        contrast: float,\n        angle: float,\n        t_start: float = 0,\n        t_end: float = 1,\n        max_figure_height_cm: float = 1.4477,\n        panel_height_cm: float = 1.4477,\n        max_figure_width_cm: float = 4.0513,\n        panel_width_cm: float = 4.0513,\n        fontsize: float = 5,\n        model_average: bool = True,\n        color: tuple[float, float, float] = (0, 0, 0),\n        legend: bool = False,\n        hide_yaxis: bool = True,\n        trim_axes: bool = True,\n        quantile: float | None = None,\n        scale_position: str | None = None,  # \"lower left\",\n        scale_label: str = \"{:.0f} ms\",\n        scale_unit: float = 1000,\n        hline: bool = False,\n        fig: plt.Figure | None = None,\n        ax: plt.Axes | None = None,\n    ):\n        \"\"\"\n        Plot the response to a moving edge stimulus.\n\n        Args:\n            contrast: The contrast of the stimulus.\n            angle: The angle of the stimulus.\n            t_start: Start time for the plot.\n            t_end: End time for the plot.\n            max_figure_height_cm: Maximum figure height in centimeters.\n            panel_height_cm: Height of each panel in centimeters.\n            max_figure_width_cm: Maximum figure width in centimeters.\n            panel_width_cm: Width of each panel in centimeters.\n            fontsize: Font size for labels and titles.\n            model_average: Whether to plot the model average.\n            color: Color for the plot.\n            legend: Whether to show the legend.\n            hide_yaxis: Whether to hide the y-axis.\n            trim_axes: Whether to trim the axes.\n            quantile: Quantile for shading.\n            scale_position: Position of the scale.\n            scale_label: Label format for the scale.\n            scale_unit: Unit for the scale.\n            hline: Whether to show a horizontal line at 0.\n            fig: Existing figure to use.\n            ax: Existing axes to use.\n\n        Returns:\n            Figure and axes objects.\n        \"\"\"\n        r_pd = (\n            self.at_angle(angle)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n        r_nd = (\n            self.at_angle((angle - 180) % 360)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n\n        color = [hex2color(PD), hex2color(ND)] if color is None else [color, color]\n\n        if model_average:\n            fig, ax, _, _ = plots.traces(\n                [r_pd.mean(axis=0), r_nd.mean(axis=0)],\n                x=self.between_seconds(t_start, t_end).time,\n                color=color,\n                linewidth=1,\n                fontsize=fontsize,\n                null_line=False,\n                fig=fig,\n                ax=ax,\n                linestyle=[\"solid\", \"dashed\"],\n                legend=\"\" if not legend else [f\"{self.target_type}\", \"null direction\"],\n                scale_pos=scale_position,\n                scale_label=scale_label,\n                scale_unit=scale_unit,\n            )\n        else:\n            fig, ax, _, _ = plots.traces(\n                r_pd,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[0], 1),\n                color=adapt_color_alpha(color[0], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                ax=ax,\n            )\n            plots.traces(\n                r_nd,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[1], 1),\n                color=adapt_color_alpha(color[1], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                linestyle=\"dashed\",\n                ax=ax,\n            )\n        if quantile:\n            quantile_pd = np.quantile(r_pd, quantile, axis=0)\n            quantile_nd = np.quantile(r_nd, quantile, axis=0)\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_pd[0],\n                quantile_pd[1],\n                facecolor=adapt_color_alpha(color[0], 0.1),\n                edgecolor=adapt_color_alpha(color[0], 1),\n                linewidth=0.25,\n            )\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_nd[0],\n                quantile_nd[1],\n                facecolor=adapt_color_alpha(color[1], 0.1),\n                edgecolor=adapt_color_alpha(color[1], 1),\n                linewidth=0.25,\n                linestyle=\"dashed\",\n            )\n\n        if hline:\n            # horizontal line at 0\n            ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        return fig, ax\n\n    def plot_response_pc_nc(\n        self,\n        contrast: float,\n        angle: float,\n        t_start: float = 0,\n        t_end: float = 1,\n        max_figure_height_cm: float = 1.4477,\n        panel_height_cm: float = 1.4477,\n        max_figure_width_cm: float = 4.0513,\n        panel_width_cm: float = 4.0513,\n        fontsize: float = 5,\n        model_average: bool = True,\n        color: tuple[float, float, float] = (0, 0, 0),\n        legend: bool = False,\n        hide_yaxis: bool = True,\n        trim_axes: bool = True,\n        quantile: float | None = None,\n        scale_position: str | None = None,\n        scale_label: str = \"{:.0f} ms\",\n        scale_unit: float = 1000,\n        fig: plt.Figure | None = None,\n        ax: plt.Axes | None = None,\n        hline: bool = False,\n    ) -&gt; tuple[plt.Figure, plt.Axes]:\n        \"\"\"\n        Plot the response to a moving edge stimulus with positive and negative contrasts.\n\n        Args:\n            contrast: The contrast of the stimulus.\n            angle: The angle of the stimulus.\n            t_start: Start time for the plot.\n            t_end: End time for the plot.\n            max_figure_height_cm: Maximum figure height in centimeters.\n            panel_height_cm: Height of each panel in centimeters.\n            max_figure_width_cm: Maximum figure width in centimeters.\n            panel_width_cm: Width of each panel in centimeters.\n            fontsize: Font size for labels and titles.\n            model_average: Whether to plot the model average.\n            color: Color for the plot.\n            legend: Whether to show the legend.\n            hide_yaxis: Whether to hide the y-axis.\n            trim_axes: Whether to trim the axes.\n            quantile: Quantile for shading.\n            scale_position: Position of the scale.\n            scale_label: Label format for the scale.\n            scale_unit: Unit for the scale.\n            fig: Existing figure to use.\n            ax: Existing axes to use.\n            hline: Whether to show a horizontal line at 0.\n\n        Returns:\n            Figure and axes objects.\n        \"\"\"\n        r_pc = (\n            self.at_angle(angle)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n        r_nc = (\n            self.at_angle(angle)\n            .at_contrast(0 if contrast == 1 else 1)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n\n        color = [hex2color(PD), hex2color(ND)] if color is None else [color, color]\n\n        if model_average:\n            fig, ax, _, _ = plots.traces(\n                [r_pc.mean(axis=0), r_nc.mean(axis=0)],\n                x=self.between_seconds(t_start, t_end).time,\n                color=color,\n                linewidth=1,\n                fontsize=fontsize,\n                null_line=False,\n                fig=fig,\n                ax=ax,\n                linestyle=[\"solid\", \"dotted\"],\n                legend=\"\" if not legend else [f\"{self.target_type}\", \"null contrast\"],\n                scale_pos=scale_position,\n                scale_label=scale_label,\n                scale_unit=scale_unit,\n            )\n        else:\n            fig, ax, _, _ = plots.traces(\n                r_pc,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[0], 1),\n                color=adapt_color_alpha(color[0], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                ax=ax,\n            )\n            plots.traces(\n                r_nc,\n                x=self.between_seconds(t_start, t_end).time,\n                mean_color=adapt_color_alpha(color[1], 1),\n                color=adapt_color_alpha(color[1], 0.5),\n                linewidth=0.25,\n                zorder_traces=0,\n                zorder_mean=10,\n                fontsize=fontsize,\n                null_line=False,\n                highlight_mean=True,\n                fig=fig,\n                linestyle=\"dashed\",\n                ax=ax,\n            )\n        if quantile:\n            quantile_pd = np.quantile(r_pc, quantile, axis=0)\n            quantile_nd = np.quantile(r_nc, quantile, axis=0)\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_pd[0],\n                quantile_pd[1],\n                facecolor=adapt_color_alpha(color[0], 0.1),\n                edgecolor=adapt_color_alpha(color[0], 1),\n                linewidth=0.25,\n            )\n            ax.fill_between(\n                self.between_seconds(t_start, t_end).time,\n                quantile_nd[0],\n                quantile_nd[1],\n                facecolor=adapt_color_alpha(color[1], 0.1),\n                edgecolor=adapt_color_alpha(color[1], 1),\n                linewidth=0.25,\n                linestyle=\"dashed\",\n            )\n\n        # horizontal line at 0\n        if hline:\n            ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        return fig, ax\n\n    def plot_temporal_contributions(\n        self,\n        contrast: float,\n        angle: float,\n        t_start: float = 0,\n        t_end: float = 1,\n        fontsize: float = 5,\n        linewidth: float = 0.25,\n        legend: bool = False,\n        legend_standalone: bool = True,\n        legend_figsize_cm: tuple[float, float] = (4.0572, 1),\n        legend_n_rows: int | None = None,\n        max_figure_height_cm: float = 3.3941,\n        panel_height_cm: float = 3.3941,\n        max_figure_width_cm: float = 4.0572,\n        panel_width_cm: float = 4.0572,\n        model_average: bool = True,\n        highlight_mean: bool = True,  # only applies if model_average is False\n        sum_exc_inh: bool = False,\n        only_sum: bool = False,\n        hide_source_types: str | list | None = \"auto\",\n        hide_source_types_bins: int = 5,\n        hide_source_types_cut_off_edge: int = 1,\n        hide_source_types_mode: str = \"below_cut_off\",\n        hide_yaxis: bool = True,\n        trim_axes: bool = True,\n        quantile: float | None = None,\n        fig: plt.Figure | None = None,\n        ax: plt.Axes | None = None,\n        legend_ax: plt.Axes | None = None,\n        hline: bool = True,\n        legend_n_cols: int | None = None,\n        baseline_color: tuple[float, float, float, float] | None = None,\n        colors: dict[str, tuple[float, float, float, float]] | None = None,\n    ):\n        \"\"\"\n        Plot temporal contributions of different source types.\n\n        Args:\n            contrast: The contrast of the stimulus.\n            angle: The angle of the stimulus.\n            t_start: Start time for the plot.\n            t_end: End time for the plot.\n            fontsize: Font size for labels and titles.\n            linewidth: Line width for traces.\n            legend: Whether to show the legend.\n            legend_standalone: Whether to create a standalone legend.\n            legend_figsize_cm: Figure size for the standalone legend.\n            legend_n_rows: Number of rows for the standalone legend.\n            max_figure_height_cm: Maximum figure height in centimeters.\n            panel_height_cm: Height of each panel in centimeters.\n            max_figure_width_cm: Maximum figure width in centimeters.\n            panel_width_cm: Width of each panel in centimeters.\n            model_average: Whether to plot the model average.\n            highlight_mean: Whether to highlight the mean trace.\n            sum_exc_inh: Whether to sum excitatory and inhibitory contributions.\n            only_sum: Whether to only plot the summed contributions.\n            hide_source_types: Source types to hide or \"auto\".\n            hide_source_types_bins: Number of bins for auto-hiding.\n            hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n            hide_source_types_mode: Mode for auto-hiding source types.\n            hide_yaxis: Whether to hide the y-axis.\n            trim_axes: Whether to trim the axes.\n            quantile: Quantile for shading.\n            fig: Existing figure to use.\n            ax: Existing axes to use.\n            legend_ax: Existing axes for the standalone legend.\n            hline: Whether to show a horizontal line at 0.\n            legend_n_cols: Number of columns for the standalone legend.\n            baseline_color: Color for the baseline.\n            colors: Colors for each source type.\n\n        Returns:\n            Figure, axes, and legend axes objects.\n\n        Example:\n            ```\n            view = MovingEdgeCurrentView(...)\n            fig, ax = view.plot_temporal_contributions(\n                contrast=1.0,\n                angle=0,\n                t_start=0,\n                t_end=1,\n                fontsize=5,\n                linewidth=0.25,\n                legend=True\n            )\n            ```\n        \"\"\"\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n        cv_pd = (\n            self.at_contrast(contrast)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n        cv_nd = (\n            self.at_contrast(contrast)\n            .at_angle((angle - 180) % 360)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n\n        source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                hide_source_types,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n\n        color_source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                None,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n        cv_pd.init_colors(color_source_types)\n        cv_nd.init_colors(color_source_types)\n\n        def plot_mean_trace(\n            time, trace, label, color, zorder, linestyle=\"solid\", ax=None, fig=None\n        ):\n            ax.plot(\n                time,\n                trace,\n                label=label,\n                color=color,\n                zorder=zorder,\n                linestyle=linestyle,\n            )\n\n        def plot_individual_traces(\n            traces, time, color, zorder, label, linestyle=\"solid\", legend=None\n        ):\n            if not only_sum and not model_average:\n                plots.traces(\n                    traces,\n                    time,\n                    mean_color=color,\n                    color=color,\n                    linewidth=linewidth,\n                    zorder_traces=0,\n                    zorder_mean=zorder,\n                    fontsize=fontsize,\n                    null_line=True,\n                    highlight_mean=highlight_mean,\n                    fig=fig,\n                    ax=ax,\n                    legend=legend or label,\n                    linestyle=linestyle,\n                )\n\n        def plot_quantile(traces, time, color, zorder, linestyle=\"solid\"):\n            if quantile:\n                Q = np.quantile(traces, quantile, axis=0)\n                ax.fill_between(\n                    time,\n                    Q[0],\n                    Q[1],\n                    facecolor=adapt_color_alpha(color, 0.1),\n                    edgecolor=color,\n                    linewidth=0.25,\n                    linestyle=linestyle,\n                    zorder=zorder - 1,\n                )\n\n        def plot_summed_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n            if np.any(trace):\n                ax.plot(\n                    time,\n                    trace,\n                    label=label,\n                    color=color,\n                    zorder=zorder,\n                    linestyle=linestyle,\n                )\n\n        def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n            # sum over cell types then average over models\n            exc_pd = np.zeros(cv_pd.shape)\n            inh_pd = np.zeros(cv_pd.shape)\n            exc_nd = np.zeros(cv_nd.shape)\n            inh_nd = np.zeros(cv_nd.shape)\n            # sum over cell types\n            for source_type in source_types:\n                if signs[source_type] == 1:\n                    exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                    exc_nd += cv_nd[source_type][:]\n                else:\n                    inh_pd += cv_pd[source_type][:]\n                    inh_nd += cv_nd[source_type][:]\n            # (n_models, n_timesteps)\n            return (\n                exc_pd.squeeze(),\n                inh_pd.squeeze(),\n                exc_nd.squeeze(),\n                inh_nd.squeeze(),\n            )\n\n        for source_type in source_types:\n            if model_average and not only_sum:\n                # mean traces solid for PD and dashed for ND\n                if baseline_color is not None:\n                    color = baseline_color\n                elif colors:\n                    color = colors[source_type]\n                else:\n                    color = cv_pd.color(source_type)\n\n                plot_mean_trace(\n                    cv_pd.time,\n                    cv_pd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    color,\n                    cv_pd.zorder(source_types, source_type),\n                    ax=ax,\n                    fig=fig,\n                )\n                plot_mean_trace(\n                    cv_nd.time,\n                    cv_nd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    color,\n                    linestyle=\"dashed\",\n                    zorder=cv_pd.zorder(source_types, source_type),\n                    ax=ax,\n                    fig=fig,\n                )\n\n            elif not model_average and not only_sum:\n                # individual traces\n                plot_individual_traces(\n                    cv_pd[source_type][:].squeeze(axis=-2),\n                    cv_pd.time,\n                    cv_pd.color(source_type),\n                    cv_pd.zorder(source_types, source_type),\n                    source_type,\n                )\n                plot_individual_traces(\n                    cv_nd[source_type][:].squeeze(axis=-2),\n                    cv_nd.time,\n                    cv_pd.color(source_type),\n                    cv_pd.zorder(source_types, source_type),\n                    source_type,\n                    linestyle=\"dashed\",\n                    legend=\"null direction\",\n                )\n\n            # quantiles\n            plot_quantile(\n                cv_pd[source_type][:].squeeze(axis=-2),\n                cv_pd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                linestyle=\"solid\",\n            )\n            plot_quantile(\n                cv_nd[source_type][:].squeeze(axis=-2),\n                cv_nd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                linestyle=\"dashed\",\n            )\n        if sum_exc_inh or only_sum:\n            # plot summed traces\n            signs = cv_pd.signs()\n            exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n                signs, source_types, cv_pd, cv_nd\n            )\n            plot_summed_trace(\n                cv_pd.time,\n                exc_pd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                exc_pd,\n                cv_pd.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nd.time,\n                exc_nd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n                linestyle=\"dashed\",\n            )\n            plot_quantile(\n                exc_nd,\n                cv_pd.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=\"dashed\",\n            )\n            plot_summed_trace(\n                cv_pd.time,\n                inh_pd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                inh_pd,\n                cv_pd.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nd.time,\n                inh_nd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n                linestyle=\"dashed\",\n            )\n            plot_quantile(\n                inh_nd,\n                cv_pd.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=\"dashed\",\n            )\n\n        if hline:\n            ax.hlines(\n                0,\n                cv_pd.time.min(),\n                cv_pd.time.max(),\n                color=(0, 0, 0, 1),\n                linewidth=0.25,\n                zorder=-10,\n            )\n\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        else:\n            ax.legend().set_visible(False)\n\n        ax.set_xlabel(\"time (s)\", fontsize=fontsize)\n        #         ax.set_ylabel(\"current (a.u.)\", fontsize=fontsize)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n\n        if legend_standalone:\n            handles, labels = ax.get_legend_handles_labels()\n            nd_handle = Line2D(\n                [0], [0], color=\"k\", lw=1, label=\"null direction\", ls=\"dashed\"\n            )\n            legend_n_rows = legend_n_rows or len(labels) + 1\n            # legend_n_cols = (len(labels) + 1) // legend_n_rows\n            legend_fig, legend_ax = plt_utils.standalone_legend(\n                [*labels[::2], \"null direction\"],\n                None,\n                [*handles[::2], nd_handle],\n                fontsize=fontsize,\n                n_cols=legend_n_cols,\n                handlelength=2,\n                columnspacing=0.8,\n                labelspacing=0.25,\n                figsize=cm_to_inch(legend_figsize_cm),\n                fig=fig if legend_ax is not None else None,\n                ax=legend_ax,\n            )\n            return fig, ax, legend_fig, legend_ax\n        return fig, ax\n\n    def plot_temporal_contributions_pc_nc(\n        self,\n        contrast: float,\n        angle: float,\n        t_start: float = 0,\n        t_end: float = 1,\n        fontsize: float = 5,\n        linewidth: float = 0.25,\n        legend: bool = False,\n        legend_standalone: bool = True,\n        legend_figsize_cm: tuple[float, float] = (4.0572, 1),\n        legend_n_rows: int | None = None,\n        max_figure_height_cm: float = 3.3941,\n        panel_height_cm: float = 3.3941,\n        max_figure_width_cm: float = 4.0572,\n        panel_width_cm: float = 4.0572,\n        model_average: bool = True,\n        highlight_mean: bool = True,\n        sum_exc_inh: bool = False,\n        only_sum: bool = False,\n        hide_source_types: str | list | None = \"auto\",\n        hide_source_types_bins: int = 5,\n        hide_source_types_cut_off_edge: int = 1,\n        hide_source_types_mode: str = \"below_cut_off\",\n        hide_yaxis: bool = True,\n        trim_axes: bool = True,\n        quantile: float | None = None,\n        fig: plt.Figure | None = None,\n        ax: plt.Axes | None = None,\n        legend_ax: plt.Axes | None = None,\n        null_linestyle: str = \"dotted\",\n        legend_n_cols: int | None = None,\n    ) -&gt; tuple[plt.Figure, plt.Axes, plt.Figure | None, plt.Axes | None]:\n        \"\"\"\n        Temporal contributions of different source types for positive/negative contrasts.\n\n        Args:\n            contrast: The contrast of the stimulus.\n            angle: The angle of the stimulus.\n            t_start: Start time for the plot.\n            t_end: End time for the plot.\n            fontsize: Font size for labels and titles.\n            linewidth: Line width for traces.\n            legend: Whether to show the legend.\n            legend_standalone: Whether to create a standalone legend.\n            legend_figsize_cm: Figure size for the standalone legend.\n            legend_n_rows: Number of rows for the standalone legend.\n            max_figure_height_cm: Maximum figure height in centimeters.\n            panel_height_cm: Height of each panel in centimeters.\n            max_figure_width_cm: Maximum figure width in centimeters.\n            panel_width_cm: Width of each panel in centimeters.\n            model_average: Whether to plot the model average.\n            highlight_mean: Whether to highlight the mean trace.\n            sum_exc_inh: Whether to sum excitatory and inhibitory contributions.\n            only_sum: Whether to only plot the summed contributions.\n            hide_source_types: Source types to hide or \"auto\".\n            hide_source_types_bins: Number of bins for auto-hiding.\n            hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n            hide_source_types_mode: Mode for auto-hiding source types.\n            hide_yaxis: Whether to hide the y-axis.\n            trim_axes: Whether to trim the axes.\n            quantile: Quantile for shading.\n            fig: Existing figure to use.\n            ax: Existing axes to use.\n            legend_ax: Existing axes for the standalone legend.\n            null_linestyle: Linestyle for null direction traces.\n            legend_n_cols: Number of columns for the standalone legend.\n\n        Returns:\n            Figure, axes, and legend axes objects.\n\n        Example:\n            ```\n            view = MovingEdgeCurrentView(...)\n            fig, ax = view.plot_temporal_contributions_pc_nc(\n                contrast=1.0,\n                angle=0,\n                t_start=0,\n                t_end=1,\n                fontsize=5,\n                linewidth=0.25,\n                legend=True\n            )\n            ```\n        \"\"\"\n        if fig is None and ax is None:\n            figsize = figsize_from_n_items(\n                1,\n                max_figure_height_cm=max_figure_height_cm,\n                panel_height_cm=panel_height_cm,\n                max_figure_width_cm=max_figure_width_cm,\n                panel_width_cm=panel_width_cm,\n            )\n            fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n            ax = axes[0]\n        cv_pd = (\n            self.at_contrast(contrast)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n        cv_nd = (\n            self.at_contrast(contrast)\n            .at_angle((angle - 180) % 360)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n\n        source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                hide_source_types,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n\n        color_source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                None,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n        cv_pd.init_colors(color_source_types)\n        cv_nd.init_colors(color_source_types)\n\n        def plot_mean_trace(\n            time, trace, label, color, zorder, linestyle=\"solid\", ax=None, fig=None\n        ):\n            ax.plot(\n                time,\n                trace,\n                label=label,\n                color=color,\n                zorder=zorder,\n                linestyle=linestyle,\n            )\n\n        def plot_individual_traces(\n            traces, time, color, zorder, label, linestyle=\"solid\", legend=None\n        ):\n            if not only_sum and not model_average:\n                plots.traces(\n                    traces,\n                    time,\n                    mean_color=color,\n                    color=color,\n                    linewidth=linewidth,\n                    zorder_traces=0,\n                    zorder_mean=zorder,\n                    fontsize=fontsize,\n                    null_line=True,\n                    highlight_mean=highlight_mean,\n                    fig=fig,\n                    ax=ax,\n                    legend=legend or label,\n                    linestyle=linestyle,\n                )\n\n        def plot_quantile(traces, time, color, zorder, linestyle=\"solid\"):\n            if quantile:\n                Q = np.quantile(traces, quantile, axis=0)\n                ax.fill_between(\n                    time,\n                    Q[0],\n                    Q[1],\n                    facecolor=adapt_color_alpha(color, 0.1),\n                    edgecolor=color,\n                    linewidth=0.25,\n                    linestyle=linestyle,\n                    zorder=zorder - 1,\n                )\n\n        def plot_summed_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n            if np.any(trace):\n                ax.plot(\n                    time,\n                    trace,\n                    label=label,\n                    color=color,\n                    zorder=zorder,\n                    linestyle=linestyle,\n                )\n\n        def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n            # sum over cell types then average over models\n            exc_pd = np.zeros(cv_pd.shape)\n            inh_pd = np.zeros(cv_pd.shape)\n            exc_nd = np.zeros(cv_nd.shape)\n            inh_nd = np.zeros(cv_nd.shape)\n            # sum over cell types\n            for source_type in source_types:\n                if signs[source_type] == 1:\n                    exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                    exc_nd += cv_nd[source_type][:]\n                else:\n                    inh_pd += cv_pd[source_type][:]\n                    inh_nd += cv_nd[source_type][:]\n            # (n_models, n_timesteps)\n            return (\n                exc_pd.squeeze(),\n                inh_pd.squeeze(),\n                exc_nd.squeeze(),\n                inh_nd.squeeze(),\n            )\n\n        for source_type in source_types:\n            if model_average and not only_sum:\n                # mean traces solid for PD and dashed for ND\n                color = cv_pd.color(source_type)\n\n                plot_mean_trace(\n                    cv_pd.time,\n                    cv_pd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    color,\n                    cv_pd.zorder(source_types, source_type),\n                    ax=ax,\n                    fig=fig,\n                )\n                plot_mean_trace(\n                    cv_nd.time,\n                    cv_nd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                    source_type,\n                    color,\n                    linestyle=null_linestyle,\n                    zorder=cv_pd.zorder(source_types, source_type),\n                    ax=ax,\n                    fig=fig,\n                )\n\n            elif not model_average and not only_sum:\n                # individual traces\n                plot_individual_traces(\n                    cv_pd[source_type][:].squeeze(axis=-2),\n                    cv_pd.time,\n                    cv_pd.color(source_type),\n                    cv_pd.zorder(source_types, source_type),\n                    source_type,\n                )\n                plot_individual_traces(\n                    cv_nd[source_type][:].squeeze(axis=-2),\n                    cv_nd.time,\n                    cv_pd.color(source_type),\n                    cv_pd.zorder(source_types, source_type),\n                    source_type,\n                    linestyle=null_linestyle,\n                    legend=\"null direction\",\n                )\n\n            # quantiles\n            plot_quantile(\n                cv_pd[source_type][:].squeeze(axis=-2),\n                cv_pd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                linestyle=\"solid\",\n            )\n            plot_quantile(\n                cv_nd[source_type][:].squeeze(axis=-2),\n                cv_nd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                linestyle=null_linestyle,\n            )\n        if sum_exc_inh or only_sum:\n            # plot summed traces\n            signs = cv_pd.signs()\n            exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n                signs, source_types, cv_pd, cv_nd\n            )\n            plot_summed_trace(\n                cv_pd.time,\n                exc_pd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                exc_pd,\n                cv_pd.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nd.time,\n                exc_nd.mean(axis=0),\n                \"excitatory\",\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=2000,\n                linestyle=null_linestyle,\n            )\n            plot_quantile(\n                exc_nd,\n                cv_pd.time,\n                (0.931, 0.0, 0.0, 1.0),\n                zorder=0,\n                linestyle=null_linestyle,\n            )\n            plot_summed_trace(\n                cv_pd.time,\n                inh_pd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n            )\n            plot_quantile(\n                inh_pd,\n                cv_pd.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=\"solid\",\n            )\n            plot_summed_trace(\n                cv_nd.time,\n                inh_nd.mean(axis=0),\n                \"inhibitory\",\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=2000,\n                linestyle=null_linestyle,\n            )\n            plot_quantile(\n                inh_nd,\n                cv_pd.time,\n                (0.0, 0.0, 0.849, 1.0),\n                zorder=0,\n                linestyle=null_linestyle,\n            )\n\n        if legend:\n            ax.legend(\n                fontsize=fontsize,\n                ncols=1,\n                bbox_to_anchor=(1.05, 1),\n                loc=\"upper left\",\n                borderaxespad=0.0,\n            )\n        else:\n            ax.legend().set_visible(False)\n\n        ax.set_xlabel(\"time (s)\", fontsize=fontsize)\n        #         ax.set_ylabel(\"current (a.u.)\", fontsize=fontsize)\n\n        if hide_yaxis:\n            plt_utils.rm_spines(ax, (\"left\",))\n\n        if trim_axes:\n            plt_utils.trim_axis(ax)\n\n        if legend_standalone:\n            handles, labels = ax.get_legend_handles_labels()\n            nd_handle = Line2D(\n                [0], [0], color=\"k\", lw=1, label=\"null direction\", ls=null_linestyle\n            )\n            legend_n_rows = legend_n_rows or len(labels) + 1\n            # legend_n_cols = (len(labels) + 1) // legend_n_rows\n            legend_fig, legend_ax = plt_utils.standalone_legend(\n                [*labels[::2], \"null direction\"],\n                None,\n                [*handles[::2], nd_handle],\n                fontsize=fontsize,\n                n_cols=legend_n_cols,\n                handlelength=2,\n                columnspacing=0.8,\n                labelspacing=0.25,\n                figsize=cm_to_inch(legend_figsize_cm),\n                fig=fig if legend_ax is not None else None,\n                ax=legend_ax,\n            )\n            return fig, ax, legend_fig, legend_ax\n        return fig, ax, None, None\n\n    def get_temporal_contributions(\n        self,\n        contrast: float,\n        angle: float,\n        t_start: float = 0,\n        t_end: float = 1,\n        hide_source_types: str | list | None = \"auto\",\n        hide_source_types_bins: int = 5,\n        hide_source_types_cut_off_edge: int = 1,\n        hide_source_types_mode: str = \"below_cut_off\",\n        summed_traces: bool = False,\n    ) -&gt; tuple[\n        \"MovingEdgeCurrentView\" | np.ndarray,\n        \"MovingEdgeCurrentView\" | np.ndarray,\n        list[str],\n        list[str],\n    ]:\n        cv_pd = (\n            self.at_contrast(contrast)\n            .at_angle(angle)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n        cv_nd = (\n            self.at_contrast(contrast)\n            .at_angle((angle - 180) % 360)\n            .between_seconds(t_start, t_end)\n            .sum_over_cells()\n        )\n\n        source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                hide_source_types,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n\n        color_source_types = (\n            self.at_contrast(contrast)\n            .at_angle([angle, (angle - 180) % 360])\n            .between_seconds(t_start, t_end)\n            .filter_source_types(\n                None,\n                hide_source_types_bins,\n                hide_source_types_cut_off_edge,\n                hide_source_types_mode,\n            )\n        )\n        cv_pd.init_colors(color_source_types)\n        cv_nd.init_colors(color_source_types)\n\n        def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n            # sum over cell types then average over models\n            exc_pd = np.zeros(cv_pd.shape)\n            inh_pd = np.zeros(cv_pd.shape)\n            exc_nd = np.zeros(cv_nd.shape)\n            inh_nd = np.zeros(cv_nd.shape)\n            # sum over cell types\n            for source_type in source_types:\n                if signs[source_type] == 1:\n                    exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                    exc_nd += cv_nd[source_type][:]\n                else:\n                    inh_pd += cv_pd[source_type][:]\n                    inh_nd += cv_nd[source_type][:]\n            # (n_models, n_timesteps)\n            return (\n                exc_pd.squeeze(),\n                inh_pd.squeeze(),\n                exc_nd.squeeze(),\n                inh_nd.squeeze(),\n            )\n\n        if summed_traces:\n            exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n                cv_pd.signs(), source_types, cv_pd, cv_nd\n            )\n            # return exc_pd, inh_pd, exc_nd, inh_nd, source_types, color_source_types\n            return exc_pd, inh_pd, exc_nd, inh_nd\n\n        return cv_pd, cv_nd, source_types, color_source_types\n\n    def get_response(\n        self,\n        contrast: float,\n        angle: float,\n        t_start: float = 0,\n        t_end: float = 1,\n        model_average: bool = True,\n    ) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n        r_pd = (\n            self.at_angle(angle)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n        r_nd = (\n            self.at_angle((angle - 180) % 360)\n            .at_contrast(contrast)\n            .between_seconds(t_start, t_end)\n            .responses.squeeze(axis=-2)\n        )\n\n        if model_average:\n            return (\n                r_pd.mean(axis=0),\n                r_nd.mean(axis=0),\n                self.between_seconds(t_start, t_end).time,\n            )\n\n        return r_pd, r_nd, self.between_seconds(t_start, t_end).time\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.on","title":"on  <code>property</code>","text":"<pre><code>on\n</code></pre> <p>Return a view of the ON responses.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.off","title":"off  <code>property</code>","text":"<pre><code>off\n</code></pre> <p>Return a view of the OFF responses.</p>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.init_currents","title":"init_currents","text":"<pre><code>init_currents(currents)\n</code></pre> <p>Initialize the currents for each source type.</p> <p>Parameters:</p> Name Type Description Default <code>currents</code> <code>Namespace | None</code> <p>Currents for each source type.</p> required Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def init_currents(self, currents: Namespace | None) -&gt; None:\n    \"\"\"Initialize the currents for each source type.\n\n    Args:\n        currents: Currents for each source type.\n    \"\"\"\n    if currents is not None:\n        self.currents = currents\n        return\n    self.currents = Namespace()\n    for source_type in self.rfs.source_types:\n        # (on/off, n_models, n_angles, n_timesteps, n_input_cells)\n        self.currents[source_type] = np.array(\n            [\n                np.array(exp.target_data[self.target_type].source_data[source_type])\n                for exp in self.exp_data\n            ],\n        )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.init_responses","title":"init_responses","text":"<pre><code>init_responses(responses)\n</code></pre> <p>Initialize the responses of the target cells.</p> <p>Parameters:</p> Name Type Description Default <code>responses</code> <code>ndarray | None</code> <p>Responses of the target cells.</p> required Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def init_responses(self, responses: np.ndarray | None) -&gt; None:\n    \"\"\"Initialize the responses of the target cells.\n\n    Args:\n        responses: Responses of the target cells.\n    \"\"\"\n    if responses is not None:\n        self.responses = responses\n        return\n    # (on/off, n_models, n_angles, n_timesteps)\n    self.responses = np.array(\n        [\n            np.array(exp.target_data[self.target_type].activity_central)\n            for exp in self.exp_data\n        ],\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.init_time","title":"init_time","text":"<pre><code>init_time(time)\n</code></pre> <p>Initialize the time array for the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>time</code> <code>ndarray | None</code> <p>Time array for the simulation.</p> required Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def init_time(self, time: np.ndarray | None) -&gt; None:\n    \"\"\"Initialize the time array for the simulation.\n\n    Args:\n        time: Time array for the simulation.\n    \"\"\"\n    if time is not None:\n        self.time = time\n        return\n    self.time = self.time or (\n        np.arange(0, next(iter(self.currents.values())).shape[-2]) * self.config.dt\n        - self.config.t_pre\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.divide_by_given_norm","title":"divide_by_given_norm","text":"<pre><code>divide_by_given_norm(norm)\n</code></pre> <p>Divide currents and responses by a given norm.</p> <p>Parameters:</p> Name Type Description Default <code>norm</code> <code>CellTypeArray</code> <p>The norm to divide by.</p> required <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with normalized currents and responses.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If norm is not a CellTypeArray.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def divide_by_given_norm(self, norm: CellTypeArray) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Divide currents and responses by a given norm.\n\n    Args:\n        norm: The norm to divide by.\n\n    Returns:\n        A new view with normalized currents and responses.\n\n    Raises:\n        ValueError: If norm is not a CellTypeArray.\n    \"\"\"\n    if not isinstance(norm, CellTypeArray):\n        raise ValueError\n\n    response_dims = np.arange(len(self.responses.shape))\n    response_norm = np.expand_dims(\n        norm[self.target_type].squeeze(), list(set(response_dims) - set([0]))\n    )\n\n    # divide the responses by the norm\n    new_responses = self.responses[:] / response_norm\n\n    # note: we also divide by the norm of the target cell type\n\n    currents_dims = np.arange(len(next(iter(self.currents.values())).shape))\n\n    currents_norm = np.expand_dims(\n        norm[self.target_type].squeeze(), list(set(currents_dims) - set([0]))\n    )\n\n    # divide the currents by the norm\n    new_currents = Namespace({\n        cell_type: c / currents_norm for cell_type, c in self.currents.items()\n    })\n    return self.view(currents=new_currents, responses=new_responses)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.at_contrast","title":"at_contrast","text":"<pre><code>at_contrast(contrast)\n</code></pre> <p>Create a new view filtered by contrast.</p> <p>Parameters:</p> Name Type Description Default <code>contrast</code> <code>float</code> <p>The contrast value to filter by.</p> required <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with data filtered by the specified contrast.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def at_contrast(self, contrast: float) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Create a new view filtered by contrast.\n\n    Args:\n        contrast: The contrast value to filter by.\n\n    Returns:\n        A new view with data filtered by the specified contrast.\n    \"\"\"\n    contrast_index = get_stimulus_index(self.arg_df, intensity=contrast)\n    arg_df = self.arg_df.iloc[contrast_index]\n    return self.view(\n        Namespace({\n            cell_type: np.take(c, indices=contrast_index, axis=1)\n            for cell_type, c in self.currents.items()\n        }),\n        responses=np.take(self.responses, indices=contrast_index, axis=1),\n        arg_df=arg_df,\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.at_angle","title":"at_angle","text":"<pre><code>at_angle(angle)\n</code></pre> <p>Create a new view filtered by angle.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <code>float</code> <p>The angle value to filter by.</p> required <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with data filtered by the specified angle.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def at_angle(self, angle: float) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Create a new view filtered by angle.\n\n    Args:\n        angle: The angle value to filter by.\n\n    Returns:\n        A new view with data filtered by the specified angle.\n    \"\"\"\n    angle_index = get_stimulus_index(self.arg_df, angle=angle)\n    arg_df = self.arg_df.iloc[angle_index]\n    return self.view(\n        Namespace({\n            cell_type: np.take(c, indices=angle_index, axis=1)\n            for cell_type, c in self.currents.items()\n        }),\n        responses=np.take(self.responses, indices=angle_index, axis=1),\n        arg_df=arg_df,\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.at_position","title":"at_position","text":"<pre><code>at_position(u=None, v=None, central=True)\n</code></pre> <p>Create a new view filtered by position.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>float | None</code> <p>The u-coordinate.</p> <code>None</code> <code>v</code> <code>float | None</code> <p>The v-coordinate.</p> <code>None</code> <code>central</code> <code>bool</code> <p>Whether to use central position.</p> <code>True</code> <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with data filtered by the specified position.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def at_position(\n    self, u: float | None = None, v: float | None = None, central: bool = True\n) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Create a new view filtered by position.\n\n    Args:\n        u: The u-coordinate.\n        v: The v-coordinate.\n        central: Whether to use central position.\n\n    Returns:\n        A new view with data filtered by the specified position.\n    \"\"\"\n    rfs = at_position(self.rfs, u, v, central)\n    currents = Namespace({\n        cell_type: c[:, :, :, :, rfs[cell_type].index]\n        for cell_type, c in self.currents.items()\n    })\n    return self.view(currents, rfs=rfs)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.between_seconds","title":"between_seconds","text":"<pre><code>between_seconds(t_start, t_end)\n</code></pre> <p>Create a new view filtered by time range.</p> <p>Parameters:</p> Name Type Description Default <code>t_start</code> <code>float</code> <p>Start time in seconds.</p> required <code>t_end</code> <code>float</code> <p>End time in seconds.</p> required <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with data filtered by the specified time range.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def between_seconds(self, t_start: float, t_end: float) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Create a new view filtered by time range.\n\n    Args:\n        t_start: Start time in seconds.\n        t_end: End time in seconds.\n\n    Returns:\n        A new view with data filtered by the specified time range.\n    \"\"\"\n    slice = np.where((self.time &gt;= t_start) &amp; (self.time &lt; t_end))[0]\n    newview = self[:, :, slice, :]\n    newview.time = self.time[slice]\n    newview.responses = self.responses[:, :, slice]\n    return newview\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.model_selection","title":"model_selection","text":"<pre><code>model_selection(mask)\n</code></pre> <p>Create a new view with selected models.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Boolean mask for model selection.</p> required <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with selected models.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def model_selection(self, mask: np.ndarray) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Create a new view with selected models.\n\n    Args:\n        mask: Boolean mask for model selection.\n\n    Returns:\n        A new view with selected models.\n    \"\"\"\n    return self[mask, :, :, :]\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.sorting","title":"sorting","text":"<pre><code>sorting(average_over_models=True, mode='all')\n</code></pre> <p>Sort cell types based on their contributions.</p> <p>Parameters:</p> Name Type Description Default <code>average_over_models</code> <code>bool</code> <p>Whether to average over models.</p> <code>True</code> <code>mode</code> <code>str</code> <p>Sorting mode (\u201call\u201d, \u201cexcitatory\u201d, or \u201cinhibitory\u201d).</p> <code>'all'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted array of cell types.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid mode is provided.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def sorting(self, average_over_models: bool = True, mode: str = \"all\") -&gt; np.ndarray:\n    \"\"\"Sort cell types based on their contributions.\n\n    Args:\n        average_over_models: Whether to average over models.\n        mode: Sorting mode (\"all\", \"excitatory\", or \"inhibitory\").\n\n    Returns:\n        Sorted array of cell types.\n\n    Raises:\n        ValueError: If an invalid mode is provided.\n    \"\"\"\n    summed = self if len(self.shape) == 4 else self.sum_over_cells()\n    signs = self.signs()\n    if average_over_models:\n        absmax = {\n            k: v * signs[k]\n            for k, v in valmap(\n                lambda v: np.nanmax(\n                    np.abs(np.nanmean(v, axis=1, keepdims=True)),\n                    axis=(0, 2, 3),\n                ),\n                summed[:],\n            ).items()\n        }\n    else:\n        # summing over on/off, angles and time to sort -- results in n_models sortings\n        absmax = {\n            k: v * signs[k]\n            for k, v in valmap(\n                lambda v: np.nanmax(np.abs(v), axis=(0, 2, 3)), summed[:]\n            ).items()\n        }\n    cell_types = np.array(list(absmax.keys()))\n    values = np.array(list(absmax.values()))\n    sorting = np.argsort(values, axis=0).T\n    #         if average_over_models:\n    #             # add extra dimension here for the next operation\n    #             sorting = sorting[None]\n    self.sorted_cell_types = cell_types[sorting[:, ::-1]]\n\n    # return all excitatory and inhibitory from most excitatory to most inhibitory\n    if mode == \"all\":\n        return self.sorted_cell_types\n    # from most excitatory to least excitatory\n    elif mode == \"excitatory\":\n        assert average_over_models\n        return np.array([\n            cell_type\n            for cell_type in self.sorted_cell_types[0]\n            if signs[cell_type] == 1\n        ])\n    # from most inhibitory to least inhibitory\n    elif mode == \"inhibitory\":\n        assert average_over_models\n        return np.array([\n            cell_type\n            for cell_type in self.sorted_cell_types[0][::-1]\n            if signs[cell_type] == -1\n        ])\n    else:\n        raise ValueError(f\"mode {mode}\")\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.filter_cell_types_by_contribution","title":"filter_cell_types_by_contribution","text":"<pre><code>filter_cell_types_by_contribution(bins=3, cut_off_edge=1, mode='above_cut_off', statistic=np.max)\n</code></pre> <p>Filter cell types based on their contribution.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>int</code> <p>Number of bins for contribution levels.</p> <code>3</code> <code>cut_off_edge</code> <code>int</code> <p>Edge index for cut-off.</p> <code>1</code> <code>mode</code> <code>str</code> <p>Filtering mode (\u201cabove_cut_off\u201d or \u201cbelow_cut_off\u201d).</p> <code>'above_cut_off'</code> <code>statistic</code> <code>Callable</code> <p>Function to compute the statistic.</p> <code>max</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered array of cell types.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid mode is provided.</p> Info <p>In principle, chunks the y-axis of the current plots into excitatory and inhibitory parts and each of the parts into bins. All cell types with currents above or below, depending on the mode, the specified bin edge are discarded.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def filter_cell_types_by_contribution(\n    self,\n    bins: int = 3,\n    cut_off_edge: int = 1,\n    mode: str = \"above_cut_off\",\n    statistic: Callable = np.max,\n) -&gt; np.ndarray:\n    \"\"\"Filter cell types based on their contribution.\n\n    Args:\n        bins: Number of bins for contribution levels.\n        cut_off_edge: Edge index for cut-off.\n        mode: Filtering mode (\"above_cut_off\" or \"below_cut_off\").\n        statistic: Function to compute the statistic.\n\n    Returns:\n        Filtered array of cell types.\n\n    Raises:\n        ValueError: If an invalid mode is provided.\n\n    Info:\n        In principle, chunks the y-axis of the current plots into excitatory and\n        inhibitory parts and each of the parts into bins. All cell types with currents\n        above or below, depending on the mode, the specified bin edge are discarded.\n    \"\"\"\n    sorting = self.sorting()[0]\n    signs = self.signs()\n    currents = self.sum_over_cells().currents\n\n    filtered_cell_types = []\n    for sign in [1, -1]:\n        # compute the std over all inputs\n        values = {\n            cell_type: statistic(np.abs(currents[cell_type][:]))\n            for cell_type in sorting\n            if signs[cell_type] == sign\n        }\n        # bin into three bins\n        # ala (low contribution, medium contribution, high contribution)\n        counts, bins = np.histogram(list(values.values()), bins=bins)\n        cut_off_value = bins[cut_off_edge]\n        if mode == \"above_cut_off\":\n            filtered_cell_types.extend(\n                list(valfilter(lambda v, cut_off=cut_off_value: v &gt;= cut_off, values))\n            )\n        elif mode == \"below_cut_off\":\n            filtered_cell_types.extend(\n                list(valfilter(lambda v, cut_off=cut_off_value: v &lt; cut_off, values))\n            )\n        else:\n            raise ValueError(f\"mode {mode}\")\n    return np.array(filtered_cell_types)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.filter_source_types","title":"filter_source_types","text":"<pre><code>filter_source_types(hide_source_types, bins, edge, mode, statistic=np.max)\n</code></pre> <p>Filter source types based on various criteria.</p> <p>Parameters:</p> Name Type Description Default <code>hide_source_types</code> <code>str | list | None</code> <p>Source types to hide or \u201cauto\u201d.</p> required <code>bins</code> <code>int</code> <p>Number of bins for contribution levels.</p> required <code>edge</code> <code>int</code> <p>Edge index for cut-off.</p> required <code>mode</code> <code>str</code> <p>Filtering mode.</p> required <code>statistic</code> <code>Callable</code> <p>Function to compute the statistic.</p> <code>max</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered array of source types.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def filter_source_types(\n    self,\n    hide_source_types: str | list | None,\n    bins: int,\n    edge: int,\n    mode: str,\n    statistic: Callable = np.max,\n) -&gt; np.ndarray:\n    \"\"\"Filter source types based on various criteria.\n\n    Args:\n        hide_source_types: Source types to hide or \"auto\".\n        bins: Number of bins for contribution levels.\n        edge: Edge index for cut-off.\n        mode: Filtering mode.\n        statistic: Function to compute the statistic.\n\n    Returns:\n        Filtered array of source types.\n    \"\"\"\n    source_types = self.sorting()[0]\n    if isinstance(hide_source_types, str) and hide_source_types == \"auto\":\n        hide_source_types = self.filter_cell_types_by_contribution(\n            bins=bins, cut_off_edge=edge, mode=mode, statistic=statistic\n        )\n\n    if hide_source_types is not None:\n        source_types = np.array([\n            source_type\n            for source_type in source_types\n            if source_type not in hide_source_types\n        ])\n    return source_types\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.signs","title":"signs","text":"<pre><code>signs()\n</code></pre> <p>Compute the signs of receptive fields for each source type.</p> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary of signs for each source type.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def signs(self) -&gt; dict[str, float]:\n    \"\"\"Compute the signs of receptive fields for each source type.\n\n    Returns:\n        Dictionary of signs for each source type.\n    \"\"\"\n    return {ct: np.mean(self.rfs[ct].sign) for ct in self.rfs.source_types}\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.sum_over_cells","title":"sum_over_cells","text":"<pre><code>sum_over_cells()\n</code></pre> <p>Sum currents over cells.</p> <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with currents summed over cells.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def sum_over_cells(self) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"Sum currents over cells.\n\n    Returns:\n        A new view with currents summed over cells.\n    \"\"\"\n    return self.view(\n        Namespace({\n            cell_type: c.sum(axis=-1) for cell_type, c in self.currents.items()\n        }),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_spatial_contribution","title":"plot_spatial_contribution","text":"<pre><code>plot_spatial_contribution(source_type, t_start, t_end, mode='peak', title='{source_type} :\u2192', fig=None, ax=None, max_extent=None, **kwargs)\n</code></pre> <p>Plot the spatial contribution of a source type.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>The source type to plot.</p> required <code>t_start</code> <code>float</code> <p>Start time for the plot.</p> required <code>t_end</code> <code>float</code> <p>End time for the plot.</p> required <code>mode</code> <code>str</code> <p>Mode for calculating values (\u201cpeak\u201d, \u201cmean\u201d, or \u201cstd\u201d).</p> <code>'peak'</code> <code>title</code> <code>str</code> <p>Title format string for the plot.</p> <code>'{source_type} :\u2192'</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes | None</code> <p>Existing axes to use.</p> <code>None</code> <code>max_extent</code> <code>float | None</code> <p>Maximum extent of the spatial filter.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for plt_utils.kernel.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Axes object containing the plot.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_spatial_contribution(\n    self,\n    source_type: str,\n    t_start: float,\n    t_end: float,\n    mode: str = \"peak\",\n    title: str = \"{source_type} :\u2192\",\n    fig: plt.Figure | None = None,\n    ax: plt.Axes | None = None,\n    max_extent: float | None = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot the spatial contribution of a source type.\n\n    Args:\n        source_type: The source type to plot.\n        t_start: Start time for the plot.\n        t_end: End time for the plot.\n        mode: Mode for calculating values (\"peak\", \"mean\", or \"std\").\n        title: Title format string for the plot.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n        max_extent: Maximum extent of the spatial filter.\n        **kwargs: Additional keyword arguments for plt_utils.kernel.\n\n    Returns:\n        Axes object containing the plot.\n    \"\"\"\n    current_view = kwargs.get(\"current_view\") or (\n        self.between_seconds(t_start, t_end)  # .at_contrast(contrast).at_angle(angle)\n    )\n\n    vmin = kwargs.get(\"vmin\") or (\n        np.floor(\n            min(\n                0,\n                min(\n                    current.mean(axis=(0, 1, 2)).min()\n                    for current in list(current_view[:].values())\n                ),\n            )\n            * 100\n        )\n        / 100\n    )\n\n    vmax = kwargs.get(\"vmax\") or (\n        np.ceil(\n            max(\n                0,\n                max(\n                    current.mean(axis=(0, 1, 2)).max()\n                    for current in list(current_view[:].values())\n                ),\n            )\n            * 100\n        )\n        / 100\n    )\n\n    u, v = current_view.rfs[source_type][[\"source_u\", \"source_v\"]].values.T\n    # average over models\n    # (1, n_models, 1, n_timesteps, n_models) -&gt; (n_timesteps, n_models)\n    # import pdb\n\n    # pdb.set_trace()\n    values = current_view[source_type][:].mean(axis=(0, 1))\n    if mode == \"peak\":\n        values = values[\n            np.argmax(np.abs(values), axis=0), np.arange(values.shape[-1])\n        ]\n    elif mode == \"mean\":\n        values = np.mean(values, axis=0)\n    elif mode == \"std\":\n        signs = self.signs()\n        values = signs[source_type] * np.std(values, axis=0)\n    fig, ax, _ = plots.kernel(\n        u,\n        v,\n        values,\n        fill=True,\n        max_extent=max_extent or current_view.rfs.max_extent,\n        label=title.format(source_type=source_type),\n        labelxy=\"auto\",\n        strict_sign=False,\n        fig=fig,\n        ax=ax,\n        **kwargs,\n    )\n    (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n    ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n    ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_spatial_contribution_grid","title":"plot_spatial_contribution_grid","text":"<pre><code>plot_spatial_contribution_grid(t_start, t_end, max_extent=3, mode='peak', title='{source_type} :\u2192', fig=None, axes=None, fontsize=5, edgewidth=0.125, title_y=0.8, max_figure_height_cm=9.271, panel_height_cm='auto', max_figure_width_cm=2.54, panel_width_cm=2.54, annotate=False, cbar=False, hide_source_types='auto', hide_source_types_bins=5, hide_source_types_cut_off_edge=1, hide_source_types_mode='below_cut_off', max_axes=None, **kwargs)\n</code></pre> <p>Plot a grid of spatial contributions for different source types.</p> <p>Parameters:</p> Name Type Description Default <code>t_start</code> <code>float</code> <p>Start time for the plot.</p> required <code>t_end</code> <code>float</code> <p>End time for the plot.</p> required <code>max_extent</code> <code>float</code> <p>Maximum extent of the spatial filter.</p> <code>3</code> <code>mode</code> <code>str</code> <p>Mode for calculating values (\u201cpeak\u201d, \u201cmean\u201d, or \u201cstd\u201d).</p> <code>'peak'</code> <code>title</code> <code>str</code> <p>Title format string for each subplot.</p> <code>'{source_type} :\u2192'</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>axes</code> <code>ndarray[Axes] | None</code> <p>Existing axes to use.</p> <code>None</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>edgewidth</code> <code>float</code> <p>Width of edges in the plot.</p> <code>0.125</code> <code>title_y</code> <code>float</code> <p>Y-position of the title.</p> <code>0.8</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>9.271</code> <code>panel_height_cm</code> <code>float | str</code> <p>Height of each panel in centimeters.</p> <code>'auto'</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>2.54</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>2.54</code> <code>annotate</code> <code>bool</code> <p>Whether to annotate the plots.</p> <code>False</code> <code>cbar</code> <code>bool</code> <p>Whether to add a colorbar.</p> <code>False</code> <code>hide_source_types</code> <code>str | list | None</code> <p>Source types to hide or \u201cauto\u201d.</p> <code>'auto'</code> <code>hide_source_types_bins</code> <code>int</code> <p>Number of bins for auto-hiding.</p> <code>5</code> <code>hide_source_types_cut_off_edge</code> <code>int</code> <p>Cut-off edge for auto-hiding.</p> <code>1</code> <code>hide_source_types_mode</code> <code>str</code> <p>Mode for auto-hiding source types.</p> <code>'below_cut_off'</code> <code>max_axes</code> <code>int | None</code> <p>Maximum number of axes to create.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for plot_spatial_contribution.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Figure, ndarray[Axes], tuple[Colorbar, Colormap, Normalize, float, float]]</code> <p>Figure, axes, and colorbar information (cbar, cmap, norm, vmin, vmax).</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_spatial_contribution_grid(\n    self,\n    t_start: float,\n    t_end: float,\n    max_extent: float = 3,\n    mode: str = \"peak\",\n    title: str = \"{source_type} :\u2192\",\n    fig: plt.Figure | None = None,\n    axes: np.ndarray[plt.Axes] | None = None,\n    fontsize: float = 5,\n    edgewidth: float = 0.125,\n    title_y: float = 0.8,\n    max_figure_height_cm: float = 9.271,\n    panel_height_cm: float | str = \"auto\",\n    max_figure_width_cm: float = 2.54,\n    panel_width_cm: float = 2.54,\n    annotate: bool = False,\n    cbar: bool = False,\n    hide_source_types: str | list | None = \"auto\",\n    hide_source_types_bins: int = 5,\n    hide_source_types_cut_off_edge: int = 1,\n    hide_source_types_mode: str = \"below_cut_off\",\n    max_axes: int | None = None,\n    **kwargs,\n) -&gt; tuple[\n    plt.Figure,\n    np.ndarray[plt.Axes],\n    tuple[plt.Colorbar, plt.Colormap, plt.Normalize, float, float],\n]:\n    \"\"\"Plot a grid of spatial contributions for different source types.\n\n    Args:\n        t_start: Start time for the plot.\n        t_end: End time for the plot.\n        max_extent: Maximum extent of the spatial filter.\n        mode: Mode for calculating values (\"peak\", \"mean\", or \"std\").\n        title: Title format string for each subplot.\n        fig: Existing figure to use.\n        axes: Existing axes to use.\n        fontsize: Font size for labels and titles.\n        edgewidth: Width of edges in the plot.\n        title_y: Y-position of the title.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        annotate: Whether to annotate the plots.\n        cbar: Whether to add a colorbar.\n        hide_source_types: Source types to hide or \"auto\".\n        hide_source_types_bins: Number of bins for auto-hiding.\n        hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n        hide_source_types_mode: Mode for auto-hiding source types.\n        max_axes: Maximum number of axes to create.\n        **kwargs: Additional keyword arguments for plot_spatial_contribution.\n\n    Returns:\n        Figure, axes, and colorbar information (cbar, cmap, norm, vmin, vmax).\n    \"\"\"\n    current_view = self.between_seconds(t_start, t_end)\n\n    vmin = (\n        np.floor(\n            min(\n                0,\n                min(\n                    current.mean(axis=(0, 1, 2)).min()\n                    for current in list(current_view[:].values())\n                ),\n            )\n            * 10\n        )\n        / 10\n    )\n\n    vmax = (\n        np.ceil(\n            max(\n                0,\n                max(\n                    current.mean(axis=(0, 1, 2)).max()\n                    for current in list(current_view[:].values())\n                ),\n            )\n            * 10\n        )\n        / 10\n    )\n\n    source_types = self.filter_source_types(\n        hide_source_types,\n        bins=hide_source_types_bins,\n        edge=hide_source_types_cut_off_edge,\n        mode=hide_source_types_mode,\n    )\n\n    if fig is None and axes is None:\n        figsize = figsize_from_n_items(\n            max_axes or len(source_types),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=(\n                max_figure_height_cm / (max_axes or len(source_types))\n                if panel_height_cm == \"auto\"\n                else panel_height_cm\n            ),\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(\n            unmask_n=max_axes or len(source_types), hspace=0.1, wspace=0\n        )\n        if max_axes is not None and len(source_types) &lt; max_axes:\n            for ax in np.array(axes).flatten():\n                if isinstance(ax, Axes):\n                    ax.axis(\"off\")\n\n    for i, source_type in enumerate(source_types):\n        self.plot_spatial_contribution(\n            source_type,\n            #                 contrast,\n            #                 angle,\n            t_start,\n            t_end,\n            mode=mode,\n            title=title,\n            fontsize=fontsize,\n            edgewidth=edgewidth,\n            title_y=title_y,\n            fig=fig,\n            ax=axes[i],\n            current_view=current_view,\n            vmin=vmin,\n            vmax=vmax,\n            annotate=annotate,\n            cbar=False,\n            max_extent=max_extent or current_view.rfs.max_extent,\n            **kwargs,\n        )\n\n    cmap = plt.cm.seismic\n    norm = plt_utils.get_norm(vmin=vmin, vmax=vmax, midpoint=0)\n    if cbar:\n        cbar = plt_utils.add_colorbar_to_fig(\n            fig,\n            width=0.01,\n            height=0.25,\n            fontsize=fontsize,\n            cmap=cmap,\n            norm=norm,\n            label=f\"{mode} input currents\",\n            n_ticks=4,\n            n_decimals=1,\n        )\n    return fig, axes, (cbar, cmap, norm, vmin, vmax)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_spatial_filter","title":"plot_spatial_filter","text":"<pre><code>plot_spatial_filter(source_type, title='{source_type} :\u2192', fig=None, ax=None, max_extent=None, **kwargs)\n</code></pre> <p>Plot the spatial filter for a given source type.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>The source type to plot.</p> required <code>title</code> <code>str</code> <p>Title format string for the plot.</p> <code>'{source_type} :\u2192'</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes | None</code> <p>Existing axes to use.</p> <code>None</code> <code>max_extent</code> <code>float | None</code> <p>Maximum extent of the spatial filter.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for plt_utils.kernel.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Axes object containing the plot.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_spatial_filter(\n    self,\n    source_type: str,\n    title: str = \"{source_type} :\u2192\",\n    fig: plt.Figure | None = None,\n    ax: plt.Axes | None = None,\n    max_extent: float | None = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot the spatial filter for a given source type.\n\n    Args:\n        source_type: The source type to plot.\n        title: Title format string for the plot.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n        max_extent: Maximum extent of the spatial filter.\n        **kwargs: Additional keyword arguments for plt_utils.kernel.\n\n    Returns:\n        Axes object containing the plot.\n    \"\"\"\n    filter = self.rfs\n\n    def filter_values(rf):\n        return (rf.n_syn * rf.sign).values\n\n    vmin = kwargs.pop(\"vmin\", None) or (\n        np.floor(\n            min(\n                0,\n                min(\n                    min(filter_values(filter[source_type]))\n                    for source_type in self.source_types\n                ),\n            )\n            * 100\n        )\n        / 100\n    )\n\n    vmax = kwargs.pop(\"vmax\", None) or (\n        np.ceil(\n            max(\n                0,\n                max(\n                    max(filter_values(filter[source_type]))\n                    for source_type in self.source_types\n                ),\n            )\n            * 100\n        )\n        / 100\n    )\n\n    u, v = filter[source_type][[\"source_u\", \"source_v\"]].values.T\n    # average over models\n    # (1, n_models, 1, n_timesteps, n_models) -&gt; (n_timesteps, n_models)\n    values = filter_values(filter[source_type])\n\n    label = title.format(source_type=source_type)\n    fig, ax, _ = plt_utils.kernel(\n        u,\n        v,\n        values,\n        fill=True,\n        max_extent=max_extent or filter.max_extent,\n        label=label,\n        labelxy=\"auto\",\n        strict_sign=False,\n        fig=fig,\n        ax=ax,\n        vmin=vmin,\n        vmax=vmax,\n        **kwargs,\n    )\n    (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n    ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n    ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n    return ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_spatial_filter_grid","title":"plot_spatial_filter_grid","text":"<pre><code>plot_spatial_filter_grid(title='{source_type} :\u2192', fig=None, axes=None, max_extent=None, fontsize=5, edgewidth=0.125, title_y=0.8, max_figure_height_cm=9.271, panel_height_cm='auto', max_figure_width_cm=2.54, panel_width_cm=2.54, annotate=False, cbar=False, hide_source_types='auto', hide_source_types_bins=5, hide_source_types_cut_off_edge=1, hide_source_types_mode='below_cut_off', max_axes=None, wspace=0.0, hspace=0.1, **kwargs)\n</code></pre> <p>Plot a grid of spatial filters for different source types.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title format string for each subplot.</p> <code>'{source_type} :\u2192'</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>axes</code> <code>ndarray[Axes] | None</code> <p>Existing axes to use.</p> <code>None</code> <code>max_extent</code> <code>float | None</code> <p>Maximum extent of the spatial filter.</p> <code>None</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>edgewidth</code> <code>float</code> <p>Width of edges in the plot.</p> <code>0.125</code> <code>title_y</code> <code>float</code> <p>Y-position of the title.</p> <code>0.8</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>9.271</code> <code>panel_height_cm</code> <code>float | str</code> <p>Height of each panel in centimeters.</p> <code>'auto'</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>2.54</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>2.54</code> <code>annotate</code> <code>bool</code> <p>Whether to annotate the plots.</p> <code>False</code> <code>cbar</code> <code>bool</code> <p>Whether to add a colorbar.</p> <code>False</code> <code>hide_source_types</code> <code>str | list | None</code> <p>Source types to hide or \u201cauto\u201d.</p> <code>'auto'</code> <code>hide_source_types_bins</code> <code>int</code> <p>Number of bins for auto-hiding.</p> <code>5</code> <code>hide_source_types_cut_off_edge</code> <code>int</code> <p>Cut-off edge for auto-hiding.</p> <code>1</code> <code>hide_source_types_mode</code> <code>str</code> <p>Mode for auto-hiding source types.</p> <code>'below_cut_off'</code> <code>max_axes</code> <code>int | None</code> <p>Maximum number of axes to create.</p> <code>None</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0.0</code> <code>hspace</code> <code>float</code> <p>Height space between subplots.</p> <code>0.1</code> <code>**kwargs</code> <p>Additional keyword arguments for plot_spatial_filter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Figure, ndarray[Axes], tuple[Colorbar, Colormap, Normalize, float, float]]</code> <p>Figure, axes, and colorbar information (cbar, cmap, norm, vmin, vmax).</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_spatial_filter_grid(\n    self,\n    title: str = \"{source_type} :\u2192\",\n    fig: plt.Figure | None = None,\n    axes: np.ndarray[plt.Axes] | None = None,\n    max_extent: float | None = None,\n    fontsize: float = 5,\n    edgewidth: float = 0.125,\n    title_y: float = 0.8,\n    max_figure_height_cm: float = 9.271,\n    panel_height_cm: float | str = \"auto\",\n    max_figure_width_cm: float = 2.54,\n    panel_width_cm: float = 2.54,\n    annotate: bool = False,\n    cbar: bool = False,\n    hide_source_types: str | list | None = \"auto\",\n    hide_source_types_bins: int = 5,\n    hide_source_types_cut_off_edge: int = 1,\n    hide_source_types_mode: str = \"below_cut_off\",\n    max_axes: int | None = None,\n    wspace: float = 0.0,\n    hspace: float = 0.1,\n    **kwargs,\n) -&gt; tuple[\n    plt.Figure,\n    np.ndarray[plt.Axes],\n    tuple[plt.Colorbar, plt.Colormap, plt.Normalize, float, float],\n]:\n    \"\"\"Plot a grid of spatial filters for different source types.\n\n    Args:\n        title: Title format string for each subplot.\n        fig: Existing figure to use.\n        axes: Existing axes to use.\n        max_extent: Maximum extent of the spatial filter.\n        fontsize: Font size for labels and titles.\n        edgewidth: Width of edges in the plot.\n        title_y: Y-position of the title.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        annotate: Whether to annotate the plots.\n        cbar: Whether to add a colorbar.\n        hide_source_types: Source types to hide or \"auto\".\n        hide_source_types_bins: Number of bins for auto-hiding.\n        hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n        hide_source_types_mode: Mode for auto-hiding source types.\n        max_axes: Maximum number of axes to create.\n        wspace: Width space between subplots.\n        hspace: Height space between subplots.\n        **kwargs: Additional keyword arguments for plot_spatial_filter.\n\n    Returns:\n        Figure, axes, and colorbar information (cbar, cmap, norm, vmin, vmax).\n    \"\"\"\n    filter = self.rfs\n\n    def filter_values(rf):\n        return (rf.n_syn * rf.sign).values\n\n    vmin = kwargs.pop(\"vmin\", None) or (\n        np.floor(\n            min(\n                0,\n                min(\n                    min(filter_values(filter[source_type]))\n                    for source_type in self.source_types\n                ),\n            )\n            * 100\n        )\n        / 100\n    )\n\n    vmax = kwargs.pop(\"vmax\", None) or (\n        np.ceil(\n            max(\n                0,\n                max(\n                    max(filter_values(filter[source_type]))\n                    for source_type in self.source_types\n                ),\n            )\n            * 100\n        )\n        / 100\n    )\n\n    source_types = self.filter_source_types(\n        hide_source_types,\n        bins=hide_source_types_bins,\n        edge=hide_source_types_cut_off_edge,\n        mode=hide_source_types_mode,\n    )\n\n    if fig is None and axes is None:\n        figsize = figsize_from_n_items(\n            max_axes or len(source_types),\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=(\n                max_figure_height_cm / (max_axes or len(source_types))\n                if panel_height_cm == \"auto\"\n                else panel_height_cm\n            ),\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(\n            unmask_n=max_axes or len(source_types), hspace=hspace, wspace=wspace\n        )\n        if max_axes is not None and len(source_types) &lt; max_axes:\n            for ax in np.array(axes).flatten():\n                if isinstance(ax, Axes):\n                    ax.axis(\"off\")\n\n    for i, source_type in enumerate(source_types):\n        self.plot_spatial_filter(\n            source_type,\n            title=title,\n            fontsize=fontsize,\n            edgewidth=edgewidth,\n            title_y=title_y,\n            fig=fig,\n            ax=axes[i],\n            vmin=vmin,\n            vmax=vmax,\n            annotate=annotate,\n            cbar=False,\n            max_extent=max_extent or filter.max_extent,\n            **kwargs,\n        )\n\n    cmap = plt.cm.seismic\n    norm = plt_utils.get_norm(vmin=vmin, vmax=vmax, midpoint=0)\n    if cbar:\n        cbar = plt_utils.add_colorbar_to_fig(\n            fig,\n            width=0.01,\n            height=0.25,\n            fontsize=fontsize,\n            cmap=cmap,\n            norm=norm,\n            label=\"spatial filters\",\n            n_ticks=4,\n            n_decimals=1,\n        )\n    return fig, axes, (cbar, cmap, norm, vmin, vmax)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.view","title":"view","text":"<pre><code>view(currents, rfs=None, time=None, responses=None, arg_df=None)\n</code></pre> <p>Create a new view with the given currents, rfs, time, responses, and arg_df.</p> <p>Parameters:</p> Name Type Description Default <code>currents</code> <code>Namespace</code> <p>Currents for each source type.</p> required <code>rfs</code> <code>ReceptiveFields | None</code> <p>Receptive fields for the target cells.</p> <code>None</code> <code>time</code> <code>ndarray | None</code> <p>Time array for the simulation.</p> <code>None</code> <code>responses</code> <code>ndarray | None</code> <p>Responses of the target cells.</p> <code>None</code> <code>arg_df</code> <code>DataFrame | None</code> <p>DataFrame containing stimulus arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with the given data.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def view(\n    self,\n    currents: Namespace,\n    rfs: ReceptiveFields | None = None,\n    time: np.ndarray | None = None,\n    responses: np.ndarray | None = None,\n    arg_df: pd.DataFrame | None = None,\n) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"\n    Create a new view with the given currents, rfs, time, responses, and arg_df.\n\n    Args:\n        currents: Currents for each source type.\n        rfs: Receptive fields for the target cells.\n        time: Time array for the simulation.\n        responses: Responses of the target cells.\n        arg_df: DataFrame containing stimulus arguments.\n\n    Returns:\n        A new view with the given data.\n    \"\"\"\n    arg_df = arg_df.reset_index(drop=True) if arg_df is not None else self.arg_df\n    return MovingEdgeCurrentView(\n        self.ensemble,\n        self.target_type,\n        self.exp_data,\n        arg_df,\n        currents,\n        rfs if rfs is not None else self.rfs,\n        time if time is not None else self.time,\n        responses if responses is not None else self.responses,\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.subtract_baseline","title":"subtract_baseline","text":"<pre><code>subtract_baseline()\n</code></pre> <p>Create a new view with baseline subtracted from the currents and responses.</p> <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with baseline subtracted data.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def subtract_baseline(self) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"\n    Create a new view with baseline subtracted from the currents and responses.\n\n    Returns:\n        A new view with baseline subtracted data.\n    \"\"\"\n    return self.view(\n        Namespace({\n            cell_type: c - np.take(c, [0], -2)\n            for cell_type, c in self.currents.items()\n        }),\n        responses=self.responses - np.take(self.responses, [0], -1),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.subtract_mean","title":"subtract_mean","text":"<pre><code>subtract_mean()\n</code></pre> <p>Create a new view with mean subtracted from the currents and responses.</p> <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with mean subtracted data.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def subtract_mean(self) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"\n    Create a new view with mean subtracted from the currents and responses.\n\n    Returns:\n        A new view with mean subtracted data.\n    \"\"\"\n    return self.view(\n        Namespace({\n            cell_type: c - np.mean(c, -2, keepdims=True)\n            for cell_type, c in self.currents.items()\n        }),\n        responses=self.responses - np.mean(self.responses, -1, keepdims=True),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.standardize","title":"standardize","text":"<pre><code>standardize()\n</code></pre> <p>Create a new view with standardized currents and responses.</p> <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with standardized data.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def standardize(self) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"\n    Create a new view with standardized currents and responses.\n\n    Returns:\n        A new view with standardized data.\n    \"\"\"\n    return self.view(\n        Namespace({\n            cell_type: (c - np.mean(c, -2, keepdims=True))\n            / (np.std(c, -2, keepdims=True) + 1e-15)\n            for cell_type, c in self.currents.items()\n        }),\n        responses=(self.responses - np.mean(self.responses, -1, keepdims=True))\n        / (np.std(self.responses, -1, keepdims=True) + 1e-15),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.standardize_over_time_and_pd_nd","title":"standardize_over_time_and_pd_nd","text":"<pre><code>standardize_over_time_and_pd_nd(t_start, t_end, pd)\n</code></pre> <p>Create a new view with standardized currents and responses over time and PD/ND.</p> <p>Parameters:</p> Name Type Description Default <code>t_start</code> <code>float</code> <p>Start time for standardization.</p> required <code>t_end</code> <code>float</code> <p>End time for standardization.</p> required <code>pd</code> <code>float</code> <p>Preferred direction for standardization.</p> required <p>Returns:</p> Type Description <code>'MovingEdgeCurrentView'</code> <p>A new view with standardized data.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def standardize_over_time_and_pd_nd(\n    self, t_start: float, t_end: float, pd: float\n) -&gt; \"MovingEdgeCurrentView\":\n    \"\"\"\n    Create a new view with standardized currents and responses over time and PD/ND.\n\n    Args:\n        t_start: Start time for standardization.\n        t_end: End time for standardization.\n        pd: Preferred direction for standardization.\n\n    Returns:\n        A new view with standardized data.\n    \"\"\"\n    temp = self.between_seconds(t_start, t_end).at_angle([pd, (pd - 180) % 360])\n    return self.view(\n        Namespace({\n            cell_type: (\n                c - np.mean(temp.currents[cell_type], (-2, -3), keepdims=True)\n            )\n            / (np.std(temp.currents[cell_type], (-2, -3), keepdims=True) + 1e-15)\n            for cell_type, c in self.currents.items()\n        }),\n        responses=(self.responses - np.mean(temp.responses, (-1, -2), keepdims=True))\n        / (np.std(temp.responses, (-1, -2), keepdims=True) + 1e-15),\n    )\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.init_colors","title":"init_colors","text":"<pre><code>init_colors(source_types)\n</code></pre> <p>Initialize colors for source types.</p> <p>Parameters:</p> Name Type Description Default <code>source_types</code> <code>list[str]</code> <p>List of source types.</p> required Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def init_colors(self, source_types: list[str]) -&gt; None:\n    \"\"\"\n    Initialize colors for source types.\n\n    Args:\n        source_types: List of source types.\n    \"\"\"\n    signs = self.signs()\n    signs = {cell_type: signs[cell_type] for cell_type in source_types}\n    signs_reversed = {cell_type: signs[cell_type] for cell_type in source_types[::-1]}\n    n_exc = len([v for v in signs.values() if v == 1])\n    n_inh = len([v for v in signs.values() if v == -1])\n    exc_colors_pd = cmap_iter(\n        truncate_colormap(plt.cm.RdBu, minval=0.05, maxval=0.45, n=n_exc)\n    )\n    inh_cmap_pd = cmap_iter(\n        truncate_colormap(plt.cm.RdBu_r, minval=0.05, maxval=0.45, n=n_inh)\n    )\n    exc_colors_nd = cmap_iter(\n        truncate_colormap(plt.cm.BrBG_r, minval=0.05, maxval=0.45, n=n_exc)\n    )\n    inh_cmap_nd = cmap_iter(\n        truncate_colormap(plt.cm.BrBG, minval=0.05, maxval=0.45, n=n_inh)\n    )\n    colors_pd = {}\n    colors_nd = {}\n    for _, (cell_type, sign) in enumerate(signs.items()):\n        if sign == 1:\n            # take the first half of the RdBu colormap, i.e. red\n            colors_pd[cell_type] = next(exc_colors_pd)\n            colors_nd[cell_type] = next(exc_colors_nd)\n\n    for _, (cell_type, sign) in enumerate(signs_reversed.items()):\n        if sign == -1:\n            # take the second half of the RdBu colormap, i.e. blue\n            colors_pd[cell_type] = next(inh_cmap_pd)\n            colors_nd[cell_type] = next(inh_cmap_nd)\n    self.colors_pd = colors_pd\n    self.colors_nd = colors_nd\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.color","title":"color","text":"<pre><code>color(source_type, pd=True)\n</code></pre> <p>Get the color for a given source type.</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>str</code> <p>The source type.</p> required <code>pd</code> <code>bool</code> <p>Whether to use PD or ND colors.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[float, float, float]</code> <p>The color as an RGB tuple.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def color(self, source_type: str, pd: bool = True) -&gt; tuple[float, float, float]:\n    \"\"\"\n    Get the color for a given source type.\n\n    Args:\n        source_type: The source type.\n        pd: Whether to use PD or ND colors.\n\n    Returns:\n        The color as an RGB tuple.\n    \"\"\"\n    if pd:\n        return self.colors_pd[source_type]\n    return self.colors_nd[source_type]\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.zorder","title":"zorder","text":"<pre><code>zorder(source_types, source_type, start_exc=1000, start_inh=1000)\n</code></pre> <p>Get the z-order for a given source type.</p> <p>Parameters:</p> Name Type Description Default <code>source_types</code> <code>list[str]</code> <p>List of source types.</p> required <code>source_type</code> <code>str</code> <p>The source type.</p> required <code>start_exc</code> <code>int</code> <p>Starting z-order for excitatory cells.</p> <code>1000</code> <code>start_inh</code> <code>int</code> <p>Starting z-order for inhibitory cells.</p> <code>1000</code> <p>Returns:</p> Type Description <code>int</code> <p>The z-order for the given source type.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def zorder(\n    self,\n    source_types: list[str],\n    source_type: str,\n    start_exc: int = 1000,\n    start_inh: int = 1000,\n) -&gt; int:\n    \"\"\"\n    Get the z-order for a given source type.\n\n    Args:\n        source_types: List of source types.\n        source_type: The source type.\n        start_exc: Starting z-order for excitatory cells.\n        start_inh: Starting z-order for inhibitory cells.\n\n    Returns:\n        The z-order for the given source type.\n    \"\"\"\n    signs = self.signs()\n    signs_reversed = {cell_type: signs[cell_type] for cell_type in source_types[::-1]}\n\n    z_order = start_exc\n    for _, (cell_type, sign) in enumerate(signs.items()):\n        if sign == 1:\n            if cell_type == source_type:\n                return z_order\n            z_order -= 10\n\n    z_order = start_inh\n    for _, (cell_type, sign) in enumerate(signs_reversed.items()):\n        if sign == -1:\n            if cell_type == source_type:\n                return z_order\n            z_order -= 10\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.ylims","title":"ylims","text":"<pre><code>ylims(source_types=None, offset=0.02)\n</code></pre> <p>Get the y-limits for temporal contributions summed over cells.</p> <p>Parameters:</p> Name Type Description Default <code>source_types</code> <code>list[str] | None</code> <p>List of source types to consider.</p> <code>None</code> <code>offset</code> <code>float</code> <p>Offset for the y-limits.</p> <code>0.02</code> <p>Returns:</p> Type Description <code>dict[str, tuple[float, float]]</code> <p>Y-limits for the given source types or all source types.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def ylims(\n    self, source_types: list[str] | None = None, offset: float = 0.02\n) -&gt; dict[str, tuple[float, float]]:\n    \"\"\"\n    Get the y-limits for temporal contributions summed over cells.\n\n    Args:\n        source_types: List of source types to consider.\n        offset: Offset for the y-limits.\n\n    Returns:\n        Y-limits for the given source types or all source types.\n    \"\"\"\n    if source_types is not None:\n        return {\n            cell_type: plt_utils.get_lims(c, offset)\n            for cell_type, c in self.sum_over_cells().currents.items()\n            if cell_type in source_types\n        }\n    return plt_utils.get_lims(list(self.sum_over_cells().currents.values()), offset)\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_response","title":"plot_response","text":"<pre><code>plot_response(contrast, angle, t_start=0, t_end=1, max_figure_height_cm=1.4477, panel_height_cm=1.4477, max_figure_width_cm=4.0513, panel_width_cm=4.0513, fontsize=5, model_average=True, color=(0, 0, 0), legend=False, hide_yaxis=True, trim_axes=True, quantile=None, scale_position=None, scale_label='{:.0f} ms', scale_unit=1000, hline=False, fig=None, ax=None)\n</code></pre> <p>Plot the response to a moving edge stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>contrast</code> <code>float</code> <p>The contrast of the stimulus.</p> required <code>angle</code> <code>float</code> <p>The angle of the stimulus.</p> required <code>t_start</code> <code>float</code> <p>Start time for the plot.</p> <code>0</code> <code>t_end</code> <code>float</code> <p>End time for the plot.</p> <code>1</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>1.4477</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>1.4477</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>4.0513</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>4.0513</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>model_average</code> <code>bool</code> <p>Whether to plot the model average.</p> <code>True</code> <code>color</code> <code>tuple[float, float, float]</code> <p>Color for the plot.</p> <code>(0, 0, 0)</code> <code>legend</code> <code>bool</code> <p>Whether to show the legend.</p> <code>False</code> <code>hide_yaxis</code> <code>bool</code> <p>Whether to hide the y-axis.</p> <code>True</code> <code>trim_axes</code> <code>bool</code> <p>Whether to trim the axes.</p> <code>True</code> <code>quantile</code> <code>float | None</code> <p>Quantile for shading.</p> <code>None</code> <code>scale_position</code> <code>str | None</code> <p>Position of the scale.</p> <code>None</code> <code>scale_label</code> <code>str</code> <p>Label format for the scale.</p> <code>'{:.0f} ms'</code> <code>scale_unit</code> <code>float</code> <p>Unit for the scale.</p> <code>1000</code> <code>hline</code> <code>bool</code> <p>Whether to show a horizontal line at 0.</p> <code>False</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes | None</code> <p>Existing axes to use.</p> <code>None</code> <p>Returns:</p> Type Description <p>Figure and axes objects.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_response(\n    self,\n    contrast: float,\n    angle: float,\n    t_start: float = 0,\n    t_end: float = 1,\n    max_figure_height_cm: float = 1.4477,\n    panel_height_cm: float = 1.4477,\n    max_figure_width_cm: float = 4.0513,\n    panel_width_cm: float = 4.0513,\n    fontsize: float = 5,\n    model_average: bool = True,\n    color: tuple[float, float, float] = (0, 0, 0),\n    legend: bool = False,\n    hide_yaxis: bool = True,\n    trim_axes: bool = True,\n    quantile: float | None = None,\n    scale_position: str | None = None,  # \"lower left\",\n    scale_label: str = \"{:.0f} ms\",\n    scale_unit: float = 1000,\n    hline: bool = False,\n    fig: plt.Figure | None = None,\n    ax: plt.Axes | None = None,\n):\n    \"\"\"\n    Plot the response to a moving edge stimulus.\n\n    Args:\n        contrast: The contrast of the stimulus.\n        angle: The angle of the stimulus.\n        t_start: Start time for the plot.\n        t_end: End time for the plot.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        fontsize: Font size for labels and titles.\n        model_average: Whether to plot the model average.\n        color: Color for the plot.\n        legend: Whether to show the legend.\n        hide_yaxis: Whether to hide the y-axis.\n        trim_axes: Whether to trim the axes.\n        quantile: Quantile for shading.\n        scale_position: Position of the scale.\n        scale_label: Label format for the scale.\n        scale_unit: Unit for the scale.\n        hline: Whether to show a horizontal line at 0.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n\n    Returns:\n        Figure and axes objects.\n    \"\"\"\n    r_pd = (\n        self.at_angle(angle)\n        .at_contrast(contrast)\n        .between_seconds(t_start, t_end)\n        .responses.squeeze(axis=-2)\n    )\n    r_nd = (\n        self.at_angle((angle - 180) % 360)\n        .at_contrast(contrast)\n        .between_seconds(t_start, t_end)\n        .responses.squeeze(axis=-2)\n    )\n\n    if fig is None and ax is None:\n        figsize = figsize_from_n_items(\n            1,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n        ax = axes[0]\n\n    color = [hex2color(PD), hex2color(ND)] if color is None else [color, color]\n\n    if model_average:\n        fig, ax, _, _ = plots.traces(\n            [r_pd.mean(axis=0), r_nd.mean(axis=0)],\n            x=self.between_seconds(t_start, t_end).time,\n            color=color,\n            linewidth=1,\n            fontsize=fontsize,\n            null_line=False,\n            fig=fig,\n            ax=ax,\n            linestyle=[\"solid\", \"dashed\"],\n            legend=\"\" if not legend else [f\"{self.target_type}\", \"null direction\"],\n            scale_pos=scale_position,\n            scale_label=scale_label,\n            scale_unit=scale_unit,\n        )\n    else:\n        fig, ax, _, _ = plots.traces(\n            r_pd,\n            x=self.between_seconds(t_start, t_end).time,\n            mean_color=adapt_color_alpha(color[0], 1),\n            color=adapt_color_alpha(color[0], 0.5),\n            linewidth=0.25,\n            zorder_traces=0,\n            zorder_mean=10,\n            fontsize=fontsize,\n            null_line=False,\n            highlight_mean=True,\n            fig=fig,\n            ax=ax,\n        )\n        plots.traces(\n            r_nd,\n            x=self.between_seconds(t_start, t_end).time,\n            mean_color=adapt_color_alpha(color[1], 1),\n            color=adapt_color_alpha(color[1], 0.5),\n            linewidth=0.25,\n            zorder_traces=0,\n            zorder_mean=10,\n            fontsize=fontsize,\n            null_line=False,\n            highlight_mean=True,\n            fig=fig,\n            linestyle=\"dashed\",\n            ax=ax,\n        )\n    if quantile:\n        quantile_pd = np.quantile(r_pd, quantile, axis=0)\n        quantile_nd = np.quantile(r_nd, quantile, axis=0)\n        ax.fill_between(\n            self.between_seconds(t_start, t_end).time,\n            quantile_pd[0],\n            quantile_pd[1],\n            facecolor=adapt_color_alpha(color[0], 0.1),\n            edgecolor=adapt_color_alpha(color[0], 1),\n            linewidth=0.25,\n        )\n        ax.fill_between(\n            self.between_seconds(t_start, t_end).time,\n            quantile_nd[0],\n            quantile_nd[1],\n            facecolor=adapt_color_alpha(color[1], 0.1),\n            edgecolor=adapt_color_alpha(color[1], 1),\n            linewidth=0.25,\n            linestyle=\"dashed\",\n        )\n\n    if hline:\n        # horizontal line at 0\n        ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n    if hide_yaxis:\n        plt_utils.rm_spines(ax, (\"left\",))\n    if trim_axes:\n        plt_utils.trim_axis(ax)\n    if legend:\n        ax.legend(\n            fontsize=fontsize,\n            ncols=1,\n            bbox_to_anchor=(1.05, 1),\n            loc=\"upper left\",\n            borderaxespad=0.0,\n        )\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_response_pc_nc","title":"plot_response_pc_nc","text":"<pre><code>plot_response_pc_nc(contrast, angle, t_start=0, t_end=1, max_figure_height_cm=1.4477, panel_height_cm=1.4477, max_figure_width_cm=4.0513, panel_width_cm=4.0513, fontsize=5, model_average=True, color=(0, 0, 0), legend=False, hide_yaxis=True, trim_axes=True, quantile=None, scale_position=None, scale_label='{:.0f} ms', scale_unit=1000, fig=None, ax=None, hline=False)\n</code></pre> <p>Plot the response to a moving edge stimulus with positive and negative contrasts.</p> <p>Parameters:</p> Name Type Description Default <code>contrast</code> <code>float</code> <p>The contrast of the stimulus.</p> required <code>angle</code> <code>float</code> <p>The angle of the stimulus.</p> required <code>t_start</code> <code>float</code> <p>Start time for the plot.</p> <code>0</code> <code>t_end</code> <code>float</code> <p>End time for the plot.</p> <code>1</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>1.4477</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>1.4477</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>4.0513</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>4.0513</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>model_average</code> <code>bool</code> <p>Whether to plot the model average.</p> <code>True</code> <code>color</code> <code>tuple[float, float, float]</code> <p>Color for the plot.</p> <code>(0, 0, 0)</code> <code>legend</code> <code>bool</code> <p>Whether to show the legend.</p> <code>False</code> <code>hide_yaxis</code> <code>bool</code> <p>Whether to hide the y-axis.</p> <code>True</code> <code>trim_axes</code> <code>bool</code> <p>Whether to trim the axes.</p> <code>True</code> <code>quantile</code> <code>float | None</code> <p>Quantile for shading.</p> <code>None</code> <code>scale_position</code> <code>str | None</code> <p>Position of the scale.</p> <code>None</code> <code>scale_label</code> <code>str</code> <p>Label format for the scale.</p> <code>'{:.0f} ms'</code> <code>scale_unit</code> <code>float</code> <p>Unit for the scale.</p> <code>1000</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes | None</code> <p>Existing axes to use.</p> <code>None</code> <code>hline</code> <code>bool</code> <p>Whether to show a horizontal line at 0.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[Figure, Axes]</code> <p>Figure and axes objects.</p> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_response_pc_nc(\n    self,\n    contrast: float,\n    angle: float,\n    t_start: float = 0,\n    t_end: float = 1,\n    max_figure_height_cm: float = 1.4477,\n    panel_height_cm: float = 1.4477,\n    max_figure_width_cm: float = 4.0513,\n    panel_width_cm: float = 4.0513,\n    fontsize: float = 5,\n    model_average: bool = True,\n    color: tuple[float, float, float] = (0, 0, 0),\n    legend: bool = False,\n    hide_yaxis: bool = True,\n    trim_axes: bool = True,\n    quantile: float | None = None,\n    scale_position: str | None = None,\n    scale_label: str = \"{:.0f} ms\",\n    scale_unit: float = 1000,\n    fig: plt.Figure | None = None,\n    ax: plt.Axes | None = None,\n    hline: bool = False,\n) -&gt; tuple[plt.Figure, plt.Axes]:\n    \"\"\"\n    Plot the response to a moving edge stimulus with positive and negative contrasts.\n\n    Args:\n        contrast: The contrast of the stimulus.\n        angle: The angle of the stimulus.\n        t_start: Start time for the plot.\n        t_end: End time for the plot.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        fontsize: Font size for labels and titles.\n        model_average: Whether to plot the model average.\n        color: Color for the plot.\n        legend: Whether to show the legend.\n        hide_yaxis: Whether to hide the y-axis.\n        trim_axes: Whether to trim the axes.\n        quantile: Quantile for shading.\n        scale_position: Position of the scale.\n        scale_label: Label format for the scale.\n        scale_unit: Unit for the scale.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n        hline: Whether to show a horizontal line at 0.\n\n    Returns:\n        Figure and axes objects.\n    \"\"\"\n    r_pc = (\n        self.at_angle(angle)\n        .at_contrast(contrast)\n        .between_seconds(t_start, t_end)\n        .responses.squeeze(axis=-2)\n    )\n    r_nc = (\n        self.at_angle(angle)\n        .at_contrast(0 if contrast == 1 else 1)\n        .between_seconds(t_start, t_end)\n        .responses.squeeze(axis=-2)\n    )\n\n    if fig is None and ax is None:\n        figsize = figsize_from_n_items(\n            1,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n        ax = axes[0]\n\n    color = [hex2color(PD), hex2color(ND)] if color is None else [color, color]\n\n    if model_average:\n        fig, ax, _, _ = plots.traces(\n            [r_pc.mean(axis=0), r_nc.mean(axis=0)],\n            x=self.between_seconds(t_start, t_end).time,\n            color=color,\n            linewidth=1,\n            fontsize=fontsize,\n            null_line=False,\n            fig=fig,\n            ax=ax,\n            linestyle=[\"solid\", \"dotted\"],\n            legend=\"\" if not legend else [f\"{self.target_type}\", \"null contrast\"],\n            scale_pos=scale_position,\n            scale_label=scale_label,\n            scale_unit=scale_unit,\n        )\n    else:\n        fig, ax, _, _ = plots.traces(\n            r_pc,\n            x=self.between_seconds(t_start, t_end).time,\n            mean_color=adapt_color_alpha(color[0], 1),\n            color=adapt_color_alpha(color[0], 0.5),\n            linewidth=0.25,\n            zorder_traces=0,\n            zorder_mean=10,\n            fontsize=fontsize,\n            null_line=False,\n            highlight_mean=True,\n            fig=fig,\n            ax=ax,\n        )\n        plots.traces(\n            r_nc,\n            x=self.between_seconds(t_start, t_end).time,\n            mean_color=adapt_color_alpha(color[1], 1),\n            color=adapt_color_alpha(color[1], 0.5),\n            linewidth=0.25,\n            zorder_traces=0,\n            zorder_mean=10,\n            fontsize=fontsize,\n            null_line=False,\n            highlight_mean=True,\n            fig=fig,\n            linestyle=\"dashed\",\n            ax=ax,\n        )\n    if quantile:\n        quantile_pd = np.quantile(r_pc, quantile, axis=0)\n        quantile_nd = np.quantile(r_nc, quantile, axis=0)\n        ax.fill_between(\n            self.between_seconds(t_start, t_end).time,\n            quantile_pd[0],\n            quantile_pd[1],\n            facecolor=adapt_color_alpha(color[0], 0.1),\n            edgecolor=adapt_color_alpha(color[0], 1),\n            linewidth=0.25,\n        )\n        ax.fill_between(\n            self.between_seconds(t_start, t_end).time,\n            quantile_nd[0],\n            quantile_nd[1],\n            facecolor=adapt_color_alpha(color[1], 0.1),\n            edgecolor=adapt_color_alpha(color[1], 1),\n            linewidth=0.25,\n            linestyle=\"dashed\",\n        )\n\n    # horizontal line at 0\n    if hline:\n        ax.axhline(0, color=(0, 0, 0, 1), linewidth=0.25, zorder=-10)\n\n    if hide_yaxis:\n        plt_utils.rm_spines(ax, (\"left\",))\n    if trim_axes:\n        plt_utils.trim_axis(ax)\n    if legend:\n        ax.legend(\n            fontsize=fontsize,\n            ncols=1,\n            bbox_to_anchor=(1.05, 1),\n            loc=\"upper left\",\n            borderaxespad=0.0,\n        )\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_temporal_contributions","title":"plot_temporal_contributions","text":"<pre><code>plot_temporal_contributions(contrast, angle, t_start=0, t_end=1, fontsize=5, linewidth=0.25, legend=False, legend_standalone=True, legend_figsize_cm=(4.0572, 1), legend_n_rows=None, max_figure_height_cm=3.3941, panel_height_cm=3.3941, max_figure_width_cm=4.0572, panel_width_cm=4.0572, model_average=True, highlight_mean=True, sum_exc_inh=False, only_sum=False, hide_source_types='auto', hide_source_types_bins=5, hide_source_types_cut_off_edge=1, hide_source_types_mode='below_cut_off', hide_yaxis=True, trim_axes=True, quantile=None, fig=None, ax=None, legend_ax=None, hline=True, legend_n_cols=None, baseline_color=None, colors=None)\n</code></pre> <p>Plot temporal contributions of different source types.</p> <p>Parameters:</p> Name Type Description Default <code>contrast</code> <code>float</code> <p>The contrast of the stimulus.</p> required <code>angle</code> <code>float</code> <p>The angle of the stimulus.</p> required <code>t_start</code> <code>float</code> <p>Start time for the plot.</p> <code>0</code> <code>t_end</code> <code>float</code> <p>End time for the plot.</p> <code>1</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>linewidth</code> <code>float</code> <p>Line width for traces.</p> <code>0.25</code> <code>legend</code> <code>bool</code> <p>Whether to show the legend.</p> <code>False</code> <code>legend_standalone</code> <code>bool</code> <p>Whether to create a standalone legend.</p> <code>True</code> <code>legend_figsize_cm</code> <code>tuple[float, float]</code> <p>Figure size for the standalone legend.</p> <code>(4.0572, 1)</code> <code>legend_n_rows</code> <code>int | None</code> <p>Number of rows for the standalone legend.</p> <code>None</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>3.3941</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3.3941</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>4.0572</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>4.0572</code> <code>model_average</code> <code>bool</code> <p>Whether to plot the model average.</p> <code>True</code> <code>highlight_mean</code> <code>bool</code> <p>Whether to highlight the mean trace.</p> <code>True</code> <code>sum_exc_inh</code> <code>bool</code> <p>Whether to sum excitatory and inhibitory contributions.</p> <code>False</code> <code>only_sum</code> <code>bool</code> <p>Whether to only plot the summed contributions.</p> <code>False</code> <code>hide_source_types</code> <code>str | list | None</code> <p>Source types to hide or \u201cauto\u201d.</p> <code>'auto'</code> <code>hide_source_types_bins</code> <code>int</code> <p>Number of bins for auto-hiding.</p> <code>5</code> <code>hide_source_types_cut_off_edge</code> <code>int</code> <p>Cut-off edge for auto-hiding.</p> <code>1</code> <code>hide_source_types_mode</code> <code>str</code> <p>Mode for auto-hiding source types.</p> <code>'below_cut_off'</code> <code>hide_yaxis</code> <code>bool</code> <p>Whether to hide the y-axis.</p> <code>True</code> <code>trim_axes</code> <code>bool</code> <p>Whether to trim the axes.</p> <code>True</code> <code>quantile</code> <code>float | None</code> <p>Quantile for shading.</p> <code>None</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes | None</code> <p>Existing axes to use.</p> <code>None</code> <code>legend_ax</code> <code>Axes | None</code> <p>Existing axes for the standalone legend.</p> <code>None</code> <code>hline</code> <code>bool</code> <p>Whether to show a horizontal line at 0.</p> <code>True</code> <code>legend_n_cols</code> <code>int | None</code> <p>Number of columns for the standalone legend.</p> <code>None</code> <code>baseline_color</code> <code>tuple[float, float, float, float] | None</code> <p>Color for the baseline.</p> <code>None</code> <code>colors</code> <code>dict[str, tuple[float, float, float, float]] | None</code> <p>Colors for each source type.</p> <code>None</code> <p>Returns:</p> Type Description <p>Figure, axes, and legend axes objects.</p> Example <pre><code>view = MovingEdgeCurrentView(...)\nfig, ax = view.plot_temporal_contributions(\n    contrast=1.0,\n    angle=0,\n    t_start=0,\n    t_end=1,\n    fontsize=5,\n    linewidth=0.25,\n    legend=True\n)\n</code></pre> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_temporal_contributions(\n    self,\n    contrast: float,\n    angle: float,\n    t_start: float = 0,\n    t_end: float = 1,\n    fontsize: float = 5,\n    linewidth: float = 0.25,\n    legend: bool = False,\n    legend_standalone: bool = True,\n    legend_figsize_cm: tuple[float, float] = (4.0572, 1),\n    legend_n_rows: int | None = None,\n    max_figure_height_cm: float = 3.3941,\n    panel_height_cm: float = 3.3941,\n    max_figure_width_cm: float = 4.0572,\n    panel_width_cm: float = 4.0572,\n    model_average: bool = True,\n    highlight_mean: bool = True,  # only applies if model_average is False\n    sum_exc_inh: bool = False,\n    only_sum: bool = False,\n    hide_source_types: str | list | None = \"auto\",\n    hide_source_types_bins: int = 5,\n    hide_source_types_cut_off_edge: int = 1,\n    hide_source_types_mode: str = \"below_cut_off\",\n    hide_yaxis: bool = True,\n    trim_axes: bool = True,\n    quantile: float | None = None,\n    fig: plt.Figure | None = None,\n    ax: plt.Axes | None = None,\n    legend_ax: plt.Axes | None = None,\n    hline: bool = True,\n    legend_n_cols: int | None = None,\n    baseline_color: tuple[float, float, float, float] | None = None,\n    colors: dict[str, tuple[float, float, float, float]] | None = None,\n):\n    \"\"\"\n    Plot temporal contributions of different source types.\n\n    Args:\n        contrast: The contrast of the stimulus.\n        angle: The angle of the stimulus.\n        t_start: Start time for the plot.\n        t_end: End time for the plot.\n        fontsize: Font size for labels and titles.\n        linewidth: Line width for traces.\n        legend: Whether to show the legend.\n        legend_standalone: Whether to create a standalone legend.\n        legend_figsize_cm: Figure size for the standalone legend.\n        legend_n_rows: Number of rows for the standalone legend.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        model_average: Whether to plot the model average.\n        highlight_mean: Whether to highlight the mean trace.\n        sum_exc_inh: Whether to sum excitatory and inhibitory contributions.\n        only_sum: Whether to only plot the summed contributions.\n        hide_source_types: Source types to hide or \"auto\".\n        hide_source_types_bins: Number of bins for auto-hiding.\n        hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n        hide_source_types_mode: Mode for auto-hiding source types.\n        hide_yaxis: Whether to hide the y-axis.\n        trim_axes: Whether to trim the axes.\n        quantile: Quantile for shading.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n        legend_ax: Existing axes for the standalone legend.\n        hline: Whether to show a horizontal line at 0.\n        legend_n_cols: Number of columns for the standalone legend.\n        baseline_color: Color for the baseline.\n        colors: Colors for each source type.\n\n    Returns:\n        Figure, axes, and legend axes objects.\n\n    Example:\n        ```\n        view = MovingEdgeCurrentView(...)\n        fig, ax = view.plot_temporal_contributions(\n            contrast=1.0,\n            angle=0,\n            t_start=0,\n            t_end=1,\n            fontsize=5,\n            linewidth=0.25,\n            legend=True\n        )\n        ```\n    \"\"\"\n    if fig is None and ax is None:\n        figsize = figsize_from_n_items(\n            1,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n        ax = axes[0]\n    cv_pd = (\n        self.at_contrast(contrast)\n        .at_angle(angle)\n        .between_seconds(t_start, t_end)\n        .sum_over_cells()\n    )\n    cv_nd = (\n        self.at_contrast(contrast)\n        .at_angle((angle - 180) % 360)\n        .between_seconds(t_start, t_end)\n        .sum_over_cells()\n    )\n\n    source_types = (\n        self.at_contrast(contrast)\n        .at_angle([angle, (angle - 180) % 360])\n        .between_seconds(t_start, t_end)\n        .filter_source_types(\n            hide_source_types,\n            hide_source_types_bins,\n            hide_source_types_cut_off_edge,\n            hide_source_types_mode,\n        )\n    )\n\n    color_source_types = (\n        self.at_contrast(contrast)\n        .at_angle([angle, (angle - 180) % 360])\n        .between_seconds(t_start, t_end)\n        .filter_source_types(\n            None,\n            hide_source_types_bins,\n            hide_source_types_cut_off_edge,\n            hide_source_types_mode,\n        )\n    )\n    cv_pd.init_colors(color_source_types)\n    cv_nd.init_colors(color_source_types)\n\n    def plot_mean_trace(\n        time, trace, label, color, zorder, linestyle=\"solid\", ax=None, fig=None\n    ):\n        ax.plot(\n            time,\n            trace,\n            label=label,\n            color=color,\n            zorder=zorder,\n            linestyle=linestyle,\n        )\n\n    def plot_individual_traces(\n        traces, time, color, zorder, label, linestyle=\"solid\", legend=None\n    ):\n        if not only_sum and not model_average:\n            plots.traces(\n                traces,\n                time,\n                mean_color=color,\n                color=color,\n                linewidth=linewidth,\n                zorder_traces=0,\n                zorder_mean=zorder,\n                fontsize=fontsize,\n                null_line=True,\n                highlight_mean=highlight_mean,\n                fig=fig,\n                ax=ax,\n                legend=legend or label,\n                linestyle=linestyle,\n            )\n\n    def plot_quantile(traces, time, color, zorder, linestyle=\"solid\"):\n        if quantile:\n            Q = np.quantile(traces, quantile, axis=0)\n            ax.fill_between(\n                time,\n                Q[0],\n                Q[1],\n                facecolor=adapt_color_alpha(color, 0.1),\n                edgecolor=color,\n                linewidth=0.25,\n                linestyle=linestyle,\n                zorder=zorder - 1,\n            )\n\n    def plot_summed_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n        if np.any(trace):\n            ax.plot(\n                time,\n                trace,\n                label=label,\n                color=color,\n                zorder=zorder,\n                linestyle=linestyle,\n            )\n\n    def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n        # sum over cell types then average over models\n        exc_pd = np.zeros(cv_pd.shape)\n        inh_pd = np.zeros(cv_pd.shape)\n        exc_nd = np.zeros(cv_nd.shape)\n        inh_nd = np.zeros(cv_nd.shape)\n        # sum over cell types\n        for source_type in source_types:\n            if signs[source_type] == 1:\n                exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                exc_nd += cv_nd[source_type][:]\n            else:\n                inh_pd += cv_pd[source_type][:]\n                inh_nd += cv_nd[source_type][:]\n        # (n_models, n_timesteps)\n        return (\n            exc_pd.squeeze(),\n            inh_pd.squeeze(),\n            exc_nd.squeeze(),\n            inh_nd.squeeze(),\n        )\n\n    for source_type in source_types:\n        if model_average and not only_sum:\n            # mean traces solid for PD and dashed for ND\n            if baseline_color is not None:\n                color = baseline_color\n            elif colors:\n                color = colors[source_type]\n            else:\n                color = cv_pd.color(source_type)\n\n            plot_mean_trace(\n                cv_pd.time,\n                cv_pd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                source_type,\n                color,\n                cv_pd.zorder(source_types, source_type),\n                ax=ax,\n                fig=fig,\n            )\n            plot_mean_trace(\n                cv_nd.time,\n                cv_nd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                source_type,\n                color,\n                linestyle=\"dashed\",\n                zorder=cv_pd.zorder(source_types, source_type),\n                ax=ax,\n                fig=fig,\n            )\n\n        elif not model_average and not only_sum:\n            # individual traces\n            plot_individual_traces(\n                cv_pd[source_type][:].squeeze(axis=-2),\n                cv_pd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                source_type,\n            )\n            plot_individual_traces(\n                cv_nd[source_type][:].squeeze(axis=-2),\n                cv_nd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                source_type,\n                linestyle=\"dashed\",\n                legend=\"null direction\",\n            )\n\n        # quantiles\n        plot_quantile(\n            cv_pd[source_type][:].squeeze(axis=-2),\n            cv_pd.time,\n            cv_pd.color(source_type),\n            cv_pd.zorder(source_types, source_type),\n            linestyle=\"solid\",\n        )\n        plot_quantile(\n            cv_nd[source_type][:].squeeze(axis=-2),\n            cv_nd.time,\n            cv_pd.color(source_type),\n            cv_pd.zorder(source_types, source_type),\n            linestyle=\"dashed\",\n        )\n    if sum_exc_inh or only_sum:\n        # plot summed traces\n        signs = cv_pd.signs()\n        exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n            signs, source_types, cv_pd, cv_nd\n        )\n        plot_summed_trace(\n            cv_pd.time,\n            exc_pd.mean(axis=0),\n            \"excitatory\",\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=2000,\n        )\n        plot_quantile(\n            exc_pd,\n            cv_pd.time,\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=0,\n            linestyle=\"solid\",\n        )\n        plot_summed_trace(\n            cv_nd.time,\n            exc_nd.mean(axis=0),\n            \"excitatory\",\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=2000,\n            linestyle=\"dashed\",\n        )\n        plot_quantile(\n            exc_nd,\n            cv_pd.time,\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=0,\n            linestyle=\"dashed\",\n        )\n        plot_summed_trace(\n            cv_pd.time,\n            inh_pd.mean(axis=0),\n            \"inhibitory\",\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=2000,\n        )\n        plot_quantile(\n            inh_pd,\n            cv_pd.time,\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=0,\n            linestyle=\"solid\",\n        )\n        plot_summed_trace(\n            cv_nd.time,\n            inh_nd.mean(axis=0),\n            \"inhibitory\",\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=2000,\n            linestyle=\"dashed\",\n        )\n        plot_quantile(\n            inh_nd,\n            cv_pd.time,\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=0,\n            linestyle=\"dashed\",\n        )\n\n    if hline:\n        ax.hlines(\n            0,\n            cv_pd.time.min(),\n            cv_pd.time.max(),\n            color=(0, 0, 0, 1),\n            linewidth=0.25,\n            zorder=-10,\n        )\n\n    if legend:\n        ax.legend(\n            fontsize=fontsize,\n            ncols=1,\n            bbox_to_anchor=(1.05, 1),\n            loc=\"upper left\",\n            borderaxespad=0.0,\n        )\n    else:\n        ax.legend().set_visible(False)\n\n    ax.set_xlabel(\"time (s)\", fontsize=fontsize)\n    #         ax.set_ylabel(\"current (a.u.)\", fontsize=fontsize)\n\n    if hide_yaxis:\n        plt_utils.rm_spines(ax, (\"left\",))\n\n    if trim_axes:\n        plt_utils.trim_axis(ax)\n\n    if legend_standalone:\n        handles, labels = ax.get_legend_handles_labels()\n        nd_handle = Line2D(\n            [0], [0], color=\"k\", lw=1, label=\"null direction\", ls=\"dashed\"\n        )\n        legend_n_rows = legend_n_rows or len(labels) + 1\n        # legend_n_cols = (len(labels) + 1) // legend_n_rows\n        legend_fig, legend_ax = plt_utils.standalone_legend(\n            [*labels[::2], \"null direction\"],\n            None,\n            [*handles[::2], nd_handle],\n            fontsize=fontsize,\n            n_cols=legend_n_cols,\n            handlelength=2,\n            columnspacing=0.8,\n            labelspacing=0.25,\n            figsize=cm_to_inch(legend_figsize_cm),\n            fig=fig if legend_ax is not None else None,\n            ax=legend_ax,\n        )\n        return fig, ax, legend_fig, legend_ax\n    return fig, ax\n</code></pre>"},{"location":"reference/moving_stimulus_responses/#flyvis.analysis.moving_edge_currents.MovingEdgeCurrentView.plot_temporal_contributions_pc_nc","title":"plot_temporal_contributions_pc_nc","text":"<pre><code>plot_temporal_contributions_pc_nc(contrast, angle, t_start=0, t_end=1, fontsize=5, linewidth=0.25, legend=False, legend_standalone=True, legend_figsize_cm=(4.0572, 1), legend_n_rows=None, max_figure_height_cm=3.3941, panel_height_cm=3.3941, max_figure_width_cm=4.0572, panel_width_cm=4.0572, model_average=True, highlight_mean=True, sum_exc_inh=False, only_sum=False, hide_source_types='auto', hide_source_types_bins=5, hide_source_types_cut_off_edge=1, hide_source_types_mode='below_cut_off', hide_yaxis=True, trim_axes=True, quantile=None, fig=None, ax=None, legend_ax=None, null_linestyle='dotted', legend_n_cols=None)\n</code></pre> <p>Temporal contributions of different source types for positive/negative contrasts.</p> <p>Parameters:</p> Name Type Description Default <code>contrast</code> <code>float</code> <p>The contrast of the stimulus.</p> required <code>angle</code> <code>float</code> <p>The angle of the stimulus.</p> required <code>t_start</code> <code>float</code> <p>Start time for the plot.</p> <code>0</code> <code>t_end</code> <code>float</code> <p>End time for the plot.</p> <code>1</code> <code>fontsize</code> <code>float</code> <p>Font size for labels and titles.</p> <code>5</code> <code>linewidth</code> <code>float</code> <p>Line width for traces.</p> <code>0.25</code> <code>legend</code> <code>bool</code> <p>Whether to show the legend.</p> <code>False</code> <code>legend_standalone</code> <code>bool</code> <p>Whether to create a standalone legend.</p> <code>True</code> <code>legend_figsize_cm</code> <code>tuple[float, float]</code> <p>Figure size for the standalone legend.</p> <code>(4.0572, 1)</code> <code>legend_n_rows</code> <code>int | None</code> <p>Number of rows for the standalone legend.</p> <code>None</code> <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>3.3941</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3.3941</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>4.0572</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>4.0572</code> <code>model_average</code> <code>bool</code> <p>Whether to plot the model average.</p> <code>True</code> <code>highlight_mean</code> <code>bool</code> <p>Whether to highlight the mean trace.</p> <code>True</code> <code>sum_exc_inh</code> <code>bool</code> <p>Whether to sum excitatory and inhibitory contributions.</p> <code>False</code> <code>only_sum</code> <code>bool</code> <p>Whether to only plot the summed contributions.</p> <code>False</code> <code>hide_source_types</code> <code>str | list | None</code> <p>Source types to hide or \u201cauto\u201d.</p> <code>'auto'</code> <code>hide_source_types_bins</code> <code>int</code> <p>Number of bins for auto-hiding.</p> <code>5</code> <code>hide_source_types_cut_off_edge</code> <code>int</code> <p>Cut-off edge for auto-hiding.</p> <code>1</code> <code>hide_source_types_mode</code> <code>str</code> <p>Mode for auto-hiding source types.</p> <code>'below_cut_off'</code> <code>hide_yaxis</code> <code>bool</code> <p>Whether to hide the y-axis.</p> <code>True</code> <code>trim_axes</code> <code>bool</code> <p>Whether to trim the axes.</p> <code>True</code> <code>quantile</code> <code>float | None</code> <p>Quantile for shading.</p> <code>None</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes | None</code> <p>Existing axes to use.</p> <code>None</code> <code>legend_ax</code> <code>Axes | None</code> <p>Existing axes for the standalone legend.</p> <code>None</code> <code>null_linestyle</code> <code>str</code> <p>Linestyle for null direction traces.</p> <code>'dotted'</code> <code>legend_n_cols</code> <code>int | None</code> <p>Number of columns for the standalone legend.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Figure, Axes, Figure | None, Axes | None]</code> <p>Figure, axes, and legend axes objects.</p> Example <pre><code>view = MovingEdgeCurrentView(...)\nfig, ax = view.plot_temporal_contributions_pc_nc(\n    contrast=1.0,\n    angle=0,\n    t_start=0,\n    t_end=1,\n    fontsize=5,\n    linewidth=0.25,\n    legend=True\n)\n</code></pre> Source code in <code>flyvis/analysis/moving_edge_currents.py</code> <pre><code>def plot_temporal_contributions_pc_nc(\n    self,\n    contrast: float,\n    angle: float,\n    t_start: float = 0,\n    t_end: float = 1,\n    fontsize: float = 5,\n    linewidth: float = 0.25,\n    legend: bool = False,\n    legend_standalone: bool = True,\n    legend_figsize_cm: tuple[float, float] = (4.0572, 1),\n    legend_n_rows: int | None = None,\n    max_figure_height_cm: float = 3.3941,\n    panel_height_cm: float = 3.3941,\n    max_figure_width_cm: float = 4.0572,\n    panel_width_cm: float = 4.0572,\n    model_average: bool = True,\n    highlight_mean: bool = True,\n    sum_exc_inh: bool = False,\n    only_sum: bool = False,\n    hide_source_types: str | list | None = \"auto\",\n    hide_source_types_bins: int = 5,\n    hide_source_types_cut_off_edge: int = 1,\n    hide_source_types_mode: str = \"below_cut_off\",\n    hide_yaxis: bool = True,\n    trim_axes: bool = True,\n    quantile: float | None = None,\n    fig: plt.Figure | None = None,\n    ax: plt.Axes | None = None,\n    legend_ax: plt.Axes | None = None,\n    null_linestyle: str = \"dotted\",\n    legend_n_cols: int | None = None,\n) -&gt; tuple[plt.Figure, plt.Axes, plt.Figure | None, plt.Axes | None]:\n    \"\"\"\n    Temporal contributions of different source types for positive/negative contrasts.\n\n    Args:\n        contrast: The contrast of the stimulus.\n        angle: The angle of the stimulus.\n        t_start: Start time for the plot.\n        t_end: End time for the plot.\n        fontsize: Font size for labels and titles.\n        linewidth: Line width for traces.\n        legend: Whether to show the legend.\n        legend_standalone: Whether to create a standalone legend.\n        legend_figsize_cm: Figure size for the standalone legend.\n        legend_n_rows: Number of rows for the standalone legend.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        model_average: Whether to plot the model average.\n        highlight_mean: Whether to highlight the mean trace.\n        sum_exc_inh: Whether to sum excitatory and inhibitory contributions.\n        only_sum: Whether to only plot the summed contributions.\n        hide_source_types: Source types to hide or \"auto\".\n        hide_source_types_bins: Number of bins for auto-hiding.\n        hide_source_types_cut_off_edge: Cut-off edge for auto-hiding.\n        hide_source_types_mode: Mode for auto-hiding source types.\n        hide_yaxis: Whether to hide the y-axis.\n        trim_axes: Whether to trim the axes.\n        quantile: Quantile for shading.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n        legend_ax: Existing axes for the standalone legend.\n        null_linestyle: Linestyle for null direction traces.\n        legend_n_cols: Number of columns for the standalone legend.\n\n    Returns:\n        Figure, axes, and legend axes objects.\n\n    Example:\n        ```\n        view = MovingEdgeCurrentView(...)\n        fig, ax = view.plot_temporal_contributions_pc_nc(\n            contrast=1.0,\n            angle=0,\n            t_start=0,\n            t_end=1,\n            fontsize=5,\n            linewidth=0.25,\n            legend=True\n        )\n        ```\n    \"\"\"\n    if fig is None and ax is None:\n        figsize = figsize_from_n_items(\n            1,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n        fig, axes = figsize.axis_grid(hspace=0.0, wspace=0, fontsize=fontsize)\n        ax = axes[0]\n    cv_pd = (\n        self.at_contrast(contrast)\n        .at_angle(angle)\n        .between_seconds(t_start, t_end)\n        .sum_over_cells()\n    )\n    cv_nd = (\n        self.at_contrast(contrast)\n        .at_angle((angle - 180) % 360)\n        .between_seconds(t_start, t_end)\n        .sum_over_cells()\n    )\n\n    source_types = (\n        self.at_contrast(contrast)\n        .at_angle([angle, (angle - 180) % 360])\n        .between_seconds(t_start, t_end)\n        .filter_source_types(\n            hide_source_types,\n            hide_source_types_bins,\n            hide_source_types_cut_off_edge,\n            hide_source_types_mode,\n        )\n    )\n\n    color_source_types = (\n        self.at_contrast(contrast)\n        .at_angle([angle, (angle - 180) % 360])\n        .between_seconds(t_start, t_end)\n        .filter_source_types(\n            None,\n            hide_source_types_bins,\n            hide_source_types_cut_off_edge,\n            hide_source_types_mode,\n        )\n    )\n    cv_pd.init_colors(color_source_types)\n    cv_nd.init_colors(color_source_types)\n\n    def plot_mean_trace(\n        time, trace, label, color, zorder, linestyle=\"solid\", ax=None, fig=None\n    ):\n        ax.plot(\n            time,\n            trace,\n            label=label,\n            color=color,\n            zorder=zorder,\n            linestyle=linestyle,\n        )\n\n    def plot_individual_traces(\n        traces, time, color, zorder, label, linestyle=\"solid\", legend=None\n    ):\n        if not only_sum and not model_average:\n            plots.traces(\n                traces,\n                time,\n                mean_color=color,\n                color=color,\n                linewidth=linewidth,\n                zorder_traces=0,\n                zorder_mean=zorder,\n                fontsize=fontsize,\n                null_line=True,\n                highlight_mean=highlight_mean,\n                fig=fig,\n                ax=ax,\n                legend=legend or label,\n                linestyle=linestyle,\n            )\n\n    def plot_quantile(traces, time, color, zorder, linestyle=\"solid\"):\n        if quantile:\n            Q = np.quantile(traces, quantile, axis=0)\n            ax.fill_between(\n                time,\n                Q[0],\n                Q[1],\n                facecolor=adapt_color_alpha(color, 0.1),\n                edgecolor=color,\n                linewidth=0.25,\n                linestyle=linestyle,\n                zorder=zorder - 1,\n            )\n\n    def plot_summed_trace(time, trace, label, color, zorder, linestyle=\"solid\"):\n        if np.any(trace):\n            ax.plot(\n                time,\n                trace,\n                label=label,\n                color=color,\n                zorder=zorder,\n                linestyle=linestyle,\n            )\n\n    def get_summed_traces(signs, source_types, cv_pd, cv_nd):\n        # sum over cell types then average over models\n        exc_pd = np.zeros(cv_pd.shape)\n        inh_pd = np.zeros(cv_pd.shape)\n        exc_nd = np.zeros(cv_nd.shape)\n        inh_nd = np.zeros(cv_nd.shape)\n        # sum over cell types\n        for source_type in source_types:\n            if signs[source_type] == 1:\n                exc_pd += cv_pd[source_type][:]  # (1, n_models, 1, n_timesteps)\n                exc_nd += cv_nd[source_type][:]\n            else:\n                inh_pd += cv_pd[source_type][:]\n                inh_nd += cv_nd[source_type][:]\n        # (n_models, n_timesteps)\n        return (\n            exc_pd.squeeze(),\n            inh_pd.squeeze(),\n            exc_nd.squeeze(),\n            inh_nd.squeeze(),\n        )\n\n    for source_type in source_types:\n        if model_average and not only_sum:\n            # mean traces solid for PD and dashed for ND\n            color = cv_pd.color(source_type)\n\n            plot_mean_trace(\n                cv_pd.time,\n                cv_pd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                source_type,\n                color,\n                cv_pd.zorder(source_types, source_type),\n                ax=ax,\n                fig=fig,\n            )\n            plot_mean_trace(\n                cv_nd.time,\n                cv_nd[source_type][:].squeeze(axis=-2).T.mean(axis=1),\n                source_type,\n                color,\n                linestyle=null_linestyle,\n                zorder=cv_pd.zorder(source_types, source_type),\n                ax=ax,\n                fig=fig,\n            )\n\n        elif not model_average and not only_sum:\n            # individual traces\n            plot_individual_traces(\n                cv_pd[source_type][:].squeeze(axis=-2),\n                cv_pd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                source_type,\n            )\n            plot_individual_traces(\n                cv_nd[source_type][:].squeeze(axis=-2),\n                cv_nd.time,\n                cv_pd.color(source_type),\n                cv_pd.zorder(source_types, source_type),\n                source_type,\n                linestyle=null_linestyle,\n                legend=\"null direction\",\n            )\n\n        # quantiles\n        plot_quantile(\n            cv_pd[source_type][:].squeeze(axis=-2),\n            cv_pd.time,\n            cv_pd.color(source_type),\n            cv_pd.zorder(source_types, source_type),\n            linestyle=\"solid\",\n        )\n        plot_quantile(\n            cv_nd[source_type][:].squeeze(axis=-2),\n            cv_nd.time,\n            cv_pd.color(source_type),\n            cv_pd.zorder(source_types, source_type),\n            linestyle=null_linestyle,\n        )\n    if sum_exc_inh or only_sum:\n        # plot summed traces\n        signs = cv_pd.signs()\n        exc_pd, inh_pd, exc_nd, inh_nd = get_summed_traces(\n            signs, source_types, cv_pd, cv_nd\n        )\n        plot_summed_trace(\n            cv_pd.time,\n            exc_pd.mean(axis=0),\n            \"excitatory\",\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=2000,\n        )\n        plot_quantile(\n            exc_pd,\n            cv_pd.time,\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=0,\n            linestyle=\"solid\",\n        )\n        plot_summed_trace(\n            cv_nd.time,\n            exc_nd.mean(axis=0),\n            \"excitatory\",\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=2000,\n            linestyle=null_linestyle,\n        )\n        plot_quantile(\n            exc_nd,\n            cv_pd.time,\n            (0.931, 0.0, 0.0, 1.0),\n            zorder=0,\n            linestyle=null_linestyle,\n        )\n        plot_summed_trace(\n            cv_pd.time,\n            inh_pd.mean(axis=0),\n            \"inhibitory\",\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=2000,\n        )\n        plot_quantile(\n            inh_pd,\n            cv_pd.time,\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=0,\n            linestyle=\"solid\",\n        )\n        plot_summed_trace(\n            cv_nd.time,\n            inh_nd.mean(axis=0),\n            \"inhibitory\",\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=2000,\n            linestyle=null_linestyle,\n        )\n        plot_quantile(\n            inh_nd,\n            cv_pd.time,\n            (0.0, 0.0, 0.849, 1.0),\n            zorder=0,\n            linestyle=null_linestyle,\n        )\n\n    if legend:\n        ax.legend(\n            fontsize=fontsize,\n            ncols=1,\n            bbox_to_anchor=(1.05, 1),\n            loc=\"upper left\",\n            borderaxespad=0.0,\n        )\n    else:\n        ax.legend().set_visible(False)\n\n    ax.set_xlabel(\"time (s)\", fontsize=fontsize)\n    #         ax.set_ylabel(\"current (a.u.)\", fontsize=fontsize)\n\n    if hide_yaxis:\n        plt_utils.rm_spines(ax, (\"left\",))\n\n    if trim_axes:\n        plt_utils.trim_axis(ax)\n\n    if legend_standalone:\n        handles, labels = ax.get_legend_handles_labels()\n        nd_handle = Line2D(\n            [0], [0], color=\"k\", lw=1, label=\"null direction\", ls=null_linestyle\n        )\n        legend_n_rows = legend_n_rows or len(labels) + 1\n        # legend_n_cols = (len(labels) + 1) // legend_n_rows\n        legend_fig, legend_ax = plt_utils.standalone_legend(\n            [*labels[::2], \"null direction\"],\n            None,\n            [*handles[::2], nd_handle],\n            fontsize=fontsize,\n            n_cols=legend_n_cols,\n            handlelength=2,\n            columnspacing=0.8,\n            labelspacing=0.25,\n            figsize=cm_to_inch(legend_figsize_cm),\n            fig=fig if legend_ax is not None else None,\n            ax=legend_ax,\n        )\n        return fig, ax, legend_fig, legend_ax\n    return fig, ax, None, None\n</code></pre>"},{"location":"reference/network/","title":"Network","text":""},{"location":"reference/network/#flyvis.network.network.Network","title":"flyvis.network.network.Network","text":"<p>               Bases: <code>Module</code></p> <p>A connectome-constrained network with nodes, edges, and dynamics.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>Dict[str, Any]</code> <p>Connectome configuration.</p> <code>Namespace(type='ConnectomeFromAvgFilters', file='fib25-fib19_v2.2.json', extent=15, n_syn_fill=1)</code> <code>dynamics</code> <code>Dict[str, Any]</code> <p>Network dynamics configuration.</p> <code>Namespace(type='PPNeuronIGRSynapses', activation=Namespace(type='relu'))</code> <code>node_config</code> <code>Dict[str, Any]</code> <p>Node parameter configuration.</p> <code>Namespace(bias=Namespace(type='RestingPotential', groupby=['type'], initial_dist='Normal', mode='sample', requires_grad=True, mean=0.5, std=0.05, penalize=Namespace(activity=True), seed=0), time_const=Namespace(type='TimeConstant', groupby=['type'], initial_dist='Value', value=0.05, requires_grad=True))</code> <code>edge_config</code> <code>Dict[str, Any]</code> <p>Edge parameter configuration.</p> <code>Namespace(sign=Namespace(type='SynapseSign', initial_dist='Value', requires_grad=False, groupby=['source_type', 'target_type']), syn_count=Namespace(type='SynapseCount', initial_dist='Lognormal', mode='mean', requires_grad=False, std=1.0, groupby=['source_type', 'target_type', 'dv', 'du']), syn_strength=Namespace(type='SynapseCountScaling', initial_dist='Value', requires_grad=True, scale=0.01, clamp='non_negative', groupby=['source_type', 'target_type']))</code> <p>Attributes:</p> Name Type Description <code>connectome</code> <code>Connectome</code> <p>Connectome directory.</p> <code>dynamics</code> <code>NetworkDynamics</code> <p>Network dynamics.</p> <code>node_params</code> <code>Namespace</code> <p>Node parameters.</p> <code>edge_params</code> <code>Namespace</code> <p>Edge parameters.</p> <code>n_nodes</code> <code>int</code> <p>Number of nodes.</p> <code>n_edges</code> <code>int</code> <p>Number of edges.</p> <code>num_parameters</code> <code>int</code> <p>Number of parameters.</p> <code>config</code> <code>Namespace</code> <p>Config namespace.</p> <code>_source_indices</code> <code>Tensor</code> <p>Source indices.</p> <code>_target_indices</code> <code>Tensor</code> <p>Target indices.</p> <code>symmetry_config</code> <code>Namespace</code> <p>Symmetry config.</p> <code>clamp_config</code> <code>Namespace</code> <p>Clamp config.</p> <code>stimulus</code> <code>Stimulus</code> <p>Stimulus object.</p> <code>_state_hooks</code> <code>tuple</code> <p>State hooks.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>class Network(nn.Module):\n    \"\"\"A connectome-constrained network with nodes, edges, and dynamics.\n\n    Args:\n        connectome: Connectome configuration.\n        dynamics: Network dynamics configuration.\n        node_config: Node parameter configuration.\n        edge_config: Edge parameter configuration.\n\n    Attributes:\n        connectome (Connectome): Connectome directory.\n        dynamics (NetworkDynamics): Network dynamics.\n        node_params (Namespace): Node parameters.\n        edge_params (Namespace): Edge parameters.\n        n_nodes (int): Number of nodes.\n        n_edges (int): Number of edges.\n        num_parameters (int): Number of parameters.\n        config (Namespace): Config namespace.\n        _source_indices (Tensor): Source indices.\n        _target_indices (Tensor): Target indices.\n        symmetry_config (Namespace): Symmetry config.\n        clamp_config (Namespace): Clamp config.\n        stimulus (Stimulus): Stimulus object.\n        _state_hooks (tuple): State hooks.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: Dict[str, Any] = Namespace(\n            type=\"ConnectomeFromAvgFilters\",\n            file=\"fib25-fib19_v2.2.json\",\n            extent=15,\n            n_syn_fill=1,\n        ),\n        dynamics: Dict[str, Any] = Namespace(\n            type=\"PPNeuronIGRSynapses\", activation=Namespace(type=\"relu\")\n        ),\n        node_config: Dict[str, Any] = Namespace(\n            bias=Namespace(\n                type=\"RestingPotential\",\n                groupby=[\"type\"],\n                initial_dist=\"Normal\",\n                mode=\"sample\",\n                requires_grad=True,\n                mean=0.5,\n                std=0.05,\n                penalize=Namespace(activity=True),\n                seed=0,\n            ),\n            time_const=Namespace(\n                type=\"TimeConstant\",\n                groupby=[\"type\"],\n                initial_dist=\"Value\",\n                value=0.05,\n                requires_grad=True,\n            ),\n        ),\n        edge_config: Dict[str, Any] = Namespace(\n            sign=Namespace(\n                type=\"SynapseSign\",\n                initial_dist=\"Value\",\n                requires_grad=False,\n                groupby=[\"source_type\", \"target_type\"],\n            ),\n            syn_count=Namespace(\n                type=\"SynapseCount\",\n                initial_dist=\"Lognormal\",\n                mode=\"mean\",\n                requires_grad=False,\n                std=1.0,\n                groupby=[\"source_type\", \"target_type\", \"dv\", \"du\"],\n            ),\n            syn_strength=Namespace(\n                type=\"SynapseCountScaling\",\n                initial_dist=\"Value\",\n                requires_grad=True,\n                scale=0.01,\n                clamp=\"non_negative\",\n                groupby=[\"source_type\", \"target_type\"],\n            ),\n        ),\n        stimulus_config: Dict[str, Any] = Namespace(type=\"Stimulus\", init_buffer=False),\n    ):\n        super().__init__()\n\n        # Prepare configs.\n        connectome, dynamics, node_config, edge_config, stimulus_config, self.config = (\n            self.prepare_configs(\n                connectome, dynamics, node_config, edge_config, stimulus_config\n            )\n        )\n\n        # Store the connectome, dynamics, and parameters.\n        self.connectome = init_connectome(**connectome)\n        self.dynamics = forward_subclass(NetworkDynamics, dynamics)\n\n        # Load constant indices into memory.\n        # Store source/target indices.\n        self._source_indices = torch.tensor(self.connectome.edges.source_index[:])\n        self._target_indices = torch.tensor(self.connectome.edges.target_index[:])\n\n        self.n_nodes = len(self.connectome.nodes.index)\n        self.n_edges = len(self.connectome.edges.source_index)\n\n        # Optional way of parameter sharing is averaging at every call across\n        # precomputed masks. This can be useful for e.g. symmetric electrical\n        # compartments.\n        # These masks are collected from Parameters into this namespace.\n        self.symmetry_config = Namespace()  # type: Dict[str, List[torch.Tensor]]\n        # Clamp configuration is collected from Parameter into this Namespace\n        # for projected gradient descent.\n        self.clamp_config = Namespace()\n\n        # Construct node parameter sets.\n        self.node_params = Namespace()\n        for param_name, param_config in node_config.items():\n            param = forward_subclass(\n                Parameter,\n                config={\n                    \"type\": param_config.type,\n                    \"param_config\": param_config,\n                    \"connectome\": self.connectome,\n                },\n            )\n\n            # register parameter to module\n            self.register_parameter(f\"nodes_{param_name}\", param.raw_values)\n\n            # creating index to map shared parameters onto all nodes,\n            # sources, or targets\n            param.readers = dict(\n                nodes=param.indices,\n                sources=param.indices[self._source_indices],\n                targets=param.indices[self._target_indices],\n            )\n            self.node_params[param_name] = param\n\n            # additional map to optional boolean masks to constrain\n            # parameters (called in self.clamp)\n            self.symmetry_config[f\"nodes_{param_name}\"] = getattr(\n                param, \"symmetry_masks\", []\n            )\n\n            # additional map to optional clamp configuration to constrain\n            # parameters (called in self.clamp)\n            self.clamp_config[f\"nodes_{param_name}\"] = getattr(\n                param_config, \"clamp\", None\n            )\n\n        # Construct edge parameter sets.\n        self.edge_params = Namespace()\n        for param_name, param_config in edge_config.items():\n            param = forward_subclass(\n                Parameter,\n                config={\n                    \"type\": param_config.type,\n                    \"param_config\": param_config,\n                    \"connectome\": self.connectome,\n                },\n            )\n\n            self.register_parameter(f\"edges_{param_name}\", param.raw_values)\n\n            # creating index to map shared parameters onto all edges\n            param.readers = dict(edges=param.indices)\n\n            self.edge_params[param_name] = param\n\n            self.symmetry_config[f\"edges_{param_name}\"] = getattr(\n                param, \"symmetry_masks\", []\n            )\n\n            self.clamp_config[f\"edges_{param_name}\"] = getattr(\n                param_config, \"clamp\", None\n            )\n\n        self.num_parameters = n_params(self)\n        self._state_hooks = tuple()\n\n        self.stimulus = init_stimulus(self.connectome, **stimulus_config)\n\n        logger.info(\"Initialized network with %s parameters.\", self.num_parameters)\n\n    def __repr__(self):\n        return self.config.__repr__().replace(\"Namespace\", \"Network\", 1)\n\n    def prepare_configs(\n        self, connectome, dynamics, node_config, edge_config, stimulus_config\n    ):\n        \"\"\"Prepare configs for network initialization.\"\"\"\n        connectome = namespacify(connectome).deepcopy()\n        dynamics = namespacify(dynamics).deepcopy()\n        node_config = namespacify(node_config).deepcopy()\n        edge_config = namespacify(edge_config).deepcopy()\n        stimulus_config = namespacify(stimulus_config).deepcopy()\n        config = Namespace(\n            connectome=connectome,\n            dynamics=dynamics,\n            node_config=node_config,\n            edge_config=edge_config,\n            stimulus_config=stimulus_config,\n        ).deepcopy()\n        return connectome, dynamics, node_config, edge_config, stimulus_config, config\n\n    def param_api(self) -&gt; Dict[str, Dict[str, Tensor]]:\n        \"\"\"Param api for inspection.\n\n        Returns:\n            Parameter namespace for inspection.\n\n        Note:\n            This is not the same as the parameter api passed to the dynamics. This is a\n            convenience function to inspect the parameters, but does not write derived\n            parameters or sources and targets states.\n        \"\"\"\n        # Construct the base parameter namespace.\n        params = Namespace(\n            nodes=Namespace(),\n            edges=Namespace(),\n            sources=Namespace(),\n            targets=Namespace(),\n        )\n        for param_name, parameter in {\n            **self.node_params,\n            **self.edge_params,\n        }.items():\n            values = parameter.semantic_values\n            for route, indices in parameter.readers.items():\n                # route one of (\"nodes\", \"sources\", \"target\", \"edges\")\n                params[route][param_name] = Namespace(parameter=values, indices=indices)\n        return params\n\n    def _param_api(self) -&gt; AutoDeref[str, AutoDeref[str, RefTensor]]:\n        \"\"\"Returns params object passed to `dynamics`.\n\n        Returns:\n            Parameter namespace for dynamics.\n        \"\"\"\n        # Construct the base parameter namespace.\n        params = AutoDeref(\n            nodes=AutoDeref(),\n            edges=AutoDeref(),\n            sources=AutoDeref(),\n            targets=AutoDeref(),\n        )\n        for param_name, parameter in {\n            **self.node_params,\n            **self.edge_params,\n        }.items():\n            values = parameter.semantic_values\n            for route, indices in parameter.readers.items():\n                # route one of (\"nodes\", \"sources\", \"target\", \"edges\")\n                params[route][param_name] = RefTensor(values, indices)\n        # Add derived parameters.\n        self.dynamics.write_derived_params(params)\n        for k, v in params.nodes.items():\n            if k not in params.sources:\n                params.sources[k] = self._source_gather(v)\n                params.targets[k] = self._target_gather(v)\n\n        return params\n\n    def _source_gather(self, x: Tensor) -&gt; RefTensor:\n        \"\"\"Gathers source node states across edges.\n\n        Args:\n            x: Node-level activation, e.g., voltages. Shape is (n_nodes).\n\n        Returns:\n            Edge-level representation. Shape is (n_edges).\n\n        Note:\n            For edge-level access to target node states for elementwise operations.\n            Called in _param_api and _state_api.\n        \"\"\"\n        return RefTensor(x, self._source_indices)\n\n    def _target_gather(self, x: Tensor) -&gt; RefTensor:\n        \"\"\"Gathers target node states across edges.\n\n        Args:\n            x: Node-level activation, e.g., voltages. Shape is (n_nodes).\n\n        Returns:\n            Edge-level representation. Shape is (n_edges).\n\n        Note:\n            For edge-level access to target node states for elementwise operations.\n            Called in _param_api and _state_api.\n        \"\"\"\n        return RefTensor(x, self._target_indices)\n\n    def target_sum(self, x: Tensor) -&gt; Tensor:\n        \"\"\"Scatter sum operation creating target node states from inputs.\n\n        Args:\n            x: Edge inputs to targets, e.g., currents. Shape is (batch_size, n_edges).\n\n        Returns:\n            Node-level input. Shape is (batch_size, n_nodes).\n        \"\"\"\n        result = torch.zeros((*x.shape[:-1], self.n_nodes))\n        # signature: tensor.scatter_add_(dim, index, other)\n        result.scatter_add_(\n            -1,  # nodes dim\n            self._target_indices.expand(  # view of index expanded over dims of x\n                *x.shape\n            ),\n            x,\n        )\n        return result\n\n    def _initial_state(\n        self, params: AutoDeref[str, AutoDeref[str, RefTensor]], batch_size: int\n    ) -&gt; AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]:\n        \"\"\"Compute the initial state, given the parameters and batch size.\n\n        Args:\n            params: Parameter namespace.\n            batch_size: Batch size.\n\n        Returns:\n            Initial state namespace of node, edge, source, and target states.\n        \"\"\"\n        # Initialize the network.\n        state = AutoDeref(nodes=AutoDeref(), edges=AutoDeref())\n        self.dynamics.write_initial_state(state, params)\n\n        # Expand over batch dimension.\n        for k, v in state.nodes.items():\n            state.nodes[k] = v.expand(batch_size, *v.shape)\n        for k, v in state.edges.items():\n            state.edges[k] = v.expand(batch_size, *v.shape)\n\n        return self._state_api(state)\n\n    def _next_state(\n        self,\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n        state: AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]],\n        x_t: Tensor,\n        dt: float,\n    ) -&gt; AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]:\n        \"\"\"Compute the next state, given the current `state` and stimulus `x_t`.\n\n        Args:\n            params: Parameters.\n            state: Current state.\n            x_t: Stimulus at time t. Shape is (batch_size, n_nodes).\n            dt: Time step.\n\n        Returns:\n            Next state namespace of node, edge, source, and target states.\n\n        Note:\n            Uses simple, elementwise Euler integration.\n        \"\"\"\n        vel = AutoDeref(nodes=AutoDeref(), edges=AutoDeref())\n\n        self.dynamics.write_state_velocity(\n            vel, state, params, self.target_sum, x_t, dt=dt\n        )\n\n        next_state = AutoDeref(\n            nodes=AutoDeref(**{\n                k: state.nodes[k] + vel.nodes[k] * dt for k in state.nodes\n            }),\n            edges=AutoDeref(**{\n                k: state.edges[k] + vel.edges[k] * dt for k in state.edges\n            }),\n        )\n\n        return self._state_api(next_state)\n\n    def _state_api(\n        self, state: AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]\n    ) -&gt; AutoDeref[str, AutoDeref[str, Union[Tensor, RefTensor]]]:\n        \"\"\"Populate sources and targets states from nodes states.\n\n        Args:\n            state: Current state.\n\n        Returns:\n            Updated state with populated sources and targets.\n\n        Note:\n            Optional state hooks are called here (in order of registration).\n            This is returned by _initial_state and _next_state.\n        \"\"\"\n        for hook in self._state_hooks:\n            _state = hook(state)\n            if _state is not None:\n                state = _state\n\n        state = AutoDeref(\n            nodes=state.nodes,\n            edges=state.edges,\n            sources=AutoDeref(**valmap(self._source_gather, state.nodes)),\n            targets=AutoDeref(**valmap(self._target_gather, state.nodes)),\n        )\n\n        return state\n\n    def register_state_hook(self, state_hook: Callable, **kwargs) -&gt; None:\n        \"\"\"Register a state hook to retrieve or modify the state.\n\n        Args:\n            state_hook: Callable to be used as a hook.\n            **kwargs: Keyword arguments to pass to the callable.\n\n        Raises:\n            ValueError: If state_hook is not callable.\n\n        Note:\n            The hook is called in _state_api. Useful for targeted perturbations.\n        \"\"\"\n\n        class StateHook:\n            def __init__(self, hook, **kwargs):\n                self.hook = hook\n                self.kwargs = kwargs or {}\n\n            def __call__(self, state):\n                return self.hook(state, **self.kwargs)\n\n        if not isinstance(state_hook, Callable):\n            raise ValueError(\"state_hook must be callable\")\n\n        self._state_hooks += (StateHook(state_hook, **kwargs),)\n\n    def clear_state_hooks(self, clear: bool = True):\n        \"\"\"Clear all state hooks.\n\n        Args:\n            clear: If True, clear all state hooks.\n        \"\"\"\n        if clear:\n            self._state_hooks = tuple()\n\n    def clamp(self):\n        \"\"\"Clamp free parameters to their range specified in their config.\n\n        Valid configs are `non_negative` to clamp at zero and tuple of the form\n        (min, max) to clamp to an arbitrary range.\n\n        Note:\n            This function also enforces symmetry constraints.\n        \"\"\"\n        # clamp parameters\n        for param_name, mode in self.clamp_config.items():\n            param = getattr(self, param_name)\n            if param.requires_grad:\n                if mode is None:\n                    pass\n                elif mode == \"non_negative\":\n                    param.data.clamp_(0)\n                elif isinstance(mode, Iterable) and len(mode) == 2:\n                    param.data.clamp_(*mode)\n                else:\n                    raise NotImplementedError(f\"Clamping mode {mode} not implemented.\")\n\n        # enforce symmetry constraints\n        for param_name, masks in self.symmetry_config.items():\n            param = getattr(self, param_name)\n            if param.requires_grad:\n                for symmetry in masks:\n                    param.data[symmetry] = param.data[symmetry].mean()\n\n    def forward(\n        self, x: Tensor, dt: float, state: AutoDeref = None, as_states: bool = False\n    ) -&gt; Union[torch.Tensor, AutoDeref]:\n        \"\"\"Forward pass of the network.\n\n        Args:\n            x: Whole-network stimulus of shape (batch_size, n_frames, n_cells).\n            dt: Integration time constant.\n            state: Initial state of the network. If not given, computed from\n                NetworksDynamics.write_initial_state. initial_state and fade_in_state\n                are convenience functions to compute initial steady states.\n            as_states: If True, returns the states as List[AutoDeref], else concatenates\n                the activity of the nodes and returns a tensor.\n\n        Returns:\n            Network activity or states.\n        \"\"\"\n        # To keep the parameters within their valid domain, they get clamped.\n        self.clamp()\n        # Construct the parameter API.\n        params = self._param_api()\n\n        # Initialize the network state.\n        if state is None:\n            state = self._initial_state(params, x.shape[0])\n\n        def handle(state):\n            # loop over the temporal dimension for integration of dynamics\n            for i in range(x.shape[1]):\n                state = self._next_state(params, state, x[:, i], dt)\n                if as_states is False:\n                    yield state.nodes.activity\n                else:\n                    yield state\n\n        if as_states is True:\n            return list(handle(state))\n        return torch.stack(list(handle(state)), dim=1)\n\n    def steady_state(\n        self,\n        t_pre: float,\n        dt: float,\n        batch_size: int,\n        value: float = 0.5,\n        state: Optional[AutoDeref] = None,\n        grad: bool = False,\n        return_last: bool = True,\n    ) -&gt; AutoDeref:\n        \"\"\"Compute state after grey-scale stimulus.\n\n        Args:\n            t_pre: Time of the grey-scale stimulus.\n            dt: Integration time constant.\n            batch_size: Batch size.\n            value: Value of the grey-scale stimulus.\n            state: Initial state of the network. If not given, computed from\n                NetworksDynamics.write_initial_state. initial_state and fade_in_state\n                are convenience functions to compute initial steady states.\n            grad: If True, the state is computed with gradient.\n            return_last: If True, return only the last state.\n\n        Returns:\n            Steady state of the network after a grey-scale stimulus.\n        \"\"\"\n        if t_pre is None or t_pre &lt;= 0.0:\n            return state\n\n        if value is None:\n            return state\n\n        self.stimulus.zero(batch_size, int(t_pre / dt))\n        self.stimulus.add_pre_stim(value)\n\n        with self.enable_grad(grad):\n            if return_last:\n                return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n            return self(self.stimulus(), dt, as_states=True, state=state)\n\n    def fade_in_state(\n        self,\n        t_fade_in: float,\n        dt: float,\n        initial_frames: Tensor,\n        state: Optional[AutoDeref] = None,\n        grad: bool = False,\n    ) -&gt; AutoDeref:\n        \"\"\"Compute state after fade-in stimulus of initial_frames.\n\n        Args:\n            t_fade_in: Time of the fade-in stimulus.\n            dt: Integration time constant.\n            initial_frames: Tensor of shape (batch_size, 1, n_input_elements).\n            state: Initial state of the network. If not given, computed from\n                NetworksDynamics.write_initial_state. initial_state and fade_in_state\n                are convenience functions to compute initial steady states.\n            grad: If True, the state is computed with gradient.\n\n        Returns:\n            State after fade-in stimulus.\n        \"\"\"\n        if t_fade_in is None or t_fade_in &lt;= 0.0:\n            return state\n\n        batch_size = initial_frames.shape[0]\n\n        # replicate initial frame over int(t_fade_in/dt) frames and fade in\n        # by ramping up the contrast\n        self.stimulus.zero(batch_size, int(t_fade_in / dt))\n\n        initial_frames = (\n            torch.linspace(0, 1, int(t_fade_in / dt))[None, :, None]\n            * (initial_frames.repeat(1, int(t_fade_in / dt), 1) - 0.5)\n            + 0.5\n        )\n        self.stimulus.add_input(initial_frames[:, :, None])\n        with self.enable_grad(grad):\n            return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n\n    def simulate(\n        self,\n        movie_input: torch.Tensor,\n        dt: float,\n        initial_state: Union[AutoDeref, None, Literal[\"auto\"]] = \"auto\",\n        as_states: bool = False,\n        as_layer_activity: bool = False,\n    ) -&gt; Union[torch.Tensor, AutoDeref, LayerActivity]:\n        \"\"\"Simulate the network activity from movie input.\n\n        Args:\n            movie_input: Tensor of shape (batch_size, n_frames, 1, hexals).\n            dt: Integration time constant. Warns if dt &gt; 1/50.\n            initial_state: Network activity at the beginning of the simulation.\n                Use fade_in_state or steady_state to compute the initial state from grey\n                input or from ramping up the contrast of the first movie frame.\n                Defaults to \"auto\", which uses the steady_state after 1s of grey input.\n            as_states: If True, return the states as AutoDeref dictionary instead of\n                a tensor. Defaults to False.\n            as_layer_activity: If True, return a LayerActivity object. Defaults to False.\n                Currently only supported for ConnectomeFromAvgFilters.\n\n        Returns:\n            Activity tensor of shape (batch_size, n_frames, #neurons),\n            or AutoDeref dictionary if `as_states` is True,\n            or LayerActivity object if `as_layer_activity` is True.\n\n        Raises:\n            ValueError: If the movie_input is not four-dimensional.\n            ValueError: If the integration time step is bigger than 1/50.\n            ValueError: If the network is not in evaluation mode or any\n                parameters require grad.\n        \"\"\"\n        if len(movie_input.shape) != 4:\n            raise ValueError(\"requires shape (sample, frame, 1, hexals)\")\n\n        if (\n            as_layer_activity\n            and not self.connectome.__class__.__name__ == \"ConnectomeFromAvgFilters\"\n        ):\n            raise ValueError(\n                \"as_layer_activity is currently only supported for \"\n                \"ConnectomeFromAvgFilters\"\n            )\n\n        if dt &gt; 1 / 50:\n            warnings.warn(\n                f\"dt={dt} is very large for integration. \"\n                \"Better choose a smaller dt (&lt;= 1/50 to avoid this warning)\",\n                IntegrationWarning,\n                stacklevel=2,\n            )\n\n        batch_size, n_frames = movie_input.shape[:2]\n        if initial_state == \"auto\":\n            initial_state = self.steady_state(1.0, dt, batch_size)\n        with simulation(self):\n            assert self.training is False and all(\n                not p.requires_grad for p in self.parameters()\n            )\n            self.stimulus.zero(batch_size, n_frames)\n            self.stimulus.add_input(movie_input)\n            if as_layer_activity:\n                return LayerActivity(\n                    self.forward(self.stimulus(), dt, initial_state, as_states).cpu(),\n                    self.connectome,\n                    keepref=True,\n                )\n            return self.forward(self.stimulus(), dt, initial_state, as_states)\n\n    @contextmanager\n    def enable_grad(self, grad: bool = True):\n        \"\"\"Context manager to enable or disable gradient computation.\n\n        Args:\n            grad: If True, enable gradient computation.\n        \"\"\"\n        prev = torch.is_grad_enabled()\n        torch.set_grad_enabled(grad)\n        try:\n            yield\n        finally:\n            torch.set_grad_enabled(prev)\n\n    def stimulus_response(\n        self,\n        stim_dataset: SequenceDataset,\n        dt: float,\n        indices: Optional[Iterable[int]] = None,\n        t_pre: float = 1.0,\n        t_fade_in: float = 0.0,\n        grad: bool = False,\n        default_stim_key: Any = \"lum\",\n        batch_size: int = 1,\n    ):\n        \"\"\"Compute stimulus responses for a given stimulus dataset.\n\n        Args:\n            stim_dataset: Stimulus dataset.\n            dt: Integration time constant.\n            indices: Indices of the stimuli to compute the response for.\n                If not given, all stimuli responses are computed.\n            t_pre: Time of the grey-scale stimulus.\n            t_fade_in: Time of the fade-in stimulus (slow).\n            grad: If True, the state is computed with gradient.\n            default_stim_key: Key of the stimulus in the dataset if it returns\n                a dictionary.\n            batch_size: Batch size for processing.\n\n        Note:\n            Per default, applies a grey-scale stimulus for 1 second, no\n            fade-in stimulus.\n\n        Yields:\n            Tuple of (stimulus, response) as numpy arrays.\n        \"\"\"\n        stim_dataset.dt = dt\n        if indices is None:\n            indices = np.arange(len(stim_dataset))\n        stim_loader = DataLoader(\n            stim_dataset, batch_size=batch_size, sampler=IndexSampler(indices)\n        )\n\n        stimulus = self.stimulus\n\n        # compute initial state\n        initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n\n        with self.enable_grad(grad):\n            logger.info(\"Computing %s stimulus responses.\", len(indices))\n            for stim in tqdm(\n                stim_loader, desc=\"Batch\", total=len(stim_loader), leave=False\n            ):\n                # when datasets return dictionaries, we assume that the stimulus\n                # is stored under the key `default_stim_key`\n                if isinstance(stim, dict):\n                    stim = stim[default_stim_key]  # (batch, frames, 1, hexals)\n                else:\n                    stim = stim.unsqueeze(-2)  # (batch, frames, 1, hexals)\n\n                # fade in stimulus\n                fade_in_state = self.fade_in_state(\n                    t_fade_in=t_fade_in,\n                    dt=dt,\n                    initial_frames=stim[:, 0],\n                    state=initial_state,\n                )\n\n                def handle_stim(stim, fade_in_state):\n                    # reset stimulus\n                    batch_size, n_frames = stim.shape[:2]\n                    stimulus.zero(batch_size, n_frames)\n\n                    # add stimulus\n                    stimulus.add_input(stim)\n\n                    # compute response\n                    if grad is False:\n                        return (\n                            stim.cpu().numpy(),\n                            self(stimulus(), dt, state=fade_in_state)\n                            .detach()\n                            .cpu()\n                            .numpy(),\n                        )\n                    elif grad is True:\n                        return (\n                            stim.cpu().numpy(),\n                            self(stimulus(), dt, state=fade_in_state),\n                        )\n\n                yield handle_stim(stim, fade_in_state)\n\n    def current_response(\n        self,\n        stim_dataset: SequenceDataset,\n        dt: float,\n        indices: Optional[Iterable[int]] = None,\n        t_pre: float = 1.0,\n        t_fade_in: float = 0,\n        default_stim_key: Any = \"lum\",\n    ):\n        \"\"\"Compute stimulus currents and responses for a given stimulus dataset.\n\n        Note:\n            Requires Dynamics to implement `currents`.\n\n        Args:\n            stim_dataset: Stimulus dataset.\n            dt: Integration time constant.\n            indices: Indices of the stimuli to compute the response for.\n                If not given, all stimuli responses are computed.\n            t_pre: Time of the grey-scale stimulus.\n            t_fade_in: Time of the fade-in stimulus (slow).\n            default_stim_key: Key of the stimulus in the dataset if it returns\n                a dictionary.\n\n        Yields:\n            Tuple of (stimulus, activity, currents) as numpy arrays.\n        \"\"\"\n        self.clamp()\n        # Construct the parameter API.\n        params = self._param_api()\n\n        stim_dataset.dt = dt\n        if indices is None:\n            indices = np.arange(len(stim_dataset))\n        stim_loader = DataLoader(\n            stim_dataset, batch_size=1, sampler=IndexSampler(indices)\n        )\n\n        stimulus = self.stimulus\n        initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n        with torch.no_grad():\n            logger.info(\"Computing %d stimulus responses.\", len(indices))\n            for stim in stim_loader:\n                if isinstance(stim, dict):\n                    stim = stim[default_stim_key].squeeze(-2)\n\n                fade_in_state = self.fade_in_state(\n                    t_fade_in=t_fade_in,\n                    dt=dt,\n                    initial_frames=stim[:, 0].unsqueeze(1),\n                    state=initial_state,\n                )\n\n                def handle_stim(stim, fade_in_state):\n                    # reset stimulus\n                    batch_size, n_frames, _ = stim.shape\n                    stimulus.zero(batch_size, n_frames)\n\n                    # add stimulus\n                    stimulus.add_input(stim.unsqueeze(2))\n\n                    # compute response\n                    states = self(stimulus(), dt, state=fade_in_state, as_states=True)\n                    return (\n                        stim.cpu().numpy().squeeze(),\n                        torch.stack(\n                            [s.nodes.activity.cpu() for s in states],\n                            dim=1,\n                        )\n                        .numpy()\n                        .squeeze(),\n                        torch.stack(\n                            [self.dynamics.currents(s, params).cpu() for s in states],\n                            dim=1,\n                        )\n                        .numpy()\n                        .squeeze(),\n                    )\n\n                # stim, activity, currents\n                yield handle_stim(stim, fade_in_state)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.prepare_configs","title":"prepare_configs","text":"<pre><code>prepare_configs(connectome, dynamics, node_config, edge_config, stimulus_config)\n</code></pre> <p>Prepare configs for network initialization.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def prepare_configs(\n    self, connectome, dynamics, node_config, edge_config, stimulus_config\n):\n    \"\"\"Prepare configs for network initialization.\"\"\"\n    connectome = namespacify(connectome).deepcopy()\n    dynamics = namespacify(dynamics).deepcopy()\n    node_config = namespacify(node_config).deepcopy()\n    edge_config = namespacify(edge_config).deepcopy()\n    stimulus_config = namespacify(stimulus_config).deepcopy()\n    config = Namespace(\n        connectome=connectome,\n        dynamics=dynamics,\n        node_config=node_config,\n        edge_config=edge_config,\n        stimulus_config=stimulus_config,\n    ).deepcopy()\n    return connectome, dynamics, node_config, edge_config, stimulus_config, config\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.param_api","title":"param_api","text":"<pre><code>param_api()\n</code></pre> <p>Param api for inspection.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Tensor]]</code> <p>Parameter namespace for inspection.</p> Note <p>This is not the same as the parameter api passed to the dynamics. This is a convenience function to inspect the parameters, but does not write derived parameters or sources and targets states.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def param_api(self) -&gt; Dict[str, Dict[str, Tensor]]:\n    \"\"\"Param api for inspection.\n\n    Returns:\n        Parameter namespace for inspection.\n\n    Note:\n        This is not the same as the parameter api passed to the dynamics. This is a\n        convenience function to inspect the parameters, but does not write derived\n        parameters or sources and targets states.\n    \"\"\"\n    # Construct the base parameter namespace.\n    params = Namespace(\n        nodes=Namespace(),\n        edges=Namespace(),\n        sources=Namespace(),\n        targets=Namespace(),\n    )\n    for param_name, parameter in {\n        **self.node_params,\n        **self.edge_params,\n    }.items():\n        values = parameter.semantic_values\n        for route, indices in parameter.readers.items():\n            # route one of (\"nodes\", \"sources\", \"target\", \"edges\")\n            params[route][param_name] = Namespace(parameter=values, indices=indices)\n    return params\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.target_sum","title":"target_sum","text":"<pre><code>target_sum(x)\n</code></pre> <p>Scatter sum operation creating target node states from inputs.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Edge inputs to targets, e.g., currents. Shape is (batch_size, n_edges).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Node-level input. Shape is (batch_size, n_nodes).</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def target_sum(self, x: Tensor) -&gt; Tensor:\n    \"\"\"Scatter sum operation creating target node states from inputs.\n\n    Args:\n        x: Edge inputs to targets, e.g., currents. Shape is (batch_size, n_edges).\n\n    Returns:\n        Node-level input. Shape is (batch_size, n_nodes).\n    \"\"\"\n    result = torch.zeros((*x.shape[:-1], self.n_nodes))\n    # signature: tensor.scatter_add_(dim, index, other)\n    result.scatter_add_(\n        -1,  # nodes dim\n        self._target_indices.expand(  # view of index expanded over dims of x\n            *x.shape\n        ),\n        x,\n    )\n    return result\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.register_state_hook","title":"register_state_hook","text":"<pre><code>register_state_hook(state_hook, **kwargs)\n</code></pre> <p>Register a state hook to retrieve or modify the state.</p> <p>Parameters:</p> Name Type Description Default <code>state_hook</code> <code>Callable</code> <p>Callable to be used as a hook.</p> required <code>**kwargs</code> <p>Keyword arguments to pass to the callable.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If state_hook is not callable.</p> Note <p>The hook is called in _state_api. Useful for targeted perturbations.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def register_state_hook(self, state_hook: Callable, **kwargs) -&gt; None:\n    \"\"\"Register a state hook to retrieve or modify the state.\n\n    Args:\n        state_hook: Callable to be used as a hook.\n        **kwargs: Keyword arguments to pass to the callable.\n\n    Raises:\n        ValueError: If state_hook is not callable.\n\n    Note:\n        The hook is called in _state_api. Useful for targeted perturbations.\n    \"\"\"\n\n    class StateHook:\n        def __init__(self, hook, **kwargs):\n            self.hook = hook\n            self.kwargs = kwargs or {}\n\n        def __call__(self, state):\n            return self.hook(state, **self.kwargs)\n\n    if not isinstance(state_hook, Callable):\n        raise ValueError(\"state_hook must be callable\")\n\n    self._state_hooks += (StateHook(state_hook, **kwargs),)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.clear_state_hooks","title":"clear_state_hooks","text":"<pre><code>clear_state_hooks(clear=True)\n</code></pre> <p>Clear all state hooks.</p> <p>Parameters:</p> Name Type Description Default <code>clear</code> <code>bool</code> <p>If True, clear all state hooks.</p> <code>True</code> Source code in <code>flyvis/network/network.py</code> <pre><code>def clear_state_hooks(self, clear: bool = True):\n    \"\"\"Clear all state hooks.\n\n    Args:\n        clear: If True, clear all state hooks.\n    \"\"\"\n    if clear:\n        self._state_hooks = tuple()\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.clamp","title":"clamp","text":"<pre><code>clamp()\n</code></pre> <p>Clamp free parameters to their range specified in their config.</p> <p>Valid configs are <code>non_negative</code> to clamp at zero and tuple of the form (min, max) to clamp to an arbitrary range.</p> Note <p>This function also enforces symmetry constraints.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def clamp(self):\n    \"\"\"Clamp free parameters to their range specified in their config.\n\n    Valid configs are `non_negative` to clamp at zero and tuple of the form\n    (min, max) to clamp to an arbitrary range.\n\n    Note:\n        This function also enforces symmetry constraints.\n    \"\"\"\n    # clamp parameters\n    for param_name, mode in self.clamp_config.items():\n        param = getattr(self, param_name)\n        if param.requires_grad:\n            if mode is None:\n                pass\n            elif mode == \"non_negative\":\n                param.data.clamp_(0)\n            elif isinstance(mode, Iterable) and len(mode) == 2:\n                param.data.clamp_(*mode)\n            else:\n                raise NotImplementedError(f\"Clamping mode {mode} not implemented.\")\n\n    # enforce symmetry constraints\n    for param_name, masks in self.symmetry_config.items():\n        param = getattr(self, param_name)\n        if param.requires_grad:\n            for symmetry in masks:\n                param.data[symmetry] = param.data[symmetry].mean()\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.forward","title":"forward","text":"<pre><code>forward(x, dt, state=None, as_states=False)\n</code></pre> <p>Forward pass of the network.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Whole-network stimulus of shape (batch_size, n_frames, n_cells).</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <code>state</code> <code>AutoDeref</code> <p>Initial state of the network. If not given, computed from NetworksDynamics.write_initial_state. initial_state and fade_in_state are convenience functions to compute initial steady states.</p> <code>None</code> <code>as_states</code> <code>bool</code> <p>If True, returns the states as List[AutoDeref], else concatenates the activity of the nodes and returns a tensor.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, AutoDeref]</code> <p>Network activity or states.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def forward(\n    self, x: Tensor, dt: float, state: AutoDeref = None, as_states: bool = False\n) -&gt; Union[torch.Tensor, AutoDeref]:\n    \"\"\"Forward pass of the network.\n\n    Args:\n        x: Whole-network stimulus of shape (batch_size, n_frames, n_cells).\n        dt: Integration time constant.\n        state: Initial state of the network. If not given, computed from\n            NetworksDynamics.write_initial_state. initial_state and fade_in_state\n            are convenience functions to compute initial steady states.\n        as_states: If True, returns the states as List[AutoDeref], else concatenates\n            the activity of the nodes and returns a tensor.\n\n    Returns:\n        Network activity or states.\n    \"\"\"\n    # To keep the parameters within their valid domain, they get clamped.\n    self.clamp()\n    # Construct the parameter API.\n    params = self._param_api()\n\n    # Initialize the network state.\n    if state is None:\n        state = self._initial_state(params, x.shape[0])\n\n    def handle(state):\n        # loop over the temporal dimension for integration of dynamics\n        for i in range(x.shape[1]):\n            state = self._next_state(params, state, x[:, i], dt)\n            if as_states is False:\n                yield state.nodes.activity\n            else:\n                yield state\n\n    if as_states is True:\n        return list(handle(state))\n    return torch.stack(list(handle(state)), dim=1)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.steady_state","title":"steady_state","text":"<pre><code>steady_state(t_pre, dt, batch_size, value=0.5, state=None, grad=False, return_last=True)\n</code></pre> <p>Compute state after grey-scale stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>t_pre</code> <code>float</code> <p>Time of the grey-scale stimulus.</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <code>batch_size</code> <code>int</code> <p>Batch size.</p> required <code>value</code> <code>float</code> <p>Value of the grey-scale stimulus.</p> <code>0.5</code> <code>state</code> <code>Optional[AutoDeref]</code> <p>Initial state of the network. If not given, computed from NetworksDynamics.write_initial_state. initial_state and fade_in_state are convenience functions to compute initial steady states.</p> <code>None</code> <code>grad</code> <code>bool</code> <p>If True, the state is computed with gradient.</p> <code>False</code> <code>return_last</code> <code>bool</code> <p>If True, return only the last state.</p> <code>True</code> <p>Returns:</p> Type Description <code>AutoDeref</code> <p>Steady state of the network after a grey-scale stimulus.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def steady_state(\n    self,\n    t_pre: float,\n    dt: float,\n    batch_size: int,\n    value: float = 0.5,\n    state: Optional[AutoDeref] = None,\n    grad: bool = False,\n    return_last: bool = True,\n) -&gt; AutoDeref:\n    \"\"\"Compute state after grey-scale stimulus.\n\n    Args:\n        t_pre: Time of the grey-scale stimulus.\n        dt: Integration time constant.\n        batch_size: Batch size.\n        value: Value of the grey-scale stimulus.\n        state: Initial state of the network. If not given, computed from\n            NetworksDynamics.write_initial_state. initial_state and fade_in_state\n            are convenience functions to compute initial steady states.\n        grad: If True, the state is computed with gradient.\n        return_last: If True, return only the last state.\n\n    Returns:\n        Steady state of the network after a grey-scale stimulus.\n    \"\"\"\n    if t_pre is None or t_pre &lt;= 0.0:\n        return state\n\n    if value is None:\n        return state\n\n    self.stimulus.zero(batch_size, int(t_pre / dt))\n    self.stimulus.add_pre_stim(value)\n\n    with self.enable_grad(grad):\n        if return_last:\n            return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n        return self(self.stimulus(), dt, as_states=True, state=state)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.fade_in_state","title":"fade_in_state","text":"<pre><code>fade_in_state(t_fade_in, dt, initial_frames, state=None, grad=False)\n</code></pre> <p>Compute state after fade-in stimulus of initial_frames.</p> <p>Parameters:</p> Name Type Description Default <code>t_fade_in</code> <code>float</code> <p>Time of the fade-in stimulus.</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <code>initial_frames</code> <code>Tensor</code> <p>Tensor of shape (batch_size, 1, n_input_elements).</p> required <code>state</code> <code>Optional[AutoDeref]</code> <p>Initial state of the network. If not given, computed from NetworksDynamics.write_initial_state. initial_state and fade_in_state are convenience functions to compute initial steady states.</p> <code>None</code> <code>grad</code> <code>bool</code> <p>If True, the state is computed with gradient.</p> <code>False</code> <p>Returns:</p> Type Description <code>AutoDeref</code> <p>State after fade-in stimulus.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def fade_in_state(\n    self,\n    t_fade_in: float,\n    dt: float,\n    initial_frames: Tensor,\n    state: Optional[AutoDeref] = None,\n    grad: bool = False,\n) -&gt; AutoDeref:\n    \"\"\"Compute state after fade-in stimulus of initial_frames.\n\n    Args:\n        t_fade_in: Time of the fade-in stimulus.\n        dt: Integration time constant.\n        initial_frames: Tensor of shape (batch_size, 1, n_input_elements).\n        state: Initial state of the network. If not given, computed from\n            NetworksDynamics.write_initial_state. initial_state and fade_in_state\n            are convenience functions to compute initial steady states.\n        grad: If True, the state is computed with gradient.\n\n    Returns:\n        State after fade-in stimulus.\n    \"\"\"\n    if t_fade_in is None or t_fade_in &lt;= 0.0:\n        return state\n\n    batch_size = initial_frames.shape[0]\n\n    # replicate initial frame over int(t_fade_in/dt) frames and fade in\n    # by ramping up the contrast\n    self.stimulus.zero(batch_size, int(t_fade_in / dt))\n\n    initial_frames = (\n        torch.linspace(0, 1, int(t_fade_in / dt))[None, :, None]\n        * (initial_frames.repeat(1, int(t_fade_in / dt), 1) - 0.5)\n        + 0.5\n    )\n    self.stimulus.add_input(initial_frames[:, :, None])\n    with self.enable_grad(grad):\n        return self(self.stimulus(), dt, as_states=True, state=state)[-1]\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.simulate","title":"simulate","text":"<pre><code>simulate(movie_input, dt, initial_state='auto', as_states=False, as_layer_activity=False)\n</code></pre> <p>Simulate the network activity from movie input.</p> <p>Parameters:</p> Name Type Description Default <code>movie_input</code> <code>Tensor</code> <p>Tensor of shape (batch_size, n_frames, 1, hexals).</p> required <code>dt</code> <code>float</code> <p>Integration time constant. Warns if dt &gt; 1/50.</p> required <code>initial_state</code> <code>Union[AutoDeref, None, Literal['auto']]</code> <p>Network activity at the beginning of the simulation. Use fade_in_state or steady_state to compute the initial state from grey input or from ramping up the contrast of the first movie frame. Defaults to \u201cauto\u201d, which uses the steady_state after 1s of grey input.</p> <code>'auto'</code> <code>as_states</code> <code>bool</code> <p>If True, return the states as AutoDeref dictionary instead of a tensor. Defaults to False.</p> <code>False</code> <code>as_layer_activity</code> <code>bool</code> <p>If True, return a LayerActivity object. Defaults to False. Currently only supported for ConnectomeFromAvgFilters.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, AutoDeref, LayerActivity]</code> <p>Activity tensor of shape (batch_size, n_frames, #neurons),</p> <code>Union[Tensor, AutoDeref, LayerActivity]</code> <p>or AutoDeref dictionary if <code>as_states</code> is True,</p> <code>Union[Tensor, AutoDeref, LayerActivity]</code> <p>or LayerActivity object if <code>as_layer_activity</code> is True.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the movie_input is not four-dimensional.</p> <code>ValueError</code> <p>If the integration time step is bigger than 1/50.</p> <code>ValueError</code> <p>If the network is not in evaluation mode or any parameters require grad.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def simulate(\n    self,\n    movie_input: torch.Tensor,\n    dt: float,\n    initial_state: Union[AutoDeref, None, Literal[\"auto\"]] = \"auto\",\n    as_states: bool = False,\n    as_layer_activity: bool = False,\n) -&gt; Union[torch.Tensor, AutoDeref, LayerActivity]:\n    \"\"\"Simulate the network activity from movie input.\n\n    Args:\n        movie_input: Tensor of shape (batch_size, n_frames, 1, hexals).\n        dt: Integration time constant. Warns if dt &gt; 1/50.\n        initial_state: Network activity at the beginning of the simulation.\n            Use fade_in_state or steady_state to compute the initial state from grey\n            input or from ramping up the contrast of the first movie frame.\n            Defaults to \"auto\", which uses the steady_state after 1s of grey input.\n        as_states: If True, return the states as AutoDeref dictionary instead of\n            a tensor. Defaults to False.\n        as_layer_activity: If True, return a LayerActivity object. Defaults to False.\n            Currently only supported for ConnectomeFromAvgFilters.\n\n    Returns:\n        Activity tensor of shape (batch_size, n_frames, #neurons),\n        or AutoDeref dictionary if `as_states` is True,\n        or LayerActivity object if `as_layer_activity` is True.\n\n    Raises:\n        ValueError: If the movie_input is not four-dimensional.\n        ValueError: If the integration time step is bigger than 1/50.\n        ValueError: If the network is not in evaluation mode or any\n            parameters require grad.\n    \"\"\"\n    if len(movie_input.shape) != 4:\n        raise ValueError(\"requires shape (sample, frame, 1, hexals)\")\n\n    if (\n        as_layer_activity\n        and not self.connectome.__class__.__name__ == \"ConnectomeFromAvgFilters\"\n    ):\n        raise ValueError(\n            \"as_layer_activity is currently only supported for \"\n            \"ConnectomeFromAvgFilters\"\n        )\n\n    if dt &gt; 1 / 50:\n        warnings.warn(\n            f\"dt={dt} is very large for integration. \"\n            \"Better choose a smaller dt (&lt;= 1/50 to avoid this warning)\",\n            IntegrationWarning,\n            stacklevel=2,\n        )\n\n    batch_size, n_frames = movie_input.shape[:2]\n    if initial_state == \"auto\":\n        initial_state = self.steady_state(1.0, dt, batch_size)\n    with simulation(self):\n        assert self.training is False and all(\n            not p.requires_grad for p in self.parameters()\n        )\n        self.stimulus.zero(batch_size, n_frames)\n        self.stimulus.add_input(movie_input)\n        if as_layer_activity:\n            return LayerActivity(\n                self.forward(self.stimulus(), dt, initial_state, as_states).cpu(),\n                self.connectome,\n                keepref=True,\n            )\n        return self.forward(self.stimulus(), dt, initial_state, as_states)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.enable_grad","title":"enable_grad","text":"<pre><code>enable_grad(grad=True)\n</code></pre> <p>Context manager to enable or disable gradient computation.</p> <p>Parameters:</p> Name Type Description Default <code>grad</code> <code>bool</code> <p>If True, enable gradient computation.</p> <code>True</code> Source code in <code>flyvis/network/network.py</code> <pre><code>@contextmanager\ndef enable_grad(self, grad: bool = True):\n    \"\"\"Context manager to enable or disable gradient computation.\n\n    Args:\n        grad: If True, enable gradient computation.\n    \"\"\"\n    prev = torch.is_grad_enabled()\n    torch.set_grad_enabled(grad)\n    try:\n        yield\n    finally:\n        torch.set_grad_enabled(prev)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.stimulus_response","title":"stimulus_response","text":"<pre><code>stimulus_response(stim_dataset, dt, indices=None, t_pre=1.0, t_fade_in=0.0, grad=False, default_stim_key='lum', batch_size=1)\n</code></pre> <p>Compute stimulus responses for a given stimulus dataset.</p> <p>Parameters:</p> Name Type Description Default <code>stim_dataset</code> <code>SequenceDataset</code> <p>Stimulus dataset.</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <code>indices</code> <code>Optional[Iterable[int]]</code> <p>Indices of the stimuli to compute the response for. If not given, all stimuli responses are computed.</p> <code>None</code> <code>t_pre</code> <code>float</code> <p>Time of the grey-scale stimulus.</p> <code>1.0</code> <code>t_fade_in</code> <code>float</code> <p>Time of the fade-in stimulus (slow).</p> <code>0.0</code> <code>grad</code> <code>bool</code> <p>If True, the state is computed with gradient.</p> <code>False</code> <code>default_stim_key</code> <code>Any</code> <p>Key of the stimulus in the dataset if it returns a dictionary.</p> <code>'lum'</code> <code>batch_size</code> <code>int</code> <p>Batch size for processing.</p> <code>1</code> Note <p>Per default, applies a grey-scale stimulus for 1 second, no fade-in stimulus.</p> <p>Yields:</p> Type Description <p>Tuple of (stimulus, response) as numpy arrays.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def stimulus_response(\n    self,\n    stim_dataset: SequenceDataset,\n    dt: float,\n    indices: Optional[Iterable[int]] = None,\n    t_pre: float = 1.0,\n    t_fade_in: float = 0.0,\n    grad: bool = False,\n    default_stim_key: Any = \"lum\",\n    batch_size: int = 1,\n):\n    \"\"\"Compute stimulus responses for a given stimulus dataset.\n\n    Args:\n        stim_dataset: Stimulus dataset.\n        dt: Integration time constant.\n        indices: Indices of the stimuli to compute the response for.\n            If not given, all stimuli responses are computed.\n        t_pre: Time of the grey-scale stimulus.\n        t_fade_in: Time of the fade-in stimulus (slow).\n        grad: If True, the state is computed with gradient.\n        default_stim_key: Key of the stimulus in the dataset if it returns\n            a dictionary.\n        batch_size: Batch size for processing.\n\n    Note:\n        Per default, applies a grey-scale stimulus for 1 second, no\n        fade-in stimulus.\n\n    Yields:\n        Tuple of (stimulus, response) as numpy arrays.\n    \"\"\"\n    stim_dataset.dt = dt\n    if indices is None:\n        indices = np.arange(len(stim_dataset))\n    stim_loader = DataLoader(\n        stim_dataset, batch_size=batch_size, sampler=IndexSampler(indices)\n    )\n\n    stimulus = self.stimulus\n\n    # compute initial state\n    initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n\n    with self.enable_grad(grad):\n        logger.info(\"Computing %s stimulus responses.\", len(indices))\n        for stim in tqdm(\n            stim_loader, desc=\"Batch\", total=len(stim_loader), leave=False\n        ):\n            # when datasets return dictionaries, we assume that the stimulus\n            # is stored under the key `default_stim_key`\n            if isinstance(stim, dict):\n                stim = stim[default_stim_key]  # (batch, frames, 1, hexals)\n            else:\n                stim = stim.unsqueeze(-2)  # (batch, frames, 1, hexals)\n\n            # fade in stimulus\n            fade_in_state = self.fade_in_state(\n                t_fade_in=t_fade_in,\n                dt=dt,\n                initial_frames=stim[:, 0],\n                state=initial_state,\n            )\n\n            def handle_stim(stim, fade_in_state):\n                # reset stimulus\n                batch_size, n_frames = stim.shape[:2]\n                stimulus.zero(batch_size, n_frames)\n\n                # add stimulus\n                stimulus.add_input(stim)\n\n                # compute response\n                if grad is False:\n                    return (\n                        stim.cpu().numpy(),\n                        self(stimulus(), dt, state=fade_in_state)\n                        .detach()\n                        .cpu()\n                        .numpy(),\n                    )\n                elif grad is True:\n                    return (\n                        stim.cpu().numpy(),\n                        self(stimulus(), dt, state=fade_in_state),\n                    )\n\n            yield handle_stim(stim, fade_in_state)\n</code></pre>"},{"location":"reference/network/#flyvis.network.network.Network.current_response","title":"current_response","text":"<pre><code>current_response(stim_dataset, dt, indices=None, t_pre=1.0, t_fade_in=0, default_stim_key='lum')\n</code></pre> <p>Compute stimulus currents and responses for a given stimulus dataset.</p> Note <p>Requires Dynamics to implement <code>currents</code>.</p> <p>Parameters:</p> Name Type Description Default <code>stim_dataset</code> <code>SequenceDataset</code> <p>Stimulus dataset.</p> required <code>dt</code> <code>float</code> <p>Integration time constant.</p> required <code>indices</code> <code>Optional[Iterable[int]]</code> <p>Indices of the stimuli to compute the response for. If not given, all stimuli responses are computed.</p> <code>None</code> <code>t_pre</code> <code>float</code> <p>Time of the grey-scale stimulus.</p> <code>1.0</code> <code>t_fade_in</code> <code>float</code> <p>Time of the fade-in stimulus (slow).</p> <code>0</code> <code>default_stim_key</code> <code>Any</code> <p>Key of the stimulus in the dataset if it returns a dictionary.</p> <code>'lum'</code> <p>Yields:</p> Type Description <p>Tuple of (stimulus, activity, currents) as numpy arrays.</p> Source code in <code>flyvis/network/network.py</code> <pre><code>def current_response(\n    self,\n    stim_dataset: SequenceDataset,\n    dt: float,\n    indices: Optional[Iterable[int]] = None,\n    t_pre: float = 1.0,\n    t_fade_in: float = 0,\n    default_stim_key: Any = \"lum\",\n):\n    \"\"\"Compute stimulus currents and responses for a given stimulus dataset.\n\n    Note:\n        Requires Dynamics to implement `currents`.\n\n    Args:\n        stim_dataset: Stimulus dataset.\n        dt: Integration time constant.\n        indices: Indices of the stimuli to compute the response for.\n            If not given, all stimuli responses are computed.\n        t_pre: Time of the grey-scale stimulus.\n        t_fade_in: Time of the fade-in stimulus (slow).\n        default_stim_key: Key of the stimulus in the dataset if it returns\n            a dictionary.\n\n    Yields:\n        Tuple of (stimulus, activity, currents) as numpy arrays.\n    \"\"\"\n    self.clamp()\n    # Construct the parameter API.\n    params = self._param_api()\n\n    stim_dataset.dt = dt\n    if indices is None:\n        indices = np.arange(len(stim_dataset))\n    stim_loader = DataLoader(\n        stim_dataset, batch_size=1, sampler=IndexSampler(indices)\n    )\n\n    stimulus = self.stimulus\n    initial_state = self.steady_state(t_pre, dt, batch_size=1, value=0.5)\n    with torch.no_grad():\n        logger.info(\"Computing %d stimulus responses.\", len(indices))\n        for stim in stim_loader:\n            if isinstance(stim, dict):\n                stim = stim[default_stim_key].squeeze(-2)\n\n            fade_in_state = self.fade_in_state(\n                t_fade_in=t_fade_in,\n                dt=dt,\n                initial_frames=stim[:, 0].unsqueeze(1),\n                state=initial_state,\n            )\n\n            def handle_stim(stim, fade_in_state):\n                # reset stimulus\n                batch_size, n_frames, _ = stim.shape\n                stimulus.zero(batch_size, n_frames)\n\n                # add stimulus\n                stimulus.add_input(stim.unsqueeze(2))\n\n                # compute response\n                states = self(stimulus(), dt, state=fade_in_state, as_states=True)\n                return (\n                    stim.cpu().numpy().squeeze(),\n                    torch.stack(\n                        [s.nodes.activity.cpu() for s in states],\n                        dim=1,\n                    )\n                    .numpy()\n                    .squeeze(),\n                    torch.stack(\n                        [self.dynamics.currents(s, params).cpu() for s in states],\n                        dim=1,\n                    )\n                    .numpy()\n                    .squeeze(),\n                )\n\n            # stim, activity, currents\n            yield handle_stim(stim, fade_in_state)\n</code></pre>"},{"location":"reference/network/#stimulus","title":"Stimulus","text":"<p>Stimuli must implement the <code>StimulusProtocol</code> to be compatible with <code>flyvis.network.network.Network</code>.</p>"},{"location":"reference/network/#flyvis.network.stimulus.StimulusProtocol","title":"flyvis.network.stimulus.StimulusProtocol","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for the Stimulus class.</p> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>@runtime_checkable\nclass StimulusProtocol(Protocol):\n    \"\"\"Protocol for the Stimulus class.\"\"\"\n\n    def __call__(self) -&gt; Tensor: ...\n    def add_input(self, x: Tensor, **kwargs) -&gt; None: ...\n    def add_pre_stim(self, x: Tensor, **kwargs) -&gt; None: ...\n    def zero(self, **kwargs) -&gt; None: ...\n    def nonzero(self) -&gt; bool: ...\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.Stimulus","title":"flyvis.network.stimulus.Stimulus","text":"<p>Interface to control the cell-specific stimulus buffer for the network.</p> <p>Creates a buffer and maps standard video input to the photoreceptors but can map input to any other cell as well, e.g. to do perturbation experiments.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory to retrieve indexes for the stimulus buffer at the respective cell positions.</p> required <code>n_samples</code> <code>int</code> <p>Number of samples to initialize the buffer with.</p> <code>1</code> <code>n_frames</code> <code>int</code> <p>Number of frames to initialize the buffer with.</p> <code>1</code> <code>init_buffer</code> <code>bool</code> <p>If False, do not initialize the stimulus buffer.</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>layer_index</code> <code>Dict[str, NDArray]</code> <p>Dictionary of cell type to index array.</p> <code>central_cells_index</code> <code>Dict[str, int]</code> <p>Dictionary of cell type to central cell index.</p> <code>input_index</code> <code>NDArray</code> <p>Index array of photoreceptors.</p> <code>n_frames</code> <code>int</code> <p>Number of frames in the stimulus buffer.</p> <code>n_samples</code> <code>int</code> <p>Number of samples in the stimulus buffer.</p> <code>n_nodes</code> <code>int</code> <p>Number of nodes in the stimulus buffer.</p> <code>n_input_elements</code> <code>int</code> <p>Number of input elements.</p> <code>buffer</code> <code>Tensor</code> <p>Stimulus buffer of shape (n_samples, n_frames, n_cells).</p> <p>Returns:</p> Name Type Description <code>Tensor</code> <p>Stimulus of shape (n_samples, n_frames, n_cells)</p> Example <pre><code>stim = Stimulus(network.connectome, *x.shape[:2])\nstim.add_input(x)\nresponse = network(stim(), dt)\n</code></pre> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>@register_stimulus\nclass Stimulus:\n    \"\"\"Interface to control the cell-specific stimulus buffer for the network.\n\n    Creates a buffer and maps standard video input to the photoreceptors\n    but can map input to any other cell as well, e.g. to do perturbation\n    experiments.\n\n    Args:\n        connectome: Connectome directory to retrieve indexes for the stimulus\n            buffer at the respective cell positions.\n        n_samples: Number of samples to initialize the buffer with.\n        n_frames: Number of frames to initialize the buffer with.\n        init_buffer: If False, do not initialize the stimulus buffer.\n\n    Attributes:\n        layer_index (Dict[str, NDArray]): Dictionary of cell type to index array.\n        central_cells_index (Dict[str, int]): Dictionary of cell type to\n            central cell index.\n        input_index (NDArray): Index array of photoreceptors.\n        n_frames (int): Number of frames in the stimulus buffer.\n        n_samples (int): Number of samples in the stimulus buffer.\n        n_nodes (int): Number of nodes in the stimulus buffer.\n        n_input_elements (int): Number of input elements.\n        buffer (Tensor): Stimulus buffer of shape (n_samples, n_frames, n_cells).\n\n    Returns:\n        Tensor: Stimulus of shape (n_samples, n_frames, n_cells)\n\n    Example:\n        ```python\n        stim = Stimulus(network.connectome, *x.shape[:2])\n        stim.add_input(x)\n        response = network(stim(), dt)\n        ```\n    \"\"\"\n\n    layer_index: Dict[str, NDArray]\n    central_cells_index: Dict[str, int]\n    input_index: NDArray\n    n_frames: int\n    n_samples: int\n    n_nodes: int\n    n_input_elements: int\n    buffer: Tensor\n\n    def __init__(\n        self,\n        connectome: ConnectomeFromAvgFilters,\n        n_samples: int = 1,\n        n_frames: int = 1,\n        init_buffer: bool = True,\n    ):\n        self.layer_index = {\n            cell_type: index[:]\n            for cell_type, index in connectome.nodes.layer_index.items()\n        }\n        self.central_cells_index = dict(\n            zip(\n                connectome.unique_cell_types[:].astype(str),\n                connectome.central_cells_index[:],\n            )\n        )\n        self.input_index = np.array([\n            self.layer_index[cell_type.decode()]\n            for cell_type in connectome.input_cell_types[:]\n        ])\n        self.n_input_elements = self.input_index.shape[1]\n        self.n_samples, self.n_frames, self.n_nodes = (\n            n_samples,\n            n_frames,\n            len(connectome.nodes.type),\n        )\n        self.connectome = connectome\n        if init_buffer:\n            self.zero()\n\n    def zero(\n        self,\n        n_samples: Optional[int] = None,\n        n_frames: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Reset the stimulus buffer to zero.\n\n        Args:\n            n_samples: Number of samples. If provided, the buffer will be resized.\n            n_frames: Number of frames. If provided, the buffer will be resized.\n        \"\"\"\n        self.n_samples = n_samples or self.n_samples\n        self.n_frames = n_frames or self.n_frames\n        if hasattr(self, \"buffer\") and self.buffer.shape[:2] == (\n            self.n_samples,\n            self.n_frames,\n        ):\n            self.buffer.zero_()\n            return\n        self.buffer = torch.zeros((self.n_samples, self.n_frames, self.n_nodes))\n        self._nonzero = False\n\n    @property\n    def nonzero(self) -&gt; bool:\n        \"\"\"Check if elements have been added to the stimulus buffer.\n\n        Returns:\n            bool: True if elements have been added, even if those elements were all zero.\n        \"\"\"\n        return self._nonzero\n\n    def add_input(\n        self,\n        x: torch.Tensor,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        n_frames_buffer: Optional[int] = None,\n        cumulate: bool = False,\n    ) -&gt; None:\n        \"\"\"Add input to the input/photoreceptor cells.\n\n        Args:\n            x: Input video of shape (n_samples, n_frames, 1, n_input_elements).\n            start: Temporal start index of the stimulus.\n            stop: Temporal stop index of the stimulus.\n            n_frames_buffer: Number of frames to resize the buffer to.\n            cumulate: If True, add input to the existing buffer.\n\n        Raises:\n            ValueError: If input shape is incorrect.\n            RuntimeError: If input shape doesn't match buffer shape.\n        \"\"\"\n        shape = x.shape\n        if len(shape) != 4:\n            raise ValueError(\n                f\"input has shape {x.shape} but must have \"\n                \"(n_samples, n_frames, 1, n_input_elements)\"\n            )\n        n_samples, n_frames_input = shape[:2]\n\n        if not hasattr(self, \"buffer\") or not cumulate and self.nonzero:\n            self.zero(n_samples, n_frames_buffer or n_frames_input)\n\n        try:\n            self.buffer[:, slice(start, stop), self.input_index] += x.to(\n                self.buffer.device\n            )\n        except RuntimeError as e:\n            raise RuntimeError(\n                f\"input has shape {x.shape} but buffer has shape {self.buffer.shape}\"\n            ) from e\n        self._nonzero = True\n\n    def add_pre_stim(\n        self,\n        x: torch.Tensor,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        n_frames_buffer: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Add a constant or sequence of constants to the input/photoreceptor cells.\n\n        Args:\n            x: Grey value(s). If Tensor, must have length `n_frames` or `stop - start`.\n            start: Start index in time.\n            stop: Stop index in time.\n            n_frames_buffer: Number of frames to resize the buffer to.\n\n        Raises:\n            RuntimeError: If input shape doesn't match buffer shape.\n        \"\"\"\n        if not hasattr(self, \"buffer\") or self.nonzero:\n            self.zero(None, n_frames_buffer)\n\n        try:\n            if isinstance(x, torch.Tensor) and x.ndim == 1:\n                self.buffer[:, slice(start, stop), self.input_index] += x.view(\n                    1, len(x), 1, 1\n                )\n            else:\n                self.buffer[:, slice(start, stop), self.input_index] += x\n        except RuntimeError as e:\n            raise RuntimeError(\n                f\"input has shape {x.shape} but buffer has shape {self.buffer.shape}\"\n            ) from e\n        self._nonzero = True\n\n    def __call__(self) -&gt; torch.Tensor:\n        \"\"\"Return the stimulus tensor.\n\n        Returns:\n            torch.Tensor: The stimulus buffer.\n        \"\"\"\n        return self.buffer\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.Stimulus.nonzero","title":"nonzero  <code>property</code>","text":"<pre><code>nonzero\n</code></pre> <p>Check if elements have been added to the stimulus buffer.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if elements have been added, even if those elements were all zero.</p>"},{"location":"reference/network/#flyvis.network.stimulus.Stimulus.zero","title":"zero","text":"<pre><code>zero(n_samples=None, n_frames=None)\n</code></pre> <p>Reset the stimulus buffer to zero.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>Optional[int]</code> <p>Number of samples. If provided, the buffer will be resized.</p> <code>None</code> <code>n_frames</code> <code>Optional[int]</code> <p>Number of frames. If provided, the buffer will be resized.</p> <code>None</code> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>def zero(\n    self,\n    n_samples: Optional[int] = None,\n    n_frames: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Reset the stimulus buffer to zero.\n\n    Args:\n        n_samples: Number of samples. If provided, the buffer will be resized.\n        n_frames: Number of frames. If provided, the buffer will be resized.\n    \"\"\"\n    self.n_samples = n_samples or self.n_samples\n    self.n_frames = n_frames or self.n_frames\n    if hasattr(self, \"buffer\") and self.buffer.shape[:2] == (\n        self.n_samples,\n        self.n_frames,\n    ):\n        self.buffer.zero_()\n        return\n    self.buffer = torch.zeros((self.n_samples, self.n_frames, self.n_nodes))\n    self._nonzero = False\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.Stimulus.add_input","title":"add_input","text":"<pre><code>add_input(x, start=None, stop=None, n_frames_buffer=None, cumulate=False)\n</code></pre> <p>Add input to the input/photoreceptor cells.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input video of shape (n_samples, n_frames, 1, n_input_elements).</p> required <code>start</code> <code>Optional[int]</code> <p>Temporal start index of the stimulus.</p> <code>None</code> <code>stop</code> <code>Optional[int]</code> <p>Temporal stop index of the stimulus.</p> <code>None</code> <code>n_frames_buffer</code> <code>Optional[int]</code> <p>Number of frames to resize the buffer to.</p> <code>None</code> <code>cumulate</code> <code>bool</code> <p>If True, add input to the existing buffer.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input shape is incorrect.</p> <code>RuntimeError</code> <p>If input shape doesn\u2019t match buffer shape.</p> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>def add_input(\n    self,\n    x: torch.Tensor,\n    start: Optional[int] = None,\n    stop: Optional[int] = None,\n    n_frames_buffer: Optional[int] = None,\n    cumulate: bool = False,\n) -&gt; None:\n    \"\"\"Add input to the input/photoreceptor cells.\n\n    Args:\n        x: Input video of shape (n_samples, n_frames, 1, n_input_elements).\n        start: Temporal start index of the stimulus.\n        stop: Temporal stop index of the stimulus.\n        n_frames_buffer: Number of frames to resize the buffer to.\n        cumulate: If True, add input to the existing buffer.\n\n    Raises:\n        ValueError: If input shape is incorrect.\n        RuntimeError: If input shape doesn't match buffer shape.\n    \"\"\"\n    shape = x.shape\n    if len(shape) != 4:\n        raise ValueError(\n            f\"input has shape {x.shape} but must have \"\n            \"(n_samples, n_frames, 1, n_input_elements)\"\n        )\n    n_samples, n_frames_input = shape[:2]\n\n    if not hasattr(self, \"buffer\") or not cumulate and self.nonzero:\n        self.zero(n_samples, n_frames_buffer or n_frames_input)\n\n    try:\n        self.buffer[:, slice(start, stop), self.input_index] += x.to(\n            self.buffer.device\n        )\n    except RuntimeError as e:\n        raise RuntimeError(\n            f\"input has shape {x.shape} but buffer has shape {self.buffer.shape}\"\n        ) from e\n    self._nonzero = True\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.Stimulus.add_pre_stim","title":"add_pre_stim","text":"<pre><code>add_pre_stim(x, start=None, stop=None, n_frames_buffer=None)\n</code></pre> <p>Add a constant or sequence of constants to the input/photoreceptor cells.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Grey value(s). If Tensor, must have length <code>n_frames</code> or <code>stop - start</code>.</p> required <code>start</code> <code>Optional[int]</code> <p>Start index in time.</p> <code>None</code> <code>stop</code> <code>Optional[int]</code> <p>Stop index in time.</p> <code>None</code> <code>n_frames_buffer</code> <code>Optional[int]</code> <p>Number of frames to resize the buffer to.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If input shape doesn\u2019t match buffer shape.</p> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>def add_pre_stim(\n    self,\n    x: torch.Tensor,\n    start: Optional[int] = None,\n    stop: Optional[int] = None,\n    n_frames_buffer: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Add a constant or sequence of constants to the input/photoreceptor cells.\n\n    Args:\n        x: Grey value(s). If Tensor, must have length `n_frames` or `stop - start`.\n        start: Start index in time.\n        stop: Stop index in time.\n        n_frames_buffer: Number of frames to resize the buffer to.\n\n    Raises:\n        RuntimeError: If input shape doesn't match buffer shape.\n    \"\"\"\n    if not hasattr(self, \"buffer\") or self.nonzero:\n        self.zero(None, n_frames_buffer)\n\n    try:\n        if isinstance(x, torch.Tensor) and x.ndim == 1:\n            self.buffer[:, slice(start, stop), self.input_index] += x.view(\n                1, len(x), 1, 1\n            )\n        else:\n            self.buffer[:, slice(start, stop), self.input_index] += x\n    except RuntimeError as e:\n        raise RuntimeError(\n            f\"input has shape {x.shape} but buffer has shape {self.buffer.shape}\"\n        ) from e\n    self._nonzero = True\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.Stimulus.__call__","title":"__call__","text":"<pre><code>__call__()\n</code></pre> <p>Return the stimulus tensor.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The stimulus buffer.</p> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>def __call__(self) -&gt; torch.Tensor:\n    \"\"\"Return the stimulus tensor.\n\n    Returns:\n        torch.Tensor: The stimulus buffer.\n    \"\"\"\n    return self.buffer\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.register_stimulus","title":"flyvis.network.stimulus.register_stimulus","text":"<pre><code>register_stimulus(cls=None)\n</code></pre> <p>Register a stimulus class.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Optional[Type[StimulusProtocol]]</code> <p>The stimulus class to register (optional when used as a decorator).</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Callable[[Type[StimulusProtocol]], Type[StimulusProtocol]], Type[StimulusProtocol]]</code> <p>Registered class or decorator function.</p> Example <p>As a standalone function: <pre><code>register_stimulus(CustomStimulus)\n</code></pre></p> <p>As a decorator: <pre><code>@register_stimulus\nclass CustomStimulus(StimulusProtocol): ...\n</code></pre></p> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>def register_stimulus(\n    cls: Optional[Type[StimulusProtocol]] = None,\n) -&gt; Union[\n    Callable[[Type[StimulusProtocol]], Type[StimulusProtocol]], Type[StimulusProtocol]\n]:\n    \"\"\"Register a stimulus class.\n\n    Args:\n        cls: The stimulus class to register (optional when used as a decorator).\n\n    Returns:\n        Registered class or decorator function.\n\n    Example:\n        As a standalone function:\n        ```python\n        register_stimulus(CustomStimulus)\n        ```\n\n        As a decorator:\n        ```python\n        @register_stimulus\n        class CustomStimulus(StimulusProtocol): ...\n        ```\n    \"\"\"\n\n    def decorator(cls: Type[StimulusProtocol]) -&gt; Type[StimulusProtocol]:\n        AVAILABLE_STIMULI[cls.__name__] = cls\n        return cls\n\n    if cls is None:\n        return decorator\n    else:\n        return decorator(cls)\n</code></pre>"},{"location":"reference/network/#flyvis.network.stimulus.init_stimulus","title":"flyvis.network.stimulus.init_stimulus","text":"<pre><code>init_stimulus(connectome, **kwargs)\n</code></pre> Source code in <code>flyvis/network/stimulus.py</code> <pre><code>def init_stimulus(connectome: ConnectomeFromAvgFilters, **kwargs) -&gt; StimulusProtocol:\n    if \"type\" not in kwargs:\n        return None\n    stimulus_class = AVAILABLE_STIMULI[kwargs.pop(\"type\")]\n    return stimulus_class(connectome, **kwargs)\n</code></pre>"},{"location":"reference/network/#dynamics","title":"Dynamics","text":""},{"location":"reference/network/#flyvis.network.dynamics.NetworkDynamics","title":"flyvis.network.dynamics.NetworkDynamics","text":"<p>Defines the initialization and behavior of a Network during simulation.</p> <p>This class serves as an extension point for implementing custom network dynamics models. Subclasses must implement the following methods:</p> <ul> <li>write_derived_params</li> <li>write_initial_state</li> <li>write_state_velocity</li> </ul> <p>Attributes:</p> Name Type Description <code>activation</code> <code>Module</code> <p>The activation function for the network.</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>dict</code> <p>A dictionary specifying the activation function type and its parameters.</p> <code>{'type': 'relu'}</code> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>class NetworkDynamics:\n    \"\"\"\n    Defines the initialization and behavior of a Network during simulation.\n\n    This class serves as an extension point for implementing custom network dynamics\n    models. Subclasses must implement the following methods:\n\n    - write_derived_params\n    - write_initial_state\n    - write_state_velocity\n\n    Attributes:\n        activation (nn.Module): The activation function for the network.\n\n    Args:\n        activation (dict): A dictionary specifying the activation function type and\n            its parameters.\n    \"\"\"\n\n    def __init__(self, activation: Dict[str, str] = {\"type\": \"relu\"}):\n        self.activation = activation_fns[activation.pop(\"type\")](**activation)\n\n    def write_derived_params(\n        self, params: AutoDeref[str, AutoDeref[str, RefTensor]], **kwargs\n    ) -&gt; None:\n        \"\"\"\n        Augment `params`, called once at every forward pass.\n\n        Args:\n            params: A directory containing two subdirectories: `nodes` and\n                `edges`, containing node and edges parameters, respectively.\n            **kwargs: Additional keyword arguments.\n\n        Note:\n            This is called once per forward pass at the beginning. It's required\n            after parameters have been updated by an optimizer but not at every\n            timestep. Called by Network._param_api.\n        \"\"\"\n        pass\n\n    def write_initial_state(\n        self,\n        state: AutoDeref[str, AutoDeref[str, RefTensor]],\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a network's state variables from its network parameters.\n\n        Args:\n            state: A directory containing two subdirectories: `nodes` and\n                `edges`. Write initial node and edge state variable values, as\n                1D tensors, into them, respectively.\n            params: A directory containing four subdirectories: `nodes`,\n                `edges`, `sources`, and `targets`. `nodes` and `edges` contain\n                node and edges parameters, respectively. `sources` and\n                `targets` provide access to the node parameters associated with\n                the source node and target node of each edge, respectively.\n            **kwargs: Additional keyword arguments.\n\n        Note:\n            Called by Network._initial_state.\n        \"\"\"\n        pass\n\n    def write_state_velocity(\n        self,\n        vel: AutoDeref[str, AutoDeref[str, RefTensor]],\n        state: AutoDeref[str, AutoDeref[str, RefTensor]],\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n        target_sum: Callable,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Compute dx/dt for each state variable.\n\n        Args:\n            vel: A directory containing two subdirectories: `nodes` and\n                `edges`. Write dx/dt for node and edge state variables\n                into them, respectively.\n            state: A directory containing two subdirectories: `nodes` and\n                `edges`, containing node and edge state variable values,\n                respectively.\n            params: A directory containing four subdirectories: `nodes`,\n                `edges`, `sources`, and `targets`. `nodes` and `edges` contain\n                node and edges parameters, respectively. `sources` and\n                `targets` provide access to the node parameters associated with\n                the source node and target node of each edge, respectively.\n            target_sum: Sums the entries in a `len(edges)` tensor corresponding\n                to edges with the same target node, yielding a `len(nodes)`\n                tensor.\n            **kwargs: Additional keyword arguments.\n\n        Note:\n            Called by Network._next_state.\n        \"\"\"\n        pass\n\n    def currents(\n        self,\n        state: AutoDeref[str, AutoDeref[str, RefTensor]],\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the current flowing through each edge.\n\n        Args:\n            state: A directory containing two subdirectories: `nodes` and\n                `edges`, containing node and edge state variable values,\n                respectively.\n            params: A directory containing four subdirectories: `nodes`,\n                `edges`, `sources`, and `targets`. `nodes` and `edges` contain\n                node and edges parameters, respectively. `sources` and\n                `targets` provide access to the node parameters associated with\n                the source node and target node of each edge, respectively.\n\n        Returns:\n            A tensor of currents flowing through each edge.\n\n        Note:\n            Called by Network.current_response.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.NetworkDynamics.write_derived_params","title":"write_derived_params","text":"<pre><code>write_derived_params(params, **kwargs)\n</code></pre> <p>Augment <code>params</code>, called once at every forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing two subdirectories: <code>nodes</code> and <code>edges</code>, containing node and edges parameters, respectively.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Note <p>This is called once per forward pass at the beginning. It\u2019s required after parameters have been updated by an optimizer but not at every timestep. Called by Network._param_api.</p> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def write_derived_params(\n    self, params: AutoDeref[str, AutoDeref[str, RefTensor]], **kwargs\n) -&gt; None:\n    \"\"\"\n    Augment `params`, called once at every forward pass.\n\n    Args:\n        params: A directory containing two subdirectories: `nodes` and\n            `edges`, containing node and edges parameters, respectively.\n        **kwargs: Additional keyword arguments.\n\n    Note:\n        This is called once per forward pass at the beginning. It's required\n        after parameters have been updated by an optimizer but not at every\n        timestep. Called by Network._param_api.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.NetworkDynamics.write_initial_state","title":"write_initial_state","text":"<pre><code>write_initial_state(state, params, **kwargs)\n</code></pre> <p>Initialize a network\u2019s state variables from its network parameters.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing two subdirectories: <code>nodes</code> and <code>edges</code>. Write initial node and edge state variable values, as 1D tensors, into them, respectively.</p> required <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing four subdirectories: <code>nodes</code>, <code>edges</code>, <code>sources</code>, and <code>targets</code>. <code>nodes</code> and <code>edges</code> contain node and edges parameters, respectively. <code>sources</code> and <code>targets</code> provide access to the node parameters associated with the source node and target node of each edge, respectively.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Note <p>Called by Network._initial_state.</p> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def write_initial_state(\n    self,\n    state: AutoDeref[str, AutoDeref[str, RefTensor]],\n    params: AutoDeref[str, AutoDeref[str, RefTensor]],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Initialize a network's state variables from its network parameters.\n\n    Args:\n        state: A directory containing two subdirectories: `nodes` and\n            `edges`. Write initial node and edge state variable values, as\n            1D tensors, into them, respectively.\n        params: A directory containing four subdirectories: `nodes`,\n            `edges`, `sources`, and `targets`. `nodes` and `edges` contain\n            node and edges parameters, respectively. `sources` and\n            `targets` provide access to the node parameters associated with\n            the source node and target node of each edge, respectively.\n        **kwargs: Additional keyword arguments.\n\n    Note:\n        Called by Network._initial_state.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.NetworkDynamics.write_state_velocity","title":"write_state_velocity","text":"<pre><code>write_state_velocity(vel, state, params, target_sum, **kwargs)\n</code></pre> <p>Compute dx/dt for each state variable.</p> <p>Parameters:</p> Name Type Description Default <code>vel</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing two subdirectories: <code>nodes</code> and <code>edges</code>. Write dx/dt for node and edge state variables into them, respectively.</p> required <code>state</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing two subdirectories: <code>nodes</code> and <code>edges</code>, containing node and edge state variable values, respectively.</p> required <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing four subdirectories: <code>nodes</code>, <code>edges</code>, <code>sources</code>, and <code>targets</code>. <code>nodes</code> and <code>edges</code> contain node and edges parameters, respectively. <code>sources</code> and <code>targets</code> provide access to the node parameters associated with the source node and target node of each edge, respectively.</p> required <code>target_sum</code> <code>Callable</code> <p>Sums the entries in a <code>len(edges)</code> tensor corresponding to edges with the same target node, yielding a <code>len(nodes)</code> tensor.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Note <p>Called by Network._next_state.</p> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def write_state_velocity(\n    self,\n    vel: AutoDeref[str, AutoDeref[str, RefTensor]],\n    state: AutoDeref[str, AutoDeref[str, RefTensor]],\n    params: AutoDeref[str, AutoDeref[str, RefTensor]],\n    target_sum: Callable,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Compute dx/dt for each state variable.\n\n    Args:\n        vel: A directory containing two subdirectories: `nodes` and\n            `edges`. Write dx/dt for node and edge state variables\n            into them, respectively.\n        state: A directory containing two subdirectories: `nodes` and\n            `edges`, containing node and edge state variable values,\n            respectively.\n        params: A directory containing four subdirectories: `nodes`,\n            `edges`, `sources`, and `targets`. `nodes` and `edges` contain\n            node and edges parameters, respectively. `sources` and\n            `targets` provide access to the node parameters associated with\n            the source node and target node of each edge, respectively.\n        target_sum: Sums the entries in a `len(edges)` tensor corresponding\n            to edges with the same target node, yielding a `len(nodes)`\n            tensor.\n        **kwargs: Additional keyword arguments.\n\n    Note:\n        Called by Network._next_state.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.NetworkDynamics.currents","title":"currents","text":"<pre><code>currents(state, params)\n</code></pre> <p>Compute the current flowing through each edge.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing two subdirectories: <code>nodes</code> and <code>edges</code>, containing node and edge state variable values, respectively.</p> required <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing four subdirectories: <code>nodes</code>, <code>edges</code>, <code>sources</code>, and <code>targets</code>. <code>nodes</code> and <code>edges</code> contain node and edges parameters, respectively. <code>sources</code> and <code>targets</code> provide access to the node parameters associated with the source node and target node of each edge, respectively.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of currents flowing through each edge.</p> Note <p>Called by Network.current_response.</p> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def currents(\n    self,\n    state: AutoDeref[str, AutoDeref[str, RefTensor]],\n    params: AutoDeref[str, AutoDeref[str, RefTensor]],\n) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the current flowing through each edge.\n\n    Args:\n        state: A directory containing two subdirectories: `nodes` and\n            `edges`, containing node and edge state variable values,\n            respectively.\n        params: A directory containing four subdirectories: `nodes`,\n            `edges`, `sources`, and `targets`. `nodes` and `edges` contain\n            node and edges parameters, respectively. `sources` and\n            `targets` provide access to the node parameters associated with\n            the source node and target node of each edge, respectively.\n\n    Returns:\n        A tensor of currents flowing through each edge.\n\n    Note:\n        Called by Network.current_response.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.PPNeuronIGRSynapses","title":"flyvis.network.dynamics.PPNeuronIGRSynapses","text":"<p>               Bases: <code>NetworkDynamics</code></p> <p>Passive point neurons with instantaneous graded release synapses.</p> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>class PPNeuronIGRSynapses(NetworkDynamics):\n    \"\"\"Passive point neurons with instantaneous graded release synapses.\"\"\"\n\n    def write_derived_params(\n        self, params: AutoDeref[str, AutoDeref[str, RefTensor]], **kwargs\n    ) -&gt; None:\n        \"\"\"\n        Calculate weights as the product of sign, synapse count, and strength.\n\n        Args:\n            params: A directory containing edge parameters.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        params.edges.weight = (\n            params.edges.sign * params.edges.syn_count * params.edges.syn_strength\n        )\n\n    def write_initial_state(\n        self,\n        state: AutoDeref[str, AutoDeref[str, RefTensor]],\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Set the initial state to the bias.\n\n        Args:\n            state: A directory to write the initial state.\n            params: A directory containing node parameters.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        state.nodes.activity = params.nodes.bias\n\n    def write_state_velocity(\n        self,\n        vel: AutoDeref[str, AutoDeref[str, RefTensor]],\n        state: AutoDeref[str, AutoDeref[str, RefTensor]],\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n        target_sum: Callable,\n        x_t: torch.Tensor,\n        dt: float,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Calculate velocity as bias plus sum of weighted rectified inputs.\n\n        Args:\n            vel: A directory to write the calculated velocity.\n            state: A directory containing current state values.\n            params: A directory containing node and edge parameters.\n            target_sum: Function to sum edge values for each target node.\n            x_t: External input at time t.\n            dt: Time step.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        vel.nodes.activity = (\n            1\n            / torch.max(params.nodes.time_const, torch.tensor(dt).float())\n            * (\n                -state.nodes.activity\n                + params.nodes.bias\n                + target_sum(\n                    params.edges.weight * self.activation(state.sources.activity)\n                )  # internal chemical current\n                + x_t\n            )\n        )\n\n    def currents(\n        self,\n        state: AutoDeref[str, AutoDeref[str, RefTensor]],\n        params: AutoDeref[str, AutoDeref[str, RefTensor]],\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Calculate the internal chemical current.\n\n        Args:\n            state: A directory containing current state values.\n            params: A directory containing edge parameters.\n\n        Returns:\n            torch.Tensor: The calculated internal chemical current.\n        \"\"\"\n        return params.edges.weight * self.activation(state.sources.activity)\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.PPNeuronIGRSynapses.write_derived_params","title":"write_derived_params","text":"<pre><code>write_derived_params(params, **kwargs)\n</code></pre> <p>Calculate weights as the product of sign, synapse count, and strength.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing edge parameters.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def write_derived_params(\n    self, params: AutoDeref[str, AutoDeref[str, RefTensor]], **kwargs\n) -&gt; None:\n    \"\"\"\n    Calculate weights as the product of sign, synapse count, and strength.\n\n    Args:\n        params: A directory containing edge parameters.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    params.edges.weight = (\n        params.edges.sign * params.edges.syn_count * params.edges.syn_strength\n    )\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.PPNeuronIGRSynapses.write_initial_state","title":"write_initial_state","text":"<pre><code>write_initial_state(state, params, **kwargs)\n</code></pre> <p>Set the initial state to the bias.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory to write the initial state.</p> required <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing node parameters.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def write_initial_state(\n    self,\n    state: AutoDeref[str, AutoDeref[str, RefTensor]],\n    params: AutoDeref[str, AutoDeref[str, RefTensor]],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Set the initial state to the bias.\n\n    Args:\n        state: A directory to write the initial state.\n        params: A directory containing node parameters.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    state.nodes.activity = params.nodes.bias\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.PPNeuronIGRSynapses.write_state_velocity","title":"write_state_velocity","text":"<pre><code>write_state_velocity(vel, state, params, target_sum, x_t, dt, **kwargs)\n</code></pre> <p>Calculate velocity as bias plus sum of weighted rectified inputs.</p> <p>Parameters:</p> Name Type Description Default <code>vel</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory to write the calculated velocity.</p> required <code>state</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing current state values.</p> required <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing node and edge parameters.</p> required <code>target_sum</code> <code>Callable</code> <p>Function to sum edge values for each target node.</p> required <code>x_t</code> <code>Tensor</code> <p>External input at time t.</p> required <code>dt</code> <code>float</code> <p>Time step.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def write_state_velocity(\n    self,\n    vel: AutoDeref[str, AutoDeref[str, RefTensor]],\n    state: AutoDeref[str, AutoDeref[str, RefTensor]],\n    params: AutoDeref[str, AutoDeref[str, RefTensor]],\n    target_sum: Callable,\n    x_t: torch.Tensor,\n    dt: float,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Calculate velocity as bias plus sum of weighted rectified inputs.\n\n    Args:\n        vel: A directory to write the calculated velocity.\n        state: A directory containing current state values.\n        params: A directory containing node and edge parameters.\n        target_sum: Function to sum edge values for each target node.\n        x_t: External input at time t.\n        dt: Time step.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    vel.nodes.activity = (\n        1\n        / torch.max(params.nodes.time_const, torch.tensor(dt).float())\n        * (\n            -state.nodes.activity\n            + params.nodes.bias\n            + target_sum(\n                params.edges.weight * self.activation(state.sources.activity)\n            )  # internal chemical current\n            + x_t\n        )\n    )\n</code></pre>"},{"location":"reference/network/#flyvis.network.dynamics.PPNeuronIGRSynapses.currents","title":"currents","text":"<pre><code>currents(state, params)\n</code></pre> <p>Calculate the internal chemical current.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing current state values.</p> required <code>params</code> <code>AutoDeref[str, AutoDeref[str, RefTensor]]</code> <p>A directory containing edge parameters.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The calculated internal chemical current.</p> Source code in <code>flyvis/network/dynamics.py</code> <pre><code>def currents(\n    self,\n    state: AutoDeref[str, AutoDeref[str, RefTensor]],\n    params: AutoDeref[str, AutoDeref[str, RefTensor]],\n) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate the internal chemical current.\n\n    Args:\n        state: A directory containing current state values.\n        params: A directory containing edge parameters.\n\n    Returns:\n        torch.Tensor: The calculated internal chemical current.\n    \"\"\"\n    return params.edges.weight * self.activation(state.sources.activity)\n</code></pre>"},{"location":"reference/network/#initialization","title":"Initialization","text":""},{"location":"reference/network/#flyvis.network.initialization","title":"flyvis.network.initialization","text":"<p>The parameters that the networks can be initialized with. Each parameter is a type on its own, because different parameters are shared differently. These types handle the initialization of indices to perform gather and scatter opera- tions. Parameter types can be initialized from a range of initial distribution types.</p>"},{"location":"reference/network/#flyvis.network.initialization.InitialDistribution","title":"InitialDistribution","text":"<p>Initial distribution base class.</p> <p>Attributes:</p> Name Type Description <code>raw_values</code> <code>Tensor</code> <p>Initial parameters must store raw_values as attribute in their init.</p> <code>readers</code> <code>Dict[str, Tensor]</code> <p>Readers will be written by the network during initialization.</p> Note <p>To add a new initial distribution type, subclass this class and implement the init method. The init method should take the param_config as its first argument, and should store the attribute raw_values as a torch.nn.Parameter.</p> Example <p>An example of a viable param_config is: <pre><code>param_config = Namespace(\n    requires_grad=True,\n    initial_dist=\"Normal\",\n    mean=0,\n    std=1,\n    mode=\"sample\",\n)\n</code></pre></p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class InitialDistribution:\n    \"\"\"Initial distribution base class.\n\n    Attributes:\n        raw_values (Tensor): Initial parameters must store raw_values as attribute in\n            their __init__.\n        readers (Dict[str, Tensor]): Readers will be written by the network during\n            initialization.\n\n    Note:\n        To add a new initial distribution type, subclass this class and implement the\n        __init__ method. The __init__ method should take the param_config as its first\n        argument, and should store the attribute raw_values as a torch.nn.Parameter.\n\n    Example:\n        An example of a viable param_config is:\n        ```python\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Normal\",\n            mean=0,\n            std=1,\n            mode=\"sample\",\n        )\n        ```\n    \"\"\"\n\n    raw_values: Tensor\n    readers: Dict[str, Tensor]\n\n    @property\n    def semantic_values(self):\n        \"\"\"Optional reparametrization of raw values invoked for computation.\"\"\"\n        return self.raw_values\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__} (semantic values): \\n{self.semantic_values}\"\n\n    def __len__(self):\n        return len(self.raw_values)\n\n    def clamp(self, values, mode):\n        \"\"\"To clamp the raw_values of the parameters at initialization.\n\n        Note, mild clash with raw_values/semantic_values reparametrization.\n        Parameters that use reparametrization in terms of semantic_values\n        should not use clamp.\n        \"\"\"\n        if mode == \"non_negative\":\n            values.clamp_(min=0)\n        elif isinstance(mode, Iterable) and len(mode) == 2:\n            values.clamp_(*mode)\n        elif mode in [False, None]:\n            return values\n        else:\n            raise ParameterConfigError(f\"{mode} not a valid argument for clamp\")\n        return values\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.InitialDistribution.semantic_values","title":"semantic_values  <code>property</code>","text":"<pre><code>semantic_values\n</code></pre> <p>Optional reparametrization of raw values invoked for computation.</p>"},{"location":"reference/network/#flyvis.network.initialization.InitialDistribution.clamp","title":"clamp","text":"<pre><code>clamp(values, mode)\n</code></pre> <p>To clamp the raw_values of the parameters at initialization.</p> <p>Note, mild clash with raw_values/semantic_values reparametrization. Parameters that use reparametrization in terms of semantic_values should not use clamp.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def clamp(self, values, mode):\n    \"\"\"To clamp the raw_values of the parameters at initialization.\n\n    Note, mild clash with raw_values/semantic_values reparametrization.\n    Parameters that use reparametrization in terms of semantic_values\n    should not use clamp.\n    \"\"\"\n    if mode == \"non_negative\":\n        values.clamp_(min=0)\n    elif isinstance(mode, Iterable) and len(mode) == 2:\n        values.clamp_(*mode)\n    elif mode in [False, None]:\n        return values\n    else:\n        raise ParameterConfigError(f\"{mode} not a valid argument for clamp\")\n    return values\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Value","title":"Value","text":"<p>               Bases: <code>InitialDistribution</code></p> <p>Initializes parameters with a single value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>The value to initialize the parameter with.</p> required <code>requires_grad</code> <code>bool</code> <p>Whether the parameter requires gradients.</p> required <code>clamp</code> <code>bool</code> <p>Whether to clamp the values. Defaults to False.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Example <pre><code>param_config = Namespace(\n    requires_grad=True,\n    initial_dist=\"Value\",\n    value=0,\n)\n</code></pre> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class Value(InitialDistribution):\n    \"\"\"Initializes parameters with a single value.\n\n    Args:\n        value: The value to initialize the parameter with.\n        requires_grad (bool): Whether the parameter requires gradients.\n        clamp (bool, optional): Whether to clamp the values. Defaults to False.\n        **kwargs: Additional keyword arguments.\n\n    Example:\n        ```python\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Value\",\n            value=0,\n        )\n        ```\n    \"\"\"\n\n    def __init__(self, value, requires_grad, clamp=False, **kwargs) -&gt; None:\n        _values = torch.tensor(value).float()\n        _values = self.clamp(_values, clamp)\n        self.raw_values = nn.Parameter(_values, requires_grad=requires_grad)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Normal","title":"Normal","text":"<p>               Bases: <code>InitialDistribution</code></p> <p>Initializes parameters independently from normal distributions.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <p>The mean of the normal distribution.</p> required <code>std</code> <p>The standard deviation of the normal distribution.</p> required <code>requires_grad</code> <code>bool</code> <p>Whether the parameter requires gradients.</p> required <code>mode</code> <code>str</code> <p>The initialization mode. Defaults to \u201csample\u201d.</p> <code>'sample'</code> <code>clamp</code> <code>bool</code> <p>Whether to clamp the values. Defaults to False.</p> <code>False</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Example <pre><code>param_config = Namespace(\n    requires_grad=True,\n    initial_dist=\"Normal\",\n    mean=0,\n    std=1,\n    mode=\"sample\",\n)\n</code></pre> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class Normal(InitialDistribution):\n    \"\"\"Initializes parameters independently from normal distributions.\n\n    Args:\n        mean: The mean of the normal distribution.\n        std: The standard deviation of the normal distribution.\n        requires_grad (bool): Whether the parameter requires gradients.\n        mode (str, optional): The initialization mode. Defaults to \"sample\".\n        clamp (bool, optional): Whether to clamp the values. Defaults to False.\n        seed (int, optional): Random seed for reproducibility. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Example:\n        ```python\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Normal\",\n            mean=0,\n            std=1,\n            mode=\"sample\",\n        )\n        ```\n    \"\"\"\n\n    def __init__(\n        self, mean, std, requires_grad, mode=\"sample\", clamp=False, seed=None, **kwargs\n    ) -&gt; None:\n        if mode == \"mean\":\n            _values = torch.tensor(mean).float()\n        elif mode == \"sample\":\n            # set seed for reproducibility and avoid seeding the global RNG\n            generator = torch.Generator(device=device)\n            if seed is not None:\n                generator.manual_seed(seed)\n            else:\n                generator.seed()\n            try:\n                _values = torch.normal(\n                    torch.tensor(mean).float(),\n                    torch.tensor(std).float(),\n                    generator=generator,\n                )\n            except RuntimeError as e:\n                raise RuntimeError(\n                    f\"Failed to sample from normal with mean {mean} and std {std}\"\n                ) from e\n        else:\n            raise ValueError(\"Mode must be either mean or sample.\")\n        _values = self.clamp(_values, clamp)\n        self.raw_values = nn.Parameter(_values, requires_grad=requires_grad)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Lognormal","title":"Lognormal","text":"<p>               Bases: <code>Normal</code></p> <p>Initializes parameters independently from lognormal distributions.</p> Note <p>The lognormal distribution reparametrizes a normal through semantic values.</p> Example <pre><code>param_config = Namespace(\n    requires_grad=True,\n    initial_dist=\"Lognormal\",\n    mean=0,\n    std=1,\n    mode=\"sample\",\n)\n</code></pre> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class Lognormal(Normal):\n    \"\"\"Initializes parameters independently from lognormal distributions.\n\n    Note:\n        The lognormal distribution reparametrizes a normal through semantic values.\n\n    Example:\n        ```python\n        param_config = Namespace(\n            requires_grad=True,\n            initial_dist=\"Lognormal\",\n            mean=0,\n            std=1,\n            mode=\"sample\",\n        )\n        ```\n    \"\"\"\n\n    @property\n    def semantic_values(self):\n        \"\"\"n_syn ~ self._values.exp().\"\"\"\n        return self.raw_values.exp()\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Lognormal.semantic_values","title":"semantic_values  <code>property</code>","text":"<pre><code>semantic_values\n</code></pre> <p>n_syn ~ self._values.exp().</p>"},{"location":"reference/network/#flyvis.network.initialization.Parameter","title":"Parameter","text":"<p>Base class for all parameters to share across nodes or edges.</p> <p>Parameters:</p> Name Type Description Default <code>param_config</code> <code>Namespace</code> <p>Namespace containing parameter configuration.</p> required <code>connectome</code> <code>Connectome</code> <p>Connectome object.</p> required <p>Attributes:</p> Name Type Description <code>parameter</code> <code>InitialDistribution</code> <p>InitialDistribution object.</p> <code>indices</code> <code>Tensor</code> <p>Indices for parameter sharing.</p> <code>keys</code> <code>List[Any]</code> <p>Keys to access individual parameter values associated with certain identifiers.</p> <code>symmetry_masks</code> <code>List[Tensor]</code> <p>Symmetry masks that can be configured optionally to apply further symmetry constraints to the parameter values.</p> Note <p>Subclasses must implement <code>__init__(self, param_config, connectome_dir)</code> with the following requirements:</p> <ol> <li>Configure all attributes defined in the base class.</li> <li>Decorate <code>__init__</code> with <code>@deepcopy_config</code> if it updates <code>param_config</code> to    prevent mutations in the outer scope.</li> <li>Update <code>param_config</code> with key-value pairs informed by <code>connectome</code> and    matching the desired <code>InitialDistribution</code>.</li> <li>Store <code>parameter</code> from <code>InitialDistribution(param_config)</code>, which constructs    and holds the <code>nn.Parameter</code>.</li> <li>Store <code>indices</code> for parameter sharing using    <code>get_scatter_indices(dataframe, grouped_dataframe, groupby)</code>.</li> <li>Store <code>keys</code> to access individual parameter values associated with certain    identifiers.</li> <li>Store <code>symmetry_masks</code> (optional) to apply further symmetry constraints to    the parameter values.</li> </ol> <p>Example implementation structure:</p> <pre><code>@deepcopy_config\ndef __init__(self, param_config: Namespace, connectome: Connectome):\n    # Update param_config based on connectome data\n    # ...\n\n    # Initialize parameter\n    self.parameter = InitialDistribution(param_config)\n\n    # Set up indices, keys, and symmetry masks\n    self.indices = get_scatter_indices(...)\n    self.keys = ...\n    self.symmetry_masks = symmetry_masks(...)\n</code></pre> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class Parameter:\n    \"\"\"Base class for all parameters to share across nodes or edges.\n\n    Args:\n        param_config (Namespace): Namespace containing parameter configuration.\n        connectome (Connectome): Connectome object.\n\n    Attributes:\n        parameter (InitialDistribution): InitialDistribution object.\n        indices (torch.Tensor): Indices for parameter sharing.\n        keys (List[Any]): Keys to access individual parameter values associated with\n            certain identifiers.\n        symmetry_masks (List[torch.Tensor]): Symmetry masks that can be configured\n            optionally to apply further symmetry constraints to the parameter values.\n\n    Note:\n        Subclasses must implement `__init__(self, param_config, connectome_dir)` with the\n        following requirements:\n\n        1. Configure all attributes defined in the base class.\n        2. Decorate `__init__` with `@deepcopy_config` if it updates `param_config` to\n           prevent mutations in the outer scope.\n        3. Update `param_config` with key-value pairs informed by `connectome` and\n           matching the desired `InitialDistribution`.\n        4. Store `parameter` from `InitialDistribution(param_config)`, which constructs\n           and holds the `nn.Parameter`.\n        5. Store `indices` for parameter sharing using\n           `get_scatter_indices(dataframe, grouped_dataframe, groupby)`.\n        6. Store `keys` to access individual parameter values associated with certain\n           identifiers.\n        7. Store `symmetry_masks` (optional) to apply further symmetry constraints to\n           the parameter values.\n\n        Example implementation structure:\n\n        ```python\n        @deepcopy_config\n        def __init__(self, param_config: Namespace, connectome: Connectome):\n            # Update param_config based on connectome data\n            # ...\n\n            # Initialize parameter\n            self.parameter = InitialDistribution(param_config)\n\n            # Set up indices, keys, and symmetry masks\n            self.indices = get_scatter_indices(...)\n            self.keys = ...\n            self.symmetry_masks = symmetry_masks(...)\n        ```\n    \"\"\"\n\n    parameter: InitialDistribution\n    indices: torch.Tensor\n    symmetry_masks: List[torch.Tensor]\n    keys: List[Any]\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeFromAvgFilters):\n        pass\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the Parameter object.\"\"\"\n        init_arg_names = list(self.__init__.__annotations__.keys())\n        dir_type = self.__init__.__annotations__[init_arg_names[1]].__name__\n        return f\"{self.__class__.__name__}({self.config}, {dir_type})\"\n\n    def __getitem__(self, key):\n        \"\"\"Get parameter value for a given key.\"\"\"\n        if key in self.keys:\n            if self.parameter.raw_values.dim() == 0:\n                return self.parameter.raw_values\n            return self.parameter.raw_values[self.keys.index(key)]\n        else:\n            raise ValueError(key)\n\n    def __len__(self):\n        \"\"\"Return the length of raw_values.\"\"\"\n        return len(self.raw_values)\n\n    @property\n    def raw_values(self) -&gt; torch.Tensor:\n        \"\"\"Get raw parameter values.\"\"\"\n        return self.parameter.raw_values\n\n    @property\n    def semantic_values(self) -&gt; torch.Tensor:\n        \"\"\"Get semantic parameter values.\"\"\"\n        return self.parameter.semantic_values\n\n    @property\n    def readers(self) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Get parameter readers.\"\"\"\n        return self.parameter.readers\n\n    @readers.setter\n    def readers(self, value) -&gt; None:\n        \"\"\"Set parameter readers.\"\"\"\n        self.parameter.readers = value\n\n    def _symmetry(self):\n        \"\"\"Return symmetry constraints from symmetry masks for debugging.\"\"\"\n        keys = np.array(self.keys)\n        return [keys[mask.cpu()] for mask in self.symmetry_masks]\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Parameter.raw_values","title":"raw_values  <code>property</code>","text":"<pre><code>raw_values\n</code></pre> <p>Get raw parameter values.</p>"},{"location":"reference/network/#flyvis.network.initialization.Parameter.semantic_values","title":"semantic_values  <code>property</code>","text":"<pre><code>semantic_values\n</code></pre> <p>Get semantic parameter values.</p>"},{"location":"reference/network/#flyvis.network.initialization.Parameter.readers","title":"readers  <code>property</code> <code>writable</code>","text":"<pre><code>readers\n</code></pre> <p>Get parameter readers.</p>"},{"location":"reference/network/#flyvis.network.initialization.Parameter.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Return a string representation of the Parameter object.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the Parameter object.\"\"\"\n    init_arg_names = list(self.__init__.__annotations__.keys())\n    dir_type = self.__init__.__annotations__[init_arg_names[1]].__name__\n    return f\"{self.__class__.__name__}({self.config}, {dir_type})\"\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Parameter.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Get parameter value for a given key.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"Get parameter value for a given key.\"\"\"\n    if key in self.keys:\n        if self.parameter.raw_values.dim() == 0:\n            return self.parameter.raw_values\n        return self.parameter.raw_values[self.keys.index(key)]\n    else:\n        raise ValueError(key)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.Parameter.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Return the length of raw_values.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the length of raw_values.\"\"\"\n    return len(self.raw_values)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.RestingPotential","title":"RestingPotential","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize resting potentials a.k.a. biases for cell types.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class RestingPotential(Parameter):\n    \"\"\"Initialize resting potentials a.k.a. biases for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeFromAvgFilters):\n        nodes_dir = connectome.nodes\n\n        nodes = pd.DataFrame({\n            k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby\n        })\n        grouped_nodes = nodes.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"mean\"] = np.repeat(param_config[\"mean\"], len(grouped_nodes))\n        param_config[\"std\"] = np.repeat(param_config[\"std\"], len(grouped_nodes))\n\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.indices = get_scatter_indices(nodes, grouped_nodes, param_config.groupby)\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.TimeConstant","title":"TimeConstant","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize time constants for cell types.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class TimeConstant(Parameter):\n    \"\"\"Initialize time constants for cell types.\"\"\"\n\n    @deepcopy_config\n    def __init__(self, param_config: Namespace, connectome: ConnectomeFromAvgFilters):\n        nodes_dir = connectome.nodes\n\n        nodes = pd.DataFrame({\n            k: byte_to_str(nodes_dir[k][:]) for k in param_config.groupby\n        })\n        grouped_nodes = nodes.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config[\"type\"] = grouped_nodes[\"type\"].values\n        param_config[\"value\"] = np.repeat(param_config[\"value\"], len(grouped_nodes))\n\n        self.indices = get_scatter_indices(nodes, grouped_nodes, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = param_config[\"type\"].tolist()\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.SynapseSign","title":"SynapseSign","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize synapse signs for edge types.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class SynapseSign(Parameter):\n    \"\"\"Initialize synapse signs for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(\n        self, param_config: Namespace, connectome: ConnectomeFromAvgFilters\n    ) -&gt; None:\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame({\n            k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"sign\"]\n        })\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).first()\n\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.value = grouped_edges.sign.values\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.SynapseCount","title":"SynapseCount","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize synapse counts for edge types.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class SynapseCount(Parameter):\n    \"\"\"Initialize synapse counts for edge types.\"\"\"\n\n    @deepcopy_config\n    def __init__(\n        self, param_config: Namespace, connectome: ConnectomeFromAvgFilters\n    ) -&gt; None:\n        mode = param_config.get(\"mode\", \"\")\n        if mode != \"mean\":\n            raise NotImplementedError(\n                f\"SynapseCount does not implement {mode}. Implement \"\n                \"a custom Parameter subclass.\"\n            )\n\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame({\n            k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"n_syn\"]\n        })\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).mean()\n\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.du = grouped_edges.du.values\n        param_config.dv = grouped_edges.dv.values\n\n        param_config.mode = \"mean\"\n        param_config.mean = np.log(grouped_edges.n_syn.values)\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n                param_config.du.tolist(),\n                param_config.dv.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.SynapseCountScaling","title":"SynapseCountScaling","text":"<p>               Bases: <code>Parameter</code></p> <p>Initialize synapse count scaling for edge types.</p> <p>This class initializes synapse strengths based on the average synapse count for each edge type, scaling them differently for chemical and electrical synapses.</p> <p>The initialization follows this equation:</p> \\[\\alpha_{t_it_j} =\\frac{\\rho}{\\langle N \\rangle_{t_it_j}}\\] <p>where:</p> <ol> <li>\\(\\alpha_{t_it_j}\\) is the synapse strength between neurons \\(i\\) and \\(j\\).</li> <li>\\(\\langle N \\rangle_{t_it_j}\\) is the average synapse count for the edge type     across columnar offsets \\(u_i-u_j\\) and \\(v_i-v_j\\)</li> <li>\\(\\rho\\) is a scaling factor (default: 0.01)</li> </ol> Source code in <code>flyvis/network/initialization.py</code> <pre><code>class SynapseCountScaling(Parameter):\n    \"\"\"Initialize synapse count scaling for edge types.\n\n    This class initializes synapse strengths based on the average synapse count for each\n    edge type, scaling them differently for chemical and electrical synapses.\n\n    The initialization follows this equation:\n\n    $$\\\\alpha_{t_it_j} =\\\\frac{\\\\rho}{\\\\langle N \\\\rangle_{t_it_j}}$$\n\n    where:\n\n    1. $\\\\alpha_{t_it_j}$ is the synapse strength between neurons $i$ and $j$.\n    2. $\\\\langle N \\\\rangle_{t_it_j}$ is the average synapse count for the edge type\n        across columnar offsets $u_i-u_j$ and $v_i-v_j$\n    3. $\\\\rho$ is a scaling factor (default: 0.01)\n\n    \"\"\"\n\n    @deepcopy_config\n    def __init__(\n        self, param_config: Namespace, connectome: ConnectomeFromAvgFilters\n    ) -&gt; None:\n        edges_dir = connectome.edges\n\n        edges = pd.DataFrame({\n            k: byte_to_str(edges_dir[k][:]) for k in [*param_config.groupby, \"n_syn\"]\n        })\n        grouped_edges = edges.groupby(\n            param_config.groupby, as_index=False, sort=False\n        ).mean()\n\n        # to initialize synapse strengths with scale/&lt;N&gt;_rf\n        syn_strength = param_config.get(\"scale\", 0.01) / grouped_edges.n_syn.values\n\n        param_config.target_type = grouped_edges.target_type.values\n        param_config.source_type = grouped_edges.source_type.values\n        param_config.value = syn_strength\n\n        self.indices = get_scatter_indices(edges, grouped_edges, param_config.groupby)\n        self.parameter = forward_subclass(\n            InitialDistribution, param_config, subclass_key=\"initial_dist\"\n        )\n        self.keys = list(\n            zip(\n                param_config.source_type.tolist(),\n                param_config.target_type.tolist(),\n            )\n        )\n        self.symmetry_masks = symmetry_masks(param_config.get(\"symmetric\", []), self.keys)\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.deepcopy_config","title":"deepcopy_config","text":"<pre><code>deepcopy_config(f)\n</code></pre> <p>Decorator to deepcopy the parameter configuration.</p> Note <p>This decorator is necessary because the <code>__init__</code> method of parameter classes often modifies the <code>param_config</code> object. By creating a deep copy, we ensure that these modifications don\u2019t affect the original <code>param_config</code> object in the outer scope. This prevents unintended side effects and maintains the integrity of the original configuration.</p> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def deepcopy_config(f):\n    \"\"\"Decorator to deepcopy the parameter configuration.\n\n    Note:\n        This decorator is necessary because the `__init__` method of parameter classes\n        often modifies the `param_config` object. By creating a deep copy, we ensure\n        that these modifications don't affect the original `param_config` object in the\n        outer scope. This prevents unintended side effects and maintains the integrity\n        of the original configuration.\n    \"\"\"\n\n    @functools.wraps(f)\n    def wrapper(cls, param_config, connectome):\n        cls.config = deepcopy(param_config)\n        return f(cls, deepcopy(param_config), connectome)\n\n    return wrapper\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.get_scatter_indices","title":"get_scatter_indices","text":"<pre><code>get_scatter_indices(dataframe, grouped_dataframe, groupby)\n</code></pre> <p>Get indices for scattering operations to share parameters.</p> <p>Maps each node/edge from the complete computational graph to a parameter index.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>Dataframe of nodes or edges of the graph.</p> required <code>grouped_dataframe</code> <code>DataFrame</code> <p>Aggregated version of the same dataframe.</p> required <code>groupby</code> <code>List[str]</code> <p>The same columns from which the grouped_dataframe was constructed.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of indices for scattering operations.</p> Note <p>For N elements that are grouped into M groups, this function returns N indices from 0 to M-1 that can be used to scatter the parameters of the M groups to the N elements.</p> Example <pre><code>elements = [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"D\", \"E\"]\ngroups = [\"A\", \"B\", \"C\", \"D\", \"E\"]\nparameter = [1, 2, 3, 4, 5]\n# get_scatter_indices would return\nscatter_indices = [0, 0, 0, 1, 1, 2, 3, 3, 4]\nscattered_parameters = [parameter[idx] for idx in scatter_indices]\nscattered_parameters == [1, 1, 1, 2, 2, 3, 4, 4, 5]\n</code></pre> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def get_scatter_indices(\n    dataframe: pd.DataFrame, grouped_dataframe: pd.DataFrame, groupby: List[str]\n) -&gt; Tensor:\n    \"\"\"Get indices for scattering operations to share parameters.\n\n    Maps each node/edge from the complete computational graph to a parameter index.\n\n    Args:\n        dataframe: Dataframe of nodes or edges of the graph.\n        grouped_dataframe: Aggregated version of the same dataframe.\n        groupby: The same columns from which the grouped_dataframe was constructed.\n\n    Returns:\n        Tensor of indices for scattering operations.\n\n    Note:\n        For N elements that are grouped into M groups, this function returns N indices\n        from 0 to M-1 that can be used to scatter the parameters of the M groups to the\n        N elements.\n\n    Example:\n        ```python\n        elements = [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"D\", \"E\"]\n        groups = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n        parameter = [1, 2, 3, 4, 5]\n        # get_scatter_indices would return\n        scatter_indices = [0, 0, 0, 1, 1, 2, 3, 3, 4]\n        scattered_parameters = [parameter[idx] for idx in scatter_indices]\n        scattered_parameters == [1, 1, 1, 2, 2, 3, 4, 4, 5]\n        ```\n    \"\"\"\n    ungrouped_elements = zip(*[dataframe[k][:] for k in groupby])\n    grouped_elements = zip(*[grouped_dataframe[k][:] for k in groupby])\n    to_index = {k: i for i, k in enumerate(grouped_elements)}\n    return torch.tensor([to_index[k] for k in ungrouped_elements])\n</code></pre>"},{"location":"reference/network/#flyvis.network.initialization.symmetry_masks","title":"symmetry_masks","text":"<pre><code>symmetry_masks(symmetric, keys, as_mask=False)\n</code></pre> <p>Create masks for subsets of parameters for joint constraints.</p> <p>Parameters:</p> Name Type Description Default <code>symmetric</code> <code>List[Any]</code> <p>Contains subsets of keys that point to the subsets of parameters to be indexed.</p> required <code>keys</code> <code>List[Any]</code> <p>List of keys that point to individual parameter values.</p> required <code>as_mask</code> <code>bool</code> <p>If True, returns a boolean mask, otherwise integer indices.</p> <code>False</code> <p>Returns:</p> Type Description <code>List[Tensor]</code> <p>List of masks (List[torch.BoolTensor]).</p> Note <p>This is experimental for configuration-based fine-grained shared parameter optimization, e.g. for models including multi-compartment cells or gap junctions.</p> Example <pre><code># For node type parameters with individual node types as keys:\nsymmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n# This would constrain the parameter values of all T4 subtypes to their joint\n# mean and the parameter values of all T5 subtypes to their joint mean.\n\n# For edge type parameters with individual edge types as keys:\nsymmetric = [[(\"CT1(M10)\", \"CT1(Lo1)\"), (\"CT1(Lo1)\", \"CT1(M10)\")]]\n# This would constrain the edge parameter of the directed edge from CT1(M10) to\n# CT1(Lo1) and the directed edge from CT1(Lo1) to CT1(M10) to their joint mean.\n</code></pre> Source code in <code>flyvis/network/initialization.py</code> <pre><code>def symmetry_masks(\n    symmetric: List[Any], keys: List[Any], as_mask: bool = False\n) -&gt; List[torch.Tensor]:\n    \"\"\"Create masks for subsets of parameters for joint constraints.\n\n    Args:\n        symmetric: Contains subsets of keys that point to the subsets of parameters\n            to be indexed.\n        keys: List of keys that point to individual parameter values.\n        as_mask: If True, returns a boolean mask, otherwise integer indices.\n\n    Returns:\n        List of masks (List[torch.BoolTensor]).\n\n    Note:\n        This is experimental for configuration-based fine-grained shared parameter\n        optimization, e.g. for models including multi-compartment cells or gap\n        junctions.\n\n    Example:\n        ```python\n        # For node type parameters with individual node types as keys:\n        symmetric = [[\"T4a\", \"T4b\", \"T4c\", \"T4d\"], [\"T5a\", \"T5b\", \"T5c\", \"T5d\"]]\n        # This would constrain the parameter values of all T4 subtypes to their joint\n        # mean and the parameter values of all T5 subtypes to their joint mean.\n\n        # For edge type parameters with individual edge types as keys:\n        symmetric = [[(\"CT1(M10)\", \"CT1(Lo1)\"), (\"CT1(Lo1)\", \"CT1(M10)\")]]\n        # This would constrain the edge parameter of the directed edge from CT1(M10) to\n        # CT1(Lo1) and the directed edge from CT1(Lo1) to CT1(M10) to their joint mean.\n        ```\n    \"\"\"\n    if not symmetric:\n        return []\n    symmetry_masks = []  # type: List[torch.Tensor]\n    keys = atleast_column_vector(keys)\n    for identifiers in symmetric:\n        identifiers = atleast_column_vector(identifiers)\n        # to allow identifiers like [None, \"A\", None, 0]\n        # for parameters that have tuples as keys\n        columns = np.arange(identifiers.shape[1] + 1)[\n            np.where((identifiers is not None).all(axis=0))\n        ]\n        try:\n            symmetry_masks.append(\n                torch.tensor(\n                    where_equal_rows(\n                        identifiers[:, columns], keys[:, columns], as_mask=as_mask\n                    )\n                )\n            )\n        except Exception as e:\n            raise ValueError(\n                f\"{identifiers} cannot be a symmetry constraint \"\n                f\"for parameter with keys {keys}: {e}\"\n            ) from e\n    return symmetry_masks\n</code></pre>"},{"location":"reference/network_view/","title":"NetworkView","text":""},{"location":"reference/network_view/#flyvis.network.directories.NetworkDir","title":"flyvis.network.directories.NetworkDir","text":"<p>               Bases: <code>Directory</code></p> <p>Directory for a network.</p> <p>Written to by the solver.</p> Name Type Description <code>loss</code> <code>ArrayFile</code> <p>Loss values over iterations.</p> <code>activity</code> <code>ArrayFile</code> <p>Mean activity values over iterations.</p> <code>activity_min</code> <code>ArrayFile</code> <p>Minimum activity values over iterations.</p> <code>activity_max</code> <code>ArrayFile</code> <p>Maximum activity values over iterations.</p> <code>loss_&lt;task&gt;</code> <code>ArrayFile</code> <p>Loss values for each specific task over iterations.</p> <code>chkpt_index</code> <code>ArrayFile</code> <p>Numerical identifiers of checkpoints.</p> <code>chkpt_iter</code> <code>ArrayFile</code> <p>Iterations at which checkpoints were recorded.</p> <code>best_chkpt_index</code> <code>ArrayFile</code> <p>Checkpoint index with minimal validation loss.</p> <code>dt</code> <code>ArrayFile</code> <p>Current time constant of the dataset.</p> <code>time_trained</code> <code>ArrayFile</code> <p>Total time spent training.</p> <p>Written by NetworkView.</p> Name Type Description <code>__cache__</code> <code>Directory</code> <p>joblib cache.</p> Source code in <code>flyvis/network/directories.py</code> <pre><code>@root(flyvis.results_dir)\nclass NetworkDir(Directory):\n    \"\"\"Directory for a network.\n\n    Attributes: Written to by the solver.\n        loss (ArrayFile): Loss values over iterations.\n        activity (ArrayFile): Mean activity values over iterations.\n        activity_min (ArrayFile): Minimum activity values over iterations.\n        activity_max (ArrayFile): Maximum activity values over iterations.\n        loss_&lt;task&gt; (ArrayFile): Loss values for each specific task over iterations.\n        chkpt_index (ArrayFile): Numerical identifiers of checkpoints.\n        chkpt_iter (ArrayFile): Iterations at which checkpoints were recorded.\n        best_chkpt_index (ArrayFile): Checkpoint index with minimal validation loss.\n        dt (ArrayFile): Current time constant of the dataset.\n        time_trained (ArrayFile): Total time spent training.\n\n    Attributes: Written by NetworkView.\n        __cache__ (Directory): joblib cache.\n    \"\"\"\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView","title":"flyvis.network.network_view.NetworkView","text":"<p>IO interface for network.</p> <p>Parameters:</p> Name Type Description Default <code>network_dir</code> <code>Union[str, PathLike, NetworkDir]</code> <p>Directory of the network.</p> required <code>network_class</code> <code>Module</code> <p>Network class. Defaults to Network.</p> <code>Network</code> <code>root_dir</code> <code>PathLike</code> <p>Root directory. Defaults to flyvis.results_dir.</p> <code>results_dir</code> <code>connectome_getter</code> <code>Callable</code> <p>Function to get the connectome. Defaults to flyvision_connectome.</p> <code>get_avgfilt_connectome</code> <code>checkpoint_mapper</code> <code>Callable</code> <p>Function to map checkpoints. Defaults to resolve_checkpoints.</p> <code>resolve_checkpoints</code> <code>best_checkpoint_fn</code> <code>Callable</code> <p>Function to get the best checkpoint. Defaults to best_checkpoint_default_fn.</p> <code>best_checkpoint_default_fn</code> <code>best_checkpoint_fn_kwargs</code> <code>dict</code> <p>Keyword arguments for best_checkpoint_fn. Defaults to {\u201cvalidation_subdir\u201d: \u201cvalidation\u201d, \u201closs_file_name\u201d: \u201closs\u201d}.</p> <code>{'validation_subdir': 'validation', 'loss_file_name': 'epe'}</code> <code>recover_fn</code> <code>Callable</code> <p>Function to recover the network. Defaults to recover_network.</p> <code>recover_network</code> <p>Attributes:</p> Name Type Description <code>network_class</code> <code>Module</code> <p>Network class.</p> <code>dir</code> <code>Directory</code> <p>Network directory.</p> <code>name</code> <code>str</code> <p>Network name.</p> <code>root_dir</code> <code>PathLike</code> <p>Root directory.</p> <code>connectome_getter</code> <code>Callable</code> <p>Function to get the connectome.</p> <code>checkpoint_mapper</code> <code>Callable</code> <p>Function to map checkpoints.</p> <code>connectome_view</code> <code>ConnectomeView</code> <p>Connectome view.</p> <code>connectome</code> <code>Directory</code> <p>Connectome directory.</p> <code>checkpoints</code> <p>Mapped checkpoints.</p> <code>memory</code> <code>Memory</code> <p>Joblib memory cache.</p> <code>best_checkpoint_fn</code> <code>Callable</code> <p>Function to get the best checkpoint.</p> <code>best_checkpoint_fn_kwargs</code> <code>dict</code> <p>Keyword arguments for best_checkpoint_fn.</p> <code>recover_fn</code> <code>Callable</code> <p>Function to recover the network.</p> <code>_network</code> <code>CheckpointedNetwork</code> <p>Checkpointed network instance.</p> <code>decoder</code> <p>Decoder instance.</p> <code>_initialized</code> <code>dict</code> <p>Initialization status for network and decoder.</p> <code>cache</code> <code>FIFOCache</code> <p>Cache for storing results.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>class NetworkView:\n    \"\"\"IO interface for network.\n\n    Args:\n        network_dir: Directory of the network.\n        network_class: Network class. Defaults to Network.\n        root_dir: Root directory. Defaults to flyvis.results_dir.\n        connectome_getter: Function to get the connectome.\n            Defaults to flyvision_connectome.\n        checkpoint_mapper: Function to map checkpoints. Defaults to resolve_checkpoints.\n        best_checkpoint_fn: Function to get the best checkpoint. Defaults to\n            best_checkpoint_default_fn.\n        best_checkpoint_fn_kwargs: Keyword arguments for best_checkpoint_fn. Defaults to\n            {\"validation_subdir\": \"validation\", \"loss_file_name\": \"loss\"}.\n        recover_fn: Function to recover the network. Defaults to recover_network.\n\n    Attributes:\n        network_class (nn.Module): Network class.\n        dir (Directory): Network directory.\n        name (str): Network name.\n        root_dir (PathLike): Root directory.\n        connectome_getter (Callable): Function to get the connectome.\n        checkpoint_mapper (Callable): Function to map checkpoints.\n        connectome_view (ConnectomeView): Connectome view.\n        connectome (Directory): Connectome directory.\n        checkpoints: Mapped checkpoints.\n        memory (Memory): Joblib memory cache.\n        best_checkpoint_fn (Callable): Function to get the best checkpoint.\n        best_checkpoint_fn_kwargs (dict): Keyword arguments for best_checkpoint_fn.\n        recover_fn (Callable): Function to recover the network.\n        _network (CheckpointedNetwork): Checkpointed network instance.\n        decoder: Decoder instance.\n        _initialized (dict): Initialization status for network and decoder.\n        cache (FIFOCache): Cache for storing results.\n    \"\"\"\n\n    def __init__(\n        self,\n        network_dir: Union[str, PathLike, NetworkDir],\n        network_class: nn.Module = Network,\n        root_dir: PathLike = flyvis.results_dir,\n        connectome_getter: Callable = get_avgfilt_connectome,\n        checkpoint_mapper: Callable = resolve_checkpoints,\n        best_checkpoint_fn: Callable = best_checkpoint_default_fn,\n        best_checkpoint_fn_kwargs: dict = {\n            \"validation_subdir\": \"validation\",\n            \"loss_file_name\": \"epe\",\n        },\n        recover_fn: Callable = recover_network,\n    ):\n        self.network_class = network_class\n        self.dir, self.name = self._resolve_dir(network_dir, root_dir)\n        self.root_dir = root_dir\n        self.connectome_getter = connectome_getter\n        self.checkpoint_mapper = checkpoint_mapper\n        self.connectome_view: ConnectomeView = connectome_getter(\n            self.dir.config.network.connectome\n        )\n        self.connectome = self.connectome_view.dir\n        self.checkpoints = checkpoint_mapper(self.dir)\n        self.memory = Memory(\n            location=self.dir.path / \"__cache__\",\n            backend=\"xarray_dataset_h5\",\n            verbose=0,\n            # verbose=11,\n        )\n        self.best_checkpoint_fn = best_checkpoint_fn\n        self.best_checkpoint_fn_kwargs = best_checkpoint_fn_kwargs\n        self.recover_fn = recover_fn\n        self._network_instance = None\n        self.decoder = None\n        self._initialized = {\"network\": None, \"decoder\": None}\n        self.cache = FIFOCache(maxsize=3)\n        logging.info(\"Initialized network view at %s\", str(self.dir.path))\n\n    @property\n    def _network(self) -&gt; CheckpointedNetwork:\n        \"\"\"Lazy init of CheckpointedNetwork because get_checkpoint can be slow.\"\"\"\n        if self._network_instance is None:\n            self._network_instance = CheckpointedNetwork(\n                self.network_class,\n                self.dir.config.network.to_dict(),\n                self.name,\n                self.get_checkpoint(\"best\"),\n                self.recover_fn,\n                network=None,\n            )\n        return self._network_instance\n\n    @_network.setter\n    def _network(self, value):\n        \"\"\"Setter for _network property.\"\"\"\n        self._network_instance = value\n\n    def _clear_cache(self):\n        \"\"\"Clear the FIFO cache.\"\"\"\n        self.cache = self.cache.__class__(maxsize=self.cache.maxsize)\n\n    def _clear_memory(self):\n        \"\"\"Clear the joblib memory cache.\"\"\"\n        self.memory.clear()\n\n    # --- ConnectomeView API for static code analysis\n    # pylint: disable=missing-function-docstring\n    @wraps(ConnectomeView.connectivity_matrix)\n    def connectivity_matrix(self, *args, **kwargs):\n        return self.connectome_view.connectivity_matrix(*args, **kwargs)\n\n    connectivity_matrix.__doc__ = ConnectomeView.connectivity_matrix.__doc__\n\n    @wraps(ConnectomeView.network_layout)\n    def network_layout(self, *args, **kwargs):\n        return self.connectome_view.network_layout(*args, **kwargs)\n\n    network_layout.__doc__ = ConnectomeView.network_layout.__doc__\n\n    @wraps(ConnectomeView.hex_layout)\n    def hex_layout(self, *args, **kwargs):\n        return self.connectome_view.hex_layout(*args, **kwargs)\n\n    hex_layout.__doc__ = ConnectomeView.hex_layout.__doc__\n\n    @wraps(ConnectomeView.hex_layout_all)\n    def hex_layout_all(self, *args, **kwargs):\n        return self.connectome_view.hex_layout_all(*args, **kwargs)\n\n    hex_layout_all.__doc__ = ConnectomeView.hex_layout_all.__doc__\n\n    @wraps(ConnectomeView.get_uv)\n    def get_uv(self, *args, **kwargs):\n        return self.connectome_view.get_uv(*args, **kwargs)\n\n    get_uv.__doc__ = ConnectomeView.get_uv.__doc__\n\n    @wraps(ConnectomeView.sources_list)\n    def sources_list(self, *args, **kwargs):\n        return self.connectome_view.sources_list(*args, **kwargs)\n\n    sources_list.__doc__ = ConnectomeView.sources_list.__doc__\n\n    @wraps(ConnectomeView.targets_list)\n    def targets_list(self, *args, **kwargs):\n        return self.connectome_view.targets_list(*args, **kwargs)\n\n    targets_list.__doc__ = ConnectomeView.targets_list.__doc__\n\n    @wraps(ConnectomeView.receptive_field)\n    def receptive_field(self, *args, **kwargs):\n        return self.connectome_view.receptive_field(*args, **kwargs)\n\n    receptive_field.__doc__ = ConnectomeView.receptive_field.__doc__\n\n    @wraps(ConnectomeView.receptive_fields_grid)\n    def receptive_fields_grid(self, *args, **kwargs):\n        return self.connectome_view.receptive_fields_grid(*args, **kwargs)\n\n    receptive_fields_grid.__doc__ = ConnectomeView.receptive_fields_grid.__doc__\n\n    @wraps(ConnectomeView.projective_field)\n    def projective_field(self, *args, **kwargs):\n        return self.connectome_view.projective_field(*args, **kwargs)\n\n    projective_field.__doc__ = ConnectomeView.projective_field.__doc__\n\n    @wraps(ConnectomeView.projective_fields_grid)\n    def projective_fields_grid(self, *args, **kwargs):\n        return self.connectome_view.projective_fields_grid(*args, **kwargs)\n\n    projective_fields_grid.__doc__ = ConnectomeView.projective_fields_grid.__doc__\n\n    @wraps(ConnectomeView.receptive_fields_df)\n    def receptive_fields_df(self, *args, **kwargs):\n        return self.connectome_view.receptive_fields_df(*args, **kwargs)\n\n    receptive_fields_df.__doc__ = ConnectomeView.receptive_fields_df.__doc__\n\n    @wraps(ConnectomeView.receptive_fields_sum)\n    def receptive_fields_sum(self, *args, **kwargs):\n        return self.connectome_view.receptive_fields_sum(*args, **kwargs)\n\n    receptive_fields_sum.__doc__ = ConnectomeView.receptive_fields_sum.__doc__\n\n    @wraps(ConnectomeView.projective_fields_df)\n    def projective_fields_df(self, *args, **kwargs):\n        return self.connectome_view.projective_fields_df(*args, **kwargs)\n\n    projective_fields_df.__doc__ = ConnectomeView.projective_fields_df.__doc__\n\n    @wraps(ConnectomeView.projective_fields_sum)\n    def projective_fields_sum(self, *args, **kwargs):\n        return self.connectome_view.projective_fields_sum(*args, **kwargs)\n\n    projective_fields_sum.__doc__ = ConnectomeView.projective_fields_sum.__doc__\n\n    # --- own API\n\n    def get_checkpoint(self, checkpoint=\"best\"):\n        \"\"\"Return the best checkpoint index.\n\n        Args:\n            checkpoint: Checkpoint identifier. Defaults to \"best\".\n\n        Returns:\n            str: Path to the checkpoint.\n        \"\"\"\n        try:\n            if checkpoint == \"best\":\n                return self.best_checkpoint_fn(\n                    self.dir.path,\n                    **self.best_checkpoint_fn_kwargs,\n                )\n            return self.checkpoints.paths[checkpoint]\n        except FileNotFoundError:\n            logger.warning(\"Checkpoint %s not found at %s\", checkpoint, self.dir.path)\n            return None\n\n    def network(\n        self, checkpoint=\"best\", network: Optional[Any] = None, lazy=False\n    ) -&gt; CheckpointedNetwork:\n        \"\"\"Lazy loading of network instance.\n\n        Args:\n            checkpoint: Checkpoint identifier. Defaults to \"best\".\n            network: Existing network instance to use. Defaults to None.\n            lazy: If True, don't recover the network immediately. Defaults to False.\n\n        Returns:\n            CheckpointedNetwork: Checkpointed network instance.\n        \"\"\"\n        self._network = CheckpointedNetwork(\n            self.network_class,\n            self.dir.config.network.to_dict(),\n            self.name,\n            self.get_checkpoint(checkpoint),\n            self.recover_fn,\n            network=network or self._network.network,\n        )\n        if self._network.network is not None and not lazy:\n            self._network.recover()\n        return self._network\n\n    def init_network(self, checkpoint=\"best\", network: Optional[Any] = None) -&gt; Network:\n        \"\"\"Initialize the network.\n\n        Args:\n            checkpoint: Checkpoint identifier. Defaults to \"best\".\n            network: Existing network instance to use. Defaults to None.\n\n        Returns:\n            Network: Initialized network instance.\n        \"\"\"\n        checkpointed_network = self.network(checkpoint=checkpoint, network=network)\n\n        if checkpointed_network.network is not None:\n            return checkpointed_network.network\n        checkpointed_network.init()\n        return checkpointed_network.recover()\n\n    def init_decoder(self, checkpoint=\"best\", decoder=None):\n        \"\"\"Initialize the decoder.\n\n        Args:\n            checkpoint: Checkpoint identifier. Defaults to \"best\".\n            decoder: Existing decoder instance to use. Defaults to None.\n\n        Returns:\n            Decoder: Initialized decoder instance.\n        \"\"\"\n        checkpointed_network = self.network(checkpoint=checkpoint, lazy=True)\n        if (\n            self._initialized[\"decoder\"] == checkpointed_network.checkpoint\n            and decoder is None\n        ):\n            return self.decoder\n        self.decoder = decoder or init_decoder(\n            self.dir.config.task.decoder, self.connectome\n        )\n        recover_decoder(self.decoder, checkpointed_network.checkpoint)\n        self._initialized[\"decoder\"] = checkpointed_network.checkpoint\n        return self.decoder\n\n    def _resolve_dir(self, network_dir, root_dir):\n        \"\"\"Resolve the network directory.\n\n        Args:\n            network_dir: Network directory path or Directory instance.\n            root_dir: Root directory path.\n\n        Returns:\n            tuple: (Directory, str) - Network directory and name.\n\n        Raises:\n            ValueError: If the directory is not a NetworkDir.\n        \"\"\"\n        if isinstance(network_dir, (PathLike, str)):\n            with set_root_context(root_dir):\n                network_dir = Directory(network_dir)\n        if not network_dir.config.type == \"NetworkDir\":\n            raise ValueError(f\"NetworkDir not found at {network_dir.path}.\")\n        name = os.path.sep.join(network_dir.path.parts[-3:])\n        return network_dir, name\n\n    # --- stimulus responses\n\n    @wraps(stimulus_responses.flash_responses)\n    @context_aware_cache\n    def flash_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate flash responses.\"\"\"\n        return stimulus_responses.flash_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.moving_edge_responses)\n    @context_aware_cache\n    def moving_edge_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate moving edge responses.\"\"\"\n        return stimulus_responses.moving_edge_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses_currents.moving_edge_currents)\n    @context_aware_cache\n    def moving_edge_currents(\n        self, *args, **kwargs\n    ) -&gt; List[stimulus_responses_currents.ExperimentData]:\n        \"\"\"Generate moving edge currents.\"\"\"\n        return stimulus_responses_currents.moving_edge_currents(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.moving_bar_responses)\n    @context_aware_cache\n    def moving_bar_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate moving bar responses.\"\"\"\n        return stimulus_responses.moving_bar_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.naturalistic_stimuli_responses)\n    @context_aware_cache\n    def naturalistic_stimuli_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate naturalistic stimuli responses.\"\"\"\n        return stimulus_responses.naturalistic_stimuli_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.central_impulses_responses)\n    @context_aware_cache\n    def central_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate central ommatidium impulses responses.\"\"\"\n        return stimulus_responses.central_impulses_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.spatial_impulses_responses)\n    @context_aware_cache\n    def spatial_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n        \"\"\"Generate spatial ommatidium impulses responses.\"\"\"\n        return stimulus_responses.spatial_impulses_responses(self, *args, **kwargs)\n\n    @wraps(stimulus_responses.optimal_stimulus_responses)\n    @context_aware_cache\n    def optimal_stimulus_responses(\n        self, cell_type, *args, **kwargs\n    ) -&gt; optimal_stimuli.RegularizedOptimalStimulus:\n        \"\"\"Generate optimal stimuli responses.\"\"\"\n        return stimulus_responses.optimal_stimulus_responses(\n            self, cell_type, *args, **kwargs\n        )\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.get_checkpoint","title":"get_checkpoint","text":"<pre><code>get_checkpoint(checkpoint='best')\n</code></pre> <p>Return the best checkpoint index.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>Checkpoint identifier. Defaults to \u201cbest\u201d.</p> <code>'best'</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Path to the checkpoint.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>def get_checkpoint(self, checkpoint=\"best\"):\n    \"\"\"Return the best checkpoint index.\n\n    Args:\n        checkpoint: Checkpoint identifier. Defaults to \"best\".\n\n    Returns:\n        str: Path to the checkpoint.\n    \"\"\"\n    try:\n        if checkpoint == \"best\":\n            return self.best_checkpoint_fn(\n                self.dir.path,\n                **self.best_checkpoint_fn_kwargs,\n            )\n        return self.checkpoints.paths[checkpoint]\n    except FileNotFoundError:\n        logger.warning(\"Checkpoint %s not found at %s\", checkpoint, self.dir.path)\n        return None\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.network","title":"network","text":"<pre><code>network(checkpoint='best', network=None, lazy=False)\n</code></pre> <p>Lazy loading of network instance.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>Checkpoint identifier. Defaults to \u201cbest\u201d.</p> <code>'best'</code> <code>network</code> <code>Optional[Any]</code> <p>Existing network instance to use. Defaults to None.</p> <code>None</code> <code>lazy</code> <p>If True, don\u2019t recover the network immediately. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>CheckpointedNetwork</code> <code>CheckpointedNetwork</code> <p>Checkpointed network instance.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>def network(\n    self, checkpoint=\"best\", network: Optional[Any] = None, lazy=False\n) -&gt; CheckpointedNetwork:\n    \"\"\"Lazy loading of network instance.\n\n    Args:\n        checkpoint: Checkpoint identifier. Defaults to \"best\".\n        network: Existing network instance to use. Defaults to None.\n        lazy: If True, don't recover the network immediately. Defaults to False.\n\n    Returns:\n        CheckpointedNetwork: Checkpointed network instance.\n    \"\"\"\n    self._network = CheckpointedNetwork(\n        self.network_class,\n        self.dir.config.network.to_dict(),\n        self.name,\n        self.get_checkpoint(checkpoint),\n        self.recover_fn,\n        network=network or self._network.network,\n    )\n    if self._network.network is not None and not lazy:\n        self._network.recover()\n    return self._network\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.init_network","title":"init_network","text":"<pre><code>init_network(checkpoint='best', network=None)\n</code></pre> <p>Initialize the network.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>Checkpoint identifier. Defaults to \u201cbest\u201d.</p> <code>'best'</code> <code>network</code> <code>Optional[Any]</code> <p>Existing network instance to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Network</code> <code>Network</code> <p>Initialized network instance.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>def init_network(self, checkpoint=\"best\", network: Optional[Any] = None) -&gt; Network:\n    \"\"\"Initialize the network.\n\n    Args:\n        checkpoint: Checkpoint identifier. Defaults to \"best\".\n        network: Existing network instance to use. Defaults to None.\n\n    Returns:\n        Network: Initialized network instance.\n    \"\"\"\n    checkpointed_network = self.network(checkpoint=checkpoint, network=network)\n\n    if checkpointed_network.network is not None:\n        return checkpointed_network.network\n    checkpointed_network.init()\n    return checkpointed_network.recover()\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.init_decoder","title":"init_decoder","text":"<pre><code>init_decoder(checkpoint='best', decoder=None)\n</code></pre> <p>Initialize the decoder.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <p>Checkpoint identifier. Defaults to \u201cbest\u201d.</p> <code>'best'</code> <code>decoder</code> <p>Existing decoder instance to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Decoder</code> <p>Initialized decoder instance.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>def init_decoder(self, checkpoint=\"best\", decoder=None):\n    \"\"\"Initialize the decoder.\n\n    Args:\n        checkpoint: Checkpoint identifier. Defaults to \"best\".\n        decoder: Existing decoder instance to use. Defaults to None.\n\n    Returns:\n        Decoder: Initialized decoder instance.\n    \"\"\"\n    checkpointed_network = self.network(checkpoint=checkpoint, lazy=True)\n    if (\n        self._initialized[\"decoder\"] == checkpointed_network.checkpoint\n        and decoder is None\n    ):\n        return self.decoder\n    self.decoder = decoder or init_decoder(\n        self.dir.config.task.decoder, self.connectome\n    )\n    recover_decoder(self.decoder, checkpointed_network.checkpoint)\n    self._initialized[\"decoder\"] = checkpointed_network.checkpoint\n    return self.decoder\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.flash_responses","title":"flash_responses","text":"<pre><code>flash_responses(*args, **kwargs)\n</code></pre> <p>Generate flash responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.flash_responses)\n@context_aware_cache\ndef flash_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate flash responses.\"\"\"\n    return stimulus_responses.flash_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.moving_edge_responses","title":"moving_edge_responses","text":"<pre><code>moving_edge_responses(*args, **kwargs)\n</code></pre> <p>Generate moving edge responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.moving_edge_responses)\n@context_aware_cache\ndef moving_edge_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate moving edge responses.\"\"\"\n    return stimulus_responses.moving_edge_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.moving_edge_currents","title":"moving_edge_currents","text":"<pre><code>moving_edge_currents(*args, **kwargs)\n</code></pre> <p>Generate moving edge currents.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses_currents.moving_edge_currents)\n@context_aware_cache\ndef moving_edge_currents(\n    self, *args, **kwargs\n) -&gt; List[stimulus_responses_currents.ExperimentData]:\n    \"\"\"Generate moving edge currents.\"\"\"\n    return stimulus_responses_currents.moving_edge_currents(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.moving_bar_responses","title":"moving_bar_responses","text":"<pre><code>moving_bar_responses(*args, **kwargs)\n</code></pre> <p>Generate moving bar responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.moving_bar_responses)\n@context_aware_cache\ndef moving_bar_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate moving bar responses.\"\"\"\n    return stimulus_responses.moving_bar_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.naturalistic_stimuli_responses","title":"naturalistic_stimuli_responses","text":"<pre><code>naturalistic_stimuli_responses(*args, **kwargs)\n</code></pre> <p>Generate naturalistic stimuli responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.naturalistic_stimuli_responses)\n@context_aware_cache\ndef naturalistic_stimuli_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate naturalistic stimuli responses.\"\"\"\n    return stimulus_responses.naturalistic_stimuli_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.central_impulses_responses","title":"central_impulses_responses","text":"<pre><code>central_impulses_responses(*args, **kwargs)\n</code></pre> <p>Generate central ommatidium impulses responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.central_impulses_responses)\n@context_aware_cache\ndef central_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate central ommatidium impulses responses.\"\"\"\n    return stimulus_responses.central_impulses_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.spatial_impulses_responses","title":"spatial_impulses_responses","text":"<pre><code>spatial_impulses_responses(*args, **kwargs)\n</code></pre> <p>Generate spatial ommatidium impulses responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.spatial_impulses_responses)\n@context_aware_cache\ndef spatial_impulses_responses(self, *args, **kwargs) -&gt; xr.Dataset:\n    \"\"\"Generate spatial ommatidium impulses responses.\"\"\"\n    return stimulus_responses.spatial_impulses_responses(self, *args, **kwargs)\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.NetworkView.optimal_stimulus_responses","title":"optimal_stimulus_responses","text":"<pre><code>optimal_stimulus_responses(cell_type, *args, **kwargs)\n</code></pre> <p>Generate optimal stimuli responses.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@wraps(stimulus_responses.optimal_stimulus_responses)\n@context_aware_cache\ndef optimal_stimulus_responses(\n    self, cell_type, *args, **kwargs\n) -&gt; optimal_stimuli.RegularizedOptimalStimulus:\n    \"\"\"Generate optimal stimuli responses.\"\"\"\n    return stimulus_responses.optimal_stimulus_responses(\n        self, cell_type, *args, **kwargs\n    )\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.CheckpointedNetwork","title":"flyvis.network.network_view.CheckpointedNetwork  <code>dataclass</code>","text":"<p>A network representation with checkpoint that can be pickled.</p> <p>Attributes:</p> Name Type Description <code>network_class</code> <code>Any</code> <p>Network class (e.g., flyvis.Network).</p> <code>config</code> <code>Dict</code> <p>Configuration for the network.</p> <code>name</code> <code>str</code> <p>Name of the network.</p> <code>checkpoint</code> <code>PathLike</code> <p>Checkpoint path.</p> <code>recover_fn</code> <code>Any</code> <p>Function to recover the network.</p> <code>network</code> <code>Optional[Network]</code> <p>Network instance to avoid reinitialization.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>@dataclass\nclass CheckpointedNetwork:\n    \"\"\"A network representation with checkpoint that can be pickled.\n\n    Attributes:\n        network_class: Network class (e.g., flyvis.Network).\n        config: Configuration for the network.\n        name: Name of the network.\n        checkpoint: Checkpoint path.\n        recover_fn: Function to recover the network.\n        network: Network instance to avoid reinitialization.\n    \"\"\"\n\n    network_class: Any\n    config: Dict\n    name: str\n    checkpoint: PathLike\n    recover_fn: Any = recover_network\n    network: Optional[Network] = None\n\n    def init(self, eval: bool = True) -&gt; Network:\n        \"\"\"Initialize the network.\n\n        Args:\n            eval: Whether to set the network in evaluation mode.\n\n        Returns:\n            The initialized network.\n        \"\"\"\n        if self.network is None:\n            self.network = self.network_class(**self.config)\n        if eval:\n            self.network.eval()\n        return self.network\n\n    def recover(self, checkpoint: Optional[PathLike] = None) -&gt; Network:\n        \"\"\"Recover the network from the checkpoint.\n\n        Args:\n            checkpoint: Path to the checkpoint. If None, uses the default checkpoint.\n\n        Returns:\n            The recovered network.\n\n        Note:\n            Initializes the network if it hasn't been initialized yet.\n        \"\"\"\n        if self.network is None:\n            self.init()\n        return self.recover_fn(self.network, checkpoint or self.checkpoint)\n\n    def __repr__(self):\n        return (\n            f\"CheckpointedNetwork(\\n\"\n            f\"    network_class={self.network_class.__name__},\\n\"\n            f\"    name='{self.name}',\\n\"\n            f\"    config={pformat(self.config, indent=4)},\\n\"\n            f\"    checkpoint='{os.path.basename(str(self.checkpoint))}'\\n\"\n            f\"    recover_fn={self.recover_fn.__name__}\\n\"\n            f\")\"\n        )\n\n    def _hash_key(self):\n        return (\n            self.network_class,\n            self.name,\n            make_hashable(self.config),\n            self.checkpoint,\n            self.recover_fn.__name__,\n        )\n\n    def __hash__(self):\n        return hash(self._hash_key())\n\n    # Equality check based on hashable elements.\n    def __eq__(self, other):\n        if not isinstance(other, CheckpointedNetwork):\n            return False\n        return (\n            self.network_class == other.network_class\n            and self.name == other.name\n            and make_hashable(self.config) == make_hashable(other.config)\n            and self.checkpoint == other.checkpoint\n            and self.recover_fn.__name__ == other.recover_fn.__name__\n        )\n\n    # Custom reduce method to make the object compatible with joblib's pickling.\n    # This ensures the 'network' attribute is never pickled.\n    # Return a tuple containing:\n    # 1. A callable that will recreate the object (here, the class itself)\n    # 2. The arguments required to recreate the object (excluding the network)\n    # 3. The state, excluding the 'network' attribute\n    def __reduce__(self):\n        state = self.__dict__.copy()\n        state[\"network\"] = None  # Exclude the complex network from being pickled\n\n        return (\n            self.__class__,\n            (\n                self.network_class,\n                self.config,\n                self.checkpoint,\n                self.recover_fn.__name__,\n                None,\n            ),\n            state,\n        )\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self.network = None\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.CheckpointedNetwork.init","title":"init","text":"<pre><code>init(eval=True)\n</code></pre> <p>Initialize the network.</p> <p>Parameters:</p> Name Type Description Default <code>eval</code> <code>bool</code> <p>Whether to set the network in evaluation mode.</p> <code>True</code> <p>Returns:</p> Type Description <code>Network</code> <p>The initialized network.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>def init(self, eval: bool = True) -&gt; Network:\n    \"\"\"Initialize the network.\n\n    Args:\n        eval: Whether to set the network in evaluation mode.\n\n    Returns:\n        The initialized network.\n    \"\"\"\n    if self.network is None:\n        self.network = self.network_class(**self.config)\n    if eval:\n        self.network.eval()\n    return self.network\n</code></pre>"},{"location":"reference/network_view/#flyvis.network.network_view.CheckpointedNetwork.recover","title":"recover","text":"<pre><code>recover(checkpoint=None)\n</code></pre> <p>Recover the network from the checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[PathLike]</code> <p>Path to the checkpoint. If None, uses the default checkpoint.</p> <code>None</code> <p>Returns:</p> Type Description <code>Network</code> <p>The recovered network.</p> Note <p>Initializes the network if it hasn\u2019t been initialized yet.</p> Source code in <code>flyvis/network/network_view.py</code> <pre><code>def recover(self, checkpoint: Optional[PathLike] = None) -&gt; Network:\n    \"\"\"Recover the network from the checkpoint.\n\n    Args:\n        checkpoint: Path to the checkpoint. If None, uses the default checkpoint.\n\n    Returns:\n        The recovered network.\n\n    Note:\n        Initializes the network if it hasn't been initialized yet.\n    \"\"\"\n    if self.network is None:\n        self.init()\n    return self.recover_fn(self.network, checkpoint or self.checkpoint)\n</code></pre>"},{"location":"reference/optimal_stimuli/","title":"Optimal Stimuli","text":""},{"location":"reference/optimal_stimuli/#naturalistic","title":"Naturalistic","text":""},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.FindOptimalStimuli","title":"flyvis.analysis.optimal_stimuli.FindOptimalStimuli","text":"<p>Methods to derive optimal stimuli for cells from stimuli dataset.</p> <p>Parameters:</p> Name Type Description Default <code>network_view</code> <code>NetworkView</code> <p>Network view.</p> required <code>stimuli</code> <code>StimulusDataset | str</code> <p>Stimuli dataset. \u201cdefault\u201d uses AugmentedSintelLum.</p> <code>'default'</code> <p>Attributes:</p> Name Type Description <code>nv</code> <code>NetworkView</code> <p>Network view.</p> <code>network</code> <code>Network</code> <p>Initialized network.</p> <code>central_cells_index</code> <code>list</code> <p>Central cells index.</p> <code>stimuli</code> <code>StimulusDataset</code> <p>Stimulus dataset.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>class FindOptimalStimuli:\n    \"\"\"Methods to derive optimal stimuli for cells from stimuli dataset.\n\n    Args:\n        network_view: Network view.\n        stimuli: Stimuli dataset. \"default\" uses AugmentedSintelLum.\n\n    Attributes:\n        nv (flyvis.NetworkView): Network view.\n        network (flyvis.Network): Initialized network.\n        central_cells_index (list): Central cells index.\n        stimuli (StimulusDataset): Stimulus dataset.\n    \"\"\"\n\n    def __init__(\n        self,\n        network_view: flyvis.NetworkView,\n        stimuli: StimulusDataset | str = \"default\",\n    ):\n        self.nv = network_view\n        self.network = network_view.init_network()  # type: flyvis.Network\n        for param in self.network.parameters():\n            param.requires_grad = False\n        self.central_cells_index = self.network.connectome.central_cells_index[:]\n        self.stimuli = (\n            AugmentedSintel(tasks=[\"lum\"], dt=1 / 100, temporal_split=True)\n            if stimuli == \"default\"\n            else stimuli\n        )\n\n    def optimal_stimuli(\n        self,\n        cell_type: str,\n        dt: float = 1 / 100,\n        indices: list[int] | None = None,\n    ) -&gt; OptimalStimulus:\n        \"\"\"Finds optimal stimuli for a given cell type in stimuli dataset.\n\n        Args:\n            cell_type: Node type.\n            dt: Time step.\n            indices: Indices of stimuli.\n\n        Returns:\n            OptimalStimulus object containing the stimulus and response.\n        \"\"\"\n        responses = self.nv.naturalistic_stimuli_responses()\n        cell_responses = responses['responses'].custom.where(cell_type=cell_type)\n\n        argmax = cell_responses.argmax(dim=(\"sample\", \"frame\"))['sample'].item()\n        if indices is not None:\n            argmax = indices[argmax]\n        nat_opt_stim = self.stimuli[argmax][\"lum\"]\n\n        n_frames = nat_opt_stim.shape[0]\n        initial_state = self.network.steady_state(1.0, dt, 1)\n        stimulus = Stimulus(self.network.connectome, 1, n_frames)\n        stimulus.zero()\n        stimulus.add_input(nat_opt_stim[None])\n        response = self.network(stimulus(), dt, state=initial_state).detach().cpu()\n        response = LayerActivity(response, self.network.connectome, keepref=True)[\n            cell_type\n        ]\n\n        return OptimalStimulus(nat_opt_stim[None, :], response[:, :, None])\n\n    def regularized_optimal_stimuli(\n        self,\n        cell_type: str,\n        l2_act: float = 1,\n        lr: float = 1e-2,\n        l2_stim: float = 1,\n        n_iters: int = 100,\n        dt: float = 1 / 100,\n        indices: list[int] | None = None,\n    ) -&gt; RegularizedOptimalStimulus:\n        \"\"\"Regularizes the optimal stimulus for a given cell type.\n\n        Maintains central node activity while minimizing mean square of input pixels.\n\n        Args:\n            cell_type: Node type.\n            l2_act: L2 regularization strength for the activity.\n            lr: Learning rate.\n            l2_stim: L2 regularization strength for the stimulus.\n            n_iters: Number of iterations.\n            dt: Time step.\n            indices: Indices of stimuli.\n\n        Returns:\n            RegularizedOptimalStimulus object.\n        \"\"\"\n\n        optim_stimuli = self.optimal_stimuli(\n            cell_type=cell_type,\n            dt=dt,\n            indices=indices,\n        )\n        non_nan = ~torch.isnan(\n            optim_stimuli.stimulus[0, :, 0, optim_stimuli.stimulus.shape[-1] // 2]\n        )\n        reg_opt_stim = optim_stimuli.stimulus.clone()\n        reg_opt_stim = reg_opt_stim[:, non_nan]\n        reg_opt_stim.requires_grad = True\n\n        central_target_response = (\n            optim_stimuli.response.to(non_nan.device)[\n                :, non_nan, :, optim_stimuli.response.shape[-1] // 2\n            ]\n            .clone()\n            .detach()\n            .squeeze()\n        )\n\n        optim = torch.optim.Adam([reg_opt_stim], lr=lr)\n\n        n_frames = reg_opt_stim.shape[1]\n\n        stim = Stimulus(self.network.connectome, 1, n_frames)\n\n        layer_activity = LayerActivity(None, self.network.connectome, keepref=True)\n\n        initial_state = self.network.steady_state(1.0, dt, 1)\n\n        losses = []\n        for _ in range(n_iters):\n            optim.zero_grad()\n            stim.zero()\n            stim.add_input(reg_opt_stim)\n            activities = self.network(stim(), dt, state=initial_state)\n            layer_activity.update(activities)\n            central_predicted_response = layer_activity.central[cell_type].squeeze()\n\n            act_loss = (\n                l2_act\n                * ((central_predicted_response - central_target_response) ** 2).sum()\n            )\n            stim_loss = l2_stim * ((reg_opt_stim - 0.5) ** 2).mean(dim=0).sum()\n            loss = act_loss + stim_loss\n            loss.backward(retain_graph=True)\n            optim.step()\n            losses.append(loss.detach().cpu().numpy().item())\n\n        stim.zero()\n        reg_opt_stim.requires_grad = False\n        stim.add_input(reg_opt_stim)\n        activities = self.network(stim(), dt, state=initial_state)\n        layer_activity.update(activities)\n\n        reg_opt_stim = reg_opt_stim.detach().cpu()\n        rnmei_response = layer_activity[cell_type].detach().cpu()\n        central_predicted_response = central_predicted_response.detach().cpu()\n        central_target_response = central_target_response.detach().cpu()\n        return RegularizedOptimalStimulus(\n            optim_stimuli,\n            reg_opt_stim,\n            rnmei_response,\n            central_predicted_response,\n            central_target_response,\n            losses,\n        )\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.FindOptimalStimuli.optimal_stimuli","title":"optimal_stimuli","text":"<pre><code>optimal_stimuli(cell_type, dt=1 / 100, indices=None)\n</code></pre> <p>Finds optimal stimuli for a given cell type in stimuli dataset.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>Node type.</p> required <code>dt</code> <code>float</code> <p>Time step.</p> <code>1 / 100</code> <code>indices</code> <code>list[int] | None</code> <p>Indices of stimuli.</p> <code>None</code> <p>Returns:</p> Type Description <code>OptimalStimulus</code> <p>OptimalStimulus object containing the stimulus and response.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>def optimal_stimuli(\n    self,\n    cell_type: str,\n    dt: float = 1 / 100,\n    indices: list[int] | None = None,\n) -&gt; OptimalStimulus:\n    \"\"\"Finds optimal stimuli for a given cell type in stimuli dataset.\n\n    Args:\n        cell_type: Node type.\n        dt: Time step.\n        indices: Indices of stimuli.\n\n    Returns:\n        OptimalStimulus object containing the stimulus and response.\n    \"\"\"\n    responses = self.nv.naturalistic_stimuli_responses()\n    cell_responses = responses['responses'].custom.where(cell_type=cell_type)\n\n    argmax = cell_responses.argmax(dim=(\"sample\", \"frame\"))['sample'].item()\n    if indices is not None:\n        argmax = indices[argmax]\n    nat_opt_stim = self.stimuli[argmax][\"lum\"]\n\n    n_frames = nat_opt_stim.shape[0]\n    initial_state = self.network.steady_state(1.0, dt, 1)\n    stimulus = Stimulus(self.network.connectome, 1, n_frames)\n    stimulus.zero()\n    stimulus.add_input(nat_opt_stim[None])\n    response = self.network(stimulus(), dt, state=initial_state).detach().cpu()\n    response = LayerActivity(response, self.network.connectome, keepref=True)[\n        cell_type\n    ]\n\n    return OptimalStimulus(nat_opt_stim[None, :], response[:, :, None])\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.FindOptimalStimuli.regularized_optimal_stimuli","title":"regularized_optimal_stimuli","text":"<pre><code>regularized_optimal_stimuli(cell_type, l2_act=1, lr=0.01, l2_stim=1, n_iters=100, dt=1 / 100, indices=None)\n</code></pre> <p>Regularizes the optimal stimulus for a given cell type.</p> <p>Maintains central node activity while minimizing mean square of input pixels.</p> <p>Parameters:</p> Name Type Description Default <code>cell_type</code> <code>str</code> <p>Node type.</p> required <code>l2_act</code> <code>float</code> <p>L2 regularization strength for the activity.</p> <code>1</code> <code>lr</code> <code>float</code> <p>Learning rate.</p> <code>0.01</code> <code>l2_stim</code> <code>float</code> <p>L2 regularization strength for the stimulus.</p> <code>1</code> <code>n_iters</code> <code>int</code> <p>Number of iterations.</p> <code>100</code> <code>dt</code> <code>float</code> <p>Time step.</p> <code>1 / 100</code> <code>indices</code> <code>list[int] | None</code> <p>Indices of stimuli.</p> <code>None</code> <p>Returns:</p> Type Description <code>RegularizedOptimalStimulus</code> <p>RegularizedOptimalStimulus object.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>def regularized_optimal_stimuli(\n    self,\n    cell_type: str,\n    l2_act: float = 1,\n    lr: float = 1e-2,\n    l2_stim: float = 1,\n    n_iters: int = 100,\n    dt: float = 1 / 100,\n    indices: list[int] | None = None,\n) -&gt; RegularizedOptimalStimulus:\n    \"\"\"Regularizes the optimal stimulus for a given cell type.\n\n    Maintains central node activity while minimizing mean square of input pixels.\n\n    Args:\n        cell_type: Node type.\n        l2_act: L2 regularization strength for the activity.\n        lr: Learning rate.\n        l2_stim: L2 regularization strength for the stimulus.\n        n_iters: Number of iterations.\n        dt: Time step.\n        indices: Indices of stimuli.\n\n    Returns:\n        RegularizedOptimalStimulus object.\n    \"\"\"\n\n    optim_stimuli = self.optimal_stimuli(\n        cell_type=cell_type,\n        dt=dt,\n        indices=indices,\n    )\n    non_nan = ~torch.isnan(\n        optim_stimuli.stimulus[0, :, 0, optim_stimuli.stimulus.shape[-1] // 2]\n    )\n    reg_opt_stim = optim_stimuli.stimulus.clone()\n    reg_opt_stim = reg_opt_stim[:, non_nan]\n    reg_opt_stim.requires_grad = True\n\n    central_target_response = (\n        optim_stimuli.response.to(non_nan.device)[\n            :, non_nan, :, optim_stimuli.response.shape[-1] // 2\n        ]\n        .clone()\n        .detach()\n        .squeeze()\n    )\n\n    optim = torch.optim.Adam([reg_opt_stim], lr=lr)\n\n    n_frames = reg_opt_stim.shape[1]\n\n    stim = Stimulus(self.network.connectome, 1, n_frames)\n\n    layer_activity = LayerActivity(None, self.network.connectome, keepref=True)\n\n    initial_state = self.network.steady_state(1.0, dt, 1)\n\n    losses = []\n    for _ in range(n_iters):\n        optim.zero_grad()\n        stim.zero()\n        stim.add_input(reg_opt_stim)\n        activities = self.network(stim(), dt, state=initial_state)\n        layer_activity.update(activities)\n        central_predicted_response = layer_activity.central[cell_type].squeeze()\n\n        act_loss = (\n            l2_act\n            * ((central_predicted_response - central_target_response) ** 2).sum()\n        )\n        stim_loss = l2_stim * ((reg_opt_stim - 0.5) ** 2).mean(dim=0).sum()\n        loss = act_loss + stim_loss\n        loss.backward(retain_graph=True)\n        optim.step()\n        losses.append(loss.detach().cpu().numpy().item())\n\n    stim.zero()\n    reg_opt_stim.requires_grad = False\n    stim.add_input(reg_opt_stim)\n    activities = self.network(stim(), dt, state=initial_state)\n    layer_activity.update(activities)\n\n    reg_opt_stim = reg_opt_stim.detach().cpu()\n    rnmei_response = layer_activity[cell_type].detach().cpu()\n    central_predicted_response = central_predicted_response.detach().cpu()\n    central_target_response = central_target_response.detach().cpu()\n    return RegularizedOptimalStimulus(\n        optim_stimuli,\n        reg_opt_stim,\n        rnmei_response,\n        central_predicted_response,\n        central_target_response,\n        losses,\n    )\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.OptimalStimulus","title":"flyvis.analysis.optimal_stimuli.OptimalStimulus  <code>dataclass</code>","text":"<p>Optimal stimulus and response.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>@dataclass\nclass OptimalStimulus:\n    \"\"\"Optimal stimulus and response.\"\"\"\n\n    stimulus: np.ndarray\n    response: np.ndarray\n</code></pre>"},{"location":"reference/optimal_stimuli/#artificial","title":"Artificial","text":""},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.GeneratedOptimalStimulus","title":"flyvis.analysis.optimal_stimuli.GeneratedOptimalStimulus  <code>dataclass</code>","text":"<p>Generated optimal stimulus, response, and optimization losses.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>@dataclass\nclass GeneratedOptimalStimulus:\n    \"\"\"Generated optimal stimulus, response, and optimization losses.\"\"\"\n\n    stimulus: np.ndarray\n    response: np.ndarray\n    losses: np.ndarray\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.RegularizedOptimalStimulus","title":"flyvis.analysis.optimal_stimuli.RegularizedOptimalStimulus  <code>dataclass</code>","text":"<p>Regularized optimal stimulus and related data.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>@dataclass\nclass RegularizedOptimalStimulus:\n    \"\"\"Regularized optimal stimulus and related data.\"\"\"\n\n    stimulus: OptimalStimulus\n    regularized_stimulus: np.ndarray\n    response: np.ndarray\n    central_predicted_response: np.ndarray\n    central_target_response: np.ndarray\n    losses: np.ndarray\n</code></pre>"},{"location":"reference/optimal_stimuli/#visualization","title":"Visualization","text":""},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.StimResponsePlot","title":"flyvis.analysis.optimal_stimuli.StimResponsePlot  <code>dataclass</code>","text":"<p>Stimulus-response plot data and methods.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>@dataclass\nclass StimResponsePlot:\n    \"\"\"Stimulus-response plot data and methods.\"\"\"\n\n    stim: np.ndarray\n    response: np.ndarray\n    dt: float\n    u: np.ndarray\n    v: np.ndarray\n    time: np.ndarray\n    t_step: np.ndarray\n    t_steps_stim: np.ndarray\n    t_steps_response: np.ndarray\n    xmin_lattice: float\n    xmax_lattice: float\n    ymin_lattice: float\n    ymax_lattice: float\n    subtraced_baseline: bool\n    steps: int\n    fig: Any\n    axes: Any\n    time_axis: Any\n    trace_axis: Any\n    argmax: int\n    t_argmax: float\n\n    def __iter__(self):\n        \"\"\"Yield figure and axes.\"\"\"\n        yield from [self.fig, self.axes]\n\n    def add_to_trace_axis(\n        self,\n        other: \"StimResponsePlot\",\n        color: str | None = None,\n        label: str | None = None,\n        linewidth: float | None = None,\n    ):\n        \"\"\"Add another StimResponsePlot's trace to this plot's trace axis.\"\"\"\n        xticks = self.trace_axis.get_xticks()\n        mask = (other.time &gt;= other.t_step.min()) &amp; (other.time &lt;= other.t_step.max())\n        time = np.linspace(xticks.min(), xticks.max(), mask.sum())\n        self.trace_axis.plot(\n            time,\n            other.response[mask, other.response.shape[-1] // 2],\n            color=color,\n            label=label,\n            linewidth=linewidth,\n        )\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.StimResponsePlot.__iter__","title":"__iter__","text":"<pre><code>__iter__()\n</code></pre> <p>Yield figure and axes.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>def __iter__(self):\n    \"\"\"Yield figure and axes.\"\"\"\n    yield from [self.fig, self.axes]\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.StimResponsePlot.add_to_trace_axis","title":"add_to_trace_axis","text":"<pre><code>add_to_trace_axis(other, color=None, label=None, linewidth=None)\n</code></pre> <p>Add another StimResponsePlot\u2019s trace to this plot\u2019s trace axis.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>def add_to_trace_axis(\n    self,\n    other: \"StimResponsePlot\",\n    color: str | None = None,\n    label: str | None = None,\n    linewidth: float | None = None,\n):\n    \"\"\"Add another StimResponsePlot's trace to this plot's trace axis.\"\"\"\n    xticks = self.trace_axis.get_xticks()\n    mask = (other.time &gt;= other.t_step.min()) &amp; (other.time &lt;= other.t_step.max())\n    time = np.linspace(xticks.min(), xticks.max(), mask.sum())\n    self.trace_axis.plot(\n        time,\n        other.response[mask, other.response.shape[-1] // 2],\n        color=color,\n        label=label,\n        linewidth=linewidth,\n    )\n</code></pre>"},{"location":"reference/optimal_stimuli/#flyvis.analysis.optimal_stimuli.plot_stim_response","title":"flyvis.analysis.optimal_stimuli.plot_stim_response","text":"<pre><code>plot_stim_response(stim, response, dt, u, v, max_extent=6, subtract_baseline=True, seconds=0.2, steps=10, columns=10, suptitle='', plot_resp=True, hlines=True, vlines=True, time_axis=True, peak_central=False, wspace=-0.2, peak_last=True, fontsize=5, ylabel='', ylabelrotation=90, figsize=[5, 1], label_peak_response=False, fig=None, axes=None, crange=None, trace_axis=False, trace_label=None, trace_axis_offset=0.1, trace_color=None)\n</code></pre> <p>Plot spatio-temporal stimulus and response on regular hex lattices.</p> <p>Parameters:</p> Name Type Description Default <code>stim</code> <code>ndarray</code> <p>Stimulus array.</p> required <code>response</code> <code>ndarray</code> <p>Response array.</p> required <code>dt</code> <code>float</code> <p>Time step.</p> required <code>u</code> <code>ndarray</code> <p>Hexagonal u-coordinates.</p> required <code>v</code> <code>ndarray</code> <p>Hexagonal v-coordinates.</p> required <code>max_extent</code> <code>int</code> <p>Maximum extent of the hexagonal grid.</p> <code>6</code> <code>subtract_baseline</code> <code>bool</code> <p>Whether to subtract baseline from response.</p> <code>True</code> <code>seconds</code> <code>float</code> <p>Duration to plot in seconds.</p> <code>0.2</code> <code>steps</code> <code>int</code> <p>Number of time steps to plot.</p> <code>10</code> <code>columns</code> <code>int</code> <p>Number of columns in the plot.</p> <code>10</code> <code>suptitle</code> <code>str</code> <p>Super title for the plot.</p> <code>''</code> <code>plot_resp</code> <code>bool</code> <p>Whether to plot response.</p> <code>True</code> <code>hlines</code> <code>bool</code> <p>Whether to plot horizontal lines.</p> <code>True</code> <code>vlines</code> <code>bool</code> <p>Whether to plot vertical lines.</p> <code>True</code> <code>time_axis</code> <code>bool</code> <p>Whether to add a time axis.</p> <code>True</code> <code>peak_central</code> <code>bool</code> <p>Whether to center the plot around the peak.</p> <code>False</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>-0.2</code> <code>peak_last</code> <code>bool</code> <p>Whether to show the peak in the last frame.</p> <code>True</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and titles.</p> <code>5</code> <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> <code>''</code> <code>ylabelrotation</code> <code>int</code> <p>Rotation angle for y-axis label.</p> <code>90</code> <code>figsize</code> <code>list[float]</code> <p>Figure size.</p> <code>[5, 1]</code> <code>label_peak_response</code> <code>bool</code> <p>Whether to label the peak response.</p> <code>False</code> <code>fig</code> <code>Figure | None</code> <p>Existing figure to plot on.</p> <code>None</code> <code>axes</code> <code>ndarray | None</code> <p>Existing axes to plot on.</p> <code>None</code> <code>crange</code> <code>float | None</code> <p>Color range for the plot.</p> <code>None</code> <code>trace_axis</code> <code>bool</code> <p>Whether to add a trace axis.</p> <code>False</code> <code>trace_label</code> <code>str | None</code> <p>Label for the trace.</p> <code>None</code> <code>trace_axis_offset</code> <code>float</code> <p>Offset for the trace axis.</p> <code>0.1</code> <code>trace_color</code> <code>str | None</code> <p>Color for the trace.</p> <code>None</code> <p>Returns:</p> Type Description <code>StimResponsePlot</code> <p>StimResponsePlot object containing plot data and figure.</p> Source code in <code>flyvis/analysis/optimal_stimuli.py</code> <pre><code>def plot_stim_response(\n    stim: np.ndarray,\n    response: np.ndarray,\n    dt: float,\n    u: np.ndarray,\n    v: np.ndarray,\n    max_extent: int = 6,\n    subtract_baseline: bool = True,\n    seconds: float = 0.2,\n    steps: int = 10,\n    columns: int = 10,\n    suptitle: str = \"\",\n    plot_resp: bool = True,\n    hlines: bool = True,\n    vlines: bool = True,\n    time_axis: bool = True,\n    peak_central: bool = False,\n    wspace: float = -0.2,\n    peak_last: bool = True,\n    fontsize: int = 5,\n    ylabel: str = \"\",\n    ylabelrotation: int = 90,\n    figsize: list[float] = [5, 1],\n    label_peak_response: bool = False,\n    fig: plt.Figure | None = None,\n    axes: np.ndarray | None = None,\n    crange: float | None = None,\n    trace_axis: bool = False,\n    trace_label: str | None = None,\n    trace_axis_offset: float = 0.1,\n    trace_color: str | None = None,\n) -&gt; StimResponsePlot:\n    \"\"\"Plot spatio-temporal stimulus and response on regular hex lattices.\n\n    Args:\n        stim: Stimulus array.\n        response: Response array.\n        dt: Time step.\n        u: Hexagonal u-coordinates.\n        v: Hexagonal v-coordinates.\n        max_extent: Maximum extent of the hexagonal grid.\n        subtract_baseline: Whether to subtract baseline from response.\n        seconds: Duration to plot in seconds.\n        steps: Number of time steps to plot.\n        columns: Number of columns in the plot.\n        suptitle: Super title for the plot.\n        plot_resp: Whether to plot response.\n        hlines: Whether to plot horizontal lines.\n        vlines: Whether to plot vertical lines.\n        time_axis: Whether to add a time axis.\n        peak_central: Whether to center the plot around the peak.\n        wspace: Width space between subplots.\n        peak_last: Whether to show the peak in the last frame.\n        fontsize: Font size for labels and titles.\n        ylabel: Y-axis label.\n        ylabelrotation: Rotation angle for y-axis label.\n        figsize: Figure size.\n        label_peak_response: Whether to label the peak response.\n        fig: Existing figure to plot on.\n        axes: Existing axes to plot on.\n        crange: Color range for the plot.\n        trace_axis: Whether to add a trace axis.\n        trace_label: Label for the trace.\n        trace_axis_offset: Offset for the trace axis.\n        trace_color: Color for the trace.\n\n    Returns:\n        StimResponsePlot object containing plot data and figure.\n    \"\"\"\n    stim = tensor_utils.to_numpy(stim).squeeze()\n    mask = ~np.isnan(stim).any(axis=-1).squeeze()\n    response = tensor_utils.to_numpy(response).squeeze()\n    stim = stim[mask]\n    response = response[mask]\n\n    if subtract_baseline:\n        response -= response[0]\n\n    argmax = np.nanargmax(response[:, response.shape[-1] // 2])\n\n    n_frames = response.shape[0]\n    time = np.arange(n_frames) * dt\n    steps = int(seconds / dt)\n    t_argmax = time[argmax]\n\n    if peak_central:\n        start = argmax - steps // 2\n        end = argmax + steps // 2\n        if start &lt; 0:\n            start = 0\n            end = steps\n        peak_last = False\n\n    if peak_last:\n        start = argmax - steps\n        end = argmax\n        if start &lt; 0:\n            start = 0\n            end = steps\n\n    _t_steps = time[start:end]\n\n    # resample in time in case seconds, number of columns, dt does not match\n    time_index = np.linspace(0, len(_t_steps), 2 * columns, endpoint=False).astype(int)\n    _t_steps = _t_steps[time_index]\n\n    # breakpoint()\n    t_steps_stim = _t_steps[0::2]\n    t_steps_resp = _t_steps[1::2]\n\n    _u, _v = hex_utils.get_hex_coords(max_extent)\n    x, y = hex_utils.hex_to_pixel(_u, _v)\n    xmin, xmax = x.min(), x.max()\n    ymin, ymax = y.min(), y.max()\n    elev = 0\n    azim = 0\n\n    if fig is None or axes is None:\n        if plot_resp:\n            x, y = hex_utils.hex_rows(2, columns)\n            fig, axes, pos = plt_utils.ax_scatter(\n                x,\n                y,\n                figsize=figsize,\n                hpad=0,\n                wpad=0.07,\n                wspace=-0.7,\n                hspace=-0.5,\n            )\n            axes = np.array(axes).reshape(2, columns)\n\n        else:\n            fig, axes = plt_utils.divide_figure_to_grid(\n                np.arange(10).reshape(1, 10),\n                wspace=wspace,\n                as_matrix=True,\n                figsize=figsize,\n            )\n\n    crange = crange or np.abs(np.nanmax(response))\n    for i, t in enumerate(t_steps_stim):\n        # plot stimulus\n        mask = np.where(np.abs(time - t) &lt;= 1e-15, True, False)\n        _stim = stim[mask].squeeze()\n        plots.quick_hex_scatter(\n            _stim,\n            vmin=0,\n            vmax=1,\n            cbar=False,\n            max_extent=max_extent,\n            fig=fig,\n            ax=axes[0, i],\n        )\n\n        if hlines:\n            axes[0, i].hlines(elev, xmin, xmax, color=\"#006400\", linewidth=0.25)\n        if vlines:\n            axes[0, i].vlines(azim, ymin, ymax, color=\"#006400\", linewidth=0.25)\n\n        if plot_resp:\n            # --- plot response\n\n            mask = np.where(np.abs(time - t_steps_resp[i]) &lt;= 1e-15, True, False)\n            _resp = response[mask].squeeze()\n            plots.hex_scatter(\n                u,\n                v,\n                _resp,\n                fill=True,\n                # edgecolor=\"0.3\",\n                # edgewidth=0.1,\n                cmap=plt.cm.coolwarm,\n                vmin=-crange,\n                vmax=crange,\n                midpoint=0,\n                cbar=False,\n                max_extent=max_extent,\n                fig=fig,\n                ax=axes[1, i],\n            )\n            if t_steps_resp[i] == t_argmax and label_peak_response:\n                axes[1, i].set_title(\"peak\", fontsize=fontsize)\n\n            if hlines:\n                axes[1, i].hlines(elev, xmin, xmax, color=\"#006400\", linewidth=0.25)\n            if vlines:\n                axes[1, i].vlines(azim, ymin, ymax, color=\"#006400\", linewidth=0.25)\n\n    if trace_axis:\n        left = fig.transFigure.inverted().transform(\n            axes[0, 0].transData.transform((0, 0))\n        )[0]\n        right = fig.transFigure.inverted().transform(\n            axes[-1, -1].transData.transform((0, 0))\n        )[0]\n\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n\n        trace_axis = fig.add_axes(\n            (\n                left,\n                bottoms.min() - trace_axis_offset,\n                right - left,\n                trace_axis_offset - 0.05 * trace_axis_offset,\n            ),\n            label=\"trace_axis\",\n        )\n        plt_utils.rm_spines(\n            trace_axis, (\"top\", \"right\"), rm_yticks=False, rm_xticks=False\n        )\n\n        data_centers_in_points = np.array([\n            ax.transData.transform((0, 0)) for ax in axes.flatten(order=\"F\")\n        ])\n        trace_axis.tick_params(axis=\"both\", labelsize=fontsize)\n        if plot_resp:\n            xticks = trace_axis.transData.inverted().transform(data_centers_in_points)[\n                1::2, 0\n            ]\n            trace_axis.set_xticks(xticks)\n            ticklabels = np.round(_t_steps * 1000, 0)\n            trace_axis.set_xticklabels((ticklabels - ticklabels.max())[1::2])\n        else:\n            xticks = trace_axis.transData.inverted().transform(data_centers_in_points)[\n                :, 0\n            ]\n            trace_axis.set_xticks(xticks)\n            ticklabels = np.round(t_steps_stim * 1000, 0)\n            trace_axis.set_xticklabels((ticklabels - ticklabels.max()))\n        trace_axis.set_xlabel(\"time (ms)\", fontsize=fontsize, labelpad=2)\n        plt_utils.set_spine_tick_params(\n            trace_axis,\n            spinewidth=0.25,\n            tickwidth=0.25,\n            ticklength=3,\n            ticklabelpad=2,\n            spines=(\"top\", \"right\", \"bottom\", \"left\"),\n        )\n        xlim = trace_axis.get_xlim()\n        mask = (time &gt;= _t_steps.min()) &amp; (time &lt;= _t_steps.max())\n\n        time = np.linspace(xticks.min(), xticks.max(), mask.sum())\n\n        trace_axis.plot(\n            time,\n            response[mask, response.shape[-1] // 2],\n            label=trace_label,\n            color=trace_color,\n        )\n        trace_axis.set_xlim(*xlim)\n        trace_axis.set_ylabel(\"central\\nresponse\", fontsize=fontsize)\n        # flyvis.plots.trim_axis(trace_axis)\n\n        time_axis = False\n\n    if time_axis:\n        left = fig.transFigure.inverted().transform(\n            axes[0, 0].transData.transform((0, 0))\n        )[0]\n        right = fig.transFigure.inverted().transform(\n            axes[-1, -1].transData.transform((0, 0))\n        )[0]\n\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n\n        time_axis = fig.add_axes((left, bottoms.min(), right - left, 0.01))\n        plt_utils.rm_spines(\n            time_axis, (\"left\", \"top\", \"right\"), rm_yticks=True, rm_xticks=False\n        )\n\n        data_centers_in_points = np.array([\n            ax.transData.transform((0, 0)) for ax in axes.flatten(order=\"F\")\n        ])\n        time_axis.tick_params(axis=\"both\", labelsize=fontsize)\n        if plot_resp:\n            time_axis.set_xticks(\n                time_axis.transData.inverted().transform(data_centers_in_points)[1::2, 0]\n            )\n            ticklabels = np.round(_t_steps * 1000, 0)\n            time_axis.set_xticklabels((ticklabels - ticklabels.max())[1::2])\n        else:\n            time_axis.set_xticks(\n                time_axis.transData.inverted().transform(data_centers_in_points)[:, 0]\n            )\n            ticklabels = np.round(t_steps_stim * 1000, 0)\n            time_axis.set_xticklabels((ticklabels - ticklabels.max()))\n        time_axis.set_xlabel(\"time (ms)\", fontsize=fontsize, labelpad=2)\n        plt_utils.set_spine_tick_params(\n            time_axis,\n            spinewidth=0.25,\n            tickwidth=0.25,\n            ticklength=3,\n            ticklabelpad=2,\n            spines=(\"top\", \"right\", \"bottom\", \"left\"),\n        )\n\n    if ylabel:\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n        ylabel_axis = fig.add_axes((\n            lefts.min(),\n            bottoms.min(),\n            0.01,\n            tops.max() - bottoms.min(),\n        ))\n        plt_utils.rm_spines(\n            ylabel_axis,\n            (\"left\", \"top\", \"right\", \"bottom\"),\n            rm_yticks=True,\n            rm_xticks=True,\n        )\n        ylabel_axis.set_ylabel(ylabel, fontsize=fontsize, rotation=ylabelrotation)\n        ylabel_axis.patch.set_alpha(0)\n\n    if plot_resp and ylabel is not None:\n        axes[0, 0].annotate(\n            \"stimulus\",\n            xy=(0, 0.5),\n            ha=\"right\",\n            va=\"center\",\n            fontsize=fontsize,\n            rotation=90,\n            xycoords=\"axes fraction\",\n        )\n        axes[1, 0].annotate(\n            \"response\",\n            xy=(0, 0.5),\n            ha=\"right\",\n            va=\"center\",\n            fontsize=fontsize,\n            rotation=90,\n            xycoords=\"axes fraction\",\n        )\n\n    if suptitle:\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n        fig.suptitle(suptitle, fontsize=fontsize, y=tops.max(), va=\"bottom\")\n\n    plt_utils.set_spine_tick_params(\n        fig.axes[-1],\n        spinewidth=0.25,\n        tickwidth=0.25,\n        ticklength=3,\n        ticklabelpad=2,\n        spines=(\"top\", \"right\", \"bottom\", \"left\"),\n    )\n\n    fig.crange = crange\n\n    return StimResponsePlot(\n        stim,\n        response,\n        dt,\n        u,\n        v,\n        time,\n        _t_steps,\n        t_steps_stim,\n        t_steps_resp,\n        xmin,\n        xmax,\n        ymin,\n        ymax,\n        subtract_baseline,\n        steps,\n        fig,\n        axes,\n        time_axis,\n        trace_axis,\n        argmax,\n        t_argmax,\n    )\n</code></pre>"},{"location":"reference/rendering/","title":"Rendering","text":""},{"location":"reference/rendering/#boxeye","title":"BoxEye","text":""},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.BoxEye","title":"flyvis.datasets.rendering.eye.BoxEye","text":"<p>BoxFilter to produce an array of hexals matching the photoreceptor array.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Radius, in number of receptors, of the hexagonal array.</p> <code>15</code> <code>kernel_size</code> <code>int</code> <p>Photon collection radius, in pixels.</p> <code>13</code> <p>Attributes:</p> Name Type Description <code>extent</code> <code>int</code> <p>Radius, in number of receptors, of the hexagonal array.</p> <code>kernel_size</code> <code>int</code> <p>Photon collection radius, in pixels.</p> <code>receptor_centers</code> <code>Tensor</code> <p>Tensor of shape (hexals, 2) containing the y, x coordinates of the hexal centers.</p> <code>hexals</code> <code>int</code> <p>Number of hexals in the array.</p> <code>min_frame_size</code> <code>Tensor</code> <p>Minimum frame size to contain the hexal array.</p> <code>pad</code> <code>Tuple[int, int, int, int]</code> <p>Padding to apply to the frame before convolution.</p> <code>conv</code> <code>Conv2d</code> <p>Convolutional box filter to apply to the frame.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>class BoxEye:\n    \"\"\"BoxFilter to produce an array of hexals matching the photoreceptor array.\n\n    Args:\n        extent: Radius, in number of receptors, of the hexagonal array.\n        kernel_size: Photon collection radius, in pixels.\n\n    Attributes:\n        extent (int): Radius, in number of receptors, of the hexagonal array.\n        kernel_size (int): Photon collection radius, in pixels.\n        receptor_centers (torch.Tensor): Tensor of shape (hexals, 2) containing the y, x\n            coordinates of the hexal centers.\n        hexals (int): Number of hexals in the array.\n        min_frame_size (torch.Tensor): Minimum frame size to contain the hexal array.\n        pad (Tuple[int, int, int, int]): Padding to apply to the frame before convolution.\n        conv (nn.Conv2d): Convolutional box filter to apply to the frame.\n    \"\"\"\n\n    def __init__(self, extent: int = 15, kernel_size: int = 13):\n        self.extent = extent\n        self.kernel_size = kernel_size\n        self.receptor_centers = torch.tensor(\n            [*self._receptor_centers()], dtype=torch.long\n        )\n        self.hexals = len(self.receptor_centers)\n        # The rest of kernel_size distance from outer centers to the border\n        # is taken care of by the padding of the convolution object.\n        self.min_frame_size = (\n            self.receptor_centers.max(dim=0).values\n            - self.receptor_centers.min(dim=0).values\n            + 1\n        )\n        self._set_filter()\n\n        pad = (self.kernel_size - 1) / 2\n        self.pad = (\n            int(np.ceil(pad)),\n            int(np.floor(pad)),\n            int(np.ceil(pad)),\n            int(np.floor(pad)),\n        )\n\n    def _receptor_centers(self) -&gt; Iterator[Tuple[float, float]]:\n        \"\"\"Generate receptor center coordinates.\n\n        Returns:\n            Iterator[Tuple[float, float]]: Yields y, x coordinates of receptor centers.\n        \"\"\"\n        n = self.extent\n        d = self.kernel_size\n        for u in range(-n, n + 1):\n            v_min = max(-n, -n - u)\n            v_max = min(n, n - u)\n            for v in range(v_min, v_max + 1):\n                # y = -d * v\n                # x = 2 / np.sqrt(3) * d * (u + v/2)\n                y = d * (\n                    u + v / 2\n                )  # - d * v # either must be negative or origin must be upper\n                x = d * v  # 2 / np.sqrt(3) * d * (u + v / 2)\n                yield y, x\n                # xs.append()\n                # ys.append()\n\n    def _set_filter(self) -&gt; None:\n        \"\"\"Set up the convolutional filter for the box kernel.\"\"\"\n        self.conv = nn.Conv2d(1, 1, kernel_size=self.kernel_size, stride=1, padding=0)\n        self.conv.weight.data /= self.conv.weight.data\n        self.conv.bias.data.fill_(0)  # if not self.requires_grad else None\n        self.conv.weight.requires_grad = False  # self.requires_grad\n        self.conv.bias.requires_grad = False  # self.requires_grad\n\n    def __call__(\n        self,\n        sequence: torch.Tensor,\n        ftype: Literal[\"mean\", \"sum\", \"median\"] = \"mean\",\n        hex_sample: bool = True,\n    ) -&gt; torch.Tensor:\n        \"\"\"Apply a box kernel to all frames in a sequence.\n\n        Args:\n            sequence: Cartesian movie sequences of shape (samples, frames, height, width).\n            ftype: Filter type.\n            hex_sample: If False, returns filtered cartesian sequences.\n\n        Returns:\n            torch.Tensor: Shape (samples, frames, 1, hexals) if hex_sample is True,\n                otherwise (samples, frames, height, width).\n        \"\"\"\n        samples, frames, height, width = sequence.shape\n\n        if not isinstance(sequence, torch.Tensor):\n            # auto-moving to GPU in case default tensor is cuda but passed\n            # sequence is not, for convenience\n            sequence = torch.tensor(sequence, dtype=torch.float32, device=flyvis.device)\n\n        if (self.min_frame_size &gt; torch.tensor([height, width])).any():\n            # to rescale to the minimum frame size\n            sequence = ttf.resize(sequence, self.min_frame_size.tolist())\n            height, width = sequence.shape[2:]\n\n        def _convolve():\n            # convole each sample sequentially to avoid gpu memory issues\n            def conv(x):\n                return self.conv(x.unsqueeze(1))\n\n            return torch.cat(\n                tuple(map(conv, torch.unbind(F.pad(sequence, self.pad), dim=0))), dim=0\n            )\n\n        if ftype == \"mean\":\n            out = _convolve() / self.kernel_size**2\n        elif ftype == \"sum\":\n            out = _convolve()\n        elif ftype == \"median\":\n            out = median(sequence, self.kernel_size)\n        else:\n            raise ValueError(\"ftype must be 'sum', 'mean', or 'median.\" f\"Is {ftype}.\")\n\n        if hex_sample is True:\n            return self.hex_render(out).reshape(samples, frames, 1, -1)\n\n        return out.reshape(samples, frames, height, width)\n\n    def hex_render(self, sequence: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Sample receptor locations from a sequence of cartesian frames.\n\n        Args:\n            sequence: Cartesian movie sequences of shape (samples, frames, height, width).\n\n        Returns:\n            torch.Tensor: Shape (samples, frames, 1, hexals).\n\n        Note:\n            Resizes the sequence to the minimum frame size if necessary.\n        \"\"\"\n        h, w = sequence.shape[2:]\n        if (self.min_frame_size &gt; torch.tensor([h, w])).any():\n            sequence = ttf.resize(sequence, self.min_frame_size.tolist())\n            h, w = sequence.shape[2:]\n        c = self.receptor_centers + torch.tensor([h // 2, w // 2])\n        out = sequence[:, :, c[:, 0], c[:, 1]]\n        return out.view(*sequence.shape[:2], 1, -1)\n\n    def illustrate(self) -&gt; plt.Figure:\n        \"\"\"Illustrate the receptive field centers and the hexagonal sampling.\n\n        Returns:\n            plt.Figure: Matplotlib figure object.\n        \"\"\"\n        figsize = [2, 2]\n        fontsize = 5\n        y_hc, x_hc = np.array(list(self._receptor_centers())).T\n\n        height, width = self.min_frame_size.cpu().numpy()\n        x_img, y_img = np.array(\n            list(\n                product(\n                    np.arange(-width / 2, width / 2),\n                    np.arange(-height / 2, height / 2),\n                )\n            )\n        ).T\n\n        r = np.sqrt(2) * self.kernel_size / 2\n\n        vertices = []\n        angles = [45, 135, 225, 315, 405]\n        for _y_c, _x_c in zip(y_hc, x_hc):\n            _vertices = []\n            for angle in angles:\n                offset = r * np.exp(np.radians(angle) * 1j)\n                _vertices.append([_y_c + offset.real, _x_c + offset.imag])\n            vertices.append(_vertices)\n        vertices = np.transpose(vertices, (1, 2, 0))\n\n        fig, ax = init_plot(figsize=figsize, fontsize=fontsize)\n        ax.scatter(x_hc, y_hc, color=\"#00008B\", zorder=1, s=0.5)\n        ax.scatter(x_img, y_img, color=\"#34ebd6\", s=0.1, zorder=0)\n\n        for h in range(len(x_hc)):\n            for i in range(4):\n                y1, x1 = vertices[i, :, h]  # x1, y1: (n_hexagons)\n                y2, x2 = vertices[i + 1, :, h]\n                ax.plot([x1, x2], [y1, y2], c=\"black\", lw=0.25)\n\n        ax.set_xlim(-width / 2, width / 2)\n        ax.set_ylim(-height / 2, height / 2)\n        rm_spines(ax)\n        # fig.tight_layout()\n        return fig\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.BoxEye.__call__","title":"__call__","text":"<pre><code>__call__(sequence, ftype='mean', hex_sample=True)\n</code></pre> <p>Apply a box kernel to all frames in a sequence.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Tensor</code> <p>Cartesian movie sequences of shape (samples, frames, height, width).</p> required <code>ftype</code> <code>Literal['mean', 'sum', 'median']</code> <p>Filter type.</p> <code>'mean'</code> <code>hex_sample</code> <code>bool</code> <p>If False, returns filtered cartesian sequences.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Shape (samples, frames, 1, hexals) if hex_sample is True, otherwise (samples, frames, height, width).</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def __call__(\n    self,\n    sequence: torch.Tensor,\n    ftype: Literal[\"mean\", \"sum\", \"median\"] = \"mean\",\n    hex_sample: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Apply a box kernel to all frames in a sequence.\n\n    Args:\n        sequence: Cartesian movie sequences of shape (samples, frames, height, width).\n        ftype: Filter type.\n        hex_sample: If False, returns filtered cartesian sequences.\n\n    Returns:\n        torch.Tensor: Shape (samples, frames, 1, hexals) if hex_sample is True,\n            otherwise (samples, frames, height, width).\n    \"\"\"\n    samples, frames, height, width = sequence.shape\n\n    if not isinstance(sequence, torch.Tensor):\n        # auto-moving to GPU in case default tensor is cuda but passed\n        # sequence is not, for convenience\n        sequence = torch.tensor(sequence, dtype=torch.float32, device=flyvis.device)\n\n    if (self.min_frame_size &gt; torch.tensor([height, width])).any():\n        # to rescale to the minimum frame size\n        sequence = ttf.resize(sequence, self.min_frame_size.tolist())\n        height, width = sequence.shape[2:]\n\n    def _convolve():\n        # convole each sample sequentially to avoid gpu memory issues\n        def conv(x):\n            return self.conv(x.unsqueeze(1))\n\n        return torch.cat(\n            tuple(map(conv, torch.unbind(F.pad(sequence, self.pad), dim=0))), dim=0\n        )\n\n    if ftype == \"mean\":\n        out = _convolve() / self.kernel_size**2\n    elif ftype == \"sum\":\n        out = _convolve()\n    elif ftype == \"median\":\n        out = median(sequence, self.kernel_size)\n    else:\n        raise ValueError(\"ftype must be 'sum', 'mean', or 'median.\" f\"Is {ftype}.\")\n\n    if hex_sample is True:\n        return self.hex_render(out).reshape(samples, frames, 1, -1)\n\n    return out.reshape(samples, frames, height, width)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.BoxEye.hex_render","title":"hex_render","text":"<pre><code>hex_render(sequence)\n</code></pre> <p>Sample receptor locations from a sequence of cartesian frames.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Tensor</code> <p>Cartesian movie sequences of shape (samples, frames, height, width).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Shape (samples, frames, 1, hexals).</p> Note <p>Resizes the sequence to the minimum frame size if necessary.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def hex_render(self, sequence: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Sample receptor locations from a sequence of cartesian frames.\n\n    Args:\n        sequence: Cartesian movie sequences of shape (samples, frames, height, width).\n\n    Returns:\n        torch.Tensor: Shape (samples, frames, 1, hexals).\n\n    Note:\n        Resizes the sequence to the minimum frame size if necessary.\n    \"\"\"\n    h, w = sequence.shape[2:]\n    if (self.min_frame_size &gt; torch.tensor([h, w])).any():\n        sequence = ttf.resize(sequence, self.min_frame_size.tolist())\n        h, w = sequence.shape[2:]\n    c = self.receptor_centers + torch.tensor([h // 2, w // 2])\n    out = sequence[:, :, c[:, 0], c[:, 1]]\n    return out.view(*sequence.shape[:2], 1, -1)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.BoxEye.illustrate","title":"illustrate","text":"<pre><code>illustrate()\n</code></pre> <p>Illustrate the receptive field centers and the hexagonal sampling.</p> <p>Returns:</p> Type Description <code>Figure</code> <p>plt.Figure: Matplotlib figure object.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def illustrate(self) -&gt; plt.Figure:\n    \"\"\"Illustrate the receptive field centers and the hexagonal sampling.\n\n    Returns:\n        plt.Figure: Matplotlib figure object.\n    \"\"\"\n    figsize = [2, 2]\n    fontsize = 5\n    y_hc, x_hc = np.array(list(self._receptor_centers())).T\n\n    height, width = self.min_frame_size.cpu().numpy()\n    x_img, y_img = np.array(\n        list(\n            product(\n                np.arange(-width / 2, width / 2),\n                np.arange(-height / 2, height / 2),\n            )\n        )\n    ).T\n\n    r = np.sqrt(2) * self.kernel_size / 2\n\n    vertices = []\n    angles = [45, 135, 225, 315, 405]\n    for _y_c, _x_c in zip(y_hc, x_hc):\n        _vertices = []\n        for angle in angles:\n            offset = r * np.exp(np.radians(angle) * 1j)\n            _vertices.append([_y_c + offset.real, _x_c + offset.imag])\n        vertices.append(_vertices)\n    vertices = np.transpose(vertices, (1, 2, 0))\n\n    fig, ax = init_plot(figsize=figsize, fontsize=fontsize)\n    ax.scatter(x_hc, y_hc, color=\"#00008B\", zorder=1, s=0.5)\n    ax.scatter(x_img, y_img, color=\"#34ebd6\", s=0.1, zorder=0)\n\n    for h in range(len(x_hc)):\n        for i in range(4):\n            y1, x1 = vertices[i, :, h]  # x1, y1: (n_hexagons)\n            y2, x2 = vertices[i + 1, :, h]\n            ax.plot([x1, x2], [y1, y2], c=\"black\", lw=0.25)\n\n    ax.set_xlim(-width / 2, width / 2)\n    ax.set_ylim(-height / 2, height / 2)\n    rm_spines(ax)\n    # fig.tight_layout()\n    return fig\n</code></pre>"},{"location":"reference/rendering/#hexeye","title":"HexEye","text":""},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye","title":"flyvis.datasets.rendering.eye.HexEye","text":"<p>Hexagonal eye model for more precise rendering.</p> <p>Parameters:</p> Name Type Description Default <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia in the eye. Must currently fill a regular hex grid.</p> <code>721</code> <code>ppo</code> <code>int</code> <p>Pixels per ommatidium.</p> <code>25</code> <code>monitor_height_px</code> <code>Optional[int]</code> <p>Monitor height in pixels.</p> <code>None</code> <code>monitor_width_px</code> <code>Optional[int]</code> <p>Monitor width in pixels.</p> <code>None</code> <code>device</code> <code>device</code> <p>Computation device.</p> <code>device</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float16</code> <p>Attributes:</p> Name Type Description <code>monitor_width_px</code> <code>int</code> <p>Monitor width in pixels.</p> <code>monitor_height_px</code> <code>int</code> <p>Monitor height in pixels.</p> <code>is_inside</code> <code>Tensor</code> <p>Boolean mask for pixels inside hexagons.</p> <code>n_ommatidia</code> <code>int</code> <p>Number of ommatidia in the eye.</p> <code>omm_width_rad</code> <code>float</code> <p>Ommatidium width in radians.</p> <code>omm_height_rad</code> <code>float</code> <p>Ommatidium height in radians.</p> <code>ppo</code> <code>int</code> <p>Pixels per ommatidium.</p> <code>n_hex_circfer</code> <code>float</code> <p>Number of hexagons in the circumference.</p> <code>device</code> <code>device</code> <p>Computation device.</p> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>class HexEye:\n    \"\"\"Hexagonal eye model for more precise rendering.\n\n    Args:\n        n_ommatidia: Number of ommatidia in the eye. Must currently fill a regular\n            hex grid.\n        ppo: Pixels per ommatidium.\n        monitor_height_px: Monitor height in pixels.\n        monitor_width_px: Monitor width in pixels.\n        device: Computation device.\n        dtype: Data type for computations.\n\n    Attributes:\n        monitor_width_px (int): Monitor width in pixels.\n        monitor_height_px (int): Monitor height in pixels.\n        is_inside (torch.Tensor): Boolean mask for pixels inside hexagons.\n        n_ommatidia (int): Number of ommatidia in the eye.\n        omm_width_rad (float): Ommatidium width in radians.\n        omm_height_rad (float): Ommatidium height in radians.\n        ppo (int): Pixels per ommatidium.\n        n_hex_circfer (float): Number of hexagons in the circumference.\n        device (torch.device): Computation device.\n        dtype (torch.dtype): Data type for computations.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_ommatidia: int = 721,\n        ppo: int = 25,\n        monitor_height_px: Optional[int] = None,\n        monitor_width_px: Optional[int] = None,\n        device: torch.device = flyvis.device,\n        dtype: torch.dtype = torch.float16,\n    ):\n        n_hex_circfer = 2 * (-1 / 2 + np.sqrt(1 / 4 - ((1 - n_ommatidia) / 3))) + 1\n\n        if n_hex_circfer % 1 != 0:\n            raise ValueError(f\"{n_ommatidia} does not fill a regular hex grid.\")\n\n        self.monitor_width_px = monitor_width_px or ppo * int(n_hex_circfer)\n        self.monitor_height_px = monitor_height_px or ppo * int(n_hex_circfer)\n\n        x_hc, y_hc, (dist_w, dist_h) = hex_center_coordinates(\n            n_ommatidia, self.monitor_width_px, self.monitor_height_px\n        )\n\n        x_img, y_img = np.array(\n            list(\n                product(\n                    np.arange(self.monitor_width_px),\n                    np.arange(self.monitor_height_px),\n                )\n            )\n        ).T\n\n        dist_to_edge = (dist_w + dist_h) / 4\n\n        _, self.is_inside = is_inside_hex(\n            torch.tensor(y_img, dtype=dtype, device=device),\n            torch.tensor(x_img, dtype=dtype, device=device),\n            torch.tensor(x_hc, dtype=dtype, device=device),\n            torch.tensor(y_hc, dtype=dtype, device=device),\n            torch.tensor(dist_to_edge, dtype=dtype, device=device),\n            torch.tensor(np.radians(0), dtype=dtype, device=device),\n            device=device,\n            dtype=dtype,\n        )\n        self.kernel_sum = self.is_inside.sum(dim=0)\n        # Clean up excessive memory usage.\n        if device != \"cpu\":\n            torch.cuda.empty_cache()\n        self.n_ommatidia = n_ommatidia\n        self.omm_width_rad = np.radians(5.8)\n        self.omm_height_rad = np.radians(5.8)\n        self.ppo = ppo or int(\n            (self.monitor_width_px + self.monitor_width_px) / (2 * n_hex_circfer)\n        )\n        self.n_hex_circfer = n_hex_circfer\n        self.device = device\n        self.dtype = dtype\n\n    def __call__(\n        self,\n        stim: torch.Tensor,\n        mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n        n_chunks: int = 1,\n    ) -&gt; torch.Tensor:\n        \"\"\"Process stimulus through the hexagonal eye model.\n\n        Args:\n            stim: Input stimulus tensor (n_frames, height, width) or\n                (n_frames, height * width). Height and width must correspond to the\n                monitor size.\n            mode: Processing mode.\n            n_chunks: Number of chunks to process the stimulus in.\n\n        Returns:\n            torch.Tensor: Processed stimulus.\n        \"\"\"\n        shape = stim.shape\n        if mode not in [\"mean\", \"median\", \"sum\"]:\n            raise ValueError\n\n        if len(stim.shape) == 3:\n            h, w = stim.shape[1:]\n            # resize to monitor size if necessary\n            if h &lt; self.monitor_height_px or w &lt; self.monitor_width_px:\n                stim = ttf.resize(stim, [self.monitor_height_px, self.monitor_width_px])\n            stim = stim.reshape(shape[0], -1)\n\n        try:\n            if mode == \"median\":\n                n_pixels = shape[1]\n                stim = median(\n                    stim.view(-1, self.monitor_height_px, self.monitor_width_px)\n                    .float()\n                    .to(self.device),\n                    int(np.sqrt(self.ppo)),\n                ).view(-1, n_pixels)\n            elif mode == \"sum\":\n                return (stim[:, :, None] * self.is_inside).sum(dim=1)\n            elif mode == \"mean\":\n                return (stim[:, :, None] * self.is_inside).sum(dim=1) / self.kernel_sum\n            else:\n                raise ValueError(f\"Invalid mode: {mode}\")\n\n        except RuntimeError as e:\n            if \"memory\" not in str(e):\n                raise e\n            if \"CUDA\" in str(e):\n                torch.cuda.empty_cache()\n            if n_chunks &gt; shape[0]:\n                raise ValueError from e\n\n            chunks = torch.chunk(stim, max(n_chunks, 1), dim=0)\n\n            def map_fn(chunk):\n                return self(chunk, mode=mode, n_chunks=n_chunks + 1)\n\n            return torch.cat(tuple(map(map_fn, chunks)), dim=0)\n\n    # Rendering functions\n    # TODO: move to separate file and make agnostic of the eye model\n\n    def render_bar(\n        self,\n        bar_width_rad: float,\n        bar_height_rad: float,\n        bar_loc_theta: float,\n        bar_loc_phi: float,\n        n_bars: int,\n        bar_intensity: float,\n        bg_intensity: float,\n        moving_angle: float,\n        cartesian: bool = False,\n        mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        \"\"\"Render a bar stimulus.\n\n        Args:\n            bar_width_rad: Width of bars in radians.\n            bar_height_rad: Height of bars in radians.\n            bar_loc_theta: Horizontal location of bars in radians.\n            bar_loc_phi: Vertical location of bars in radians.\n            n_bars: Number of bars.\n            bar_intensity: Intensity of the bar.\n            bg_intensity: Intensity of the background.\n            moving_angle: Rotation angle in degrees.\n            cartesian: If True, return cartesian coordinates.\n            mode: Processing mode.\n\n        Returns:\n            Union[np.ndarray, torch.Tensor]: Generated bar stimulus.\n        \"\"\"\n        bar_width_px = int(bar_width_rad / self.omm_width_rad * self.ppo)\n        bar_height_px = int(bar_height_rad / self.omm_height_rad * self.ppo)\n        bar_loc_horizontal_px = int(\n            self.monitor_width_px * bar_loc_theta / np.radians(180)\n        )\n        bar_loc_vertical_px = int(self.monitor_height_px * bar_loc_phi / np.radians(180))\n\n        bar = render_bars_cartesian(\n            self.monitor_height_px,\n            self.monitor_width_px,\n            bar_width_px,\n            bar_height_px,\n            bar_loc_horizontal_px,\n            bar_loc_vertical_px,\n            n_bars,\n            bar_intensity,\n            bg_intensity,\n            moving_angle,\n        )\n        if cartesian:\n            return bar\n        return self(torch.tensor(bar.flatten(), device=self.device)[None], mode)\n\n    def render_grating(\n        self,\n        period_rad: float,\n        phase_rad: float,\n        intensity: float,\n        bg_intensity: float,\n        moving_angle: float,\n        width_rad: Optional[float] = None,\n        height_rad: Optional[float] = None,\n        cartesian: bool = False,\n        mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        \"\"\"Render a grating stimulus.\n\n        Args:\n            period_rad: Period of the grating in radians.\n            phase_rad: Phase of the grating in radians.\n            intensity: Intensity of the grating.\n            bg_intensity: Intensity of the background.\n            moving_angle: Rotation angle in degrees.\n            width_rad: Width of the grating in radians.\n            height_rad: Height of the grating in radians.\n            cartesian: If True, return cartesian coordinates.\n            mode: Processing mode.\n\n        Returns:\n            Union[np.ndarray, torch.Tensor]: Generated grating stimulus.\n        \"\"\"\n        period_px = int(period_rad / self.omm_width_rad * self.ppo)\n        phase_px = int(phase_rad / self.omm_width_rad * self.ppo)\n\n        height_rad_px = None\n        if height_rad:\n            height_rad_px = int(height_rad / self.omm_height_rad * self.ppo)\n\n        width_rad_px = None\n        if width_rad:\n            width_rad_px = int(width_rad / self.omm_width_rad * self.ppo)\n\n        grating = render_gratings_cartesian(\n            self.monitor_height_px,\n            self.monitor_width_px,\n            period_px,\n            intensity,\n            bg_intensity,\n            grating_phase_px=phase_px,\n            rotate=moving_angle,\n            grating_height_px=height_rad_px,\n            grating_width_px=width_rad_px,\n        )\n        if cartesian:\n            return grating\n        return self(torch.tensor(grating.flatten(), device=self.device)[None], mode)\n\n    def render_grating_offsets(\n        self,\n        period_rad: float,\n        intensity: float,\n        bg_intensity: float,\n        moving_angle: float,\n        width_rad: Optional[float] = None,\n        height_rad: Optional[float] = None,\n        cartesian: bool = False,\n        mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        \"\"\"Render grating stimuli with a range of offsets.\n\n        Args:\n            period_rad: Period of the grating in radians.\n            intensity: Intensity of the grating.\n            bg_intensity: Intensity of the background.\n            moving_angle: Rotation angle in degrees.\n            width_rad: Width of the grating in radians.\n            height_rad: Height of the grating in radians.\n            cartesian: If True, return cartesian coordinates.\n            mode: Processing mode.\n\n        Returns:\n            Union[np.ndarray, torch.Tensor]: Generated grating stimuli with offsets.\n        \"\"\"\n        dphase_px = np.radians(\n            5.8 / 2\n        )  # half ommatidia width - corresponds to led width of 2.25 degree\n        n_offsets = np.ceil(period_rad / dphase_px).astype(int)\n        gratings = []\n        for offset in range(n_offsets):\n            gratings.append(\n                self.render_grating(\n                    period_rad,\n                    offset * dphase_px,\n                    intensity,\n                    bg_intensity,\n                    moving_angle,\n                    width_rad=width_rad,\n                    height_rad=height_rad,\n                    cartesian=cartesian,\n                    mode=mode,\n                )\n            )\n        if cartesian:\n            return np.array(gratings)\n        return torch.cat(gratings, dim=0)\n\n    def render_offset_bars(\n        self,\n        bar_width_rad: float,\n        bar_height_rad: float,\n        n_bars: int,\n        offsets: List[float],\n        bar_intensity: float,\n        bg_intensity: float,\n        moving_angle: float,\n        bar_loc_horizontal: float = np.radians(90),\n        bar_loc_vertical: float = np.radians(90),\n        mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n    ) -&gt; torch.Tensor:\n        \"\"\"Render bars with a range of offsets.\n\n        Args:\n            bar_width_rad: Width of bars in radians.\n            bar_height_rad: Height of bars in radians.\n            n_bars: Number of bars.\n            offsets: Offsets of bars wrt. the center in radians.\n            bar_intensity: Intensity of the bar.\n            bg_intensity: Intensity of the background.\n            moving_angle: Rotation angle in degrees.\n            bar_loc_horizontal: Horizontal location of bars in radians.\n            bar_loc_vertical: Vertical location of bars in radians.\n            mode: Processing mode.\n\n        Returns:\n            torch.Tensor: Generated offset bars.\n        \"\"\"\n        flashes = []\n        for offset in offsets:\n            flashes.append(\n                self.render_bar(\n                    bar_width_rad,\n                    bar_height_rad,\n                    bar_loc_horizontal + offset,\n                    bar_loc_vertical,\n                    n_bars,\n                    bar_intensity,\n                    bg_intensity,\n                    moving_angle,\n                    mode=mode,\n                )\n            )\n        return torch.cat(flashes, dim=0)\n\n    def render_bar_movie(\n        self,\n        t_stim: float,\n        dt: float,\n        bar_width_rad: float,\n        bar_height_rad: float,\n        n_bars: int,\n        offsets: List[float],\n        bar_intensity: float,\n        bg_intensity: float,\n        moving_angle: float,\n        t_pre: float = 0.0,\n        t_between: float = 0.0,\n        t_post: float = 0.0,\n        bar_loc_horizontal: float = np.radians(90),\n        bar_loc_vertical: float = np.radians(90),\n    ) -&gt; torch.Tensor:\n        \"\"\"Render moving bars.\n\n        Args:\n            t_stim: Stimulus duration.\n            dt: Temporal resolution.\n            bar_width_rad: Width of bars in radians.\n            bar_height_rad: Height of bars in radians.\n            n_bars: Number of bars.\n            offsets: Offsets of bars wrt. the center in radians.\n            bar_intensity: Intensity of the bar.\n            bg_intensity: Intensity of the background.\n            moving_angle: Rotation angle in degrees.\n            t_pre: Grey pre stimulus duration.\n            t_between: Grey between offset stimulus duration.\n            t_post: Grey post stimulus duration.\n            bar_loc_horizontal: Horizontal location of bars in radians.\n            bar_loc_vertical: Vertical location of bars in radians.\n\n        Returns:\n            torch.Tensor: Generated moving bars.\n        \"\"\"\n        pre_frames = round(t_pre / dt)\n        stim_frames = round(t_stim / (len(offsets) * dt))\n        if stim_frames == 0:\n            raise ValueError(\n                f\"stimulus time {t_stim}s not sufficient to sample {len(offsets)} \"\n                \"offsets at {dt}s\"\n            )\n        between_frames = round(t_between / dt)\n        post_frames = round(t_post / dt)\n\n        flashes = []\n        if pre_frames:\n            flashes.append(torch.ones([pre_frames, self.n_ommatidia]) * bg_intensity)\n\n        for i, offset in enumerate(offsets):\n            flash = self.render_bar(\n                bar_width_rad,\n                bar_height_rad,\n                bar_loc_horizontal + offset,\n                bar_loc_vertical,\n                n_bars,\n                bar_intensity,\n                bg_intensity,\n                moving_angle,\n            )\n            flashes.append(flash.repeat(stim_frames, 1))\n\n            if between_frames and i &lt; len(offsets) - 1:\n                flashes.append(\n                    torch.ones([between_frames, self.n_ommatidia]) * bg_intensity\n                )\n        if post_frames:\n            flashes.append(torch.ones([post_frames, self.n_ommatidia]) * bg_intensity)\n        return torch.cat(flashes, dim=0)\n\n    def illustrate(\n        self, figsize: List[int] = [5, 5], fontsize: int = 5\n    ) -&gt; Tuple[plt.Figure, plt.Axes]:\n        \"\"\"Illustrate the hexagonal eye model.\n\n        Args:\n            figsize: Figure size.\n            fontsize: Font size for the plot.\n\n        Returns:\n            Tuple[plt.Figure, plt.Axes]: Matplotlib figure and axes objects.\n        \"\"\"\n        x_hc, y_hc, (dist_w, dist_h) = hex_center_coordinates(\n            self.n_ommatidia, self.monitor_width_px, self.monitor_height_px\n        )\n\n        x_img, y_img = np.array(\n            list(\n                product(\n                    np.arange(self.monitor_width_px),\n                    np.arange(\n                        self.monitor_height_px,\n                    ),\n                )\n            )\n        ).T\n\n        dist_to_edge = (dist_w + dist_h) / 4\n\n        vertices, _ = is_inside_hex(\n            torch.tensor(y_img, dtype=self.dtype),\n            torch.tensor(x_img, dtype=self.dtype),\n            torch.tensor(x_hc, dtype=self.dtype),\n            torch.tensor(y_hc, dtype=self.dtype),\n            torch.tensor(dist_to_edge, dtype=self.dtype),\n            torch.tensor(np.radians(0), dtype=self.dtype),\n        )\n        vertices = vertices.cpu()\n        fig, ax = init_plot(figsize=figsize, fontsize=fontsize)\n        ax.scatter(x_hc, y_hc, color=\"#eb4034\", zorder=1)\n        ax.scatter(x_img, y_img, color=\"#34ebd6\", s=0.5, zorder=0)\n\n        for h in range(self.n_ommatidia):\n            for i in range(6):\n                x1, y1 = vertices[i, :, h]  # x1, y1: (n_hexagons)\n                x2, y2 = vertices[i + 1, :, h]\n                ax.plot([x1, x2], [y1, y2], c=\"black\")\n\n        ax.set_xlim(0, self.monitor_width_px)\n        ax.set_ylim(0, self.monitor_height_px)\n        rm_spines(ax)\n        # fig.tight_layout()\n        return fig, ax\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.__call__","title":"__call__","text":"<pre><code>__call__(stim, mode='mean', n_chunks=1)\n</code></pre> <p>Process stimulus through the hexagonal eye model.</p> <p>Parameters:</p> Name Type Description Default <code>stim</code> <code>Tensor</code> <p>Input stimulus tensor (n_frames, height, width) or (n_frames, height * width). Height and width must correspond to the monitor size.</p> required <code>mode</code> <code>Literal['mean', 'median', 'sum']</code> <p>Processing mode.</p> <code>'mean'</code> <code>n_chunks</code> <code>int</code> <p>Number of chunks to process the stimulus in.</p> <code>1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Processed stimulus.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def __call__(\n    self,\n    stim: torch.Tensor,\n    mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n    n_chunks: int = 1,\n) -&gt; torch.Tensor:\n    \"\"\"Process stimulus through the hexagonal eye model.\n\n    Args:\n        stim: Input stimulus tensor (n_frames, height, width) or\n            (n_frames, height * width). Height and width must correspond to the\n            monitor size.\n        mode: Processing mode.\n        n_chunks: Number of chunks to process the stimulus in.\n\n    Returns:\n        torch.Tensor: Processed stimulus.\n    \"\"\"\n    shape = stim.shape\n    if mode not in [\"mean\", \"median\", \"sum\"]:\n        raise ValueError\n\n    if len(stim.shape) == 3:\n        h, w = stim.shape[1:]\n        # resize to monitor size if necessary\n        if h &lt; self.monitor_height_px or w &lt; self.monitor_width_px:\n            stim = ttf.resize(stim, [self.monitor_height_px, self.monitor_width_px])\n        stim = stim.reshape(shape[0], -1)\n\n    try:\n        if mode == \"median\":\n            n_pixels = shape[1]\n            stim = median(\n                stim.view(-1, self.monitor_height_px, self.monitor_width_px)\n                .float()\n                .to(self.device),\n                int(np.sqrt(self.ppo)),\n            ).view(-1, n_pixels)\n        elif mode == \"sum\":\n            return (stim[:, :, None] * self.is_inside).sum(dim=1)\n        elif mode == \"mean\":\n            return (stim[:, :, None] * self.is_inside).sum(dim=1) / self.kernel_sum\n        else:\n            raise ValueError(f\"Invalid mode: {mode}\")\n\n    except RuntimeError as e:\n        if \"memory\" not in str(e):\n            raise e\n        if \"CUDA\" in str(e):\n            torch.cuda.empty_cache()\n        if n_chunks &gt; shape[0]:\n            raise ValueError from e\n\n        chunks = torch.chunk(stim, max(n_chunks, 1), dim=0)\n\n        def map_fn(chunk):\n            return self(chunk, mode=mode, n_chunks=n_chunks + 1)\n\n        return torch.cat(tuple(map(map_fn, chunks)), dim=0)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.render_bar","title":"render_bar","text":"<pre><code>render_bar(bar_width_rad, bar_height_rad, bar_loc_theta, bar_loc_phi, n_bars, bar_intensity, bg_intensity, moving_angle, cartesian=False, mode='mean')\n</code></pre> <p>Render a bar stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>bar_width_rad</code> <code>float</code> <p>Width of bars in radians.</p> required <code>bar_height_rad</code> <code>float</code> <p>Height of bars in radians.</p> required <code>bar_loc_theta</code> <code>float</code> <p>Horizontal location of bars in radians.</p> required <code>bar_loc_phi</code> <code>float</code> <p>Vertical location of bars in radians.</p> required <code>n_bars</code> <code>int</code> <p>Number of bars.</p> required <code>bar_intensity</code> <code>float</code> <p>Intensity of the bar.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>moving_angle</code> <code>float</code> <p>Rotation angle in degrees.</p> required <code>cartesian</code> <code>bool</code> <p>If True, return cartesian coordinates.</p> <code>False</code> <code>mode</code> <code>Literal['mean', 'median', 'sum']</code> <p>Processing mode.</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, torch.Tensor]: Generated bar stimulus.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def render_bar(\n    self,\n    bar_width_rad: float,\n    bar_height_rad: float,\n    bar_loc_theta: float,\n    bar_loc_phi: float,\n    n_bars: int,\n    bar_intensity: float,\n    bg_intensity: float,\n    moving_angle: float,\n    cartesian: bool = False,\n    mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"Render a bar stimulus.\n\n    Args:\n        bar_width_rad: Width of bars in radians.\n        bar_height_rad: Height of bars in radians.\n        bar_loc_theta: Horizontal location of bars in radians.\n        bar_loc_phi: Vertical location of bars in radians.\n        n_bars: Number of bars.\n        bar_intensity: Intensity of the bar.\n        bg_intensity: Intensity of the background.\n        moving_angle: Rotation angle in degrees.\n        cartesian: If True, return cartesian coordinates.\n        mode: Processing mode.\n\n    Returns:\n        Union[np.ndarray, torch.Tensor]: Generated bar stimulus.\n    \"\"\"\n    bar_width_px = int(bar_width_rad / self.omm_width_rad * self.ppo)\n    bar_height_px = int(bar_height_rad / self.omm_height_rad * self.ppo)\n    bar_loc_horizontal_px = int(\n        self.monitor_width_px * bar_loc_theta / np.radians(180)\n    )\n    bar_loc_vertical_px = int(self.monitor_height_px * bar_loc_phi / np.radians(180))\n\n    bar = render_bars_cartesian(\n        self.monitor_height_px,\n        self.monitor_width_px,\n        bar_width_px,\n        bar_height_px,\n        bar_loc_horizontal_px,\n        bar_loc_vertical_px,\n        n_bars,\n        bar_intensity,\n        bg_intensity,\n        moving_angle,\n    )\n    if cartesian:\n        return bar\n    return self(torch.tensor(bar.flatten(), device=self.device)[None], mode)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.render_grating","title":"render_grating","text":"<pre><code>render_grating(period_rad, phase_rad, intensity, bg_intensity, moving_angle, width_rad=None, height_rad=None, cartesian=False, mode='mean')\n</code></pre> <p>Render a grating stimulus.</p> <p>Parameters:</p> Name Type Description Default <code>period_rad</code> <code>float</code> <p>Period of the grating in radians.</p> required <code>phase_rad</code> <code>float</code> <p>Phase of the grating in radians.</p> required <code>intensity</code> <code>float</code> <p>Intensity of the grating.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>moving_angle</code> <code>float</code> <p>Rotation angle in degrees.</p> required <code>width_rad</code> <code>Optional[float]</code> <p>Width of the grating in radians.</p> <code>None</code> <code>height_rad</code> <code>Optional[float]</code> <p>Height of the grating in radians.</p> <code>None</code> <code>cartesian</code> <code>bool</code> <p>If True, return cartesian coordinates.</p> <code>False</code> <code>mode</code> <code>Literal['mean', 'median', 'sum']</code> <p>Processing mode.</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, torch.Tensor]: Generated grating stimulus.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def render_grating(\n    self,\n    period_rad: float,\n    phase_rad: float,\n    intensity: float,\n    bg_intensity: float,\n    moving_angle: float,\n    width_rad: Optional[float] = None,\n    height_rad: Optional[float] = None,\n    cartesian: bool = False,\n    mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"Render a grating stimulus.\n\n    Args:\n        period_rad: Period of the grating in radians.\n        phase_rad: Phase of the grating in radians.\n        intensity: Intensity of the grating.\n        bg_intensity: Intensity of the background.\n        moving_angle: Rotation angle in degrees.\n        width_rad: Width of the grating in radians.\n        height_rad: Height of the grating in radians.\n        cartesian: If True, return cartesian coordinates.\n        mode: Processing mode.\n\n    Returns:\n        Union[np.ndarray, torch.Tensor]: Generated grating stimulus.\n    \"\"\"\n    period_px = int(period_rad / self.omm_width_rad * self.ppo)\n    phase_px = int(phase_rad / self.omm_width_rad * self.ppo)\n\n    height_rad_px = None\n    if height_rad:\n        height_rad_px = int(height_rad / self.omm_height_rad * self.ppo)\n\n    width_rad_px = None\n    if width_rad:\n        width_rad_px = int(width_rad / self.omm_width_rad * self.ppo)\n\n    grating = render_gratings_cartesian(\n        self.monitor_height_px,\n        self.monitor_width_px,\n        period_px,\n        intensity,\n        bg_intensity,\n        grating_phase_px=phase_px,\n        rotate=moving_angle,\n        grating_height_px=height_rad_px,\n        grating_width_px=width_rad_px,\n    )\n    if cartesian:\n        return grating\n    return self(torch.tensor(grating.flatten(), device=self.device)[None], mode)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.render_grating_offsets","title":"render_grating_offsets","text":"<pre><code>render_grating_offsets(period_rad, intensity, bg_intensity, moving_angle, width_rad=None, height_rad=None, cartesian=False, mode='mean')\n</code></pre> <p>Render grating stimuli with a range of offsets.</p> <p>Parameters:</p> Name Type Description Default <code>period_rad</code> <code>float</code> <p>Period of the grating in radians.</p> required <code>intensity</code> <code>float</code> <p>Intensity of the grating.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>moving_angle</code> <code>float</code> <p>Rotation angle in degrees.</p> required <code>width_rad</code> <code>Optional[float]</code> <p>Width of the grating in radians.</p> <code>None</code> <code>height_rad</code> <code>Optional[float]</code> <p>Height of the grating in radians.</p> <code>None</code> <code>cartesian</code> <code>bool</code> <p>If True, return cartesian coordinates.</p> <code>False</code> <code>mode</code> <code>Literal['mean', 'median', 'sum']</code> <p>Processing mode.</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Union[np.ndarray, torch.Tensor]: Generated grating stimuli with offsets.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def render_grating_offsets(\n    self,\n    period_rad: float,\n    intensity: float,\n    bg_intensity: float,\n    moving_angle: float,\n    width_rad: Optional[float] = None,\n    height_rad: Optional[float] = None,\n    cartesian: bool = False,\n    mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"Render grating stimuli with a range of offsets.\n\n    Args:\n        period_rad: Period of the grating in radians.\n        intensity: Intensity of the grating.\n        bg_intensity: Intensity of the background.\n        moving_angle: Rotation angle in degrees.\n        width_rad: Width of the grating in radians.\n        height_rad: Height of the grating in radians.\n        cartesian: If True, return cartesian coordinates.\n        mode: Processing mode.\n\n    Returns:\n        Union[np.ndarray, torch.Tensor]: Generated grating stimuli with offsets.\n    \"\"\"\n    dphase_px = np.radians(\n        5.8 / 2\n    )  # half ommatidia width - corresponds to led width of 2.25 degree\n    n_offsets = np.ceil(period_rad / dphase_px).astype(int)\n    gratings = []\n    for offset in range(n_offsets):\n        gratings.append(\n            self.render_grating(\n                period_rad,\n                offset * dphase_px,\n                intensity,\n                bg_intensity,\n                moving_angle,\n                width_rad=width_rad,\n                height_rad=height_rad,\n                cartesian=cartesian,\n                mode=mode,\n            )\n        )\n    if cartesian:\n        return np.array(gratings)\n    return torch.cat(gratings, dim=0)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.render_offset_bars","title":"render_offset_bars","text":"<pre><code>render_offset_bars(bar_width_rad, bar_height_rad, n_bars, offsets, bar_intensity, bg_intensity, moving_angle, bar_loc_horizontal=np.radians(90), bar_loc_vertical=np.radians(90), mode='mean')\n</code></pre> <p>Render bars with a range of offsets.</p> <p>Parameters:</p> Name Type Description Default <code>bar_width_rad</code> <code>float</code> <p>Width of bars in radians.</p> required <code>bar_height_rad</code> <code>float</code> <p>Height of bars in radians.</p> required <code>n_bars</code> <code>int</code> <p>Number of bars.</p> required <code>offsets</code> <code>List[float]</code> <p>Offsets of bars wrt. the center in radians.</p> required <code>bar_intensity</code> <code>float</code> <p>Intensity of the bar.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>moving_angle</code> <code>float</code> <p>Rotation angle in degrees.</p> required <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of bars in radians.</p> <code>radians(90)</code> <code>bar_loc_vertical</code> <code>float</code> <p>Vertical location of bars in radians.</p> <code>radians(90)</code> <code>mode</code> <code>Literal['mean', 'median', 'sum']</code> <p>Processing mode.</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Generated offset bars.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def render_offset_bars(\n    self,\n    bar_width_rad: float,\n    bar_height_rad: float,\n    n_bars: int,\n    offsets: List[float],\n    bar_intensity: float,\n    bg_intensity: float,\n    moving_angle: float,\n    bar_loc_horizontal: float = np.radians(90),\n    bar_loc_vertical: float = np.radians(90),\n    mode: Literal[\"mean\", \"median\", \"sum\"] = \"mean\",\n) -&gt; torch.Tensor:\n    \"\"\"Render bars with a range of offsets.\n\n    Args:\n        bar_width_rad: Width of bars in radians.\n        bar_height_rad: Height of bars in radians.\n        n_bars: Number of bars.\n        offsets: Offsets of bars wrt. the center in radians.\n        bar_intensity: Intensity of the bar.\n        bg_intensity: Intensity of the background.\n        moving_angle: Rotation angle in degrees.\n        bar_loc_horizontal: Horizontal location of bars in radians.\n        bar_loc_vertical: Vertical location of bars in radians.\n        mode: Processing mode.\n\n    Returns:\n        torch.Tensor: Generated offset bars.\n    \"\"\"\n    flashes = []\n    for offset in offsets:\n        flashes.append(\n            self.render_bar(\n                bar_width_rad,\n                bar_height_rad,\n                bar_loc_horizontal + offset,\n                bar_loc_vertical,\n                n_bars,\n                bar_intensity,\n                bg_intensity,\n                moving_angle,\n                mode=mode,\n            )\n        )\n    return torch.cat(flashes, dim=0)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.render_bar_movie","title":"render_bar_movie","text":"<pre><code>render_bar_movie(t_stim, dt, bar_width_rad, bar_height_rad, n_bars, offsets, bar_intensity, bg_intensity, moving_angle, t_pre=0.0, t_between=0.0, t_post=0.0, bar_loc_horizontal=np.radians(90), bar_loc_vertical=np.radians(90))\n</code></pre> <p>Render moving bars.</p> <p>Parameters:</p> Name Type Description Default <code>t_stim</code> <code>float</code> <p>Stimulus duration.</p> required <code>dt</code> <code>float</code> <p>Temporal resolution.</p> required <code>bar_width_rad</code> <code>float</code> <p>Width of bars in radians.</p> required <code>bar_height_rad</code> <code>float</code> <p>Height of bars in radians.</p> required <code>n_bars</code> <code>int</code> <p>Number of bars.</p> required <code>offsets</code> <code>List[float]</code> <p>Offsets of bars wrt. the center in radians.</p> required <code>bar_intensity</code> <code>float</code> <p>Intensity of the bar.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>moving_angle</code> <code>float</code> <p>Rotation angle in degrees.</p> required <code>t_pre</code> <code>float</code> <p>Grey pre stimulus duration.</p> <code>0.0</code> <code>t_between</code> <code>float</code> <p>Grey between offset stimulus duration.</p> <code>0.0</code> <code>t_post</code> <code>float</code> <p>Grey post stimulus duration.</p> <code>0.0</code> <code>bar_loc_horizontal</code> <code>float</code> <p>Horizontal location of bars in radians.</p> <code>radians(90)</code> <code>bar_loc_vertical</code> <code>float</code> <p>Vertical location of bars in radians.</p> <code>radians(90)</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Generated moving bars.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def render_bar_movie(\n    self,\n    t_stim: float,\n    dt: float,\n    bar_width_rad: float,\n    bar_height_rad: float,\n    n_bars: int,\n    offsets: List[float],\n    bar_intensity: float,\n    bg_intensity: float,\n    moving_angle: float,\n    t_pre: float = 0.0,\n    t_between: float = 0.0,\n    t_post: float = 0.0,\n    bar_loc_horizontal: float = np.radians(90),\n    bar_loc_vertical: float = np.radians(90),\n) -&gt; torch.Tensor:\n    \"\"\"Render moving bars.\n\n    Args:\n        t_stim: Stimulus duration.\n        dt: Temporal resolution.\n        bar_width_rad: Width of bars in radians.\n        bar_height_rad: Height of bars in radians.\n        n_bars: Number of bars.\n        offsets: Offsets of bars wrt. the center in radians.\n        bar_intensity: Intensity of the bar.\n        bg_intensity: Intensity of the background.\n        moving_angle: Rotation angle in degrees.\n        t_pre: Grey pre stimulus duration.\n        t_between: Grey between offset stimulus duration.\n        t_post: Grey post stimulus duration.\n        bar_loc_horizontal: Horizontal location of bars in radians.\n        bar_loc_vertical: Vertical location of bars in radians.\n\n    Returns:\n        torch.Tensor: Generated moving bars.\n    \"\"\"\n    pre_frames = round(t_pre / dt)\n    stim_frames = round(t_stim / (len(offsets) * dt))\n    if stim_frames == 0:\n        raise ValueError(\n            f\"stimulus time {t_stim}s not sufficient to sample {len(offsets)} \"\n            \"offsets at {dt}s\"\n        )\n    between_frames = round(t_between / dt)\n    post_frames = round(t_post / dt)\n\n    flashes = []\n    if pre_frames:\n        flashes.append(torch.ones([pre_frames, self.n_ommatidia]) * bg_intensity)\n\n    for i, offset in enumerate(offsets):\n        flash = self.render_bar(\n            bar_width_rad,\n            bar_height_rad,\n            bar_loc_horizontal + offset,\n            bar_loc_vertical,\n            n_bars,\n            bar_intensity,\n            bg_intensity,\n            moving_angle,\n        )\n        flashes.append(flash.repeat(stim_frames, 1))\n\n        if between_frames and i &lt; len(offsets) - 1:\n            flashes.append(\n                torch.ones([between_frames, self.n_ommatidia]) * bg_intensity\n            )\n    if post_frames:\n        flashes.append(torch.ones([post_frames, self.n_ommatidia]) * bg_intensity)\n    return torch.cat(flashes, dim=0)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.eye.HexEye.illustrate","title":"illustrate","text":"<pre><code>illustrate(figsize=[5, 5], fontsize=5)\n</code></pre> <p>Illustrate the hexagonal eye model.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>List[int]</code> <p>Figure size.</p> <code>[5, 5]</code> <code>fontsize</code> <code>int</code> <p>Font size for the plot.</p> <code>5</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>Tuple[plt.Figure, plt.Axes]: Matplotlib figure and axes objects.</p> Source code in <code>flyvis/datasets/rendering/eye.py</code> <pre><code>def illustrate(\n    self, figsize: List[int] = [5, 5], fontsize: int = 5\n) -&gt; Tuple[plt.Figure, plt.Axes]:\n    \"\"\"Illustrate the hexagonal eye model.\n\n    Args:\n        figsize: Figure size.\n        fontsize: Font size for the plot.\n\n    Returns:\n        Tuple[plt.Figure, plt.Axes]: Matplotlib figure and axes objects.\n    \"\"\"\n    x_hc, y_hc, (dist_w, dist_h) = hex_center_coordinates(\n        self.n_ommatidia, self.monitor_width_px, self.monitor_height_px\n    )\n\n    x_img, y_img = np.array(\n        list(\n            product(\n                np.arange(self.monitor_width_px),\n                np.arange(\n                    self.monitor_height_px,\n                ),\n            )\n        )\n    ).T\n\n    dist_to_edge = (dist_w + dist_h) / 4\n\n    vertices, _ = is_inside_hex(\n        torch.tensor(y_img, dtype=self.dtype),\n        torch.tensor(x_img, dtype=self.dtype),\n        torch.tensor(x_hc, dtype=self.dtype),\n        torch.tensor(y_hc, dtype=self.dtype),\n        torch.tensor(dist_to_edge, dtype=self.dtype),\n        torch.tensor(np.radians(0), dtype=self.dtype),\n    )\n    vertices = vertices.cpu()\n    fig, ax = init_plot(figsize=figsize, fontsize=fontsize)\n    ax.scatter(x_hc, y_hc, color=\"#eb4034\", zorder=1)\n    ax.scatter(x_img, y_img, color=\"#34ebd6\", s=0.5, zorder=0)\n\n    for h in range(self.n_ommatidia):\n        for i in range(6):\n            x1, y1 = vertices[i, :, h]  # x1, y1: (n_hexagons)\n            x2, y2 = vertices[i + 1, :, h]\n            ax.plot([x1, x2], [y1, y2], c=\"black\")\n\n    ax.set_xlim(0, self.monitor_width_px)\n    ax.set_ylim(0, self.monitor_height_px)\n    rm_spines(ax)\n    # fig.tight_layout()\n    return fig, ax\n</code></pre>"},{"location":"reference/rendering/#utils","title":"Utils","text":""},{"location":"reference/rendering/#flyvis.datasets.rendering.utils","title":"flyvis.datasets.rendering.utils","text":"<p>Rendering utils</p>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.median","title":"median","text":"<pre><code>median(x, kernel_size, stride=1, n_chunks=10)\n</code></pre> <p>Apply median image filter with reflected padding.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input array or tensor of shape (n_samples, n_frames, height, width). First and second dimensions are optional.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the filter kernel.</p> required <code>stride</code> <code>int</code> <p>Stride for the filter operation.</p> <code>1</code> <code>n_chunks</code> <code>int</code> <p>Number of chunks to process the data if memory is limited. Recursively increases the chunk size until the data fits in memory.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Filtered array or tensor of the same shape as input.</p> Note <p>On GPU, this creates a tensor of kernel_size ** 2 * prod(x.shape) elements, consuming significant memory (e.g., ~14 GB for 50 frames of 436x1024 with kernel_size 13). In case of a RuntimeError due to memory, the method processes the data in chunks.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def median(\n    x: torch.Tensor,\n    kernel_size: int,\n    stride: int = 1,\n    n_chunks: int = 10,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Apply median image filter with reflected padding.\n\n    Args:\n        x: Input array or tensor of shape (n_samples, n_frames, height, width).\n           First and second dimensions are optional.\n        kernel_size: Size of the filter kernel.\n        stride: Stride for the filter operation.\n        n_chunks: Number of chunks to process the data if memory is limited.\n            Recursively increases the chunk size until the data fits in memory.\n\n    Returns:\n        Filtered array or tensor of the same shape as input.\n\n    Note:\n        On GPU, this creates a tensor of kernel_size ** 2 * prod(x.shape) elements,\n        consuming significant memory (e.g., ~14 GB for 50 frames of 436x1024 with\n        kernel_size 13). In case of a RuntimeError due to memory, the method\n        processes the data in chunks.\n    \"\"\"\n    # Get padding so that the resulting tensor is of the same shape.\n    p = max(kernel_size - 1, 0)\n    p_floor = p // 2\n    p_ceil = p - p_floor\n    padding = (p_floor, p_ceil, p_floor, p_ceil)\n\n    shape = x.shape\n\n    try:\n        with torch.no_grad():\n            if len(shape) == 2:\n                x.unsqueeze_(0).unsqueeze_(0)\n            elif len(shape) == 3:\n                x.unsqueeze_(0)\n            elif len(shape) == 4:\n                pass\n            else:\n                raise ValueError(f\"Invalid shape: {shape}\")\n            assert len(x.shape) == 4\n            _x = F.pad(x, padding, mode=\"reflect\")\n            _x = _x.unfold(dimension=2, size=kernel_size, step=stride).unfold(\n                dimension=3, size=kernel_size, step=stride\n            )\n            _x = _x.contiguous().view(shape[:4] + (-1,)).median(dim=-1)[0]\n            return _x.view(shape)\n    except RuntimeError as e:\n        if \"memory\" not in str(e):\n            raise e\n        if \"CUDA\" in str(e):\n            torch.cuda.empty_cache()\n        _x = x.reshape(-1, *x.shape[-2:])\n        chunks = torch.chunk(_x, max(n_chunks, 1), dim=0)\n\n        def map_fn(z):\n            return median(z, kernel_size, n_chunks=n_chunks - 1)\n\n        _x = torch.cat(tuple(map(map_fn, chunks)), dim=0)\n        return _x.view(shape)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.split","title":"split","text":"<pre><code>split(array, out_nelements, n_splits, center_crop_fraction=0.7)\n</code></pre> <p>Split an array into overlapping segments along the last dimension.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>Union[ndarray, Tensor]</code> <p>Input array of shape (\u2026, nelements).</p> required <code>out_nelements</code> <code>int</code> <p>Number of elements in each output split.</p> required <code>n_splits</code> <code>int</code> <p>Number of splits to create.</p> required <code>center_crop_fraction</code> <code>Optional[float]</code> <p>If not None, the array is centrally cropped in the last dimension to this fraction before splitting.</p> <code>0.7</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>A new array of shape (n_splits, \u2026, out_nelements) containing the splits.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_splits is less than 0.</p> <code>TypeError</code> <p>If the input array is neither a numpy array nor a torch tensor.</p> Note <ul> <li>If n_splits is 1, the entire array is returned (with an added dimension).</li> <li>If n_splits is None or 0, the original array is returned unchanged.</li> <li>Splits may overlap if out_nelements * n_splits &gt; array.shape[-1].</li> </ul> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def split(\n    array: Union[np.ndarray, torch.Tensor],\n    out_nelements: int,\n    n_splits: int,\n    center_crop_fraction: Optional[float] = 0.7,\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"\n    Split an array into overlapping segments along the last dimension.\n\n    Args:\n        array: Input array of shape (..., nelements).\n        out_nelements: Number of elements in each output split.\n        n_splits: Number of splits to create.\n        center_crop_fraction: If not None, the array is centrally cropped in the\n            last dimension to this fraction before splitting.\n\n    Returns:\n        A new array of shape (n_splits, ..., out_nelements) containing the splits.\n\n    Raises:\n        ValueError: If n_splits is less than 0.\n        TypeError: If the input array is neither a numpy array nor a torch tensor.\n\n    Note:\n        - If n_splits is 1, the entire array is returned (with an added dimension).\n        - If n_splits is None or 0, the original array is returned unchanged.\n        - Splits may overlap if out_nelements * n_splits &gt; array.shape[-1].\n    \"\"\"\n    assert isinstance(array, (np.ndarray, torch.Tensor))\n    if center_crop_fraction is not None:\n        return split(\n            center_crop(array, center_crop_fraction),\n            out_nelements,\n            n_splits,\n            center_crop_fraction=None,\n        )\n\n    actual_nelements = array.shape[-1]\n    out_nelements = int(out_nelements)\n\n    def take(\n        arr: Union[np.ndarray, torch.Tensor], start: int, stop: int\n    ) -&gt; Union[np.ndarray, torch.Tensor]:\n        if isinstance(arr, np.ndarray):\n            return np.take(arr, np.arange(start, stop), axis=-1)[None]\n        elif isinstance(arr, torch.Tensor):\n            return torch.index_select(arr, dim=-1, index=torch.arange(start, stop))[None]\n\n    if n_splits == 1:\n        out = (array[None, :],)\n    elif n_splits &gt; 1:\n        out = ()\n        out_nelements = max(out_nelements, int(actual_nelements / n_splits))\n        overlap = np.ceil(\n            (out_nelements * n_splits - actual_nelements) / (n_splits - 1)\n        ).astype(int)\n        for i in range(n_splits):\n            start = i * out_nelements - i * overlap\n            stop = (i + 1) * out_nelements - i * overlap\n            out += (take(array, start, stop),)\n    elif n_splits is None or n_splits == 0:\n        return array\n    else:\n        raise ValueError(\"n_splits must be a non-negative integer or None\")\n\n    if isinstance(array, np.ndarray):\n        return np.concatenate(out, axis=0)\n    elif isinstance(array, torch.Tensor):\n        return torch.cat(out, dim=0)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.center_crop","title":"center_crop","text":"<pre><code>center_crop(array, out_nelements_ratio)\n</code></pre> <p>Centrally crop an array along the last dimension with given ratio.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>Union[ndarray, Tensor]</code> <p>Array of shape (\u2026, nelements).</p> required <code>out_nelements_ratio</code> <code>float</code> <p>Ratio of output elements to input elements.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Cropped array of shape (\u2026, out_nelements).</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def center_crop(\n    array: Union[np.ndarray, torch.Tensor], out_nelements_ratio: float\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"\n    Centrally crop an array along the last dimension with given ratio.\n\n    Args:\n        array: Array of shape (..., nelements).\n        out_nelements_ratio: Ratio of output elements to input elements.\n\n    Returns:\n        Cropped array of shape (..., out_nelements).\n    \"\"\"\n\n    def take(arr, start, stop):\n        if isinstance(arr, np.ndarray):\n            return np.take(arr, np.arange(start, stop), axis=-1)\n        elif isinstance(arr, torch.Tensor):\n            return torch.index_select(arr, dim=-1, index=torch.arange(start, stop))\n\n    nelements = array.shape[-1]\n    out_nelements = int(out_nelements_ratio * nelements)\n    return take(array, (nelements - out_nelements) // 2, (nelements + out_nelements) // 2)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.hex_center_coordinates","title":"hex_center_coordinates","text":"<pre><code>hex_center_coordinates(n_hex_area, img_width, img_height, center=True)\n</code></pre> <p>Calculate hexagon center coordinates for a given area.</p> <p>Parameters:</p> Name Type Description Default <code>n_hex_area</code> <code>int</code> <p>Number of hexagons in the area.</p> required <code>img_width</code> <code>int</code> <p>Width of the image.</p> required <code>img_height</code> <code>int</code> <p>Height of the image.</p> required <code>center</code> <code>bool</code> <p>If True, center the hexagon grid in the image.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, Tuple[float, float]]</code> <p>Tuple containing x coordinates, y coordinates, and (dist_w, dist_h).</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def hex_center_coordinates(\n    n_hex_area: int, img_width: int, img_height: int, center: bool = True\n) -&gt; Tuple[np.ndarray, np.ndarray, Tuple[float, float]]:\n    \"\"\"\n    Calculate hexagon center coordinates for a given area.\n\n    Args:\n        n_hex_area: Number of hexagons in the area.\n        img_width: Width of the image.\n        img_height: Height of the image.\n        center: If True, center the hexagon grid in the image.\n\n    Returns:\n        Tuple containing x coordinates, y coordinates, and (dist_w, dist_h).\n    \"\"\"\n    # Horizontal extent of the grid\n    n = np.floor(np.sqrt(n_hex_area / 3)).astype(\"int\")\n\n    dist_h = img_height / (2 * n + 1)\n    dist_w = img_width / (2 * n + 1)\n\n    xs = []\n    ys = []\n    for q in range(-n, n + 1):\n        for r in range(max(-n, -n - q), min(n, n - q) + 1):\n            xs.append(dist_w * r)\n            ys.append(\n                dist_h * (q + r / 2)\n            )  # either must be negative or origin must be upper\n    xs, ys = np.array(xs), np.array(ys)\n    if center:\n        xs += img_width // 2\n        ys += img_height // 2\n    return xs, ys, (dist_w, dist_h)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.is_inside_hex","title":"is_inside_hex","text":"<pre><code>is_inside_hex(x, y, x_centers, y_centers, dist_to_edge, tilt, device=flyvis.device, dtype=torch.float16)\n</code></pre> <p>Find whether given points are inside the given hexagons.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Cartesian x-coordinates of the points (n_points).</p> required <code>y</code> <code>Tensor</code> <p>Cartesian y-coordinates of the points (n_points).</p> required <code>x_centers</code> <code>Tensor</code> <p>Cartesian x-centers of the hexagons (n_hexagons).</p> required <code>y_centers</code> <code>Tensor</code> <p>Cartesian y-centers of the hexagons (n_hexagons).</p> required <code>dist_to_edge</code> <code>float</code> <p>Euclidean distance from center to edge of the hexagon.</p> required <code>tilt</code> <code>Union[float, Tensor]</code> <p>Angle of hexagon counter-clockwise tilt in radians.</p> required <code>device</code> <code>device</code> <p>Torch device to use for computations.</p> <code>device</code> <code>dtype</code> <code>dtype</code> <p>Data type for torch tensors.</p> <code>float16</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tuple containing:</p> <code>Tensor</code> <ul> <li>vertices: Cartesian coordinates of the hexagons\u2019 vertices (7, 2, n_hexagons).</li> </ul> <code>Tuple[Tensor, Tensor]</code> <ul> <li>is_inside: Boolean tensor indicating whether points are inside (n_points, n_hexagons).</li> </ul> Credits <p>Adapted from Roman Vaxenburg\u2019s original implementation.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def is_inside_hex(\n    x: torch.Tensor,\n    y: torch.Tensor,\n    x_centers: torch.Tensor,\n    y_centers: torch.Tensor,\n    dist_to_edge: float,\n    tilt: Union[float, torch.Tensor],\n    device: torch.device = flyvis.device,\n    dtype: torch.dtype = torch.float16,\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Find whether given points are inside the given hexagons.\n\n    Args:\n        x: Cartesian x-coordinates of the points (n_points).\n        y: Cartesian y-coordinates of the points (n_points).\n        x_centers: Cartesian x-centers of the hexagons (n_hexagons).\n        y_centers: Cartesian y-centers of the hexagons (n_hexagons).\n        dist_to_edge: Euclidean distance from center to edge of the hexagon.\n        tilt: Angle of hexagon counter-clockwise tilt in radians.\n        device: Torch device to use for computations.\n        dtype: Data type for torch tensors.\n\n    Returns:\n        Tuple containing:\n        - vertices: Cartesian coordinates of the hexagons' vertices (7, 2, n_hexagons).\n        - is_inside: Boolean tensor indicating whether points are inside\n            (n_points, n_hexagons).\n\n    Info: Credits\n        Adapted from Roman Vaxenburg's original implementation.\n    \"\"\"\n    if not isinstance(tilt, torch.Tensor):\n        tilt = torch.tensor(tilt, device=device)\n\n    R = torch.tensor(\n        [\n            [torch.cos(tilt), -torch.sin(tilt)],\n            [torch.sin(tilt), torch.cos(tilt)],\n        ],\n        dtype=dtype,\n        device=device,\n    )  # rotation matrix\n    pi = torch.tensor(np.pi, device=device, dtype=dtype)\n    R60 = torch.tensor(\n        [\n            [torch.cos(pi / 3), -torch.sin(pi / 3)],\n            [torch.sin(pi / 3), torch.cos(pi / 3)],\n        ],\n        dtype=dtype,\n        device=device,\n    )  # rotation matrix\n\n    # Generate hexagon vertices\n    dist_to_vertex = 2 / np.sqrt(3) * dist_to_edge\n    vertices = torch.zeros(7, 2, dtype=dtype, device=device)\n    vertices[0, :] = torch.matmul(\n        R, torch.tensor([dist_to_vertex, 0], dtype=dtype, device=device)\n    )\n    for i in range(1, 7):\n        vertices[i] = torch.matmul(R60, vertices[i - 1])\n    vertices = vertices[:, :, None]\n    vertices = torch.cat(\n        (\n            vertices[:, 0:1, :] + x_centers[None, None, :],\n            vertices[:, 1:2, :] + y_centers[None, None, :],\n        ),\n        dim=1,\n    )  # (7, 2, n_hexagons)\n\n    # Generate is_inside output\n    is_inside = torch.ones(len(x), len(x_centers), dtype=torch.bool, device=device)\n    for i in range(6):\n        x1, y1 = vertices[i, :, :]  # x1, y1: (n_hexagons)\n        x2, y2 = vertices[i + 1, :, :]\n        slope = (y2 - y1) / (x2 - x1)  # (n_hexagons)\n        f_center = y1 + slope * (x_centers - x1) - y_centers  # (n_hexagons)\n        f_points = (\n            y1[None, :] + slope[None, :] * (x[:, None] - x1[None, :]) - y[:, None]\n        )  # (n_points, n_hexagons)\n        is_inside = torch.logical_and(is_inside, f_center.sign() == f_points.sign())\n\n    return vertices, is_inside  # (7, 2, n_hexagons), (n_points, n_hexagons)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.render_bars_cartesian","title":"render_bars_cartesian","text":"<pre><code>render_bars_cartesian(img_height_px, img_width_px, bar_width_px, bar_height_px, bar_loc_horizontal_px, bar_loc_vertical_px, n_bars, bar_intensity, bg_intensity, rotate=0)\n</code></pre> <p>Render bars in a cartesian coordinate system.</p> <p>Parameters:</p> Name Type Description Default <code>img_height_px</code> <code>int</code> <p>Height of the image in pixels.</p> required <code>img_width_px</code> <code>int</code> <p>Width of the image in pixels.</p> required <code>bar_width_px</code> <code>int</code> <p>Width of each bar in pixels.</p> required <code>bar_height_px</code> <code>int</code> <p>Height of each bar in pixels.</p> required <code>bar_loc_horizontal_px</code> <code>int</code> <p>Horizontal location of the bars in pixels.</p> required <code>bar_loc_vertical_px</code> <code>int</code> <p>Vertical location of the bars in pixels.</p> required <code>n_bars</code> <code>int</code> <p>Number of bars to generate.</p> required <code>bar_intensity</code> <code>float</code> <p>Intensity of the bars.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>rotate</code> <code>float</code> <p>Rotation angle in degrees.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Generated image as a numpy array.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def render_bars_cartesian(\n    img_height_px: int,\n    img_width_px: int,\n    bar_width_px: int,\n    bar_height_px: int,\n    bar_loc_horizontal_px: int,\n    bar_loc_vertical_px: int,\n    n_bars: int,\n    bar_intensity: float,\n    bg_intensity: float,\n    rotate: float = 0,\n) -&gt; np.ndarray:\n    \"\"\"\n    Render bars in a cartesian coordinate system.\n\n    Args:\n        img_height_px: Height of the image in pixels.\n        img_width_px: Width of the image in pixels.\n        bar_width_px: Width of each bar in pixels.\n        bar_height_px: Height of each bar in pixels.\n        bar_loc_horizontal_px: Horizontal location of the bars in pixels.\n        bar_loc_vertical_px: Vertical location of the bars in pixels.\n        n_bars: Number of bars to generate.\n        bar_intensity: Intensity of the bars.\n        bg_intensity: Intensity of the background.\n        rotate: Rotation angle in degrees.\n\n    Returns:\n        Generated image as a numpy array.\n    \"\"\"\n    bar_spacing = int(img_width_px / n_bars - bar_width_px)\n\n    height_slice = slice(\n        int(bar_loc_vertical_px - bar_height_px / 2),\n        int(bar_loc_vertical_px + bar_height_px / 2) + 1,\n    )\n\n    img = np.ones([img_height_px, img_width_px]) * bg_intensity\n\n    loc_w = int(bar_loc_horizontal_px - bar_width_px / 2)\n    for i in range(n_bars):\n        #  Fill background with bars.\n        start = max(loc_w + i * bar_width_px + i * bar_spacing, 0)\n        width_slice = slice(start, loc_w + (i + 1) * bar_width_px + i * bar_spacing + 1)\n        img[height_slice, width_slice] = bar_intensity\n\n    if rotate % 360 != 0:\n        img = rotate_image(img, angle=rotate)\n\n    return img\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.render_gratings_cartesian","title":"render_gratings_cartesian","text":"<pre><code>render_gratings_cartesian(img_height_px, img_width_px, spatial_period_px, grating_intensity, bg_intensity, grating_height_px=None, grating_width_px=None, grating_phase_px=0, rotate=0)\n</code></pre> <p>Render gratings in a cartesian coordinate system.</p> <p>Parameters:</p> Name Type Description Default <code>img_height_px</code> <code>int</code> <p>Height of the image in pixels.</p> required <code>img_width_px</code> <code>int</code> <p>Width of the image in pixels.</p> required <code>spatial_period_px</code> <code>float</code> <p>Spatial period of the gratings in pixels.</p> required <code>grating_intensity</code> <code>float</code> <p>Intensity of the gratings.</p> required <code>bg_intensity</code> <code>float</code> <p>Intensity of the background.</p> required <code>grating_height_px</code> <code>Optional[int]</code> <p>Height of the grating area in pixels.</p> <code>None</code> <code>grating_width_px</code> <code>Optional[int]</code> <p>Width of the grating area in pixels.</p> <code>None</code> <code>grating_phase_px</code> <code>float</code> <p>Phase of the gratings in pixels.</p> <code>0</code> <code>rotate</code> <code>float</code> <p>Rotation angle in degrees.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Generated image as a numpy array.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def render_gratings_cartesian(\n    img_height_px: int,\n    img_width_px: int,\n    spatial_period_px: float,\n    grating_intensity: float,\n    bg_intensity: float,\n    grating_height_px: Optional[int] = None,\n    grating_width_px: Optional[int] = None,\n    grating_phase_px: float = 0,\n    rotate: float = 0,\n) -&gt; np.ndarray:\n    \"\"\"\n    Render gratings in a cartesian coordinate system.\n\n    Args:\n        img_height_px: Height of the image in pixels.\n        img_width_px: Width of the image in pixels.\n        spatial_period_px: Spatial period of the gratings in pixels.\n        grating_intensity: Intensity of the gratings.\n        bg_intensity: Intensity of the background.\n        grating_height_px: Height of the grating area in pixels.\n        grating_width_px: Width of the grating area in pixels.\n        grating_phase_px: Phase of the gratings in pixels.\n        rotate: Rotation angle in degrees.\n\n    Returns:\n        Generated image as a numpy array.\n    \"\"\"\n    # to save time at library import\n    from scipy.signal import square\n\n    t = (\n        2\n        * np.pi\n        / (spatial_period_px / img_width_px)\n        * (\n            np.linspace(-1 / 2, 1 / 2, int(img_width_px))\n            - grating_phase_px / img_width_px\n        )\n    )\n\n    gratings = np.tile(square(t), img_height_px).reshape(img_height_px, img_width_px)\n    gratings[gratings == -1] = bg_intensity\n    gratings[gratings == 1] = grating_intensity\n\n    if grating_height_px:\n        mask = np.ones_like(gratings).astype(bool)\n\n        height_slice = slice(\n            int(img_height_px // 2 - grating_height_px / 2),\n            int(img_height_px // 2 + grating_height_px / 2) + 1,\n        )\n        mask[height_slice] = False\n        gratings[mask] = 0.5\n\n    if grating_width_px:\n        mask = np.ones_like(gratings).astype(bool)\n\n        width_slice = slice(\n            int(img_width_px // 2 - grating_width_px / 2),\n            int(img_width_px // 2 + grating_width_px / 2) + 1,\n        )\n        mask[:, width_slice] = False\n        gratings[mask] = 0.5\n\n    if rotate % 360 != 0:\n        gratings = rotate_image(gratings, angle=rotate)\n\n    return gratings\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.rotate_image","title":"rotate_image","text":"<pre><code>rotate_image(img, angle=0)\n</code></pre> <p>Rotate an image by a given angle.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ndarray</code> <p>Input image as a numpy array.</p> required <code>angle</code> <code>float</code> <p>Rotation angle in degrees.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rotated image as a numpy array.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def rotate_image(img: np.ndarray, angle: float = 0) -&gt; np.ndarray:\n    \"\"\"\n    Rotate an image by a given angle.\n\n    Args:\n        img: Input image as a numpy array.\n        angle: Rotation angle in degrees.\n\n    Returns:\n        Rotated image as a numpy array.\n    \"\"\"\n    h, w = img.shape\n\n    diagonal = int(np.sqrt(h**2 + w**2))\n\n    pad_in_height = (diagonal - h) // 2\n    pad_in_width = (diagonal - w) // 2\n\n    img = np.pad(\n        img,\n        ((pad_in_height, pad_in_height), (pad_in_width, pad_in_width)),\n        mode=\"edge\",\n    )\n\n    img = Image.fromarray((255 * img).astype(\"uint8\")).rotate(\n        angle, Image.BILINEAR, False, None\n    )\n    img = np.array(img, dtype=float) / 255.0\n\n    padded_h, padded_w = img.shape\n    return img[\n        pad_in_height : padded_h - pad_in_height,\n        pad_in_width : padded_w - pad_in_width,\n    ]\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.resample","title":"resample","text":"<pre><code>resample(stims, t_stim, dt, dim=0, device=flyvis.device, return_indices=False)\n</code></pre> <p>Resample a set of stimuli for a given stimulus duration and time step.</p> <p>Parameters:</p> Name Type Description Default <code>stims</code> <code>Tensor</code> <p>Stimuli tensor of shape (#conditions, #hexals).</p> required <code>t_stim</code> <code>float</code> <p>Stimulus duration in seconds.</p> required <code>dt</code> <code>float</code> <p>Integration time constant in seconds.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to resample.</p> <code>0</code> <code>device</code> <code>device</code> <p>Torch device to use for computations.</p> <code>device</code> <code>return_indices</code> <code>bool</code> <p>If True, return the indices used for resampling.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, Tuple[Tensor, Tensor]]</code> <p>Resampled stimuli tensor of shape (#frames, #hexals), or a tuple of</p> <code>Union[Tensor, Tuple[Tensor, Tensor]]</code> <p>(resampled stimuli, indices) if return_indices is True.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def resample(\n    stims: torch.Tensor,\n    t_stim: float,\n    dt: float,\n    dim: int = 0,\n    device: torch.device = flyvis.device,\n    return_indices: bool = False,\n) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n    \"\"\"\n    Resample a set of stimuli for a given stimulus duration and time step.\n\n    Args:\n        stims: Stimuli tensor of shape (#conditions, #hexals).\n        t_stim: Stimulus duration in seconds.\n        dt: Integration time constant in seconds.\n        dim: Dimension along which to resample.\n        device: Torch device to use for computations.\n        return_indices: If True, return the indices used for resampling.\n\n    Returns:\n        Resampled stimuli tensor of shape (#frames, #hexals), or a tuple of\n        (resampled stimuli, indices) if return_indices is True.\n    \"\"\"\n    n_offsets = stims.shape[dim]\n    # round to nearest integer\n    # this results in unequal counts of each frame usually by +-1\n    indices = torch.linspace(0, n_offsets - 1, int(t_stim / dt), device=device).long()\n    if not return_indices:\n        return torch.index_select(stims, dim, indices)\n    return torch.index_select(stims, dim, indices), indices\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.shuffle","title":"shuffle","text":"<pre><code>shuffle(stims, randomstate=None)\n</code></pre> <p>Randomly shuffle stimuli along the frame dimension.</p> <p>Parameters:</p> Name Type Description Default <code>stims</code> <code>Tensor</code> <p>Stimuli tensor of shape (N (optional), #frames, #hexals).</p> required <code>randomstate</code> <code>Optional[RandomState]</code> <p>Random state for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Shuffled stimuli tensor.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def shuffle(\n    stims: torch.Tensor, randomstate: Optional[np.random.RandomState] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n    Randomly shuffle stimuli along the frame dimension.\n\n    Args:\n        stims: Stimuli tensor of shape (N (optional), #frames, #hexals).\n        randomstate: Random state for reproducibility.\n\n    Returns:\n        Shuffled stimuli tensor.\n    \"\"\"\n    if len(stims.shape) == 3:\n        # assume (smples frames hexals)\n        def _shuffle(x):\n            return shuffle(x, randomstate)\n\n        return torch.stack(list(map(_shuffle, stims)), dim=0)\n    perms = (\n        randomstate.permutation(stims.shape[0])\n        if randomstate is not None\n        else np.random.permutation(stims.shape[0])\n    )\n    return stims[perms]\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.resample_grating","title":"resample_grating","text":"<pre><code>resample_grating(grating, t_stim, dt, temporal_frequency)\n</code></pre> <p>Resample a grating stimulus for a given duration and temporal frequency.</p> <p>Parameters:</p> Name Type Description Default <code>grating</code> <code>Tensor</code> <p>Input grating tensor.</p> required <code>t_stim</code> <code>float</code> <p>Stimulus duration in seconds.</p> required <code>dt</code> <code>float</code> <p>Time step in seconds.</p> required <code>temporal_frequency</code> <code>float</code> <p>Temporal frequency of the grating.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Resampled grating tensor.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def resample_grating(\n    grating: torch.Tensor, t_stim: float, dt: float, temporal_frequency: float\n) -&gt; torch.Tensor:\n    \"\"\"\n    Resample a grating stimulus for a given duration and temporal frequency.\n\n    Args:\n        grating: Input grating tensor.\n        t_stim: Stimulus duration in seconds.\n        dt: Time step in seconds.\n        temporal_frequency: Temporal frequency of the grating.\n\n    Returns:\n        Resampled grating tensor.\n    \"\"\"\n    n_frames = int(t_stim / dt)\n    t_period = 1 / temporal_frequency\n    _grating = resample(grating, t_period, dt)\n    _grating = _grating.repeat(np.ceil(n_frames / _grating.shape[0]).astype(int), 1)\n    return _grating[:n_frames]\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.pad","title":"pad","text":"<pre><code>pad(stim, t_stim, dt, fill=0, mode='end', pad_mode='value')\n</code></pre> <p>Pad the second to last dimension of a stimulus tensor.</p> <p>Parameters:</p> Name Type Description Default <code>stim</code> <code>Tensor</code> <p>Stimulus tensor of shape (\u2026, n_frames, n_hexals).</p> required <code>t_stim</code> <code>float</code> <p>Target stimulus duration in seconds.</p> required <code>dt</code> <code>float</code> <p>Integration time constant in seconds.</p> required <code>fill</code> <code>float</code> <p>Value to fill with if pad_mode is \u201cvalue\u201d.</p> <code>0</code> <code>mode</code> <code>Literal['end', 'start']</code> <p>Padding mode, either \u201cend\u201d or \u201cstart\u201d.</p> <code>'end'</code> <code>pad_mode</code> <code>Literal['value', 'continue', 'reflect']</code> <p>Padding type, either \u201cvalue\u201d, \u201ccontinue\u201d, or \u201creflect\u201d.</p> <code>'value'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Padded stimulus tensor.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def pad(\n    stim: torch.Tensor,\n    t_stim: float,\n    dt: float,\n    fill: float = 0,\n    mode: Literal[\"end\", \"start\"] = \"end\",\n    pad_mode: Literal[\"value\", \"continue\", \"reflect\"] = \"value\",\n) -&gt; torch.Tensor:\n    \"\"\"\n    Pad the second to last dimension of a stimulus tensor.\n\n    Args:\n        stim: Stimulus tensor of shape (..., n_frames, n_hexals).\n        t_stim: Target stimulus duration in seconds.\n        dt: Integration time constant in seconds.\n        fill: Value to fill with if pad_mode is \"value\".\n        mode: Padding mode, either \"end\" or \"start\".\n        pad_mode: Padding type, either \"value\", \"continue\", or \"reflect\".\n\n    Returns:\n        Padded stimulus tensor.\n    \"\"\"\n    diff = int(t_stim / dt) - stim.shape[-2]\n    if diff &lt;= 0:\n        return stim\n\n    # Pad the second-to-last dimension (n_frames)\n    # Format: (pad_last_dim_left, pad_last_dim_right,\n    #          pad_second_to_last_dim_before, pad_second_to_last_dim_after)\n    if mode == \"end\":\n        pad = (0, 0, 0, diff)  # Pad after the existing frames\n    elif mode == \"start\":\n        pad = (0, 0, diff, 0)  # Pad before the existing frames\n\n    if pad_mode == \"value\":\n        return torch.nn.functional.pad(stim, pad=pad, mode=\"constant\", value=fill)\n    elif pad_mode == \"continue\":\n        return repeat_last(stim, -2, diff)\n    else:\n        return torch.nn.functional.pad(stim, pad=pad, mode=pad_mode)\n</code></pre>"},{"location":"reference/rendering/#flyvis.datasets.rendering.utils.repeat_last","title":"repeat_last","text":"<pre><code>repeat_last(stim, dim, n_repeats)\n</code></pre> <p>Repeat the last frame of a stimulus tensor along a specified dimension.</p> <p>Parameters:</p> Name Type Description Default <code>stim</code> <code>Tensor</code> <p>Input stimulus tensor.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to repeat.</p> required <code>n_repeats</code> <code>int</code> <p>Number of times to repeat the last frame.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Stimulus tensor with the last frame repeated.</p> Source code in <code>flyvis/datasets/rendering/utils.py</code> <pre><code>def repeat_last(stim: torch.Tensor, dim: int, n_repeats: int) -&gt; torch.Tensor:\n    \"\"\"\n    Repeat the last frame of a stimulus tensor along a specified dimension.\n\n    Args:\n        stim: Input stimulus tensor.\n        dim: Dimension along which to repeat.\n        n_repeats: Number of times to repeat the last frame.\n\n    Returns:\n        Stimulus tensor with the last frame repeated.\n    \"\"\"\n    last = stim.index_select(dim, torch.tensor([stim.size(dim) - 1], device=stim.device))\n    stim = torch.cat((stim, last.repeat_interleave(n_repeats, dim=dim)), dim=dim)\n    return stim\n</code></pre>"},{"location":"reference/sintel/","title":"Sintel","text":""},{"location":"reference/sintel/#rendering","title":"Rendering","text":""},{"location":"reference/sintel/#flyvis.datasets.sintel.RenderedSintel","title":"flyvis.datasets.sintel.RenderedSintel","text":"<p>               Bases: <code>Directory</code></p> <p>Rendering and referencing rendered sintel data.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[str]</code> <p>List of tasks to include in the rendering. May include \u2018flow\u2019 or \u2018depth\u2019.</p> <code>['flow']</code> <code>boxfilter</code> <code>Dict[str, int]</code> <p>Key word arguments for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>vertical_splits</code> <code>int</code> <p>Number of vertical splits of each frame.</p> <code>3</code> <code>n_frames</code> <code>int</code> <p>Number of frames to render for each sequence.</p> <code>19</code> <code>center_crop_fraction</code> <code>float</code> <p>Fraction of the image to keep after cropping.</p> <code>0.7</code> <code>unittest</code> <code>bool</code> <p>If True, only renders a single sequence.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>config</code> <p>Configuration parameters used for rendering.</p> <code>sequence_&lt;id&gt;_&lt;name&gt;_split_&lt;j&gt;/lum</code> <code>ArrayFile</code> <p>Rendered luminance data (frames, 1, hexals).</p> <code>sequence_&lt;id&gt;_&lt;name&gt;_split_&lt;j&gt;/flow</code> <code>ArrayFile</code> <p>Rendered flow data (frames, 2, hexals).</p> <code>sequence_&lt;id&gt;_&lt;name&gt;_split_&lt;j&gt;/depth</code> <code>ArrayFile</code> <p>Rendered depth data (frames, 1, hexals).</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>@root(renderings_dir)\nclass RenderedSintel(Directory):\n    \"\"\"Rendering and referencing rendered sintel data.\n\n    Args:\n        tasks: List of tasks to include in the rendering. May include 'flow' or 'depth'.\n        boxfilter: Key word arguments for the BoxEye filter.\n        vertical_splits: Number of vertical splits of each frame.\n        n_frames: Number of frames to render for each sequence.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        unittest: If True, only renders a single sequence.\n\n    Attributes:\n        config: Configuration parameters used for rendering.\n        sequence_&lt;id&gt;_&lt;name&gt;_split_&lt;j&gt;/lum (ArrayFile):\n            Rendered luminance data (frames, 1, hexals).\n        sequence_&lt;id&gt;_&lt;name&gt;_split_&lt;j&gt;/flow (ArrayFile):\n            Rendered flow data (frames, 2, hexals).\n        sequence_&lt;id&gt;_&lt;name&gt;_split_&lt;j&gt;/depth (ArrayFile):\n            Rendered depth data (frames, 1, hexals).\n    \"\"\"\n\n    def __init__(\n        self,\n        tasks: List[str] = [\"flow\"],\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        vertical_splits: int = 3,\n        n_frames: int = 19,\n        center_crop_fraction: float = 0.7,\n        unittest: bool = False,\n        sintel_path: Optional[Union[str, Path]] = None,\n    ):\n        # Convert sintel_path to Path object if it's not None\n        sintel_path = (\n            Path(sintel_path) if sintel_path else download_sintel(depth=\"depth\" in tasks)\n        )\n        boxfilter = BoxEye(**boxfilter)\n\n        lum_paths = (sintel_path / \"training/final\").iterdir()\n\n        for i, lum_path in enumerate(tqdm(sorted(lum_paths), desc=\"Rendering\")):\n            # Renders all frames for all sequences which have more than n_frames\n            if len(list(lum_path.iterdir())) - 1 &gt;= n_frames:\n                flow_path = sintel_path / \"training/flow\" / lum_path.name\n                depth_path = sintel_path / \"training/depth\" / lum_path.name\n\n                # -- Flow from naturalistic input ------------------------------\n                # Y[n] = f(X[1], ..., X[n])\n                # n X   Y\n                # 0 [x]  n.e.  # not in data\n                # 1 [1]  [1]\n                # 2 [2]  [2]\n                # ...\n                # n [n]  [n]\n\n                # (frames, height, width)\n                lum = load_sequence(\n                    lum_path,\n                    sample_lum,\n                    start=1,\n                    end=None if not unittest else 4,\n                )\n                # (splits, frames, height, width)\n                lum_split = split(\n                    lum,\n                    boxfilter.min_frame_size[1] + 2 * boxfilter.kernel_size,\n                    vertical_splits,\n                    center_crop_fraction,\n                )\n                # (splits, frames, 1, #hexals)\n                lum_hex = boxfilter(lum_split).cpu()\n\n                # (frames, 2, height, width)\n                flow = load_sequence(\n                    flow_path, sample_flow, end=None if not unittest else 3\n                )\n                # (splits, frames, 2, height, width)\n                flow_split = split(\n                    flow,\n                    boxfilter.min_frame_size[1] + 2 * boxfilter.kernel_size,\n                    vertical_splits,\n                    center_crop_fraction,\n                )\n                # (splits, frames, 2, #hexals)\n                flow_hex = torch.cat(\n                    (\n                        boxfilter(flow_split[:, :, 0], ftype=\"sum\"),\n                        boxfilter(flow_split[:, :, 1], ftype=\"sum\"),\n                    ),\n                    dim=2,\n                ).cpu()\n                if \"depth\" in tasks:\n                    # (frames, height, width)\n                    depth = load_sequence(\n                        depth_path,\n                        sample_depth,\n                        start=1,\n                        end=None if not unittest else 4,\n                    )\n                    # (splits, frames, height, width)\n                    depth_splits = split(\n                        depth,\n                        boxfilter.min_frame_size[1] + 2 * boxfilter.kernel_size,\n                        vertical_splits,\n                        center_crop_fraction,\n                    )\n                    # (splits, frames, 1, #hexals)\n                    depth_hex = boxfilter(depth_splits, ftype=\"median\").cpu()\n\n                # -- store -----------------------------------------------------\n                for j in range(lum_hex.shape[0]):\n                    path = f\"sequence_{i:02d}_{lum_path.name}_split_{j:02d}\"\n\n                    self[f\"{path}/lum\"] = lum_hex[j]\n\n                    self[f\"{path}/flow\"] = flow_hex[j]\n\n                    if \"depth\" in tasks:\n                        self[f\"{path}/depth\"] = depth_hex[j]\n            if unittest:\n                break\n\n    def __call__(self, seq_id: int) -&gt; Dict[str, np.ndarray]:\n        \"\"\"Returns all rendered data for a given sequence index.\n\n        Args:\n            seq_id: Index of the sequence to retrieve.\n\n        Returns:\n            Dictionary containing the rendered data for the specified sequence.\n        \"\"\"\n        # Load all stored h5 files into memory.\n        data = self[sorted(self)[seq_id]]\n        return {key: data[key][:] for key in sorted(data)}\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.RenderedSintel.__call__","title":"__call__","text":"<pre><code>__call__(seq_id)\n</code></pre> <p>Returns all rendered data for a given sequence index.</p> <p>Parameters:</p> Name Type Description Default <code>seq_id</code> <code>int</code> <p>Index of the sequence to retrieve.</p> required <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dictionary containing the rendered data for the specified sequence.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def __call__(self, seq_id: int) -&gt; Dict[str, np.ndarray]:\n    \"\"\"Returns all rendered data for a given sequence index.\n\n    Args:\n        seq_id: Index of the sequence to retrieve.\n\n    Returns:\n        Dictionary containing the rendered data for the specified sequence.\n    \"\"\"\n    # Load all stored h5 files into memory.\n    data = self[sorted(self)[seq_id]]\n    return {key: data[key][:] for key in sorted(data)}\n</code></pre>"},{"location":"reference/sintel/#datasets","title":"Datasets","text":""},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel","title":"flyvis.datasets.sintel.MultiTaskSintel","text":"<p>               Bases: <code>MultiTaskDataset</code></p> <p>Sintel dataset.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[str]</code> <p>List of tasks to include. May include \u2018flow\u2019, \u2018lum\u2019, or \u2018depth\u2019.</p> <code>['flow']</code> <code>boxfilter</code> <code>Dict[str, int]</code> <p>Key word arguments for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>vertical_splits</code> <code>int</code> <p>Number of vertical splits of each frame.</p> <code>3</code> <code>n_frames</code> <code>int</code> <p>Number of frames to render for each sequence.</p> <code>19</code> <code>center_crop_fraction</code> <code>float</code> <p>Fraction of the image to keep after cropping.</p> <code>0.7</code> <code>dt</code> <code>float</code> <p>Sampling and integration time constant.</p> <code>1 / 50</code> <code>augment</code> <code>bool</code> <p>Turns augmentation on and off.</p> <code>True</code> <code>random_temporal_crop</code> <code>bool</code> <p>Randomly crops a temporal window of length <code>n_frames</code> from each sequence.</p> <code>True</code> <code>all_frames</code> <code>bool</code> <p>If True, all frames are returned. If False, only <code>n_frames</code>. Takes precedence over <code>random_temporal_crop</code>.</p> <code>False</code> <code>resampling</code> <code>bool</code> <p>If True, piecewise-constant resamples the input sequence to the target framerate (1/dt).</p> <code>True</code> <code>interpolate</code> <code>bool</code> <p>If True, linearly interpolates the target sequence to the target framerate (1/dt).</p> <code>True</code> <code>p_flip</code> <code>float</code> <p>Probability of flipping the sequence across hexagonal axes.</p> <code>0.5</code> <code>p_rot</code> <code>float</code> <p>Probability of rotating the sequence by n*60 degrees.</p> <code>5 / 6</code> <code>contrast_std</code> <code>float</code> <p>Standard deviation of the contrast augmentation.</p> <code>0.2</code> <code>brightness_std</code> <code>float</code> <p>Standard deviation of the brightness augmentation.</p> <code>0.1</code> <code>gaussian_white_noise</code> <code>float</code> <p>Standard deviation of the pixel-wise gaussian white noise.</p> <code>0.08</code> <code>gamma_std</code> <code>Optional[float]</code> <p>Standard deviation of the gamma augmentation.</p> <code>None</code> <code>_init_cache</code> <code>bool</code> <p>If True, caches the dataset in memory.</p> <code>True</code> <code>unittest</code> <code>bool</code> <p>If True, only renders a single sequence.</p> <code>False</code> <code>flip_axes</code> <code>List[int]</code> <p>List of axes to flip over.</p> <code>[0, 1]</code> <p>Attributes:</p> Name Type Description <code>dt</code> <code>float</code> <p>Sampling and integration time constant.</p> <code>t_pre</code> <code>float</code> <p>Warmup time.</p> <code>t_post</code> <code>float</code> <p>Cooldown time.</p> <code>tasks</code> <code>List[str]</code> <p>List of all tasks.</p> <code>valid_tasks</code> <code>List[str]</code> <p>List of valid task names.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any element in tasks is invalid.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>class MultiTaskSintel(MultiTaskDataset):\n    \"\"\"Sintel dataset.\n\n    Args:\n        tasks: List of tasks to include. May include 'flow', 'lum', or 'depth'.\n        boxfilter: Key word arguments for the BoxEye filter.\n        vertical_splits: Number of vertical splits of each frame.\n        n_frames: Number of frames to render for each sequence.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        dt: Sampling and integration time constant.\n        augment: Turns augmentation on and off.\n        random_temporal_crop: Randomly crops a temporal window of length `n_frames` from\n            each sequence.\n        all_frames: If True, all frames are returned. If False, only `n_frames`. Takes\n            precedence over `random_temporal_crop`.\n        resampling: If True, piecewise-constant resamples the input sequence to the\n            target framerate (1/dt).\n        interpolate: If True, linearly interpolates the target sequence to the target\n            framerate (1/dt).\n        p_flip: Probability of flipping the sequence across hexagonal axes.\n        p_rot: Probability of rotating the sequence by n*60 degrees.\n        contrast_std: Standard deviation of the contrast augmentation.\n        brightness_std: Standard deviation of the brightness augmentation.\n        gaussian_white_noise: Standard deviation of the pixel-wise gaussian white noise.\n        gamma_std: Standard deviation of the gamma augmentation.\n        _init_cache: If True, caches the dataset in memory.\n        unittest: If True, only renders a single sequence.\n        flip_axes: List of axes to flip over.\n\n    Attributes:\n        dt (float): Sampling and integration time constant.\n        t_pre (float): Warmup time.\n        t_post (float): Cooldown time.\n        tasks (List[str]): List of all tasks.\n        valid_tasks (List[str]): List of valid task names.\n\n    Raises:\n        ValueError: If any element in tasks is invalid.\n    \"\"\"\n\n    original_framerate: int = 24\n    dt: float = 1 / 50\n    t_pre: float = 0.0\n    t_post: float = 0.0\n    tasks: List[str] = []\n    valid_tasks: List[str] = [\"lum\", \"flow\", \"depth\"]\n\n    def __init__(\n        self,\n        tasks: List[str] = [\"flow\"],\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        vertical_splits: int = 3,\n        n_frames: int = 19,\n        center_crop_fraction: float = 0.7,\n        dt: float = 1 / 50,\n        augment: bool = True,\n        random_temporal_crop: bool = True,\n        all_frames: bool = False,\n        resampling: bool = True,\n        interpolate: bool = True,\n        p_flip: float = 0.5,\n        p_rot: float = 5 / 6,\n        contrast_std: float = 0.2,\n        brightness_std: float = 0.1,\n        gaussian_white_noise: float = 0.08,\n        gamma_std: Optional[float] = None,\n        _init_cache: bool = True,\n        unittest: bool = False,\n        flip_axes: List[int] = [0, 1],\n        sintel_path: Optional[Union[str, Path]] = None,\n    ):\n        def check_tasks(tasks):\n            invalid_tasks = [x for x in tasks if x not in self.valid_tasks]\n            if invalid_tasks:\n                raise ValueError(f\"invalid tasks {invalid_tasks}\")\n\n            tasks = [v for v in self.valid_tasks if v in tasks]  # sort\n            # because the input 'lum' is always required\n            data_keys = tasks if \"lum\" in tasks else [\"lum\", *tasks]\n            return tasks, data_keys\n\n        self.tasks, self.data_keys = check_tasks(tasks)\n        self.interpolate = interpolate\n        self.n_frames = n_frames if not unittest else 3\n        self.dt = dt\n\n        self.all_frames = all_frames\n        self.resampling = resampling\n\n        self.boxfilter = boxfilter\n        self.extent = boxfilter[\"extent\"]\n        assert vertical_splits &gt;= 1\n        self.vertical_splits = vertical_splits\n        self.center_crop_fraction = center_crop_fraction\n\n        self.p_flip = p_flip\n        self.p_rot = p_rot\n        self.contrast_std = contrast_std\n        self.brightness_std = brightness_std\n        self.gaussian_white_noise = gaussian_white_noise\n        self.gamma_std = gamma_std\n        self.random_temporal_crop = random_temporal_crop\n        self.flip_axes = flip_axes\n        self.fix_augmentation_params = False\n\n        self.init_augmentation()\n        self._augmentations_are_initialized = True\n        # note: self.augment is a property with a setter that relies on\n        # _augmentations_are_initialized\n        self.augment = augment\n\n        self.unittest = unittest\n\n        # Download Sintel once and reuse the path\n        self.sintel_path = (\n            Path(sintel_path) if sintel_path else download_sintel(depth=\"depth\" in tasks)\n        )\n\n        self.rendered = RenderedSintel(\n            tasks=tasks,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            n_frames=n_frames,\n            center_crop_fraction=center_crop_fraction,\n            unittest=unittest,\n            sintel_path=self.sintel_path,\n        )\n\n        self.meta = sintel_meta(\n            self.rendered, self.sintel_path, n_frames, vertical_splits, \"depth\" in tasks\n        )\n\n        self.config = Namespace(\n            tasks=tasks,\n            interpolate=interpolate,\n            n_frames=n_frames,\n            dt=dt,\n            augment=augment,\n            all_frames=all_frames,\n            resampling=resampling,\n            random_temporal_crop=random_temporal_crop,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            p_flip=p_flip,\n            p_rot=p_rot,\n            contrast_std=contrast_std,\n            brightness_std=brightness_std,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma_std=gamma_std,\n            center_crop_fraction=center_crop_fraction,\n            flip_axes=flip_axes,\n        )\n\n        self.arg_df = pd.DataFrame(\n            dict(\n                index=np.arange(len(self.rendered)),\n                original_index=self.meta.sequence_indices.repeat(vertical_splits),\n                name=sorted(self.rendered.keys()),\n                original_n_frames=self.meta.frames_per_scene.repeat(vertical_splits),\n            )\n        )\n\n        if _init_cache:\n            self.init_cache()\n\n    def init_cache(self) -&gt; None:\n        \"\"\"Initialize the cache with preprocessed sequences.\"\"\"\n        self.cached_sequences = [\n            {\n                key: torch.tensor(val, dtype=torch.float32)\n                for key, val in self.rendered(seq_id).items()\n                if key in self.data_keys\n            }\n            for seq_id in range(len(self))\n        ]\n\n    def __repr__(self) -&gt; str:\n        repr = f\"{self.__class__.__name__} with {len(self)} sequences.\\n\"\n        repr += \"See docs, arg_df and meta for more details.\\n\"\n        return repr\n\n    @property\n    def docs(self) -&gt; str:\n        print(self.__doc__)\n\n    def __setattr__(self, name: str, value: Any) -&gt; None:\n        \"\"\"Custom attribute setter to handle special cases and update augmentation.\n\n        Args:\n            name: Name of the attribute to set.\n            value: Value to set the attribute to.\n\n        Raises:\n            AttributeError: If trying to change framerate or rendered initialization\n                attributes.\n        \"\"\"\n        # some changes have no effect cause they are fixed, or set by the pre-rendering\n        if name == \"framerate\":\n            raise AttributeError(\"cannot change framerate\")\n        if hasattr(self, \"rendered\") and name in self.rendered.config:\n            raise AttributeError(\"cannot change attribute of rendered initialization\")\n        super().__setattr__(name, value)\n        # also update augmentation because it may already be initialized\n        if getattr(self, \"_augmentations_are_initialized\", False):\n            self.update_augmentation(name, value)\n\n    def init_augmentation(self) -&gt; None:\n        \"\"\"Initialize augmentation callables.\"\"\"\n        self.temporal_crop = CropFrames(\n            self.n_frames, all_frames=self.all_frames, random=self.random_temporal_crop\n        )\n        self.jitter = ContrastBrightness(\n            contrast_std=self.contrast_std, brightness_std=self.brightness_std\n        )\n        self.rotate = HexRotate(self.extent, p_rot=self.p_rot)\n        self.flip = HexFlip(self.extent, p_flip=self.p_flip, flip_axes=self.flip_axes)\n        self.noise = PixelNoise(self.gaussian_white_noise)\n\n        self.piecewise_resample = Interpolate(\n            self.original_framerate, 1 / self.dt, mode=\"nearest-exact\"\n        )\n        self.linear_interpolate = Interpolate(\n            self.original_framerate,\n            1 / self.dt,\n            mode=\"linear\",\n        )\n        self.gamma_correct = GammaCorrection(1, self.gamma_std)\n\n    def update_augmentation(self, name: str, value: Any) -&gt; None:\n        \"\"\"Update augmentation parameters based on attribute changes.\n\n        Args:\n            name: Name of the attribute that changed.\n            value: New value of the attribute.\n        \"\"\"\n        if name == \"dt\":\n            self.piecewise_resample.target_framerate = 1 / value\n            self.linear_interpolate.target_framerate = 1 / value\n        if name in [\"all_frames\", \"random_temporal_crop\"]:\n            self.temporal_crop.all_frames = value\n            self.temporal_crop.random = value\n        if name in [\"contrast_std\", \"brightness_std\"]:\n            self.jitter.contrast_std = value\n            self.jitter.brightness_std = value\n        if name == \"p_rot\":\n            self.rotate.p_rot = value\n        if name == \"p_flip\":\n            self.flip.p_flip = value\n        if name == \"gaussian_white_noise\":\n            self.noise.std = value\n        if name == \"gamma_std\":\n            self.gamma_correct.std = value\n\n    def set_augmentation_params(\n        self,\n        n_rot: Optional[int] = None,\n        flip_axis: Optional[int] = None,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma: Optional[float] = None,\n        start_frame: Optional[int] = None,\n        total_sequence_length: Optional[int] = None,\n    ) -&gt; None:\n        \"\"\"Set augmentation callable parameters.\n\n        Info:\n            Called for each call of get_item.\n\n        Args:\n            n_rot: Number of rotations to apply.\n            flip_axis: Axis to flip over.\n            contrast_factor: Contrast factor for jitter augmentation.\n            brightness_factor: Brightness factor for jitter augmentation.\n            gaussian_white_noise: Standard deviation for noise augmentation.\n            gamma: Gamma value for gamma correction.\n            start_frame: Starting frame for temporal crop.\n            total_sequence_length: Total length of the sequence.\n        \"\"\"\n        if not self.fix_augmentation_params:\n            self.rotate.set_or_sample(n_rot)\n            self.flip.set_or_sample(flip_axis)\n            self.jitter.set_or_sample(contrast_factor, brightness_factor)\n            self.noise.set_or_sample(gaussian_white_noise)\n            self.gamma_correct.set_or_sample(gamma)\n            self.temporal_crop.set_or_sample(\n                start=start_frame, total_sequence_length=total_sequence_length\n            )\n\n    def get_item(self, key: int) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Return a dataset sample.\n\n        Args:\n            key: Index of the sample to retrieve.\n\n        Returns:\n            Dictionary containing the augmented sample data.\n        \"\"\"\n        return self.apply_augmentation(self.cached_sequences[key])\n\n    @contextmanager\n    def augmentation(self, abool: bool):\n        \"\"\"Context manager to turn augmentation on or off in a code block.\n\n        Args:\n            abool: Boolean value to set augmentation state.\n\n        Example:\n            ```python\n            with dataset.augmentation(True):\n                for i, data in enumerate(dataloader):\n                    ...  # all data is augmented\n            ```\n        \"\"\"\n        augmentations = [\n            \"temporal_crop\",\n            \"jitter\",\n            \"rotate\",\n            \"flip\",\n            \"noise\",\n            \"piecewise_resample\",\n            \"linear_interpolate\",\n            \"gamma_correct\",\n        ]\n        states = {key: getattr(self, key).augment for key in augmentations}\n        _augment = self.augment\n        try:\n            self.augment = abool\n            yield\n        finally:\n            self.augment = _augment\n            for key in augmentations:\n                getattr(self, key).augment = states[key]\n\n    @property\n    def augment(self) -&gt; bool:\n        \"\"\"Get the current augmentation state.\"\"\"\n        return self._augment\n\n    @augment.setter\n    def augment(self, value: bool) -&gt; None:\n        \"\"\"Set the augmentation state and update augmentation callables.\n\n        Args:\n            value: Boolean value to set augmentation state.\n        \"\"\"\n        self._augment = value\n        if not self._augmentations_are_initialized:\n            return\n        # note: random_temporal_crop can override augment=True\n        self.temporal_crop.random = self.random_temporal_crop if value else False\n        self.jitter.augment = value\n        self.rotate.augment = value\n        self.flip.augment = value\n        self.noise.augment = value\n        # note: these two are not affected by augment\n        self.piecewise_resample.augment = self.resampling\n        self.linear_interpolate.augment = self.interpolate\n        self.gamma_correct.augment = value\n\n    def apply_augmentation(\n        self,\n        data: Dict[str, torch.Tensor],\n        n_rot: Optional[int] = None,\n        flip_axis: Optional[int] = None,\n        contrast_factor: Optional[float] = None,\n        brightness_factor: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma: Optional[float] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Apply augmentation to a sample from the dataset.\n\n        Args:\n            data: Dictionary containing the sample data.\n            n_rot: Number of rotations to apply.\n            flip_axis: Axis to flip over.\n            contrast_factor: Contrast factor for jitter augmentation.\n            brightness_factor: Brightness factor for jitter augmentation.\n            gaussian_white_noise: Standard deviation for noise augmentation.\n            gamma: Gamma value for gamma correction.\n\n        Returns:\n            Dictionary containing the augmented sample data.\n        \"\"\"\n\n        self.set_augmentation_params(\n            n_rot=n_rot,\n            flip_axis=flip_axis,\n            contrast_factor=contrast_factor,\n            brightness_factor=brightness_factor,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma=gamma,\n            start_frame=None,\n            total_sequence_length=data[\"lum\"].shape[0],\n        )\n\n        def transform_lum(lum):\n            return self.piecewise_resample(\n                self.rotate(\n                    self.flip(\n                        self.jitter(\n                            self.noise(self.temporal_crop(lum)),\n                        ),\n                    )\n                )\n            )\n\n        def transform_target(target):\n            if self.interpolate:\n                return self.linear_interpolate(\n                    self.rotate(self.flip(self.temporal_crop(target)))\n                )\n            return self.piecewise_resample(\n                self.rotate(self.flip(self.temporal_crop(target)))\n            )\n\n        return {\n            **{\"lum\": transform_lum(data[\"lum\"])},\n            **{\n                target: transform_target(data[target])\n                for target in self.tasks\n                if target in [\"flow\", \"depth\"]\n            },\n        }\n\n    def original_sequence_index(self, key: int) -&gt; int:\n        \"\"\"Get the original sequence index from an index of the split.\n\n        Args:\n            key: Index of the split.\n\n        Returns:\n            Original sequence index.\n\n        Raises:\n            ValueError: If the key is not found in splits.\n        \"\"\"\n        for index, splits in self.meta.sequence_index_to_splits.items():\n            if key in splits:\n                return index\n        raise ValueError(f\"key {key} not found in splits\")\n\n    def cartesian_sequence(\n        self,\n        key: int,\n        vertical_splits: Optional[int] = None,\n        outwidth: int = 716,\n        center_crop_fraction: Optional[float] = None,\n        sampling: slice = slice(1, None, None),\n    ) -&gt; np.ndarray:\n        \"\"\"Return the cartesian sequence of a fly eye rendered sequence.\n\n        Args:\n            key: Index of the sequence.\n            vertical_splits: Number of vertical splits to apply.\n            outwidth: Output width of the sequence.\n            center_crop_fraction: Fraction of the image to keep after cropping.\n            sampling: Slice object for sampling frames.\n\n        Returns:\n            Numpy array containing the cartesian sequence.\n        \"\"\"\n        # we want to retrieve the original scene which is possibly split\n        # into multiple ones\n        key = self.original_sequence_index(key)\n        lum_path = self.meta.lum_paths[key]\n        images = np.array([\n            sample_lum(path) for path in sorted(lum_path.iterdir())[sampling]\n        ])\n        return split(\n            images,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def cartesian_flow(\n        self,\n        key: int,\n        vertical_splits: Optional[int] = None,\n        outwidth: int = 417,\n        center_crop_fraction: Optional[float] = None,\n        sampling: slice = slice(None, None, None),\n    ) -&gt; np.ndarray:\n        \"\"\"Return the cartesian flow of a fly eye rendered flow.\n\n        Args:\n            key: Index of the sequence.\n            vertical_splits: Number of vertical splits to apply.\n            outwidth: Output width of the flow.\n            center_crop_fraction: Fraction of the image to keep after cropping.\n            sampling: Slice object for sampling frames.\n\n        Returns:\n            Numpy array containing the cartesian flow.\n        \"\"\"\n        key = self.original_sequence_index(key)\n        flow_path = self.meta.flow_paths[key]\n        flow = np.array([\n            sample_flow(path) for path in sorted(flow_path.iterdir())[sampling]\n        ])\n\n        return split(\n            flow,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def cartesian_depth(\n        self,\n        key: int,\n        vertical_splits: Optional[int] = None,\n        outwidth: int = 417,\n        center_crop_fraction: Optional[float] = None,\n        sampling: slice = slice(1, None, None),\n    ) -&gt; np.ndarray:\n        \"\"\"Return the cartesian depth of a fly eye rendered depth.\n\n        Args:\n            key: Index of the sequence.\n            vertical_splits: Number of vertical splits to apply.\n            outwidth: Output width of the depth.\n            center_crop_fraction: Fraction of the image to keep after cropping.\n            sampling: Slice object for sampling frames.\n\n        Returns:\n            Numpy array containing the cartesian depth.\n        \"\"\"\n        key = self.original_sequence_index(key)\n        flow_path = self.meta.depth_paths[key]\n        depth = np.array([\n            sample_depth(path) for path in sorted(flow_path.iterdir())[sampling]\n        ])\n\n        return split(\n            depth,\n            outwidth,\n            vertical_splits or self.vertical_splits,\n            center_crop_fraction or self.center_crop_fraction,\n        )\n\n    def original_train_and_validation_indices(self) -&gt; Tuple[List[int], List[int]]:\n        \"\"\"Get original training and validation indices for the dataloader.\n\n        Returns:\n            Tuple containing lists of train and validation indices.\n        \"\"\"\n        return original_train_and_validation_indices(self)\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.augment","title":"augment  <code>property</code> <code>writable</code>","text":"<pre><code>augment\n</code></pre> <p>Get the current augmentation state.</p>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.init_cache","title":"init_cache","text":"<pre><code>init_cache()\n</code></pre> <p>Initialize the cache with preprocessed sequences.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def init_cache(self) -&gt; None:\n    \"\"\"Initialize the cache with preprocessed sequences.\"\"\"\n    self.cached_sequences = [\n        {\n            key: torch.tensor(val, dtype=torch.float32)\n            for key, val in self.rendered(seq_id).items()\n            if key in self.data_keys\n        }\n        for seq_id in range(len(self))\n    ]\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.__setattr__","title":"__setattr__","text":"<pre><code>__setattr__(name, value)\n</code></pre> <p>Custom attribute setter to handle special cases and update augmentation.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute to set.</p> required <code>value</code> <code>Any</code> <p>Value to set the attribute to.</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If trying to change framerate or rendered initialization attributes.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def __setattr__(self, name: str, value: Any) -&gt; None:\n    \"\"\"Custom attribute setter to handle special cases and update augmentation.\n\n    Args:\n        name: Name of the attribute to set.\n        value: Value to set the attribute to.\n\n    Raises:\n        AttributeError: If trying to change framerate or rendered initialization\n            attributes.\n    \"\"\"\n    # some changes have no effect cause they are fixed, or set by the pre-rendering\n    if name == \"framerate\":\n        raise AttributeError(\"cannot change framerate\")\n    if hasattr(self, \"rendered\") and name in self.rendered.config:\n        raise AttributeError(\"cannot change attribute of rendered initialization\")\n    super().__setattr__(name, value)\n    # also update augmentation because it may already be initialized\n    if getattr(self, \"_augmentations_are_initialized\", False):\n        self.update_augmentation(name, value)\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.init_augmentation","title":"init_augmentation","text":"<pre><code>init_augmentation()\n</code></pre> <p>Initialize augmentation callables.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def init_augmentation(self) -&gt; None:\n    \"\"\"Initialize augmentation callables.\"\"\"\n    self.temporal_crop = CropFrames(\n        self.n_frames, all_frames=self.all_frames, random=self.random_temporal_crop\n    )\n    self.jitter = ContrastBrightness(\n        contrast_std=self.contrast_std, brightness_std=self.brightness_std\n    )\n    self.rotate = HexRotate(self.extent, p_rot=self.p_rot)\n    self.flip = HexFlip(self.extent, p_flip=self.p_flip, flip_axes=self.flip_axes)\n    self.noise = PixelNoise(self.gaussian_white_noise)\n\n    self.piecewise_resample = Interpolate(\n        self.original_framerate, 1 / self.dt, mode=\"nearest-exact\"\n    )\n    self.linear_interpolate = Interpolate(\n        self.original_framerate,\n        1 / self.dt,\n        mode=\"linear\",\n    )\n    self.gamma_correct = GammaCorrection(1, self.gamma_std)\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.update_augmentation","title":"update_augmentation","text":"<pre><code>update_augmentation(name, value)\n</code></pre> <p>Update augmentation parameters based on attribute changes.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the attribute that changed.</p> required <code>value</code> <code>Any</code> <p>New value of the attribute.</p> required Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def update_augmentation(self, name: str, value: Any) -&gt; None:\n    \"\"\"Update augmentation parameters based on attribute changes.\n\n    Args:\n        name: Name of the attribute that changed.\n        value: New value of the attribute.\n    \"\"\"\n    if name == \"dt\":\n        self.piecewise_resample.target_framerate = 1 / value\n        self.linear_interpolate.target_framerate = 1 / value\n    if name in [\"all_frames\", \"random_temporal_crop\"]:\n        self.temporal_crop.all_frames = value\n        self.temporal_crop.random = value\n    if name in [\"contrast_std\", \"brightness_std\"]:\n        self.jitter.contrast_std = value\n        self.jitter.brightness_std = value\n    if name == \"p_rot\":\n        self.rotate.p_rot = value\n    if name == \"p_flip\":\n        self.flip.p_flip = value\n    if name == \"gaussian_white_noise\":\n        self.noise.std = value\n    if name == \"gamma_std\":\n        self.gamma_correct.std = value\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.set_augmentation_params","title":"set_augmentation_params","text":"<pre><code>set_augmentation_params(n_rot=None, flip_axis=None, contrast_factor=None, brightness_factor=None, gaussian_white_noise=None, gamma=None, start_frame=None, total_sequence_length=None)\n</code></pre> <p>Set augmentation callable parameters.</p> Info <p>Called for each call of get_item.</p> <p>Parameters:</p> Name Type Description Default <code>n_rot</code> <code>Optional[int]</code> <p>Number of rotations to apply.</p> <code>None</code> <code>flip_axis</code> <code>Optional[int]</code> <p>Axis to flip over.</p> <code>None</code> <code>contrast_factor</code> <code>Optional[float]</code> <p>Contrast factor for jitter augmentation.</p> <code>None</code> <code>brightness_factor</code> <code>Optional[float]</code> <p>Brightness factor for jitter augmentation.</p> <code>None</code> <code>gaussian_white_noise</code> <code>Optional[float]</code> <p>Standard deviation for noise augmentation.</p> <code>None</code> <code>gamma</code> <code>Optional[float]</code> <p>Gamma value for gamma correction.</p> <code>None</code> <code>start_frame</code> <code>Optional[int]</code> <p>Starting frame for temporal crop.</p> <code>None</code> <code>total_sequence_length</code> <code>Optional[int]</code> <p>Total length of the sequence.</p> <code>None</code> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def set_augmentation_params(\n    self,\n    n_rot: Optional[int] = None,\n    flip_axis: Optional[int] = None,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n    gaussian_white_noise: Optional[float] = None,\n    gamma: Optional[float] = None,\n    start_frame: Optional[int] = None,\n    total_sequence_length: Optional[int] = None,\n) -&gt; None:\n    \"\"\"Set augmentation callable parameters.\n\n    Info:\n        Called for each call of get_item.\n\n    Args:\n        n_rot: Number of rotations to apply.\n        flip_axis: Axis to flip over.\n        contrast_factor: Contrast factor for jitter augmentation.\n        brightness_factor: Brightness factor for jitter augmentation.\n        gaussian_white_noise: Standard deviation for noise augmentation.\n        gamma: Gamma value for gamma correction.\n        start_frame: Starting frame for temporal crop.\n        total_sequence_length: Total length of the sequence.\n    \"\"\"\n    if not self.fix_augmentation_params:\n        self.rotate.set_or_sample(n_rot)\n        self.flip.set_or_sample(flip_axis)\n        self.jitter.set_or_sample(contrast_factor, brightness_factor)\n        self.noise.set_or_sample(gaussian_white_noise)\n        self.gamma_correct.set_or_sample(gamma)\n        self.temporal_crop.set_or_sample(\n            start=start_frame, total_sequence_length=total_sequence_length\n        )\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.get_item","title":"get_item","text":"<pre><code>get_item(key)\n</code></pre> <p>Return a dataset sample.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sample to retrieve.</p> required <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary containing the augmented sample data.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def get_item(self, key: int) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Return a dataset sample.\n\n    Args:\n        key: Index of the sample to retrieve.\n\n    Returns:\n        Dictionary containing the augmented sample data.\n    \"\"\"\n    return self.apply_augmentation(self.cached_sequences[key])\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.augmentation","title":"augmentation","text":"<pre><code>augmentation(abool)\n</code></pre> <p>Context manager to turn augmentation on or off in a code block.</p> <p>Parameters:</p> Name Type Description Default <code>abool</code> <code>bool</code> <p>Boolean value to set augmentation state.</p> required Example <pre><code>with dataset.augmentation(True):\n    for i, data in enumerate(dataloader):\n        ...  # all data is augmented\n</code></pre> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>@contextmanager\ndef augmentation(self, abool: bool):\n    \"\"\"Context manager to turn augmentation on or off in a code block.\n\n    Args:\n        abool: Boolean value to set augmentation state.\n\n    Example:\n        ```python\n        with dataset.augmentation(True):\n            for i, data in enumerate(dataloader):\n                ...  # all data is augmented\n        ```\n    \"\"\"\n    augmentations = [\n        \"temporal_crop\",\n        \"jitter\",\n        \"rotate\",\n        \"flip\",\n        \"noise\",\n        \"piecewise_resample\",\n        \"linear_interpolate\",\n        \"gamma_correct\",\n    ]\n    states = {key: getattr(self, key).augment for key in augmentations}\n    _augment = self.augment\n    try:\n        self.augment = abool\n        yield\n    finally:\n        self.augment = _augment\n        for key in augmentations:\n            getattr(self, key).augment = states[key]\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.apply_augmentation","title":"apply_augmentation","text":"<pre><code>apply_augmentation(data, n_rot=None, flip_axis=None, contrast_factor=None, brightness_factor=None, gaussian_white_noise=None, gamma=None)\n</code></pre> <p>Apply augmentation to a sample from the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Tensor]</code> <p>Dictionary containing the sample data.</p> required <code>n_rot</code> <code>Optional[int]</code> <p>Number of rotations to apply.</p> <code>None</code> <code>flip_axis</code> <code>Optional[int]</code> <p>Axis to flip over.</p> <code>None</code> <code>contrast_factor</code> <code>Optional[float]</code> <p>Contrast factor for jitter augmentation.</p> <code>None</code> <code>brightness_factor</code> <code>Optional[float]</code> <p>Brightness factor for jitter augmentation.</p> <code>None</code> <code>gaussian_white_noise</code> <code>Optional[float]</code> <p>Standard deviation for noise augmentation.</p> <code>None</code> <code>gamma</code> <code>Optional[float]</code> <p>Gamma value for gamma correction.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary containing the augmented sample data.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def apply_augmentation(\n    self,\n    data: Dict[str, torch.Tensor],\n    n_rot: Optional[int] = None,\n    flip_axis: Optional[int] = None,\n    contrast_factor: Optional[float] = None,\n    brightness_factor: Optional[float] = None,\n    gaussian_white_noise: Optional[float] = None,\n    gamma: Optional[float] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Apply augmentation to a sample from the dataset.\n\n    Args:\n        data: Dictionary containing the sample data.\n        n_rot: Number of rotations to apply.\n        flip_axis: Axis to flip over.\n        contrast_factor: Contrast factor for jitter augmentation.\n        brightness_factor: Brightness factor for jitter augmentation.\n        gaussian_white_noise: Standard deviation for noise augmentation.\n        gamma: Gamma value for gamma correction.\n\n    Returns:\n        Dictionary containing the augmented sample data.\n    \"\"\"\n\n    self.set_augmentation_params(\n        n_rot=n_rot,\n        flip_axis=flip_axis,\n        contrast_factor=contrast_factor,\n        brightness_factor=brightness_factor,\n        gaussian_white_noise=gaussian_white_noise,\n        gamma=gamma,\n        start_frame=None,\n        total_sequence_length=data[\"lum\"].shape[0],\n    )\n\n    def transform_lum(lum):\n        return self.piecewise_resample(\n            self.rotate(\n                self.flip(\n                    self.jitter(\n                        self.noise(self.temporal_crop(lum)),\n                    ),\n                )\n            )\n        )\n\n    def transform_target(target):\n        if self.interpolate:\n            return self.linear_interpolate(\n                self.rotate(self.flip(self.temporal_crop(target)))\n            )\n        return self.piecewise_resample(\n            self.rotate(self.flip(self.temporal_crop(target)))\n        )\n\n    return {\n        **{\"lum\": transform_lum(data[\"lum\"])},\n        **{\n            target: transform_target(data[target])\n            for target in self.tasks\n            if target in [\"flow\", \"depth\"]\n        },\n    }\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.original_sequence_index","title":"original_sequence_index","text":"<pre><code>original_sequence_index(key)\n</code></pre> <p>Get the original sequence index from an index of the split.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the split.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Original sequence index.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the key is not found in splits.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def original_sequence_index(self, key: int) -&gt; int:\n    \"\"\"Get the original sequence index from an index of the split.\n\n    Args:\n        key: Index of the split.\n\n    Returns:\n        Original sequence index.\n\n    Raises:\n        ValueError: If the key is not found in splits.\n    \"\"\"\n    for index, splits in self.meta.sequence_index_to_splits.items():\n        if key in splits:\n            return index\n    raise ValueError(f\"key {key} not found in splits\")\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.cartesian_sequence","title":"cartesian_sequence","text":"<pre><code>cartesian_sequence(key, vertical_splits=None, outwidth=716, center_crop_fraction=None, sampling=slice(1, None, None))\n</code></pre> <p>Return the cartesian sequence of a fly eye rendered sequence.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sequence.</p> required <code>vertical_splits</code> <code>Optional[int]</code> <p>Number of vertical splits to apply.</p> <code>None</code> <code>outwidth</code> <code>int</code> <p>Output width of the sequence.</p> <code>716</code> <code>center_crop_fraction</code> <code>Optional[float]</code> <p>Fraction of the image to keep after cropping.</p> <code>None</code> <code>sampling</code> <code>slice</code> <p>Slice object for sampling frames.</p> <code>slice(1, None, None)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array containing the cartesian sequence.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def cartesian_sequence(\n    self,\n    key: int,\n    vertical_splits: Optional[int] = None,\n    outwidth: int = 716,\n    center_crop_fraction: Optional[float] = None,\n    sampling: slice = slice(1, None, None),\n) -&gt; np.ndarray:\n    \"\"\"Return the cartesian sequence of a fly eye rendered sequence.\n\n    Args:\n        key: Index of the sequence.\n        vertical_splits: Number of vertical splits to apply.\n        outwidth: Output width of the sequence.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        sampling: Slice object for sampling frames.\n\n    Returns:\n        Numpy array containing the cartesian sequence.\n    \"\"\"\n    # we want to retrieve the original scene which is possibly split\n    # into multiple ones\n    key = self.original_sequence_index(key)\n    lum_path = self.meta.lum_paths[key]\n    images = np.array([\n        sample_lum(path) for path in sorted(lum_path.iterdir())[sampling]\n    ])\n    return split(\n        images,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.cartesian_flow","title":"cartesian_flow","text":"<pre><code>cartesian_flow(key, vertical_splits=None, outwidth=417, center_crop_fraction=None, sampling=slice(None, None, None))\n</code></pre> <p>Return the cartesian flow of a fly eye rendered flow.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sequence.</p> required <code>vertical_splits</code> <code>Optional[int]</code> <p>Number of vertical splits to apply.</p> <code>None</code> <code>outwidth</code> <code>int</code> <p>Output width of the flow.</p> <code>417</code> <code>center_crop_fraction</code> <code>Optional[float]</code> <p>Fraction of the image to keep after cropping.</p> <code>None</code> <code>sampling</code> <code>slice</code> <p>Slice object for sampling frames.</p> <code>slice(None, None, None)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array containing the cartesian flow.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def cartesian_flow(\n    self,\n    key: int,\n    vertical_splits: Optional[int] = None,\n    outwidth: int = 417,\n    center_crop_fraction: Optional[float] = None,\n    sampling: slice = slice(None, None, None),\n) -&gt; np.ndarray:\n    \"\"\"Return the cartesian flow of a fly eye rendered flow.\n\n    Args:\n        key: Index of the sequence.\n        vertical_splits: Number of vertical splits to apply.\n        outwidth: Output width of the flow.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        sampling: Slice object for sampling frames.\n\n    Returns:\n        Numpy array containing the cartesian flow.\n    \"\"\"\n    key = self.original_sequence_index(key)\n    flow_path = self.meta.flow_paths[key]\n    flow = np.array([\n        sample_flow(path) for path in sorted(flow_path.iterdir())[sampling]\n    ])\n\n    return split(\n        flow,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.cartesian_depth","title":"cartesian_depth","text":"<pre><code>cartesian_depth(key, vertical_splits=None, outwidth=417, center_crop_fraction=None, sampling=slice(1, None, None))\n</code></pre> <p>Return the cartesian depth of a fly eye rendered depth.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the sequence.</p> required <code>vertical_splits</code> <code>Optional[int]</code> <p>Number of vertical splits to apply.</p> <code>None</code> <code>outwidth</code> <code>int</code> <p>Output width of the depth.</p> <code>417</code> <code>center_crop_fraction</code> <code>Optional[float]</code> <p>Fraction of the image to keep after cropping.</p> <code>None</code> <code>sampling</code> <code>slice</code> <p>Slice object for sampling frames.</p> <code>slice(1, None, None)</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array containing the cartesian depth.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def cartesian_depth(\n    self,\n    key: int,\n    vertical_splits: Optional[int] = None,\n    outwidth: int = 417,\n    center_crop_fraction: Optional[float] = None,\n    sampling: slice = slice(1, None, None),\n) -&gt; np.ndarray:\n    \"\"\"Return the cartesian depth of a fly eye rendered depth.\n\n    Args:\n        key: Index of the sequence.\n        vertical_splits: Number of vertical splits to apply.\n        outwidth: Output width of the depth.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        sampling: Slice object for sampling frames.\n\n    Returns:\n        Numpy array containing the cartesian depth.\n    \"\"\"\n    key = self.original_sequence_index(key)\n    flow_path = self.meta.depth_paths[key]\n    depth = np.array([\n        sample_depth(path) for path in sorted(flow_path.iterdir())[sampling]\n    ])\n\n    return split(\n        depth,\n        outwidth,\n        vertical_splits or self.vertical_splits,\n        center_crop_fraction or self.center_crop_fraction,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.MultiTaskSintel.original_train_and_validation_indices","title":"original_train_and_validation_indices","text":"<pre><code>original_train_and_validation_indices()\n</code></pre> <p>Get original training and validation indices for the dataloader.</p> <p>Returns:</p> Type Description <code>Tuple[List[int], List[int]]</code> <p>Tuple containing lists of train and validation indices.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def original_train_and_validation_indices(self) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"Get original training and validation indices for the dataloader.\n\n    Returns:\n        Tuple containing lists of train and validation indices.\n    \"\"\"\n    return original_train_and_validation_indices(self)\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.AugmentedSintel","title":"flyvis.datasets.sintel.AugmentedSintel","text":"<p>               Bases: <code>MultiTaskSintel</code></p> <p>Sintel dataset with controlled, rich augmentation.</p> Info <p>Returns deterministic augmented dataset to evaluate networks on a richer dataset.</p> <p>Parameters:</p> Name Type Description Default <code>n_frames</code> <code>int</code> <p>Number of sequence frames to sample from.</p> <code>19</code> <code>flip_axes</code> <code>List[int]</code> <p>List of axes to flip over.</p> <code>[0, 1]</code> <code>n_rotations</code> <code>List[int]</code> <p>List of number of rotations to perform.</p> <code>[0, 1, 2, 3, 4, 5]</code> <code>temporal_split</code> <code>bool</code> <p>Enable temporally controlled augmentation (experimental).</p> <code>False</code> <code>build_stim_on_init</code> <code>bool</code> <p>Build the augmented stimulus in cache.</p> <code>True</code> <code>dt</code> <code>float</code> <p>Integration and sampling time constant.</p> <code>1 / 50</code> <code>tasks</code> <code>List[Literal['flow', 'depth', 'lum']]</code> <p>List of tasks to include. May include \u2018flow\u2019, \u2018lum\u2019, or \u2018depth\u2019.</p> <code>['flow']</code> <code>interpolate</code> <code>bool</code> <p>If True, linearly interpolates the target sequence to the target framerate.</p> <code>True</code> <code>all_frames</code> <code>bool</code> <p>If True, all frames are returned. If False, only <code>n_frames</code>.</p> <code>False</code> <code>random_temporal_crop</code> <code>bool</code> <p>Randomly crops a temporal window of length <code>n_frames</code> from each sequence.</p> <code>False</code> <code>boxfilter</code> <code>Dict[str, int]</code> <p>Key word arguments for the BoxEye filter.</p> <code>dict(extent=15, kernel_size=13)</code> <code>vertical_splits</code> <code>int</code> <p>Number of vertical splits of each frame.</p> <code>3</code> <code>contrast_std</code> <code>Optional[float]</code> <p>Standard deviation of the contrast augmentation.</p> <code>None</code> <code>brightness_std</code> <code>Optional[float]</code> <p>Standard deviation of the brightness augmentation.</p> <code>None</code> <code>gaussian_white_noise</code> <code>Optional[float]</code> <p>Standard deviation of the pixel-wise gaussian white noise.</p> <code>None</code> <code>gamma_std</code> <code>Optional[float]</code> <p>Standard deviation of the gamma augmentation.</p> <code>None</code> <code>center_crop_fraction</code> <code>float</code> <p>Fraction of the image to keep after cropping.</p> <code>0.7</code> <code>indices</code> <code>Optional[List[int]]</code> <p>Indices of the sequences to include.</p> <code>None</code> <code>unittest</code> <code>bool</code> <p>If True, only renders a single sequence.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>cached_sequences</code> <code>List[Dict[str, Tensor]]</code> <p>List of preprocessed sequences for fast dataloading.</p> <code>valid_flip_axes</code> <code>List[int]</code> <p>List of valid flip axes.</p> <code>valid_rotations</code> <code>List[int]</code> <p>List of valid rotation values.</p> <code>flip_axes</code> <code>List[int]</code> <p>List of axes to flip over.</p> <code>n_rotations</code> <code>List[int]</code> <p>List of number of rotations to perform.</p> <code>temporal_split</code> <code>bool</code> <p>Flag for temporally controlled augmentation.</p> <code>_built</code> <code>bool</code> <p>Flag indicating if the dataset has been built.</p> <code>params</code> <code>List</code> <p>List of augmentation parameters for each sequence.</p> <code>arg_df</code> <code>DataFrame</code> <p>DataFrame containing augmentation parameters for each sequence.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>class AugmentedSintel(MultiTaskSintel):\n    \"\"\"Sintel dataset with controlled, rich augmentation.\n\n    Info:\n        Returns deterministic augmented dataset to evaluate networks on a richer dataset.\n\n    Args:\n        n_frames: Number of sequence frames to sample from.\n        flip_axes: List of axes to flip over.\n        n_rotations: List of number of rotations to perform.\n        temporal_split: Enable temporally controlled augmentation (experimental).\n        build_stim_on_init: Build the augmented stimulus in cache.\n        dt: Integration and sampling time constant.\n        tasks: List of tasks to include. May include 'flow', 'lum', or 'depth'.\n        interpolate: If True, linearly interpolates the target sequence to the target\n            framerate.\n        all_frames: If True, all frames are returned. If False, only `n_frames`.\n        random_temporal_crop: Randomly crops a temporal window of length `n_frames`\n            from each sequence.\n        boxfilter: Key word arguments for the BoxEye filter.\n        vertical_splits: Number of vertical splits of each frame.\n        contrast_std: Standard deviation of the contrast augmentation.\n        brightness_std: Standard deviation of the brightness augmentation.\n        gaussian_white_noise: Standard deviation of the pixel-wise gaussian white noise.\n        gamma_std: Standard deviation of the gamma augmentation.\n        center_crop_fraction: Fraction of the image to keep after cropping.\n        indices: Indices of the sequences to include.\n        unittest: If True, only renders a single sequence.\n\n    Attributes:\n        cached_sequences (List[Dict[str, torch.Tensor]]): List of preprocessed sequences\n            for fast dataloading.\n        valid_flip_axes (List[int]): List of valid flip axes.\n        valid_rotations (List[int]): List of valid rotation values.\n        flip_axes (List[int]): List of axes to flip over.\n        n_rotations (List[int]): List of number of rotations to perform.\n        temporal_split (bool): Flag for temporally controlled augmentation.\n        _built (bool): Flag indicating if the dataset has been built.\n        params (List): List of augmentation parameters for each sequence.\n        arg_df (pd.DataFrame): DataFrame containing augmentation parameters for each\n            sequence.\n    \"\"\"\n\n    cached_sequences: List[Dict[str, torch.Tensor]]\n    valid_flip_axes: List[int] = [0, 1, 2, 3]\n    valid_rotations: List[int] = [0, 1, 2, 3, 4, 5]\n\n    def __init__(\n        self,\n        n_frames: int = 19,\n        flip_axes: List[int] = [0, 1],\n        n_rotations: List[int] = [0, 1, 2, 3, 4, 5],\n        build_stim_on_init: bool = True,\n        temporal_split: bool = False,\n        augment: bool = True,\n        dt: float = 1 / 50,\n        tasks: List[Literal[\"flow\", \"depth\", \"lum\"]] = [\"flow\"],\n        interpolate: bool = True,\n        all_frames: bool = False,\n        random_temporal_crop: bool = False,\n        boxfilter: Dict[str, int] = dict(extent=15, kernel_size=13),\n        vertical_splits: int = 3,\n        contrast_std: Optional[float] = None,\n        brightness_std: Optional[float] = None,\n        gaussian_white_noise: Optional[float] = None,\n        gamma_std: Optional[float] = None,\n        center_crop_fraction: float = 0.7,\n        indices: Optional[List[int]] = None,\n        unittest: bool = False,\n        **kwargs,\n    ):\n        if any([arg not in self.valid_flip_axes for arg in flip_axes]):\n            raise ValueError(f\"invalid flip axes {flip_axes}\")\n\n        if any([arg not in self.valid_rotations for arg in n_rotations]):\n            raise ValueError(f\"invalid rotations {n_rotations}\")\n\n        super().__init__(\n            tasks=tasks,\n            interpolate=interpolate,\n            n_frames=n_frames,\n            dt=dt,\n            augment=augment,\n            all_frames=all_frames,\n            resampling=True,\n            random_temporal_crop=random_temporal_crop,\n            boxfilter=boxfilter,\n            vertical_splits=vertical_splits,\n            p_flip=0,\n            p_rot=0,\n            contrast_std=contrast_std,\n            brightness_std=brightness_std,\n            gaussian_white_noise=gaussian_white_noise,\n            gamma_std=gamma_std,\n            center_crop_fraction=center_crop_fraction,\n            unittest=unittest,\n            _init_cache=True,\n        )\n        self.indices = np.array(indices) if indices is not None else None\n        self.flip_axes = flip_axes\n        self.n_rotations = n_rotations\n        self.temporal_split = temporal_split\n\n        self.config.update({\n            'flip_axes': self.flip_axes,\n            'n_rotations': self.n_rotations,\n            'temporal_split': self.temporal_split,\n            'indices': self.indices,\n        })\n\n        self._built = False\n        if build_stim_on_init:\n            self._build()\n            self._built = True\n\n    def _build(self):\n        \"\"\"Build augmented dataset with temporal splits and geometric augmentations.\"\"\"\n        # to deterministically apply temporal augmentation/binning of sequences\n        # into ceil(sequence_length / n_frames) bins\n        (\n            self.cached_sequences,\n            self.original_repeats,\n        ) = temporal_split_cached_samples(\n            self.cached_sequences, self.n_frames, split=self.temporal_split\n        )\n\n        vsplit_index, original_index, name = (\n            self.arg_df[[\"index\", \"original_index\", \"name\"]]\n            .values.repeat(self.original_repeats, axis=0)\n            .T\n        )\n        tsplit_index = np.arange(len(self.cached_sequences))\n\n        n_frames = [d[\"lum\"].shape[0] for d in self.cached_sequences]\n\n        self.params = [\n            (*p[0], p[1], p[2])\n            for p in list(\n                product(\n                    zip(\n                        name,\n                        original_index,\n                        vsplit_index,\n                        tsplit_index,\n                        n_frames,\n                    ),\n                    self.flip_axes,\n                    self.n_rotations,\n                )\n            )\n        ]\n\n        self.arg_df = pd.DataFrame(\n            self.params,\n            columns=[\n                \"name\",\n                \"original_index\",\n                \"vertical_split_index\",\n                \"temporal_split_index\",\n                \"frames\",\n                \"flip_ax\",\n                \"n_rot\",\n            ],\n        )\n        # breakpoint()\n        # apply deterministic geometric augmentation\n        cached_sequences = {}\n        for i, (_, _, _, sample, _, flip_ax, n_rot) in enumerate(self.params):\n            self.flip.axis = flip_ax\n            self.rotate.n_rot = n_rot\n            cached_sequences[i] = {\n                key: self.rotate(self.flip(value))\n                for key, value in self.cached_sequences[sample].items()\n            }\n        self.cached_sequences = cached_sequences\n\n        if self.indices is not None:\n            self.cached_sequences = [self.cached_sequences[i] for i in self.indices]\n            self.arg_df = self.arg_df.iloc[self.indices]\n            self.params = [self.params[i] for i in self.indices]\n\n        # disable deterministically applied augmentation, such that in case\n        # self.augment is True, the other augmentation types can be applied\n        # randomly\n        self.flip.augment = False\n        self.rotate.augment = False\n        # default to cropping 0 to n_frames\n        self.temporal_crop.random = False\n        if self.temporal_split:\n            self.temporal_crop.augment = False\n\n    def _original_length(self) -&gt; int:\n        \"\"\"Return the original number of sequences before splitting.\"\"\"\n        return len(self) // self.vertical_splits\n\n    def pad_nans(\n        self, data: Dict[str, torch.Tensor], pad_to_length: Optional[int] = None\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Pad the data with NaNs to a specified length.\n\n        Args:\n            data: Dictionary containing the data to pad.\n            pad_to_length: Length to pad the data to.\n\n        Returns:\n            Padded data dictionary.\n        \"\"\"\n        if pad_to_length is not None:\n            data = {}\n            for key, value in data.items():\n                # pylint: disable=not-callable\n                data[key] = nnf.pad(\n                    value,\n                    pad=(0, 0, 0, 0, 0, pad_to_length),\n                    mode=\"constant\",\n                    value=np.nan,\n                )\n            return data\n        return data\n\n    def get_item(\n        self, key: int, pad_to_length: Optional[int] = None\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"Get a single item from the dataset.\n\n        Args:\n            key: Index of the item to retrieve.\n            pad_to_length: Length to pad the data to.\n\n        Returns:\n            Dictionary containing the retrieved data.\n        \"\"\"\n        if self.augment:\n            return self.pad_nans(\n                self.apply_augmentation(self.cached_sequences[key], n_rot=0, flip_axis=0),\n                pad_to_length,\n            )\n        return self.pad_nans(self.cached_sequences[key], pad_to_length)\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.AugmentedSintel.pad_nans","title":"pad_nans","text":"<pre><code>pad_nans(data, pad_to_length=None)\n</code></pre> <p>Pad the data with NaNs to a specified length.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Tensor]</code> <p>Dictionary containing the data to pad.</p> required <code>pad_to_length</code> <code>Optional[int]</code> <p>Length to pad the data to.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Padded data dictionary.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def pad_nans(\n    self, data: Dict[str, torch.Tensor], pad_to_length: Optional[int] = None\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Pad the data with NaNs to a specified length.\n\n    Args:\n        data: Dictionary containing the data to pad.\n        pad_to_length: Length to pad the data to.\n\n    Returns:\n        Padded data dictionary.\n    \"\"\"\n    if pad_to_length is not None:\n        data = {}\n        for key, value in data.items():\n            # pylint: disable=not-callable\n            data[key] = nnf.pad(\n                value,\n                pad=(0, 0, 0, 0, 0, pad_to_length),\n                mode=\"constant\",\n                value=np.nan,\n            )\n        return data\n    return data\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel.AugmentedSintel.get_item","title":"get_item","text":"<pre><code>get_item(key, pad_to_length=None)\n</code></pre> <p>Get a single item from the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>int</code> <p>Index of the item to retrieve.</p> required <code>pad_to_length</code> <code>Optional[int]</code> <p>Length to pad the data to.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary containing the retrieved data.</p> Source code in <code>flyvis/datasets/sintel.py</code> <pre><code>def get_item(\n    self, key: int, pad_to_length: Optional[int] = None\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"Get a single item from the dataset.\n\n    Args:\n        key: Index of the item to retrieve.\n        pad_to_length: Length to pad the data to.\n\n    Returns:\n        Dictionary containing the retrieved data.\n    \"\"\"\n    if self.augment:\n        return self.pad_nans(\n            self.apply_augmentation(self.cached_sequences[key], n_rot=0, flip_axis=0),\n            pad_to_length,\n        )\n    return self.pad_nans(self.cached_sequences[key], pad_to_length)\n</code></pre>"},{"location":"reference/sintel/#utils","title":"Utils","text":""},{"location":"reference/sintel/#flyvis.datasets.sintel_utils","title":"flyvis.datasets.sintel_utils","text":""},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.load_sequence","title":"load_sequence","text":"<pre><code>load_sequence(path, sample_function, start=0, end=None, as_tensor=True)\n</code></pre> <p>Calls sample_function on each file in the sorted path and returns a concatenation of the results.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the sequence files.</p> required <code>sample_function</code> <code>Callable</code> <p>Function to apply to each file in the sequence.</p> required <code>start</code> <code>int</code> <p>Starting index for file selection.</p> <code>0</code> <code>end</code> <code>Optional[int]</code> <p>Ending index for file selection.</p> <code>None</code> <code>as_tensor</code> <code>bool</code> <p>If True, returns a PyTorch tensor; otherwise, returns a NumPy array.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Concatenated sequence data as either a PyTorch tensor or NumPy array.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def load_sequence(\n    path: Path,\n    sample_function: Callable,\n    start: int = 0,\n    end: Optional[int] = None,\n    as_tensor: bool = True,\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"Calls sample_function on each file in the sorted path and returns\n    a concatenation of the results.\n\n    Args:\n        path: Path to the directory containing the sequence files.\n        sample_function: Function to apply to each file in the sequence.\n        start: Starting index for file selection.\n        end: Ending index for file selection.\n        as_tensor: If True, returns a PyTorch tensor; otherwise, returns a NumPy array.\n\n    Returns:\n        Concatenated sequence data as either a PyTorch tensor or NumPy array.\n    \"\"\"\n    samples = []\n    for p in sorted(path.iterdir())[start:end]:\n        samples.append(sample_function(p))\n    samples = np.array(samples)\n    if as_tensor:\n        return torch.tensor(samples, dtype=torch.float32)\n    return samples\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.sample_lum","title":"sample_lum","text":"<pre><code>sample_lum(path)\n</code></pre> <p>Sample luminance data from an image file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the image file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Normalized luminance data as a NumPy array.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def sample_lum(path: Path) -&gt; np.ndarray:\n    \"\"\"Sample luminance data from an image file.\n\n    Args:\n        path: Path to the image file.\n\n    Returns:\n        Normalized luminance data as a NumPy array.\n    \"\"\"\n    lum = np.float32(Image.open(path).convert(\"L\")) / 255\n    return lum\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.sample_flow","title":"sample_flow","text":"<pre><code>sample_flow(path)\n</code></pre> <p>Sample optical flow data from a file.</p> <p>Note: Flow is in units of pixel / image_height and with inverted negative y coordinate (i.e. y-axis pointing upwards in image plane).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the flow data file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Optical flow data as a NumPy array.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def sample_flow(path: Path) -&gt; np.ndarray:\n    \"\"\"Sample optical flow data from a file.\n\n    Note: Flow is in units of pixel / image_height and with inverted negative y\n    coordinate (i.e. y-axis pointing upwards in image plane).\n\n    Args:\n        path: Path to the flow data file.\n\n    Returns:\n        Optical flow data as a NumPy array.\n    \"\"\"\n    with open(path, \"rb\") as f:\n        _, w, h = np.fromfile(f, np.int32, count=3)\n        data = np.fromfile(f, np.float32, count=(h * w * 2))\n        uv = np.reshape(data, (h, w, 2)) / h  # why are we dividing by h?\n        # we invert the y coordinate, which points from the top of the\n        # image plane to the bottom\n        return uv.transpose(2, 0, 1) * np.array([1, -1])[:, None, None]\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.sample_depth","title":"sample_depth","text":"<pre><code>sample_depth(filename)\n</code></pre> <p>Sample depth data from a file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path</code> <p>Path to the depth data file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Depth data as a NumPy array.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def sample_depth(filename: Path) -&gt; np.ndarray:\n    \"\"\"Sample depth data from a file.\n\n    Args:\n        filename: Path to the depth data file.\n\n    Returns:\n        Depth data as a NumPy array.\n    \"\"\"\n    with open(filename, \"rb\") as f:\n        _, width, height = np.fromfile(f, dtype=np.int32, count=3)\n        depth = np.fromfile(f, dtype=np.float32, count=-1).reshape((height, width))\n    return depth\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.temporal_split_cached_samples","title":"temporal_split_cached_samples","text":"<pre><code>temporal_split_cached_samples(cached_sequences, max_frames, split=True)\n</code></pre> <p>Deterministically split sequences in time dimension into regularly binned     sequences.</p> Note <p>Overlapping splits of sequences which lengths are not an integer multiple of <code>max_frames</code> contain repeating frames.</p> <p>Parameters:</p> Name Type Description Default <code>cached_sequences</code> <code>List[Dict[str, Tensor]]</code> <p>Ordered list of dicts of sequences of shape (n_frames, n_features, n_hexals).</p> required <code>max_frames</code> <code>int</code> <p>Maximum number of frames per split.</p> required <code>split</code> <code>bool</code> <p>Whether to perform the temporal split.</p> <code>True</code> <p>Returns:</p> Type Description <code>List[Dict[str, Tensor]]</code> <p>Tuple containing:</p> <code>ndarray</code> <ul> <li>List of dictionaries with temporally split sequences.</li> </ul> <code>Tuple[List[Dict[str, Tensor]], ndarray]</code> <ul> <li>Array of original indices for each new split.</li> </ul> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def temporal_split_cached_samples(\n    cached_sequences: List[Dict[str, torch.Tensor]], max_frames: int, split: bool = True\n) -&gt; Tuple[List[Dict[str, torch.Tensor]], np.ndarray]:\n    \"\"\"Deterministically split sequences in time dimension into regularly binned\n        sequences.\n\n    Note:\n        Overlapping splits of sequences which lengths are not an integer multiple of\n        `max_frames` contain repeating frames.\n\n    Args:\n        cached_sequences: Ordered list of dicts of sequences of shape\n            (n_frames, n_features, n_hexals).\n        max_frames: Maximum number of frames per split.\n        split: Whether to perform the temporal split.\n\n    Returns:\n        Tuple containing:\n        - List of dictionaries with temporally split sequences.\n        - Array of original indices for each new split.\n    \"\"\"\n    if split:\n        seq_lists = {k: [] for k in cached_sequences[0]}\n\n        splits_per_seq = []\n        for i, sequence in enumerate(cached_sequences):\n            for key, value in sequence.items():\n                splits = temporal_split_sequence(value, max_frames)\n                seq_lists[key].extend([*splits])\n            splits_per_seq.append([i, len(splits)])\n\n        split_cached_sequences = []\n        for i in range(len(seq_lists[\"lum\"])):\n            split_cached_sequences.append({k: v[i] for k, v in seq_lists.items()})\n\n        index, repeats = np.array(splits_per_seq).T\n        return split_cached_sequences, repeats\n    return cached_sequences, np.ones(len(cached_sequences)).astype(int)\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.temporal_split_sequence","title":"temporal_split_sequence","text":"<pre><code>temporal_split_sequence(sequence, max_frames)\n</code></pre> <p>Split a sequence along the temporal dimension.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Union[ndarray, Tensor]</code> <p>Array or tensor of shape (n_frames, n_features, n_hexals).</p> required <code>max_frames</code> <code>int</code> <p>Maximum number of frames per split.</p> required <p>Returns:</p> Type Description <code>Union[ndarray, Tensor]</code> <p>Array or tensor of shape (splits, max_frames, n_features, n_hexals).</p> Notes <p>The number of splits is computed as int(np.round(n_frames / max_frames)).</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def temporal_split_sequence(\n    sequence: Union[np.ndarray, torch.Tensor], max_frames: int\n) -&gt; Union[np.ndarray, torch.Tensor]:\n    \"\"\"Split a sequence along the temporal dimension.\n\n    Args:\n        sequence: Array or tensor of shape (n_frames, n_features, n_hexals).\n        max_frames: Maximum number of frames per split.\n\n    Returns:\n        Array or tensor of shape (splits, max_frames, n_features, n_hexals).\n\n    Notes:\n        The number of splits is computed as int(np.round(n_frames / max_frames)).\n    \"\"\"\n    n_frames, _, _ = sequence.shape\n    splits = np.round(n_frames / max_frames).astype(int)\n    if splits &lt;= 1:\n        return sequence[:max_frames][None]\n    return split(\n        sequence.transpose(0, -1),  # splits along last axis\n        max_frames,\n        splits,\n        center_crop_fraction=None,\n    ).transpose(1, -1)  # cause first will be splits, second will be frames\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.remove_nans","title":"remove_nans","text":"<pre><code>remove_nans(responses)\n</code></pre> <p>Remove NaNs from responses array.</p> <p>Parameters:</p> Name Type Description Default <code>responses</code> <code>ndarray</code> <p>Array of shape (sample, frames, channels).</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>List of arrays with NaNs removed, potentially of different sizes.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def remove_nans(responses: np.ndarray) -&gt; List[np.ndarray]:\n    \"\"\"Remove NaNs from responses array.\n\n    Args:\n        responses: Array of shape (sample, frames, channels).\n\n    Returns:\n        List of arrays with NaNs removed, potentially of different sizes.\n    \"\"\"\n    _resp = []\n    for r in responses:\n        _isnan = np.isnan(r).any(axis=1)\n        _resp.append(r[~_isnan].squeeze())\n    return _resp\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.sintel_meta","title":"sintel_meta","text":"<pre><code>sintel_meta(rendered, sintel_path, n_frames, vertical_splits, render_depth)\n</code></pre> <p>Returns a dataclass with meta information about the (rendered) sintel dataset.</p> <p>Parameters:</p> Name Type Description Default <code>rendered</code> <code>RenderedSintel</code> <p>RenderedSintel object containing the rendered data.</p> required <code>sintel_path</code> <code>Path</code> <p>Path to the Sintel dataset.</p> required <code>n_frames</code> <code>int</code> <p>Number of frames to consider for each sequence.</p> required <code>vertical_splits</code> <code>int</code> <p>Number of vertical splits for each frame.</p> required <code>render_depth</code> <code>bool</code> <p>Whether depth data is rendered.</p> required <p>Returns:</p> Type Description <code>SintelMeta</code> <p>Meta dataclass containing metadata about the Sintel dataset.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def sintel_meta(\n    rendered: \"flyvis.RenderedSintel\",\n    sintel_path: Path,\n    n_frames: int,\n    vertical_splits: int,\n    render_depth: bool,\n) -&gt; SintelMeta:\n    \"\"\"Returns a dataclass with meta information about the (rendered) sintel dataset.\n\n    Args:\n        rendered: RenderedSintel object containing the rendered data.\n        sintel_path: Path to the Sintel dataset.\n        n_frames: Number of frames to consider for each sequence.\n        vertical_splits: Number of vertical splits for each frame.\n        render_depth: Whether depth data is rendered.\n\n    Returns:\n        Meta dataclass containing metadata about the Sintel dataset.\n    \"\"\"\n\n    lum_paths = []\n    sequence_indices = []\n    frames_per_scene = []\n    sequence_index_to_splits = {}\n    for i, p in enumerate(sorted((sintel_path / \"training/final\").iterdir())):\n        if len(list(p.iterdir())) - 1 &gt;= n_frames and any(\n            p.name in key for key in rendered\n        ):\n            lum_paths.append(p)\n            sequence_indices.append(i)\n            frames_per_scene.append(len(list(p.iterdir())))\n        sequence_index_to_splits[i] = vertical_splits * i + np.arange(vertical_splits)\n    sequence_indices = np.array(sequence_indices)\n    frames_per_scene = np.array(frames_per_scene)\n\n    flow_paths = [sintel_path / \"training/flow\" / path.name for path in lum_paths]\n    depth_paths = (\n        [sintel_path / \"training/depth\" / path.name for path in lum_paths]\n        if render_depth\n        else None\n    )\n    return SintelMeta(\n        lum_paths=lum_paths,\n        flow_paths=flow_paths,\n        depth_paths=depth_paths,\n        sequence_indices=sequence_indices,\n        frames_per_scene=frames_per_scene,\n        sequence_index_to_splits=sequence_index_to_splits,\n    )\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.original_train_and_validation_indices","title":"original_train_and_validation_indices","text":"<pre><code>original_train_and_validation_indices(dataset)\n</code></pre> <p>Get original training and validation indices for the dataloader.</p> <p>Returns:</p> Type Description <code>Tuple[List[int], List[int]]</code> <p>Tuple containing lists of train and validation indices.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def original_train_and_validation_indices(\n    dataset: \"flyvis.MultiTaskSintel\",\n) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"Get original training and validation indices for the dataloader.\n\n    Returns:\n        Tuple containing lists of train and validation indices.\n    \"\"\"\n    _validation = [\n        \"ambush_2\",\n        \"bamboo_1\",\n        \"bandage_1\",\n        \"cave_4\",\n        \"market_2\",\n        \"mountain_1\",\n    ]\n\n    train = [\n        \"alley_1\",\n        \"alley_2\",\n        \"ambush_4\",\n        \"ambush_5\",\n        \"ambush_6\",\n        \"ambush_7\",\n        \"bamboo_2\",\n        \"bandage_2\",\n        \"cave_2\",\n        \"market_5\",\n        \"market_6\",\n        \"shaman_2\",\n        \"shaman_3\",\n        \"sleeping_1\",\n        \"sleeping_2\",\n        \"temple_2\",\n        \"temple_3\",\n    ]\n\n    train_indices = [\n        i\n        for i, name in enumerate(dataset.arg_df.name)\n        if any([scene_name in name for scene_name in train])\n    ]\n    val_indices = [\n        i\n        for i, name in enumerate(dataset.arg_df.name)\n        if any([scene_name in name for scene_name in _validation])\n    ]\n    # these were dropped by the pytorch dataload because of the chosen\n    # batchsize in the original training run\n    val_indices.remove(37)\n    val_indices.remove(38)\n    return train_indices, val_indices\n</code></pre>"},{"location":"reference/sintel/#flyvis.datasets.sintel_utils.download_sintel","title":"download_sintel","text":"<pre><code>download_sintel(delete_if_exists=False, depth=False)\n</code></pre> <p>Download the sintel dataset.</p> <p>Parameters:</p> Name Type Description Default <code>delete_if_exists</code> <code>bool</code> <p>If True, delete the dataset if it exists and download again.</p> <code>False</code> <code>depth</code> <code>bool</code> <p>If True, download the depth dataset as well.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the sintel dataset.</p> Source code in <code>flyvis/datasets/sintel_utils.py</code> <pre><code>def download_sintel(delete_if_exists: bool = False, depth: bool = False) -&gt; Path:\n    \"\"\"Download the sintel dataset.\n\n    Args:\n        delete_if_exists: If True, delete the dataset if it exists and download again.\n        depth: If True, download the depth dataset as well.\n\n    Returns:\n        Path to the sintel dataset.\n    \"\"\"\n    sintel_dir = flyvis.sintel_dir\n    sintel_dir.mkdir(parents=True, exist_ok=True)\n\n    def exists(depth: bool = False) -&gt; bool:\n        try:\n            assert sintel_dir.exists()\n            assert (sintel_dir / \"training\").exists()\n            assert (sintel_dir / \"test\").exists()\n            assert (sintel_dir / \"training/flow\").exists()\n            if depth:\n                assert (sintel_dir / \"training/depth\").exists()\n            return True\n        except AssertionError:\n            return False\n\n    def download_and_extract(url: str, depth: bool = False) -&gt; None:\n        sintel_zip = sintel_dir / Path(url).name\n\n        if not exists(depth=depth) or delete_if_exists:\n            logger.info(\"Downloading Sintel dataset.\")\n            assert not sintel_zip.exists()\n            download_url_to_file(url, sintel_zip)\n            logger.info(\"Extracting Sintel dataset.\")\n            with zipfile.ZipFile(sintel_zip, \"r\") as zip_ref:\n                zip_ref.extractall(sintel_dir)\n        else:\n            logger.info(\"Found Sintel at %s\", sintel_dir)\n\n    download_and_extract(\n        \"http://files.is.tue.mpg.de/sintel/MPI-Sintel-complete.zip\", depth=False\n    )\n    if depth:\n        download_and_extract(\n            \"http://files.is.tue.mpg.de/jwulff/sintel/MPI-Sintel-depth-training-20150305.zip\",\n            depth=True,\n        )\n\n    assert exists(depth)\n\n    return sintel_dir\n</code></pre>"},{"location":"reference/solver/","title":"Training","text":"<p>Solvers for training, testing, checkpointing and recovering of networks.</p>"},{"location":"reference/solver/#flyvis.solver.MultiTaskSolver","title":"MultiTaskSolver","text":"<p>Implements training, testing, checkpoint, recovering of flyvis networks.</p> <p>Gives access to the network, decoder, task, optimizer, penalty and scheduler and the directory where the results are stored.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the solver.</p> <code>''</code> <code>config</code> <code>Optional[Union[dict, Namespace]]</code> <p>Configuration for the solver.</p> <code>None</code> <code>init_network</code> <code>bool</code> <p>Whether to initialize the network. Defaults to True.</p> <code>True</code> <code>init_decoder</code> <code>bool</code> <p>Whether to initialize the decoder. Defaults to True.</p> <code>True</code> <code>init_task</code> <code>bool</code> <p>Whether to initialize the task. Defaults to True.</p> <code>True</code> <code>init_optim</code> <code>bool</code> <p>Whether to initialize the optimizer. Defaults to True.</p> <code>True</code> <code>init_penalties</code> <code>bool</code> <p>Whether to initialize penalties. Defaults to True.</p> <code>True</code> <code>init_scheduler</code> <code>bool</code> <p>Whether to initialize the scheduler. Defaults to True.</p> <code>True</code> <code>delete_if_exists</code> <code>bool</code> <p>Whether to delete existing directory. Defaults to False.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>dir</code> <code>NetworkDir</code> <p>Directory where results are stored.</p> <code>network</code> <code>Network</code> <p>The neural network.</p> <code>decoder</code> <code>Dict[str, Module]</code> <p>The decoder modules.</p> <code>task</code> <code>Task</code> <p>The task being solved.</p> <code>optimizer</code> <code>Optimizer</code> <p>The optimizer.</p> <code>penalty</code> <code>Penalty</code> <p>The penalty object.</p> <code>scheduler</code> <code>HyperParamScheduler</code> <p>The hyperparameter scheduler.</p> Example <pre><code>from flyvis.utils.config_utils import get_default_config\n# Note: the config is typically defined through the command line.\nconfig = get_default_config(overrides=[\"task_name=flow\",\n                                       \"ensemble_and_network_id=0\"])\nsolver = MultiTaskSolver(\"test\", config)\nsolver.train()\n</code></pre> Source code in <code>flyvis/solver.py</code> <pre><code>class MultiTaskSolver:\n    \"\"\"Implements training, testing, checkpoint, recovering of flyvis networks.\n\n    Gives access to the network, decoder, task, optimizer, penalty and scheduler and\n    the directory where the results are stored.\n\n    Args:\n        name: Name of the solver.\n        config: Configuration for the solver.\n        init_network: Whether to initialize the network. Defaults to True.\n        init_decoder: Whether to initialize the decoder. Defaults to True.\n        init_task: Whether to initialize the task. Defaults to True.\n        init_optim: Whether to initialize the optimizer. Defaults to True.\n        init_penalties: Whether to initialize penalties. Defaults to True.\n        init_scheduler: Whether to initialize the scheduler. Defaults to True.\n        delete_if_exists: Whether to delete existing directory. Defaults to False.\n\n    Attributes:\n        dir (NetworkDir): Directory where results are stored.\n        network (Network): The neural network.\n        decoder (Dict[str, nn.Module]): The decoder modules.\n        task (Task): The task being solved.\n        optimizer (torch.optim.Optimizer): The optimizer.\n        penalty (Penalty): The penalty object.\n        scheduler (HyperParamScheduler): The hyperparameter scheduler.\n\n    Example:\n        ```python\n        from flyvis.utils.config_utils import get_default_config\n        # Note: the config is typically defined through the command line.\n        config = get_default_config(overrides=[\"task_name=flow\",\n                                               \"ensemble_and_network_id=0\"])\n        solver = MultiTaskSolver(\"test\", config)\n        solver.train()\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str = \"\",\n        config: Optional[Union[dict, Namespace]] = None,\n        init_network: bool = True,\n        init_decoder: bool = True,\n        init_task: bool = True,\n        init_optim: bool = True,\n        init_penalties: bool = True,\n        init_scheduler: bool = True,\n        delete_if_exists: bool = False,\n    ) -&gt; None:\n        name = name or config[\"network_name\"]\n        assert isinstance(name, str), \"Provided name argument is not a string.\"\n        self.dir = NetworkDir(\n            name, {**(config or {}), **dict(delete_if_exists=delete_if_exists)}\n        )\n\n        self.path = self.dir.path\n\n        self.config = self.dir.config\n\n        self.iteration = 0\n        self._val_loss = float(\"inf\")\n        self.checkpoint_path = self.dir.path / \"chkpts\"\n        checkpoints = resolve_checkpoints(self.dir)\n        self.checkpoints = checkpoints.indices\n        self._last_chkpt_ind = -1\n        self._curr_chkpt_ind = -1\n\n        self._initialized = self._init_solver(\n            init_network=init_network,\n            init_decoder=init_decoder,\n            init_task=init_task,\n            init_optim=init_optim,\n            init_penalties=init_penalties,\n            init_scheduler=init_scheduler,\n        )\n\n        logging.info(\"Initialized solver.\")\n        logging.info(repr(self.config))\n\n    def _init_solver(\n        self,\n        init_network: bool = False,\n        init_decoder: bool = False,\n        init_task: bool = False,\n        init_optim: bool = False,\n        init_penalties: bool = False,\n        init_scheduler: bool = False,\n    ) -&gt; list:\n        \"\"\"Initialize solver components.\n\n        Args:\n            init_network: Whether to initialize the network.\n            init_decoder: Whether to initialize the decoder.\n            init_task: Whether to initialize the task.\n            init_optim: Whether to initialize the optimizer.\n            init_penalties: Whether to initialize penalties.\n            init_scheduler: Whether to initialize the scheduler.\n\n        Returns:\n            A list of initialized components.\n        \"\"\"\n        initialized = []\n\n        if init_network:\n            self.network = Network(**self.config.network)\n            initialized.append(\"network\")\n\n        if init_task:\n            self.task = Task(**self.config.task)\n            initialized.append(\"task\")\n\n            if init_decoder:\n                self.decoder = self.task.init_decoder(self.network.connectome)\n                initialized.append(\"decoder\")\n\n        if init_optim:\n            self.optimizer = self._init_optimizer(\n                self.config.optim, self.network, self.decoder\n            )\n            initialized.append(\"optim\")\n\n        if init_penalties:\n            self.penalty = Penalty(self.config.penalizer, self.network)\n            initialized.append(\"penalties\")\n\n        if init_scheduler:\n            self.scheduler = HyperParamScheduler(\n                self.config.scheduler,\n                self.network,\n                self.task,\n                self.optimizer,\n                self.penalty,\n            )\n            self.scheduler(self.iteration)\n            initialized.append(\"scheduler\")\n\n        return initialized\n\n    @staticmethod\n    def _init_optimizer(\n        optim: Namespace, network: Network, decoder: Optional[Dict[str, nn.Module]]\n    ) -&gt; torch.optim.Optimizer:\n        \"\"\"Initializes the optimizer for network and decoder.\n\n        Args:\n            optim: Optimizer configuration.\n            network: The neural network.\n            decoder: The decoder modules.\n\n        Returns:\n            The initialized optimizer.\n        \"\"\"\n\n        def decoder_parameters(decoder: Dict[str, nn.Module]):\n            \"\"\"Returns decoder parameters.\"\"\"\n            params = []\n            for nn_module in decoder.values():\n                params.append(\n                    dict(\n                        params=[w for w in nn_module.parameters()],\n                        **config.optim_dec,\n                    )\n                )\n            return params\n\n        config = optim.deepcopy()\n\n        optim_type = config.pop(\"type\", \"Adam\")\n        optim = torch.optim.__dict__[optim_type]\n        logging.info(\"Initializing %s for network and decoder.\", optim.__name__)\n\n        param_groups = [dict(params=network.parameters(), **config.optim_net)]\n\n        if decoder:\n            param_groups.extend(decoder_parameters(decoder))\n\n        return optim(param_groups)\n\n    def train(self, overfit: bool = False, initial_checkpoint: bool = True) -&gt; None:\n        \"\"\"Trains the network by backprop through time.\n\n        Args:\n            overfit: If true, the dataloader is substituted by a\n                single-sequence loader and augmentation is turned off.\n            initial_checkpoint: Whether to create an initial checkpoint when debugging.\n\n        Raises:\n            OverflowError: If the activity or loss reports NaN values for more\n                than 100 iterations.\n\n        Stores:\n            ```bash\n            dir / loss.h5\n            dir / loss_&lt;task&gt;.h5\n            dir / activity.h5\n            dir / activity_min.h5\n            dir / activity_max.h5\n            ```\n        \"\"\"\n        # return if iterations have already been trained.\n        if self.iteration &gt;= self.task.n_iters:\n            return\n\n        # to debug code within the training loop the initial checkpoint should be\n        # disabled\n        if initial_checkpoint:\n            self.checkpoint()\n\n        logging.info(\"Starting training.\")\n        # The overfit_data dataloader only contains a single sequence and\n        # this is to debug the model architecture, configs etc.\n        dataloader = self.task.overfit_data if overfit else self.task.train_data\n        # For overfitting we also turn the augmentation off.\n        augment = not overfit\n\n        # The number of full presentations of the training data is derived from the\n        # preset number of training iterations, the length of the dataloader and the\n        # current iteration.\n        n_epochs = np.ceil((self.task.n_iters - self.iteration) / len(dataloader)).astype(\n            int\n        )\n\n        # This is after how many epochs the training states are checkpointed.\n        chkpt_every_epoch = self.config.scheduler.chkpt_every_epoch\n\n        logging.info(\"Training for %s epochs.\", n_epochs)\n        logging.info(\"Checkpointing every %s epochs.\", chkpt_every_epoch)\n\n        # Initialize data structures to store the loss and activity over iterations.\n        loss_over_iters = []\n        activity_over_iters = []\n        activity_min_over_iters = []\n        activity_max_over_iters = []\n        loss_per_task = {f\"loss_{task}\": [] for task in self.task.dataset.tasks}\n\n        start_time = time.time()\n        with self.task.dataset.augmentation(augment):\n            for epoch in range(n_epochs):\n                # The default is to compute a steady state for each epoch, then\n                # it's computed here. Note: unless done per iteration, parameter updates\n                # within epochs are not considered in the steady state.\n                steady_state = self.network.steady_state(\n                    t_pre=self.config.get(\"t_pre_train\", 0.5),\n                    dt=self.task.dataset.dt,\n                    batch_size=dataloader.batch_size,\n                    value=0.5,\n                )\n\n                for _, data in enumerate(dataloader):\n\n                    def handle_batch(data, steady_state):\n                        \"\"\"Closure to free memory by garbage collector effectively.\"\"\"\n\n                        # Resets the stimulus buffer (samples, frames, neurons).\n                        n_samples, n_frames, _, _ = data[\"lum\"].shape\n                        self.network.stimulus.zero(n_samples, n_frames)\n\n                        # Add batch of hex-videos (#frames, #samples, #hexals) as\n                        # photorecptor stimuli.\n                        self.network.stimulus.add_input(data[\"lum\"])\n\n                        # Reset gradients.\n                        self.optimizer.zero_grad()\n\n                        # Run stimulus through network.\n                        activity = self.network(\n                            self.network.stimulus(),\n                            self.task.dataset.dt,\n                            state=steady_state,\n                        )\n\n                        losses = {task: 0 for task in self.task.dataset.tasks}\n                        for task in self.task.dataset.tasks:\n                            y = data[task]\n                            y_est = self.decoder[task](activity)\n\n                            # to pass additional kwargs to the loss function, from\n                            # the data batch from the dataset\n                            losses[task] = self.task.loss(\n                                y_est, y, task, **data.get(\"loss_kwargs\", {})\n                            )\n\n                        # Sum all task losses. The weighting of the tasks is done in the\n                        # loss function.\n                        loss = sum(losses.values())\n\n                        # Compute gradients.\n                        loss.backward(retain_graph=True)\n                        # Update parameters.\n                        self.optimizer.step()\n\n                        # Activity and parameter dependent penalties.\n                        self.penalty(activity=activity, iteration=self.iteration)\n\n                        # Log results.\n                        loss = loss.detach().cpu()\n                        for task in self.task.dataset.tasks:\n                            loss_per_task[f\"loss_{task}\"].append(\n                                losses[task].detach().cpu()\n                            )\n                        loss_over_iters.append(loss)\n                        activity = activity.detach().cpu()\n                        mean_activity = activity.mean()\n                        activity_over_iters.append(mean_activity)\n                        activity_min_over_iters.append(activity.min())\n                        activity_max_over_iters.append(activity.max())\n                        return loss, mean_activity\n\n                    # Call closure.\n                    loss, mean_activity = handle_batch(data, steady_state)\n\n                    # Increment iteration count.\n                    self.iteration += 1\n\n                # Interrupt training if the network explodes.\n                if torch.isnan(loss) or torch.isnan(mean_activity):\n                    logging.warning(\"Network exploded.\")\n                    raise OverflowError(\"Invalid values encountered in trace.\")\n\n                # The scheduling of hyperparams are functions of the iteration\n                # however, we allow steps only after full presentations of the data.\n                if epoch + 1 != n_epochs:\n                    self.scheduler(self.iteration)\n                    logging.info(\"Scheduled paremeters for iteration %s.\", self.iteration)\n\n                # Checkpointing.\n                if (epoch % chkpt_every_epoch == 0) or (epoch + 1 == n_epochs):\n                    self.dir.loss = loss_over_iters\n                    self.dir.activity = activity_over_iters\n                    self.dir.activity_min = activity_min_over_iters\n                    self.dir.activity_max = activity_max_over_iters\n\n                    for task in self.task.dataset.tasks:\n                        self.dir[f\"loss_{task}\"] = loss_per_task[f\"loss_{task}\"]\n\n                    self.checkpoint()\n\n                logging.info(\"Finished epoch.\")\n\n        time_elapsed = time.time() - start_time\n        time_trained = self.dir.time_trained[()] if \"time_trained\" in self.dir else 0\n        self.dir.time_trained = time_elapsed + time_trained\n        logging.info(\"Finished training.\")\n\n    def checkpoint(self) -&gt; None:\n        \"\"\"Creates a checkpoint.\n\n        Validates on the validation data calling ~self.test.\n        Validates on a training batch calling ~self.track_batch.\n        Stores a checkpoint of the network, decoder and optimizer parameters using\n        pytorch's pickle function.\n\n        Stores:\n            ```bash\n            dir / chkpt_index.h5  # (List): numerical identifier of the checkpoint.\n            dir / chkpt_iter.h5  # (List): iteration at which this checkpoint was\n                                 # recorded.\n            dir / best_chkpt_index.h5  # (int): chkpt index at which the val loss is\n                                       # minimal.\n            dir / dt.h5  # (float): the current time constant of the dataset.\n            dir / chkpts / chkpt_&lt;chkpt_index&gt;  # (dict): the state dicts of the network,\n                                                # decoder and optimizer.\n            ```\n        \"\"\"\n        self._last_chkpt_ind += 1\n        self._curr_chkpt_ind += 1\n\n        # Tracking of validation loss and training batch loss.\n        logging.info(\"Test on validation data.\")\n        val_loss = self.test(\n            dataloader=self.task.val_data, subdir=\"validation\", track_loss=True\n        )\n        logging.info(\"Test on validation batch.\")\n        _ = self.test(\n            dataloader=self.task.val_batch, subdir=\"validation_batch\", track_loss=True\n        )\n        logging.info(\"Test on training data.\")\n        _ = self.test(dataloader=self.task.train_data, subdir=\"training\", track_loss=True)\n        logging.info(\"Test on training batch.\")\n        _ = self.test(\n            dataloader=self.task.train_batch, subdir=\"training_batch\", track_loss=True\n        )\n\n        logging.info(\"Saving state dicts.\")\n        # Store state of pytorch modules.\n        nn_state_dict = self.network.state_dict()\n        dec_state_dict = {}\n        if self.decoder:\n            dec_state_dict = valmap(lambda x: x.state_dict(), self.decoder)\n        chkpt = {\n            \"network\": nn_state_dict,\n            \"decoder\": dec_state_dict,\n            \"optim\": self.optimizer.state_dict(),\n            \"time\": time.ctime(),\n            \"val_loss\": val_loss,\n            \"iteration\": self.iteration - 1,\n            \"dt\": self.task.dataset.dt,\n        }\n        if hasattr(self, \"penalty\"):\n            chkpt.update(self.penalty._chkpt())\n        torch.save(chkpt, self.checkpoint_path / f\"chkpt_{self._last_chkpt_ind:05}\")\n\n        # Append chkpt index.\n        self.checkpoints.append(self._last_chkpt_ind)\n        self.dir.extend(\"chkpt_index\", [self._last_chkpt_ind])\n        self.dir.extend(\"chkpt_iter\", [self.iteration - 1])\n        self.dir.dt = self.task.dataset.dt\n\n        # Overwrite best val loss.\n        if val_loss &lt; self._val_loss:\n            self.dir.best_chkpt_index = self._last_chkpt_ind\n            self._val_loss = val_loss\n\n        logging.info(\"Checkpointed.\")\n\n    @torch.no_grad()\n    def test(\n        self,\n        dataloader: torch.utils.data.DataLoader,\n        subdir: str = \"validation\",\n        track_loss: bool = False,\n        t_pre: float = 0.25,\n    ) -&gt; float:\n        \"\"\"Tests the network on a given dataloader.\n\n        Args:\n            dataloader: Data to test on.\n            subdir: Name of subdirectory. Defaults to 'validation'.\n            track_loss: Whether to store the loss in dir.subdir.\n            t_pre: Warmup time before the stimulus starts.\n\n        Returns:\n            Validation loss.\n\n        Stores:\n            ```bash\n            dir.&lt;subdir&gt;.loss_&lt;task&gt;  # (List): Loss per task, averaged over whole\n                                      # dataset.\n            dir.&lt;subdir&gt;.iteration  # (List): Iteration when this was called.\n            dir.&lt;subdir&gt;.loss  # (List): Average loss over tasks.\n            ```\n        \"\"\"\n        self._eval()\n        logging.info(\"Test\")\n\n        # Update hypterparams.\n        self.scheduler(self.iteration)\n\n        initial_state = self.network.steady_state(\n            t_pre=t_pre,\n            dt=self.task.dataset.dt,\n            batch_size=dataloader.batch_size,\n            value=0.5,\n        )\n        losses = {task: () for task in self.task.dataset.tasks}  # type: Dict[str, Tuple]\n\n        with self.task.dataset.augmentation(False):\n            for _, data in enumerate(dataloader):\n                n_samples, n_frames, _, _ = data[\"lum\"].shape\n                self.network.stimulus.zero(n_samples, n_frames)\n\n                self.network.stimulus.add_input(data[\"lum\"])\n\n                activity = self.network(\n                    self.network.stimulus(),\n                    self.task.dataset.dt,\n                    state=initial_state,\n                )\n\n                for task in self.task.dataset.tasks:\n                    y = data[task]\n                    y_est = self.decoder[task](activity)\n\n                    losses[task] += (\n                        self.task.loss(y_est, y, task, **data.get(\"loss_kwargs\", {}))\n                        .detach()\n                        .cpu()\n                        .item(),\n                    )\n\n        # track loss per task.\n        avg_loss_per_task = {}\n        for task in self.task.dataset.tasks:\n            # average the loss over the whole dataset\n            avg_loss_per_task[task] = np.mean(losses[task])\n            if track_loss:\n                self.dir[subdir].extend(\"loss\" + \"_\" + task, [avg_loss_per_task[task]])\n\n        # average the loss over all tasks with equal weight\n        summed_loss = sum(avg_loss_per_task.values())\n        val_loss = summed_loss / len(avg_loss_per_task)\n\n        if track_loss:\n            self.dir[subdir].extend(\"iteration\", [self.iteration])\n            self.dir[subdir].extend(\"loss\", [val_loss])\n\n        self._train()\n\n        return val_loss\n\n    def _train(self) -&gt; None:\n        \"\"\"Sets nn.Modules to train state.\"\"\"\n        self.network.train()\n        if self.decoder is not None:\n            for decoder in self.decoder.values():\n                decoder.train()\n\n    def _eval(self) -&gt; None:\n        \"\"\"Sets nn.Modules to eval state.\"\"\"\n        self.network.eval()\n        if self.decoder is not None:\n            for decoder in self.decoder.values():\n                decoder.eval()\n\n    def recover(\n        self,\n        network: bool = True,\n        decoder: bool = True,\n        optimizer: bool = True,\n        penalty: bool = True,\n        checkpoint: Union[int, str] = \"best\",\n        validation_subdir: str = \"validation\",\n        loss_file_name: str = \"loss\",\n        strict: bool = True,\n        force: bool = False,\n    ) -&gt; None:\n        \"\"\"Recovers the solver state from a checkpoint.\n\n        Args:\n            network: Recover network parameters.\n            decoder: Recover decoder parameters.\n            optimizer: Recover optimizer parameters.\n            penalty: Recover penalty parameters.\n            checkpoint: Index of the checkpoint to recover.\n            validation_subdir: Name of the subdir to base the best checkpoint on.\n            loss_file_name: Name of the loss to base the best checkpoint on.\n            strict: Whether to load the state dict of the decoders strictly.\n            force: Force recovery of checkpoint if _curr_chkpt_ind is already\n                the same as the checkpoint index.\n        \"\"\"\n        checkpoints = resolve_checkpoints(\n            self.dir, checkpoint, validation_subdir, loss_file_name\n        )\n\n        if checkpoint.index is None or not any((network, decoder, optimizer, penalty)):\n            logging.info(\"No checkpoint found. Continuing with initialized parameters.\")\n            return\n\n        if checkpoints.index == self._curr_chkpt_ind and not force:\n            logging.info(\"Checkpoint already recovered.\")\n            return\n\n        # Set the current and last checkpoint index. New checkpoints incrementally\n        # increase the last checkpoint index.\n        self._last_chkpt_ind = checkpoints.indices[-1]\n        self._curr_chkpt_ind = checkpoints.index\n\n        # Load checkpoint data.\n        state_dict = torch.load(checkpoints.path)\n        logging.info(f\"Checkpoint {checkpoints.path} loaded.\")\n\n        self.iteration = state_dict.get(\"iteration\", None)\n\n        if \"scheduler\" in self._initialized:\n            # Set the scheduler to the right iteration.\n            self.scheduler(self.iteration)\n\n        # The _val_loss variable is used to keep track of the best checkpoint according\n        # to the evaluation routine during training.\n        self._val_loss = state_dict.pop(\"val_loss\", float(\"inf\"))\n\n        if network and \"network\" in self._initialized:\n            recover_network(self.network, state_dict)\n        if decoder and \"decoder\" in self._initialized:\n            recover_decoder(self.decoder, state_dict, strict=strict)\n        if optimizer and \"optim\" in self._initialized:\n            recover_optimizer(self.optimizer, state_dict)\n        if penalty and \"penalties\" in self._initialized:\n            recover_penalty_optimizers(self.penalty.optimizers, state_dict)\n\n        logging.info(\"Recovered modules.\")\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.MultiTaskSolver.train","title":"train","text":"<pre><code>train(overfit=False, initial_checkpoint=True)\n</code></pre> <p>Trains the network by backprop through time.</p> <p>Parameters:</p> Name Type Description Default <code>overfit</code> <code>bool</code> <p>If true, the dataloader is substituted by a single-sequence loader and augmentation is turned off.</p> <code>False</code> <code>initial_checkpoint</code> <code>bool</code> <p>Whether to create an initial checkpoint when debugging.</p> <code>True</code> <p>Raises:</p> Type Description <code>OverflowError</code> <p>If the activity or loss reports NaN values for more than 100 iterations.</p> Stores <pre><code>dir / loss.h5\ndir / loss_&lt;task&gt;.h5\ndir / activity.h5\ndir / activity_min.h5\ndir / activity_max.h5\n</code></pre> Source code in <code>flyvis/solver.py</code> <pre><code>def train(self, overfit: bool = False, initial_checkpoint: bool = True) -&gt; None:\n    \"\"\"Trains the network by backprop through time.\n\n    Args:\n        overfit: If true, the dataloader is substituted by a\n            single-sequence loader and augmentation is turned off.\n        initial_checkpoint: Whether to create an initial checkpoint when debugging.\n\n    Raises:\n        OverflowError: If the activity or loss reports NaN values for more\n            than 100 iterations.\n\n    Stores:\n        ```bash\n        dir / loss.h5\n        dir / loss_&lt;task&gt;.h5\n        dir / activity.h5\n        dir / activity_min.h5\n        dir / activity_max.h5\n        ```\n    \"\"\"\n    # return if iterations have already been trained.\n    if self.iteration &gt;= self.task.n_iters:\n        return\n\n    # to debug code within the training loop the initial checkpoint should be\n    # disabled\n    if initial_checkpoint:\n        self.checkpoint()\n\n    logging.info(\"Starting training.\")\n    # The overfit_data dataloader only contains a single sequence and\n    # this is to debug the model architecture, configs etc.\n    dataloader = self.task.overfit_data if overfit else self.task.train_data\n    # For overfitting we also turn the augmentation off.\n    augment = not overfit\n\n    # The number of full presentations of the training data is derived from the\n    # preset number of training iterations, the length of the dataloader and the\n    # current iteration.\n    n_epochs = np.ceil((self.task.n_iters - self.iteration) / len(dataloader)).astype(\n        int\n    )\n\n    # This is after how many epochs the training states are checkpointed.\n    chkpt_every_epoch = self.config.scheduler.chkpt_every_epoch\n\n    logging.info(\"Training for %s epochs.\", n_epochs)\n    logging.info(\"Checkpointing every %s epochs.\", chkpt_every_epoch)\n\n    # Initialize data structures to store the loss and activity over iterations.\n    loss_over_iters = []\n    activity_over_iters = []\n    activity_min_over_iters = []\n    activity_max_over_iters = []\n    loss_per_task = {f\"loss_{task}\": [] for task in self.task.dataset.tasks}\n\n    start_time = time.time()\n    with self.task.dataset.augmentation(augment):\n        for epoch in range(n_epochs):\n            # The default is to compute a steady state for each epoch, then\n            # it's computed here. Note: unless done per iteration, parameter updates\n            # within epochs are not considered in the steady state.\n            steady_state = self.network.steady_state(\n                t_pre=self.config.get(\"t_pre_train\", 0.5),\n                dt=self.task.dataset.dt,\n                batch_size=dataloader.batch_size,\n                value=0.5,\n            )\n\n            for _, data in enumerate(dataloader):\n\n                def handle_batch(data, steady_state):\n                    \"\"\"Closure to free memory by garbage collector effectively.\"\"\"\n\n                    # Resets the stimulus buffer (samples, frames, neurons).\n                    n_samples, n_frames, _, _ = data[\"lum\"].shape\n                    self.network.stimulus.zero(n_samples, n_frames)\n\n                    # Add batch of hex-videos (#frames, #samples, #hexals) as\n                    # photorecptor stimuli.\n                    self.network.stimulus.add_input(data[\"lum\"])\n\n                    # Reset gradients.\n                    self.optimizer.zero_grad()\n\n                    # Run stimulus through network.\n                    activity = self.network(\n                        self.network.stimulus(),\n                        self.task.dataset.dt,\n                        state=steady_state,\n                    )\n\n                    losses = {task: 0 for task in self.task.dataset.tasks}\n                    for task in self.task.dataset.tasks:\n                        y = data[task]\n                        y_est = self.decoder[task](activity)\n\n                        # to pass additional kwargs to the loss function, from\n                        # the data batch from the dataset\n                        losses[task] = self.task.loss(\n                            y_est, y, task, **data.get(\"loss_kwargs\", {})\n                        )\n\n                    # Sum all task losses. The weighting of the tasks is done in the\n                    # loss function.\n                    loss = sum(losses.values())\n\n                    # Compute gradients.\n                    loss.backward(retain_graph=True)\n                    # Update parameters.\n                    self.optimizer.step()\n\n                    # Activity and parameter dependent penalties.\n                    self.penalty(activity=activity, iteration=self.iteration)\n\n                    # Log results.\n                    loss = loss.detach().cpu()\n                    for task in self.task.dataset.tasks:\n                        loss_per_task[f\"loss_{task}\"].append(\n                            losses[task].detach().cpu()\n                        )\n                    loss_over_iters.append(loss)\n                    activity = activity.detach().cpu()\n                    mean_activity = activity.mean()\n                    activity_over_iters.append(mean_activity)\n                    activity_min_over_iters.append(activity.min())\n                    activity_max_over_iters.append(activity.max())\n                    return loss, mean_activity\n\n                # Call closure.\n                loss, mean_activity = handle_batch(data, steady_state)\n\n                # Increment iteration count.\n                self.iteration += 1\n\n            # Interrupt training if the network explodes.\n            if torch.isnan(loss) or torch.isnan(mean_activity):\n                logging.warning(\"Network exploded.\")\n                raise OverflowError(\"Invalid values encountered in trace.\")\n\n            # The scheduling of hyperparams are functions of the iteration\n            # however, we allow steps only after full presentations of the data.\n            if epoch + 1 != n_epochs:\n                self.scheduler(self.iteration)\n                logging.info(\"Scheduled paremeters for iteration %s.\", self.iteration)\n\n            # Checkpointing.\n            if (epoch % chkpt_every_epoch == 0) or (epoch + 1 == n_epochs):\n                self.dir.loss = loss_over_iters\n                self.dir.activity = activity_over_iters\n                self.dir.activity_min = activity_min_over_iters\n                self.dir.activity_max = activity_max_over_iters\n\n                for task in self.task.dataset.tasks:\n                    self.dir[f\"loss_{task}\"] = loss_per_task[f\"loss_{task}\"]\n\n                self.checkpoint()\n\n            logging.info(\"Finished epoch.\")\n\n    time_elapsed = time.time() - start_time\n    time_trained = self.dir.time_trained[()] if \"time_trained\" in self.dir else 0\n    self.dir.time_trained = time_elapsed + time_trained\n    logging.info(\"Finished training.\")\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.MultiTaskSolver.checkpoint","title":"checkpoint","text":"<pre><code>checkpoint()\n</code></pre> <p>Creates a checkpoint.</p> <p>Validates on the validation data calling ~self.test. Validates on a training batch calling ~self.track_batch. Stores a checkpoint of the network, decoder and optimizer parameters using pytorch\u2019s pickle function.</p> Stores <pre><code>dir / chkpt_index.h5  # (List): numerical identifier of the checkpoint.\ndir / chkpt_iter.h5  # (List): iteration at which this checkpoint was\n                     # recorded.\ndir / best_chkpt_index.h5  # (int): chkpt index at which the val loss is\n                           # minimal.\ndir / dt.h5  # (float): the current time constant of the dataset.\ndir / chkpts / chkpt_&lt;chkpt_index&gt;  # (dict): the state dicts of the network,\n                                    # decoder and optimizer.\n</code></pre> Source code in <code>flyvis/solver.py</code> <pre><code>def checkpoint(self) -&gt; None:\n    \"\"\"Creates a checkpoint.\n\n    Validates on the validation data calling ~self.test.\n    Validates on a training batch calling ~self.track_batch.\n    Stores a checkpoint of the network, decoder and optimizer parameters using\n    pytorch's pickle function.\n\n    Stores:\n        ```bash\n        dir / chkpt_index.h5  # (List): numerical identifier of the checkpoint.\n        dir / chkpt_iter.h5  # (List): iteration at which this checkpoint was\n                             # recorded.\n        dir / best_chkpt_index.h5  # (int): chkpt index at which the val loss is\n                                   # minimal.\n        dir / dt.h5  # (float): the current time constant of the dataset.\n        dir / chkpts / chkpt_&lt;chkpt_index&gt;  # (dict): the state dicts of the network,\n                                            # decoder and optimizer.\n        ```\n    \"\"\"\n    self._last_chkpt_ind += 1\n    self._curr_chkpt_ind += 1\n\n    # Tracking of validation loss and training batch loss.\n    logging.info(\"Test on validation data.\")\n    val_loss = self.test(\n        dataloader=self.task.val_data, subdir=\"validation\", track_loss=True\n    )\n    logging.info(\"Test on validation batch.\")\n    _ = self.test(\n        dataloader=self.task.val_batch, subdir=\"validation_batch\", track_loss=True\n    )\n    logging.info(\"Test on training data.\")\n    _ = self.test(dataloader=self.task.train_data, subdir=\"training\", track_loss=True)\n    logging.info(\"Test on training batch.\")\n    _ = self.test(\n        dataloader=self.task.train_batch, subdir=\"training_batch\", track_loss=True\n    )\n\n    logging.info(\"Saving state dicts.\")\n    # Store state of pytorch modules.\n    nn_state_dict = self.network.state_dict()\n    dec_state_dict = {}\n    if self.decoder:\n        dec_state_dict = valmap(lambda x: x.state_dict(), self.decoder)\n    chkpt = {\n        \"network\": nn_state_dict,\n        \"decoder\": dec_state_dict,\n        \"optim\": self.optimizer.state_dict(),\n        \"time\": time.ctime(),\n        \"val_loss\": val_loss,\n        \"iteration\": self.iteration - 1,\n        \"dt\": self.task.dataset.dt,\n    }\n    if hasattr(self, \"penalty\"):\n        chkpt.update(self.penalty._chkpt())\n    torch.save(chkpt, self.checkpoint_path / f\"chkpt_{self._last_chkpt_ind:05}\")\n\n    # Append chkpt index.\n    self.checkpoints.append(self._last_chkpt_ind)\n    self.dir.extend(\"chkpt_index\", [self._last_chkpt_ind])\n    self.dir.extend(\"chkpt_iter\", [self.iteration - 1])\n    self.dir.dt = self.task.dataset.dt\n\n    # Overwrite best val loss.\n    if val_loss &lt; self._val_loss:\n        self.dir.best_chkpt_index = self._last_chkpt_ind\n        self._val_loss = val_loss\n\n    logging.info(\"Checkpointed.\")\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.MultiTaskSolver.test","title":"test","text":"<pre><code>test(dataloader, subdir='validation', track_loss=False, t_pre=0.25)\n</code></pre> <p>Tests the network on a given dataloader.</p> <p>Parameters:</p> Name Type Description Default <code>dataloader</code> <code>DataLoader</code> <p>Data to test on.</p> required <code>subdir</code> <code>str</code> <p>Name of subdirectory. Defaults to \u2018validation\u2019.</p> <code>'validation'</code> <code>track_loss</code> <code>bool</code> <p>Whether to store the loss in dir.subdir.</p> <code>False</code> <code>t_pre</code> <code>float</code> <p>Warmup time before the stimulus starts.</p> <code>0.25</code> <p>Returns:</p> Type Description <code>float</code> <p>Validation loss.</p> Stores <pre><code>dir.&lt;subdir&gt;.loss_&lt;task&gt;  # (List): Loss per task, averaged over whole\n                          # dataset.\ndir.&lt;subdir&gt;.iteration  # (List): Iteration when this was called.\ndir.&lt;subdir&gt;.loss  # (List): Average loss over tasks.\n</code></pre> Source code in <code>flyvis/solver.py</code> <pre><code>@torch.no_grad()\ndef test(\n    self,\n    dataloader: torch.utils.data.DataLoader,\n    subdir: str = \"validation\",\n    track_loss: bool = False,\n    t_pre: float = 0.25,\n) -&gt; float:\n    \"\"\"Tests the network on a given dataloader.\n\n    Args:\n        dataloader: Data to test on.\n        subdir: Name of subdirectory. Defaults to 'validation'.\n        track_loss: Whether to store the loss in dir.subdir.\n        t_pre: Warmup time before the stimulus starts.\n\n    Returns:\n        Validation loss.\n\n    Stores:\n        ```bash\n        dir.&lt;subdir&gt;.loss_&lt;task&gt;  # (List): Loss per task, averaged over whole\n                                  # dataset.\n        dir.&lt;subdir&gt;.iteration  # (List): Iteration when this was called.\n        dir.&lt;subdir&gt;.loss  # (List): Average loss over tasks.\n        ```\n    \"\"\"\n    self._eval()\n    logging.info(\"Test\")\n\n    # Update hypterparams.\n    self.scheduler(self.iteration)\n\n    initial_state = self.network.steady_state(\n        t_pre=t_pre,\n        dt=self.task.dataset.dt,\n        batch_size=dataloader.batch_size,\n        value=0.5,\n    )\n    losses = {task: () for task in self.task.dataset.tasks}  # type: Dict[str, Tuple]\n\n    with self.task.dataset.augmentation(False):\n        for _, data in enumerate(dataloader):\n            n_samples, n_frames, _, _ = data[\"lum\"].shape\n            self.network.stimulus.zero(n_samples, n_frames)\n\n            self.network.stimulus.add_input(data[\"lum\"])\n\n            activity = self.network(\n                self.network.stimulus(),\n                self.task.dataset.dt,\n                state=initial_state,\n            )\n\n            for task in self.task.dataset.tasks:\n                y = data[task]\n                y_est = self.decoder[task](activity)\n\n                losses[task] += (\n                    self.task.loss(y_est, y, task, **data.get(\"loss_kwargs\", {}))\n                    .detach()\n                    .cpu()\n                    .item(),\n                )\n\n    # track loss per task.\n    avg_loss_per_task = {}\n    for task in self.task.dataset.tasks:\n        # average the loss over the whole dataset\n        avg_loss_per_task[task] = np.mean(losses[task])\n        if track_loss:\n            self.dir[subdir].extend(\"loss\" + \"_\" + task, [avg_loss_per_task[task]])\n\n    # average the loss over all tasks with equal weight\n    summed_loss = sum(avg_loss_per_task.values())\n    val_loss = summed_loss / len(avg_loss_per_task)\n\n    if track_loss:\n        self.dir[subdir].extend(\"iteration\", [self.iteration])\n        self.dir[subdir].extend(\"loss\", [val_loss])\n\n    self._train()\n\n    return val_loss\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.MultiTaskSolver.recover","title":"recover","text":"<pre><code>recover(network=True, decoder=True, optimizer=True, penalty=True, checkpoint='best', validation_subdir='validation', loss_file_name='loss', strict=True, force=False)\n</code></pre> <p>Recovers the solver state from a checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>bool</code> <p>Recover network parameters.</p> <code>True</code> <code>decoder</code> <code>bool</code> <p>Recover decoder parameters.</p> <code>True</code> <code>optimizer</code> <code>bool</code> <p>Recover optimizer parameters.</p> <code>True</code> <code>penalty</code> <code>bool</code> <p>Recover penalty parameters.</p> <code>True</code> <code>checkpoint</code> <code>Union[int, str]</code> <p>Index of the checkpoint to recover.</p> <code>'best'</code> <code>validation_subdir</code> <code>str</code> <p>Name of the subdir to base the best checkpoint on.</p> <code>'validation'</code> <code>loss_file_name</code> <code>str</code> <p>Name of the loss to base the best checkpoint on.</p> <code>'loss'</code> <code>strict</code> <code>bool</code> <p>Whether to load the state dict of the decoders strictly.</p> <code>True</code> <code>force</code> <code>bool</code> <p>Force recovery of checkpoint if _curr_chkpt_ind is already the same as the checkpoint index.</p> <code>False</code> Source code in <code>flyvis/solver.py</code> <pre><code>def recover(\n    self,\n    network: bool = True,\n    decoder: bool = True,\n    optimizer: bool = True,\n    penalty: bool = True,\n    checkpoint: Union[int, str] = \"best\",\n    validation_subdir: str = \"validation\",\n    loss_file_name: str = \"loss\",\n    strict: bool = True,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Recovers the solver state from a checkpoint.\n\n    Args:\n        network: Recover network parameters.\n        decoder: Recover decoder parameters.\n        optimizer: Recover optimizer parameters.\n        penalty: Recover penalty parameters.\n        checkpoint: Index of the checkpoint to recover.\n        validation_subdir: Name of the subdir to base the best checkpoint on.\n        loss_file_name: Name of the loss to base the best checkpoint on.\n        strict: Whether to load the state dict of the decoders strictly.\n        force: Force recovery of checkpoint if _curr_chkpt_ind is already\n            the same as the checkpoint index.\n    \"\"\"\n    checkpoints = resolve_checkpoints(\n        self.dir, checkpoint, validation_subdir, loss_file_name\n    )\n\n    if checkpoint.index is None or not any((network, decoder, optimizer, penalty)):\n        logging.info(\"No checkpoint found. Continuing with initialized parameters.\")\n        return\n\n    if checkpoints.index == self._curr_chkpt_ind and not force:\n        logging.info(\"Checkpoint already recovered.\")\n        return\n\n    # Set the current and last checkpoint index. New checkpoints incrementally\n    # increase the last checkpoint index.\n    self._last_chkpt_ind = checkpoints.indices[-1]\n    self._curr_chkpt_ind = checkpoints.index\n\n    # Load checkpoint data.\n    state_dict = torch.load(checkpoints.path)\n    logging.info(f\"Checkpoint {checkpoints.path} loaded.\")\n\n    self.iteration = state_dict.get(\"iteration\", None)\n\n    if \"scheduler\" in self._initialized:\n        # Set the scheduler to the right iteration.\n        self.scheduler(self.iteration)\n\n    # The _val_loss variable is used to keep track of the best checkpoint according\n    # to the evaluation routine during training.\n    self._val_loss = state_dict.pop(\"val_loss\", float(\"inf\"))\n\n    if network and \"network\" in self._initialized:\n        recover_network(self.network, state_dict)\n    if decoder and \"decoder\" in self._initialized:\n        recover_decoder(self.decoder, state_dict, strict=strict)\n    if optimizer and \"optim\" in self._initialized:\n        recover_optimizer(self.optimizer, state_dict)\n    if penalty and \"penalties\" in self._initialized:\n        recover_penalty_optimizers(self.penalty.optimizers, state_dict)\n\n    logging.info(\"Recovered modules.\")\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty","title":"Penalty","text":"<p>Penalties on specific parameters.</p> <p>Parameters:</p> Name Type Description Default <code>penalty</code> <code>Namespace</code> <p>Penalty configuration.</p> required <code>network</code> <code>Network</code> <p>The neural network.</p> required Default config in config/penalizer/penalizer.yaml <pre><code>activity_penalty:\n    activity_baseline: 5.0\n    activity_penalty: 0.1\n    stop_iter: 150000\n    below_baseline_penalty_weight: 1.0\n    above_baseline_penalty_weight: 0.1\noptim: SGD\n</code></pre> Default config in config/network/node_config/bias/bias.yaml <pre><code>type: RestingPotential\ngroupby:\n    - type\ninitial_dist: Normal\nmode: sample\nrequires_grad: true\nseed: 0\nmean: 0.5\nstd: 0.05\nsymmetric: []\npenalize:\n    activity: true\n</code></pre> <p>Attributes:</p> Name Type Description <code>config</code> <code>Namespace</code> <p>Penalty configuration.</p> <code>network</code> <code>Network</code> <p>The neural network.</p> <code>central_cells_index</code> <code>ndarray</code> <p>Index of central cells.</p> <code>parameter_config</code> <code>Namespace</code> <p>Configuration for parameter penalties.</p> <code>activity_penalty</code> <code>float</code> <p>Penalty for activity.</p> <code>activity_baseline</code> <code>float</code> <p>Baseline for activity.</p> <code>activity_penalty_stop_iter</code> <code>int</code> <p>Iteration to stop activity penalty.</p> <code>below_baseline_penalty_weight</code> <code>float</code> <p>Weight for below baseline penalty.</p> <code>above_baseline_penalty_weight</code> <code>float</code> <p>Weight for above baseline penalty.</p> <code>parameter_optim</code> <code>Optimizer</code> <p>Optimizer for parameter penalties.</p> <code>activity_optim</code> <code>Optimizer</code> <p>Optimizer for activity penalties.</p> <code>optimizers</code> <code>Dict[str, Optimizer]</code> <p>Dictionary of optimizers.</p> <code>param_list_func_pen</code> <code>list</code> <p>List of parameters for function penalties.</p> <code>param_list_act_pen</code> <code>list</code> <p>List of parameters for activity penalties.</p> <p>Examples:</p> <p>Example configurations passed to the network object:</p> <pre><code># Example 1: Penalize the resting potential of all cell types.\nbias = Namespace(\n    ... (other parameters)\n    penalize=Namespace(activity=True),\n)\n\n# Example 2: add a weight decay penalty to all synapse strengths.\nsyn_strength = Namespace(\n    ... (other parameters)\n    penalize=Namespace(function=\"weight_decay\", kwargs=dict(lambda=1e-3,)),\n)\n</code></pre> Source code in <code>flyvis/solver.py</code> <pre><code>class Penalty:\n    \"\"\"Penalties on specific parameters.\n\n    Args:\n        penalty: Penalty configuration.\n        network: The neural network.\n\n    Note: Default config in config/penalizer/penalizer.yaml\n        ```yaml\n        activity_penalty:\n            activity_baseline: 5.0\n            activity_penalty: 0.1\n            stop_iter: 150000\n            below_baseline_penalty_weight: 1.0\n            above_baseline_penalty_weight: 0.1\n        optim: SGD\n        ```\n\n    Note: Default config in config/network/node_config/bias/bias.yaml\n        ```yaml\n        type: RestingPotential\n        groupby:\n            - type\n        initial_dist: Normal\n        mode: sample\n        requires_grad: true\n        seed: 0\n        mean: 0.5\n        std: 0.05\n        symmetric: []\n        penalize:\n            activity: true\n        ```\n\n    Attributes:\n        config (Namespace): Penalty configuration.\n        network (Network): The neural network.\n        central_cells_index (np.ndarray): Index of central cells.\n        parameter_config (Namespace): Configuration for parameter penalties.\n        activity_penalty (float): Penalty for activity.\n        activity_baseline (float): Baseline for activity.\n        activity_penalty_stop_iter (int): Iteration to stop activity penalty.\n        below_baseline_penalty_weight (float): Weight for below baseline penalty.\n        above_baseline_penalty_weight (float): Weight for above baseline penalty.\n        parameter_optim (torch.optim.Optimizer): Optimizer for parameter penalties.\n        activity_optim (torch.optim.Optimizer): Optimizer for activity penalties.\n        optimizers (Dict[str, torch.optim.Optimizer]): Dictionary of optimizers.\n        param_list_func_pen (list): List of parameters for function penalties.\n        param_list_act_pen (list): List of parameters for activity penalties.\n\n    Examples:\n        Example configurations passed to the network object:\n\n        ```python\n        # Example 1: Penalize the resting potential of all cell types.\n        bias = Namespace(\n            ... (other parameters)\n            penalize=Namespace(activity=True),\n        )\n\n        # Example 2: add a weight decay penalty to all synapse strengths.\n        syn_strength = Namespace(\n            ... (other parameters)\n            penalize=Namespace(function=\"weight_decay\", kwargs=dict(lambda=1e-3,)),\n        )\n        ```\n    \"\"\"\n\n    def __init__(self, penalty: Namespace, network: Network):\n        self.config = penalty\n        self.network = network\n        self.central_cells_index = self.network.connectome.central_cells_index[:]\n\n        self.parameter_config = self.get_network_param_penalty_configs()\n        self.optim_class = getattr(torch.optim, getattr(self.config, \"optim\", \"SGD\"))\n        self.parameter_optim, self.activity_optim = None, None\n        self.init_optim()\n        self.init_hparams()\n\n    def get_network_param_penalty_configs(self) -&gt; Namespace:\n        \"\"\"Returns a dictionary of all network parameters configured to be penalized.\"\"\"\n        node_config = Namespace({\n            \"nodes_\" + k: v.pop(\"penalize\", None)\n            for k, v in self.network.config.node_config.deepcopy().items()\n        })\n        edge_config = Namespace({\n            \"edges_\" + k: v.pop(\"penalize\", None)\n            for k, v in self.network.config.edge_config.deepcopy().items()\n        })\n        return valfilter(\n            lambda v: v is not None,\n            Namespace(**node_config, **edge_config),\n            factory=Namespace,\n        )\n\n    def init_optim(self) -&gt; None:\n        \"\"\"Initialize the individual optimizer instances with the correct set of\n        parameters.\n        \"\"\"\n        self.optimizers = {}\n        self.param_list_func_pen = []\n        self.param_list_act_pen = []\n\n        # collect the parameters that need to be penalized\n        # either by a function or by activity\n        for name, config in self.parameter_config.items():\n            if \"function\" in config and any(list(config.kwargs.values())):\n                self.param_list_func_pen.append(name)\n            if getattr(config, \"activity\", False):\n                self.param_list_act_pen.append(name)\n\n        if self.param_list_func_pen:\n            self.parameter_optim = self.optim_class(\n                (getattr(self.network, param) for param in self.param_list_func_pen),\n                lr=1e-3,\n            )  # LR is overwritten by scheduler.\n            self.optimizers.update(dict(parameter_optim=self.parameter_optim))\n\n        if self.param_list_act_pen:\n            self.activity_optim = self.optim_class(\n                (getattr(self.network, param) for param in self.param_list_act_pen),\n                lr=1e-3,\n            )  # LR is overwritten by scheduler.\n            self.optimizers.update(dict(activity_optim=self.activity_optim))\n\n    def init_hparams(self) -&gt; None:\n        \"\"\"Initialize the hyperparameters for the activity penalty.\"\"\"\n        config = self.config.get(\"activity_penalty\", Namespace())\n\n        # collecting activity penalty parameters\n        (\n            self.activity_penalty,\n            self.activity_baseline,\n            self.activity_penalty_stop_iter,\n            self.below_baseline_penalty_weight,\n            self.above_baseline_penalty_weight,\n        ) = (\n            config.get(\"activity_penalty\", None),\n            config.get(\"activity_baseline\", None),\n            config.get(\"stop_iter\", None),\n            config.get(\"below_baseline_penalty_weight\", None),\n            config.get(\"above_baseline_penalty_weight\", None),\n        )\n\n        if (\n            not any((\n                self.activity_penalty,\n                self.activity_baseline,\n                self.below_baseline_penalty_weight,\n                self.above_baseline_penalty_weight,\n            ))\n            and self.param_list_act_pen\n        ):\n            raise ValueError(\n                \"Activity penalty is enabled but no activity penalty parameters are \"\n                \"set.\"\n            )\n\n    def __repr__(self):\n        return (\n            f\"Penalty(\"\n            f\"parameter_config={self.parameter_config}, \"\n            f\"activity_penalty={self.activity_penalty}, \"\n            f\"activity_baseline={self.activity_baseline}, \"\n            f\"activity_penalty_stop_iter={self.activity_penalty_stop_iter}, \"\n            f\"below_baseline_penalty_weight={self.below_baseline_penalty_weight}, \"\n            f\"above_baseline_penalty_weight={self.above_baseline_penalty_weight}, \"\n            f\"optim_class={self.optim_class}\"\n            f\")\"\n        )\n\n    def __call__(self, activity: torch.Tensor, iteration: int) -&gt; None:\n        \"\"\"Run all configured penalties.\n\n        Args:\n            activity: Network activity.\n            iteration: Current iteration.\n        \"\"\"\n        if self.parameter_optim:\n            self.param_penalty_step()\n        if self.activity_optim:\n            if (\n                self.activity_penalty_stop_iter is None\n                or iteration &lt; self.activity_penalty_stop_iter\n            ):\n                self.activity_penalty_step(activity, retain_graph=False)\n            else:\n                self.activity_optim = None\n\n    def _chkpt(self) -&gt; dict:\n        \"\"\"Returns a dictionary of all state dicts of all optimizer instances.\"\"\"\n        _chkpt = {}\n        for key, optim in self.optimizers.items():\n            if optim is not None:\n                _chkpt[key] = optim.state_dict()\n        return _chkpt\n\n    def param_penalty_step(self) -&gt; None:\n        \"\"\"Apply all the penalties on the individual parameters.\"\"\"\n        self.parameter_optim.zero_grad()\n        penalty = 0\n        for param, config in self.parameter_config.items():\n            if getattr(config, \"function\", False):\n                penalty += getattr(self, config.function)(param, config)\n        penalty.backward()\n        self.parameter_optim.step()\n        self.network.clamp()\n\n    def activity_penalty_step(\n        self, activity: torch.Tensor, retain_graph: bool = True\n    ) -&gt; None:\n        \"\"\"Penalizes parameters tracked in activity_optim for too high or low activity.\n\n        Encourages the nodes to have a higher or lower temporal mean activity,\n        remedying dead or overactive neurons.\n\n        Note:\n            This assumes that the central cells are representative for all cells because\n            of shared parameters across the cell types, which makes this reasonably\n            efficient.\n\n        Args:\n            activity: Network activity of shape (n_samples, n_frames, n_nodes).\n            retain_graph: Whether to retain the computation graph.\n        \"\"\"\n        self.activity_optim.zero_grad()\n        n_samples, n_frames, n_nodes = activity.shape\n        # the temporal average activity of the central nodes after a couple of frames\n        # to avoid the initial transient response\n        activity_mean = activity[:, n_frames // 4 :, self.central_cells_index].mean(\n            dim=1\n        )  # (n_samples, n_node_types)\n        penalty = (\n            self.activity_penalty\n            * (\n                asymmetric_weighting(\n                    self.activity_baseline - activity_mean,\n                    self.below_baseline_penalty_weight,\n                    self.above_baseline_penalty_weight,\n                )\n                ** 2\n            ).mean()\n        )\n        penalty.backward(retain_graph=retain_graph)\n        self.activity_optim.step()\n        self.network.clamp()\n\n    def weight_decay(self, param: str, config: Namespace) -&gt; torch.Tensor:\n        \"\"\"Adds weight decay to the loss.\n\n        Warning: Experimental\n\n        Args:\n            param: Name of the parameter.\n            config: Configuration for the penalty.\n\n        Returns:\n            The weight decay penalty.\n\n        \"\"\"\n        w = getattr(self.network, param)\n        return config.kwargs[\"lambda\"] * (w**2).sum()\n\n    def prior(self, param: str, config: Namespace) -&gt; torch.Tensor:\n        \"\"\"L2 penalty towards initial values.\n\n        Warning: Experimental\n\n        Args:\n            param: Name of the parameter.\n            config: Configuration for the penalty.\n\n        Returns:\n            The L2 penalty.\n\n        TODO: this might be a convenient but suboptimal implementation when the initial\n        values are cast to tensors at each iteration.\n        \"\"\"\n        _key = \"edge_config\" if param.startswith(\"edges\") else \"node_config\"\n        prior = torch.tensor(\n            getattr(self.network.config, _key)[\n                param.replace(\"edges_\", \"\").replace(\"nodes_\", \"\")\n            ].value,\n            dtype=torch.float32,\n        )\n        return (\n            config.kwargs[\"lambda\"] * ((getattr(self.network, param) - prior) ** 2).sum()\n        )\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.get_network_param_penalty_configs","title":"get_network_param_penalty_configs","text":"<pre><code>get_network_param_penalty_configs()\n</code></pre> <p>Returns a dictionary of all network parameters configured to be penalized.</p> Source code in <code>flyvis/solver.py</code> <pre><code>def get_network_param_penalty_configs(self) -&gt; Namespace:\n    \"\"\"Returns a dictionary of all network parameters configured to be penalized.\"\"\"\n    node_config = Namespace({\n        \"nodes_\" + k: v.pop(\"penalize\", None)\n        for k, v in self.network.config.node_config.deepcopy().items()\n    })\n    edge_config = Namespace({\n        \"edges_\" + k: v.pop(\"penalize\", None)\n        for k, v in self.network.config.edge_config.deepcopy().items()\n    })\n    return valfilter(\n        lambda v: v is not None,\n        Namespace(**node_config, **edge_config),\n        factory=Namespace,\n    )\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.init_optim","title":"init_optim","text":"<pre><code>init_optim()\n</code></pre> <p>Initialize the individual optimizer instances with the correct set of parameters.</p> Source code in <code>flyvis/solver.py</code> <pre><code>def init_optim(self) -&gt; None:\n    \"\"\"Initialize the individual optimizer instances with the correct set of\n    parameters.\n    \"\"\"\n    self.optimizers = {}\n    self.param_list_func_pen = []\n    self.param_list_act_pen = []\n\n    # collect the parameters that need to be penalized\n    # either by a function or by activity\n    for name, config in self.parameter_config.items():\n        if \"function\" in config and any(list(config.kwargs.values())):\n            self.param_list_func_pen.append(name)\n        if getattr(config, \"activity\", False):\n            self.param_list_act_pen.append(name)\n\n    if self.param_list_func_pen:\n        self.parameter_optim = self.optim_class(\n            (getattr(self.network, param) for param in self.param_list_func_pen),\n            lr=1e-3,\n        )  # LR is overwritten by scheduler.\n        self.optimizers.update(dict(parameter_optim=self.parameter_optim))\n\n    if self.param_list_act_pen:\n        self.activity_optim = self.optim_class(\n            (getattr(self.network, param) for param in self.param_list_act_pen),\n            lr=1e-3,\n        )  # LR is overwritten by scheduler.\n        self.optimizers.update(dict(activity_optim=self.activity_optim))\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.init_hparams","title":"init_hparams","text":"<pre><code>init_hparams()\n</code></pre> <p>Initialize the hyperparameters for the activity penalty.</p> Source code in <code>flyvis/solver.py</code> <pre><code>def init_hparams(self) -&gt; None:\n    \"\"\"Initialize the hyperparameters for the activity penalty.\"\"\"\n    config = self.config.get(\"activity_penalty\", Namespace())\n\n    # collecting activity penalty parameters\n    (\n        self.activity_penalty,\n        self.activity_baseline,\n        self.activity_penalty_stop_iter,\n        self.below_baseline_penalty_weight,\n        self.above_baseline_penalty_weight,\n    ) = (\n        config.get(\"activity_penalty\", None),\n        config.get(\"activity_baseline\", None),\n        config.get(\"stop_iter\", None),\n        config.get(\"below_baseline_penalty_weight\", None),\n        config.get(\"above_baseline_penalty_weight\", None),\n    )\n\n    if (\n        not any((\n            self.activity_penalty,\n            self.activity_baseline,\n            self.below_baseline_penalty_weight,\n            self.above_baseline_penalty_weight,\n        ))\n        and self.param_list_act_pen\n    ):\n        raise ValueError(\n            \"Activity penalty is enabled but no activity penalty parameters are \"\n            \"set.\"\n        )\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.__call__","title":"__call__","text":"<pre><code>__call__(activity, iteration)\n</code></pre> <p>Run all configured penalties.</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>Tensor</code> <p>Network activity.</p> required <code>iteration</code> <code>int</code> <p>Current iteration.</p> required Source code in <code>flyvis/solver.py</code> <pre><code>def __call__(self, activity: torch.Tensor, iteration: int) -&gt; None:\n    \"\"\"Run all configured penalties.\n\n    Args:\n        activity: Network activity.\n        iteration: Current iteration.\n    \"\"\"\n    if self.parameter_optim:\n        self.param_penalty_step()\n    if self.activity_optim:\n        if (\n            self.activity_penalty_stop_iter is None\n            or iteration &lt; self.activity_penalty_stop_iter\n        ):\n            self.activity_penalty_step(activity, retain_graph=False)\n        else:\n            self.activity_optim = None\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.param_penalty_step","title":"param_penalty_step","text":"<pre><code>param_penalty_step()\n</code></pre> <p>Apply all the penalties on the individual parameters.</p> Source code in <code>flyvis/solver.py</code> <pre><code>def param_penalty_step(self) -&gt; None:\n    \"\"\"Apply all the penalties on the individual parameters.\"\"\"\n    self.parameter_optim.zero_grad()\n    penalty = 0\n    for param, config in self.parameter_config.items():\n        if getattr(config, \"function\", False):\n            penalty += getattr(self, config.function)(param, config)\n    penalty.backward()\n    self.parameter_optim.step()\n    self.network.clamp()\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.activity_penalty_step","title":"activity_penalty_step","text":"<pre><code>activity_penalty_step(activity, retain_graph=True)\n</code></pre> <p>Penalizes parameters tracked in activity_optim for too high or low activity.</p> <p>Encourages the nodes to have a higher or lower temporal mean activity, remedying dead or overactive neurons.</p> Note <p>This assumes that the central cells are representative for all cells because of shared parameters across the cell types, which makes this reasonably efficient.</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>Tensor</code> <p>Network activity of shape (n_samples, n_frames, n_nodes).</p> required <code>retain_graph</code> <code>bool</code> <p>Whether to retain the computation graph.</p> <code>True</code> Source code in <code>flyvis/solver.py</code> <pre><code>def activity_penalty_step(\n    self, activity: torch.Tensor, retain_graph: bool = True\n) -&gt; None:\n    \"\"\"Penalizes parameters tracked in activity_optim for too high or low activity.\n\n    Encourages the nodes to have a higher or lower temporal mean activity,\n    remedying dead or overactive neurons.\n\n    Note:\n        This assumes that the central cells are representative for all cells because\n        of shared parameters across the cell types, which makes this reasonably\n        efficient.\n\n    Args:\n        activity: Network activity of shape (n_samples, n_frames, n_nodes).\n        retain_graph: Whether to retain the computation graph.\n    \"\"\"\n    self.activity_optim.zero_grad()\n    n_samples, n_frames, n_nodes = activity.shape\n    # the temporal average activity of the central nodes after a couple of frames\n    # to avoid the initial transient response\n    activity_mean = activity[:, n_frames // 4 :, self.central_cells_index].mean(\n        dim=1\n    )  # (n_samples, n_node_types)\n    penalty = (\n        self.activity_penalty\n        * (\n            asymmetric_weighting(\n                self.activity_baseline - activity_mean,\n                self.below_baseline_penalty_weight,\n                self.above_baseline_penalty_weight,\n            )\n            ** 2\n        ).mean()\n    )\n    penalty.backward(retain_graph=retain_graph)\n    self.activity_optim.step()\n    self.network.clamp()\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.weight_decay","title":"weight_decay","text":"<pre><code>weight_decay(param, config)\n</code></pre> <p>Adds weight decay to the loss.</p> <p>Warning: Experimental</p> <p>Parameters:</p> Name Type Description Default <code>param</code> <code>str</code> <p>Name of the parameter.</p> required <code>config</code> <code>Namespace</code> <p>Configuration for the penalty.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The weight decay penalty.</p> Source code in <code>flyvis/solver.py</code> <pre><code>def weight_decay(self, param: str, config: Namespace) -&gt; torch.Tensor:\n    \"\"\"Adds weight decay to the loss.\n\n    Warning: Experimental\n\n    Args:\n        param: Name of the parameter.\n        config: Configuration for the penalty.\n\n    Returns:\n        The weight decay penalty.\n\n    \"\"\"\n    w = getattr(self.network, param)\n    return config.kwargs[\"lambda\"] * (w**2).sum()\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.Penalty.prior","title":"prior","text":"<pre><code>prior(param, config)\n</code></pre> <p>L2 penalty towards initial values.</p> <p>Warning: Experimental</p> <p>Parameters:</p> Name Type Description Default <code>param</code> <code>str</code> <p>Name of the parameter.</p> required <code>config</code> <code>Namespace</code> <p>Configuration for the penalty.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The L2 penalty.</p> <p>TODO: this might be a convenient but suboptimal implementation when the initial values are cast to tensors at each iteration.</p> Source code in <code>flyvis/solver.py</code> <pre><code>def prior(self, param: str, config: Namespace) -&gt; torch.Tensor:\n    \"\"\"L2 penalty towards initial values.\n\n    Warning: Experimental\n\n    Args:\n        param: Name of the parameter.\n        config: Configuration for the penalty.\n\n    Returns:\n        The L2 penalty.\n\n    TODO: this might be a convenient but suboptimal implementation when the initial\n    values are cast to tensors at each iteration.\n    \"\"\"\n    _key = \"edge_config\" if param.startswith(\"edges\") else \"node_config\"\n    prior = torch.tensor(\n        getattr(self.network.config, _key)[\n            param.replace(\"edges_\", \"\").replace(\"nodes_\", \"\")\n        ].value,\n        dtype=torch.float32,\n    )\n    return (\n        config.kwargs[\"lambda\"] * ((getattr(self.network, param) - prior) ** 2).sum()\n    )\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler","title":"HyperParamScheduler","text":"<p>Schedules hyperparameters per training iteration.</p> <p>Calling the scheduler instance updates the respective hyperparameters per training iteration.</p> <p>Parameters:</p> Name Type Description Default <code>scheduler</code> <code>Namespace</code> <p>Scheduler configuration.</p> required <code>network</code> <code>Optional[Network]</code> <p>The neural network.</p> required <code>task</code> <code>Optional[Task]</code> <p>The task being solved.</p> required <code>optimizer</code> <code>Optional[Optimizer]</code> <p>The optimizer.</p> required <code>penalizer</code> <code>Optional[Penalty]</code> <p>The penalty object.</p> required Default config in config/scheduler/scheduler.yaml <pre><code>lr_net:\n    function: stepwise\n    start: 5.0e-05\n    stop: 5.0e-06\n    steps: 10\nlr_dec:\n    function: stepwise\n    start: 5.0e-05\n    stop: 5.0e-06\n    steps: 10\nlr_pen:\n    function: stepwise\n    start: ${scheduler.lr_net.start}\n    stop: ${scheduler.lr_net.stop}\n    steps: 10\ndt:\n    function: stepwise\n    start: 0.02\n    stop: 0.02\n    steps: 10\nchkpt_every_epoch: 300\n</code></pre> <p>Attributes:</p> Name Type Description <code>config</code> <code>Namespace</code> <p>Scheduler configuration.</p> <code>scheduled_params</code> <code>Namespace</code> <p>Scheduled parameters.</p> <code>network</code> <code>Network</code> <p>The neural network.</p> <code>task</code> <code>Task</code> <p>The task being solved.</p> <code>optimizer</code> <code>Optimizer</code> <p>The optimizer.</p> <code>penalizer</code> <code>Penalty</code> <p>The penalty object.</p> <code>stop_iter</code> <code>int</code> <p>Iteration to stop scheduling.</p> <code>_current_iteration</code> <code>int</code> <p>Current iteration.</p> Source code in <code>flyvis/solver.py</code> <pre><code>class HyperParamScheduler:\n    \"\"\"Schedules hyperparameters per training iteration.\n\n    Calling the scheduler instance updates the respective hyperparameters per training\n    iteration.\n\n    Args:\n        scheduler: Scheduler configuration.\n        network: The neural network.\n        task: The task being solved.\n        optimizer: The optimizer.\n        penalizer: The penalty object.\n\n    Note: Default config in config/scheduler/scheduler.yaml\n        ```yaml\n        lr_net:\n            function: stepwise\n            start: 5.0e-05\n            stop: 5.0e-06\n            steps: 10\n        lr_dec:\n            function: stepwise\n            start: 5.0e-05\n            stop: 5.0e-06\n            steps: 10\n        lr_pen:\n            function: stepwise\n            start: ${scheduler.lr_net.start}\n            stop: ${scheduler.lr_net.stop}\n            steps: 10\n        dt:\n            function: stepwise\n            start: 0.02\n            stop: 0.02\n            steps: 10\n        chkpt_every_epoch: 300\n        ```\n\n    Attributes:\n        config (Namespace): Scheduler configuration.\n        scheduled_params (Namespace): Scheduled parameters.\n        network (Network): The neural network.\n        task (Task): The task being solved.\n        optimizer (torch.optim.Optimizer): The optimizer.\n        penalizer (Penalty): The penalty object.\n        stop_iter (int): Iteration to stop scheduling.\n        _current_iteration (int): Current iteration.\n    \"\"\"\n\n    def __init__(\n        self,\n        scheduler: Namespace,\n        network: Optional[Network],\n        task: Optional[Task],\n        optimizer: Optional[torch.optim.Optimizer],\n        penalizer: Optional[Penalty],\n    ):\n        self.config = scheduler.deepcopy()\n        self.scheduled_params = self.config.deepcopy()\n        self.network = network\n        self.task = task\n        self.optimizer = optimizer\n        self.penalizer = penalizer\n\n        self.stop_iter = scheduler.get(\"sched_stop_iter\", self.task.n_iters)\n        self._current_iteration = 0\n\n        self.scheduled_params = Namespace()\n        for key, param in self.config.items():\n            try:\n                schedfn_config = SchedulerFunction(**param)\n                logging.info(\"Init schedule for %s\", key)\n            except TypeError:\n                # lazy way to skip the parameter if it's not a SchedulerFunction\n                continue\n\n            # these are the parameters that are scheduled\n            param.array = getattr(self, schedfn_config.function)(\n                self.stop_iter,\n                self.task.n_iters,\n                param.start,\n                param.stop,\n                param.steps,\n            )\n            self.scheduled_params[key] = param\n\n    def __call__(self, iteration: int) -&gt; None:\n        \"\"\"Update hyperparameters for the given iteration.\n\n        Args:\n            iteration: Current iteration.\n        \"\"\"\n        self._current_iteration = iteration\n        for key, param in self.scheduled_params.items():\n            try:\n                setattr(self, key, param.array[iteration])\n            except IndexError as e:\n                if iteration &gt;= self.stop_iter:\n                    setattr(self, key, param.array[-1])\n                else:\n                    raise e\n        logging.info(self)\n\n    def __repr__(self):\n        return \"Scheduler. Iteration: {}/{}.\\nCurrent values: {}.\".format(\n            self._current_iteration,\n            self.task.n_iters,\n            self._params(),\n        )\n\n    def _params(self) -&gt; dict:\n        \"\"\"Get current parameter values.\n\n        Returns:\n            A dictionary of current parameter values.\n        \"\"\"\n        params = {}\n        for key, _param in self.scheduled_params.items():\n            value = getattr(self, key)\n            params[key] = value\n        return params\n\n    # -------- Setter methods called automatically by the scheduler\n\n    @property\n    def dt(self) -&gt; float:\n        return self.task.dataset.dt\n\n    @dt.setter\n    def dt(self, value: float) -&gt; None:\n        self.task.dataset.dt = value\n\n    @property\n    def lr_net(self) -&gt; float:\n        if self.optimizer is None:\n            return\n        return self.optimizer.param_groups[0][\"lr\"]\n\n    @lr_net.setter\n    def lr_net(self, value: float) -&gt; None:\n        if self.optimizer is None:\n            return\n        self.optimizer.param_groups[0][\"lr\"] = value\n\n    @property\n    def lr_dec(self) -&gt; list:\n        if self.optimizer is None:\n            return\n        return [param_group[\"lr\"] for param_group in self.optimizer.param_groups[1:]]\n\n    @lr_dec.setter\n    def lr_dec(self, value: float) -&gt; None:\n        if self.optimizer is None:\n            return\n        for param_group in self.optimizer.param_groups[1:]:\n            param_group[\"lr\"] = value\n\n    @property\n    def lr_pen(self) -&gt; list:\n        if self.penalizer is None:\n            return\n        return [\n            param_group[\"lr\"]\n            for optim in self.penalizer.optimizers.values()\n            for param_group in optim.param_groups\n        ]\n\n    @lr_pen.setter\n    def lr_pen(self, value: float) -&gt; None:\n        if self.penalizer is None:\n            return\n        for optim in self.penalizer.optimizers.values():\n            if optim is not None:\n                for param_group in optim.param_groups:\n                    param_group[\"lr\"] = value\n\n    @property\n    def relu_leak(self) -&gt; float:\n        if self.network is None:\n            return\n        return getattr(self.network.dynamics.activation, \"negative_slope\", None)\n\n    @relu_leak.setter\n    def relu_leak(self, value: float) -&gt; None:\n        if self.network is None:\n            return\n        if hasattr(self.network.dynamics.activation, \"negative_slope\"):\n            self.network.dynamics.activation.negative_slope = value\n\n    @property\n    def activity_penalty(self) -&gt; float:\n        if self.penalizer is None:\n            return\n        return self.penalizer.activity_penalty\n\n    @activity_penalty.setter\n    def activity_penalty(self, value: float) -&gt; None:\n        if self.penalizer is None:\n            return\n        self.penalizer.activity_penalty = value\n\n    # -------- Decay Options\n\n    @staticmethod\n    def linear(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate a linear schedule from start to stop value.\"\"\"\n        f = np.linspace(start, stop, stop_iter)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def stepwise(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate a stepwise schedule from start to stop value.\"\"\"\n        f = np.linspace(start, stop, steps).repeat(stop_iter / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def stepwise_2ndhalf(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate a stepwise schedule that decays in the second half of iterations.\"\"\"\n        f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n        return np.pad(f, (n_iterations - len(f) + 1, 0), constant_values=start)\n\n    @staticmethod\n    def stepwise_half(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate a stepwise schedule that decays in the first half of iterations.\"\"\"\n        f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def steponential(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate an exponential stepwise schedule from start to stop value.\"\"\"\n        x = (1 / stop) ** (1 / steps)\n        values = start / x ** np.arange(steps)\n        f = values.repeat(stop_iter / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=values[-1])\n\n    @staticmethod\n    def steponential_inv(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate an inverse exponential stepwise schedule.\"\"\"\n        _start = steps\n        _stop = 0\n        x = 1 / _stop\n        values = _start / x ** np.arange(steps)\n        f = values.repeat(stop_iter / steps)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=values[-1])\n\n    @staticmethod\n    def exponential(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate an exponential schedule from start to stop value.\"\"\"\n        tau = -stop_iter / (np.log(stop + 1e-15) - np.log(start))\n        f = start * np.exp(-np.arange(stop_iter) / tau)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n\n    @staticmethod\n    def exponential_half(\n        stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n    ) -&gt; np.ndarray:\n        \"\"\"Generate exponential schedule that decays in the first half of iterations.\"\"\"\n        tau = -int((stop_iter / 2)) / (np.log(stop) - np.log(start))\n        f = start * np.exp(-np.arange(int(stop_iter / 2)) / tau)\n        return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.__call__","title":"__call__","text":"<pre><code>__call__(iteration)\n</code></pre> <p>Update hyperparameters for the given iteration.</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>Current iteration.</p> required Source code in <code>flyvis/solver.py</code> <pre><code>def __call__(self, iteration: int) -&gt; None:\n    \"\"\"Update hyperparameters for the given iteration.\n\n    Args:\n        iteration: Current iteration.\n    \"\"\"\n    self._current_iteration = iteration\n    for key, param in self.scheduled_params.items():\n        try:\n            setattr(self, key, param.array[iteration])\n        except IndexError as e:\n            if iteration &gt;= self.stop_iter:\n                setattr(self, key, param.array[-1])\n            else:\n                raise e\n    logging.info(self)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.linear","title":"linear  <code>staticmethod</code>","text":"<pre><code>linear(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate a linear schedule from start to stop value.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef linear(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate a linear schedule from start to stop value.\"\"\"\n    f = np.linspace(start, stop, stop_iter)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.stepwise","title":"stepwise  <code>staticmethod</code>","text":"<pre><code>stepwise(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate a stepwise schedule from start to stop value.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef stepwise(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate a stepwise schedule from start to stop value.\"\"\"\n    f = np.linspace(start, stop, steps).repeat(stop_iter / steps)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.stepwise_2ndhalf","title":"stepwise_2ndhalf  <code>staticmethod</code>","text":"<pre><code>stepwise_2ndhalf(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate a stepwise schedule that decays in the second half of iterations.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef stepwise_2ndhalf(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate a stepwise schedule that decays in the second half of iterations.\"\"\"\n    f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n    return np.pad(f, (n_iterations - len(f) + 1, 0), constant_values=start)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.stepwise_half","title":"stepwise_half  <code>staticmethod</code>","text":"<pre><code>stepwise_half(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate a stepwise schedule that decays in the first half of iterations.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef stepwise_half(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate a stepwise schedule that decays in the first half of iterations.\"\"\"\n    f = np.linspace(start, stop, steps).repeat((stop_iter / 2) / steps)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.steponential","title":"steponential  <code>staticmethod</code>","text":"<pre><code>steponential(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate an exponential stepwise schedule from start to stop value.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef steponential(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate an exponential stepwise schedule from start to stop value.\"\"\"\n    x = (1 / stop) ** (1 / steps)\n    values = start / x ** np.arange(steps)\n    f = values.repeat(stop_iter / steps)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=values[-1])\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.steponential_inv","title":"steponential_inv  <code>staticmethod</code>","text":"<pre><code>steponential_inv(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate an inverse exponential stepwise schedule.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef steponential_inv(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate an inverse exponential stepwise schedule.\"\"\"\n    _start = steps\n    _stop = 0\n    x = 1 / _stop\n    values = _start / x ** np.arange(steps)\n    f = values.repeat(stop_iter / steps)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=values[-1])\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.exponential","title":"exponential  <code>staticmethod</code>","text":"<pre><code>exponential(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate an exponential schedule from start to stop value.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef exponential(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate an exponential schedule from start to stop value.\"\"\"\n    tau = -stop_iter / (np.log(stop + 1e-15) - np.log(start))\n    f = start * np.exp(-np.arange(stop_iter) / tau)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.HyperParamScheduler.exponential_half","title":"exponential_half  <code>staticmethod</code>","text":"<pre><code>exponential_half(stop_iter, n_iterations, start, stop, steps)\n</code></pre> <p>Generate exponential schedule that decays in the first half of iterations.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@staticmethod\ndef exponential_half(\n    stop_iter: int, n_iterations: int, start: float, stop: float, steps: int\n) -&gt; np.ndarray:\n    \"\"\"Generate exponential schedule that decays in the first half of iterations.\"\"\"\n    tau = -int((stop_iter / 2)) / (np.log(stop) - np.log(start))\n    f = start * np.exp(-np.arange(int(stop_iter / 2)) / tau)\n    return np.pad(f, (0, n_iterations - len(f) + 1), constant_values=stop)\n</code></pre>"},{"location":"reference/solver/#flyvis.solver.SchedulerFunction","title":"SchedulerFunction  <code>dataclass</code>","text":"<p>Configuration for a scheduler function.</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>float</code> <p>Start value.</p> <code>stop</code> <code>float</code> <p>Stop value.</p> <code>steps</code> <code>int</code> <p>Number of steps.</p> <code>function</code> <code>str</code> <p>Name of the scheduling function.</p> Source code in <code>flyvis/solver.py</code> <pre><code>@dataclass\nclass SchedulerFunction:\n    \"\"\"Configuration for a scheduler function.\n\n    Attributes:\n        start (float): Start value.\n        stop (float): Stop value.\n        steps (int): Number of steps.\n        function (str): Name of the scheduling function.\n    \"\"\"\n\n    start: float\n    stop: float\n    steps: int\n    function: str\n</code></pre>"},{"location":"reference/tasks/","title":"Task","text":""},{"location":"reference/tasks/#flyvis.task.tasks","title":"flyvis.task.tasks","text":""},{"location":"reference/tasks/#flyvis.task.tasks.Task","title":"Task","text":"<p>Defines a task for a multi-task dataset from configurations.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Namespace</code> <p>Configuration for the dataset.</p> required <code>decoder</code> <code>Namespace</code> <p>Configuration for the decoder.</p> required <code>loss</code> <code>Namespace</code> <p>Configuration for the loss functions.</p> required <code>batch_size</code> <code>int</code> <p>Size of each batch. Defaults to 4.</p> <code>4</code> <code>n_iters</code> <code>int</code> <p>Number of iterations. Defaults to 250,000.</p> <code>250000</code> <code>n_folds</code> <code>int</code> <p>Number of folds for cross-validation. Defaults to 4.</p> <code>4</code> <code>fold</code> <code>int</code> <p>Current fold number. Defaults to 1.</p> <code>1</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 0.</p> <code>0</code> <code>original_split</code> <code>bool</code> <p>Whether to use the original data split. Defaults to False.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>batch_size</code> <p>Size of each batch.</p> <code>n_iters</code> <p>Number of iterations.</p> <code>n_folds</code> <p>Number of folds for cross-validation.</p> <code>fold</code> <p>Current fold number.</p> <code>seed</code> <p>Random seed for reproducibility.</p> <code>decoder</code> <p>Configuration for the decoder.</p> <code>dataset</code> <code>MultiTaskDataset</code> <p>The initialized multi-task dataset.</p> <code>losses</code> <code>Namespace</code> <p>Loss functions for each task.</p> <code>train_seq_index</code> <code>List[int]</code> <p>Indices of training sequences.</p> <code>val_seq_index</code> <code>List[int]</code> <p>Indices of validation sequences.</p> <code>train_data</code> <code>DataLoader</code> <p>DataLoader for training data.</p> <code>train_batch</code> <code>DataLoader</code> <p>DataLoader for a single training batch.</p> <code>val_data</code> <code>DataLoader</code> <p>DataLoader for validation data.</p> <code>val_batch</code> <code>DataLoader</code> <p>DataLoader for a single validation batch.</p> <code>overfit_data</code> <code>DataLoader</code> <p>DataLoader for overfitting on a single sample.</p> Source code in <code>flyvis/task/tasks.py</code> <pre><code>class Task:\n    \"\"\"Defines a task for a multi-task dataset from configurations.\n\n    Args:\n        dataset: Configuration for the dataset.\n        decoder: Configuration for the decoder.\n        loss: Configuration for the loss functions.\n        batch_size: Size of each batch. Defaults to 4.\n        n_iters: Number of iterations. Defaults to 250,000.\n        n_folds: Number of folds for cross-validation. Defaults to 4.\n        fold: Current fold number. Defaults to 1.\n        seed: Random seed for reproducibility. Defaults to 0.\n        original_split: Whether to use the original data split. Defaults to False.\n\n    Attributes:\n        batch_size: Size of each batch.\n        n_iters: Number of iterations.\n        n_folds: Number of folds for cross-validation.\n        fold: Current fold number.\n        seed: Random seed for reproducibility.\n        decoder: Configuration for the decoder.\n        dataset (MultiTaskDataset): The initialized multi-task dataset.\n        losses (Namespace): Loss functions for each task.\n        train_seq_index (List[int]): Indices of training sequences.\n        val_seq_index (List[int]): Indices of validation sequences.\n        train_data (DataLoader): DataLoader for training data.\n        train_batch (DataLoader): DataLoader for a single training batch.\n        val_data (DataLoader): DataLoader for validation data.\n        val_batch (DataLoader): DataLoader for a single validation batch.\n        overfit_data (DataLoader): DataLoader for overfitting on a single sample.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset: Namespace,\n        decoder: Namespace,\n        loss: Namespace,\n        task_weights: Dict[str, float] = None,\n        batch_size: int = 4,\n        n_iters: int = 250_000,\n        n_folds: int = 4,\n        fold: int = 1,\n        seed: int = 0,\n        original_split: bool = False,\n    ):\n        self.batch_size = batch_size\n        self.n_iters = n_iters\n        self.n_folds = n_folds\n        self.fold = fold\n        self.seed = seed\n        self.decoder = decoder\n\n        # Initialize dataset.\n        self.dataset = forward_subclass(MultiTaskDataset, dataset)\n        self.task_weights, self.task_weights_sum = self.init_task_weights(task_weights)\n\n        self.losses = Namespace({\n            task: getattr(objectives, config) for task, config in loss.items()\n        })\n\n        if original_split:\n            self.train_seq_index, self.val_seq_index = (\n                self.dataset.original_train_and_validation_indices()\n            )\n        else:\n            self.train_seq_index, self.val_seq_index = self.dataset.get_random_data_split(\n                fold, n_folds, seed\n            )\n\n        # Initialize dataloaders.\n        self.train_data = DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=sampler.SubsetRandomSampler(self.train_seq_index),\n            drop_last=True,\n        )\n        self.train_batch = DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=IndexSampler(self.train_seq_index[:batch_size]),\n            drop_last=False,\n        )\n        logging.info(\n            \"Initialized dataloader with training sequence indices \\n%s\",\n            self.train_seq_index,\n        )\n\n        self.val_data = DataLoader(\n            self.dataset,\n            batch_size=1,\n            sampler=IndexSampler(self.val_seq_index),\n        )\n        self.val_batch = DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=IndexSampler(self.val_seq_index[:batch_size]),\n        )\n        logging.info(\n            \"Initialized dataloader with validation sequence indices \\n%s\",\n            self.val_seq_index,\n        )\n\n        # Initialize overfitting loader.\n        self.overfit_data = DataLoader(self.dataset, sampler=IndexSampler([0]))\n\n    def init_decoder(\n        self, connectome: ConnectomeFromAvgFilters\n    ) -&gt; Dict[str, ActivityDecoder]:\n        \"\"\"Initialize the decoder.\n\n        Args:\n            connectome: The connectome directory.\n\n        Returns:\n            A dictionary of initialized decoders.\n        \"\"\"\n        return init_decoder(self.decoder, connectome)\n\n    def loss(\n        self, input: torch.Tensor, target: torch.Tensor, task: str, **kwargs\n    ) -&gt; torch.Tensor:\n        \"\"\"Returns the task loss multiplied with the task weight.\n\n        Args:\n            input: Input tensor.\n            target: Target tensor.\n            task: Task name.\n            **kwargs: Additional keyword arguments for the loss function.\n\n        Returns:\n            Weighted task loss.\n        \"\"\"\n        return (\n            self.task_weights[task]\n            * self.losses[task](input, target, **kwargs)\n            / self.task_weights_sum\n        )\n\n    def init_task_weights(self, task_weights: Dict[str, float]) -&gt; Dict[str, float]:\n        \"\"\"Returns the task weights.\n\n        Returns:\n            A dictionary of task weights.\n        \"\"\"\n        task_weights = (\n            task_weights\n            if task_weights is not None\n            else {task: 1 for task in self.dataset.tasks}\n        )\n\n        return task_weights, sum(task_weights.values())\n</code></pre>"},{"location":"reference/tasks/#flyvis.task.tasks.Task.init_decoder","title":"init_decoder","text":"<pre><code>init_decoder(connectome)\n</code></pre> <p>Initialize the decoder.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>The connectome directory.</p> required <p>Returns:</p> Type Description <code>Dict[str, ActivityDecoder]</code> <p>A dictionary of initialized decoders.</p> Source code in <code>flyvis/task/tasks.py</code> <pre><code>def init_decoder(\n    self, connectome: ConnectomeFromAvgFilters\n) -&gt; Dict[str, ActivityDecoder]:\n    \"\"\"Initialize the decoder.\n\n    Args:\n        connectome: The connectome directory.\n\n    Returns:\n        A dictionary of initialized decoders.\n    \"\"\"\n    return init_decoder(self.decoder, connectome)\n</code></pre>"},{"location":"reference/tasks/#flyvis.task.tasks.Task.loss","title":"loss","text":"<pre><code>loss(input, target, task, **kwargs)\n</code></pre> <p>Returns the task loss multiplied with the task weight.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>Input tensor.</p> required <code>target</code> <code>Tensor</code> <p>Target tensor.</p> required <code>task</code> <code>str</code> <p>Task name.</p> required <code>**kwargs</code> <p>Additional keyword arguments for the loss function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Weighted task loss.</p> Source code in <code>flyvis/task/tasks.py</code> <pre><code>def loss(\n    self, input: torch.Tensor, target: torch.Tensor, task: str, **kwargs\n) -&gt; torch.Tensor:\n    \"\"\"Returns the task loss multiplied with the task weight.\n\n    Args:\n        input: Input tensor.\n        target: Target tensor.\n        task: Task name.\n        **kwargs: Additional keyword arguments for the loss function.\n\n    Returns:\n        Weighted task loss.\n    \"\"\"\n    return (\n        self.task_weights[task]\n        * self.losses[task](input, target, **kwargs)\n        / self.task_weights_sum\n    )\n</code></pre>"},{"location":"reference/tasks/#flyvis.task.tasks.Task.init_task_weights","title":"init_task_weights","text":"<pre><code>init_task_weights(task_weights)\n</code></pre> <p>Returns the task weights.</p> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>A dictionary of task weights.</p> Source code in <code>flyvis/task/tasks.py</code> <pre><code>def init_task_weights(self, task_weights: Dict[str, float]) -&gt; Dict[str, float]:\n    \"\"\"Returns the task weights.\n\n    Returns:\n        A dictionary of task weights.\n    \"\"\"\n    task_weights = (\n        task_weights\n        if task_weights is not None\n        else {task: 1 for task in self.dataset.tasks}\n    )\n\n    return task_weights, sum(task_weights.values())\n</code></pre>"},{"location":"reference/tasks/#flyvis.task.tasks.init_decoder","title":"init_decoder","text":"<pre><code>init_decoder(config, connectome)\n</code></pre> <p>Initialize decoders.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict</code> <p>Configuration for the decoders.</p> required <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>The connectome directory.</p> required <p>Returns:</p> Type Description <code>Dict[str, ActivityDecoder]</code> <p>A dictionary of decoders.</p> Example <pre><code>decoder = Namespace(\n    flow=Namespace(\n        type=\"DecoderGAVP\",\n        shape=[8, 2],\n        kernel_size=5,\n        const_weight=0.001,\n        p_dropout=0.5,\n    ),\n    depth=Namespace(\n        type=\"DecoderGAVP\",\n        shape=[8, 1],\n        kernel_size=5,\n        const_weight=0.001,\n        p_dropout=0.5,\n    ),\n    lum=Namespace(\n        type=\"DecoderGAVP\",\n        shape=[8, 3],\n        n_out_features=2,\n        kernel_size=5,\n        const_weight=0.001,\n        p_dropout=0.5,\n    ),\n    shared=False,\n)\n</code></pre> Source code in <code>flyvis/task/tasks.py</code> <pre><code>def init_decoder(\n    config: Dict, connectome: ConnectomeFromAvgFilters\n) -&gt; Dict[str, ActivityDecoder]:\n    \"\"\"Initialize decoders.\n\n    Args:\n        config: Configuration for the decoders.\n        connectome: The connectome directory.\n\n    Returns:\n        A dictionary of decoders.\n\n    Example:\n        ```python\n        decoder = Namespace(\n            flow=Namespace(\n                type=\"DecoderGAVP\",\n                shape=[8, 2],\n                kernel_size=5,\n                const_weight=0.001,\n                p_dropout=0.5,\n            ),\n            depth=Namespace(\n                type=\"DecoderGAVP\",\n                shape=[8, 1],\n                kernel_size=5,\n                const_weight=0.001,\n                p_dropout=0.5,\n            ),\n            lum=Namespace(\n                type=\"DecoderGAVP\",\n                shape=[8, 3],\n                n_out_features=2,\n                kernel_size=5,\n                const_weight=0.001,\n                p_dropout=0.5,\n            ),\n            shared=False,\n        )\n        ```\n    \"\"\"\n    config = config.deepcopy()\n\n    def init(conf):\n        return forward_subclass(ActivityDecoder, {**conf, \"connectome\": connectome})\n\n    decoder = valmap(init, config)\n\n    return decoder\n</code></pre>"},{"location":"reference/tasks/#flyvis.task.objectives","title":"flyvis.task.objectives","text":"<p>Loss functions compatible with torch loss function API.</p>"},{"location":"reference/tasks/#flyvis.task.objectives.l2norm","title":"l2norm","text":"<pre><code>l2norm(y_est, y_gt, **kwargs)\n</code></pre> <p>Calculate the mean root cumulative squared error across the last three dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>y_est</code> <code>Tensor</code> <p>The estimated tensor.</p> required <code>y_gt</code> <code>Tensor</code> <p>The ground truth tensor.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The mean root cumulative squared error.</p> Source code in <code>flyvis/task/objectives.py</code> <pre><code>def l2norm(y_est: torch.Tensor, y_gt: torch.Tensor, **kwargs: Any) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate the mean root cumulative squared error across the last three dimensions.\n\n    Args:\n        y_est: The estimated tensor.\n        y_gt: The ground truth tensor.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        The mean root cumulative squared error.\n    \"\"\"\n    return (((y_est - y_gt) ** 2).sum(dim=(1, 2, 3))).sqrt().mean()\n</code></pre>"},{"location":"reference/tasks/#flyvis.task.objectives.epe","title":"epe","text":"<pre><code>epe(y_est, y_gt, **kwargs)\n</code></pre> <p>Calculate the average endpoint error, conventionally reported in optic flow tasks.</p> <p>Parameters:</p> Name Type Description Default <code>y_est</code> <code>Tensor</code> <p>The estimated tensor with shape (samples, frames, ndim, hexals_or_features).</p> required <code>y_gt</code> <code>Tensor</code> <p>The ground truth tensor with the same shape as y_est.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The average endpoint error.</p> Source code in <code>flyvis/task/objectives.py</code> <pre><code>def epe(y_est: torch.Tensor, y_gt: torch.Tensor, **kwargs: Any) -&gt; torch.Tensor:\n    \"\"\"\n    Calculate the average endpoint error, conventionally reported in optic flow tasks.\n\n    Args:\n        y_est: The estimated tensor with shape\n            (samples, frames, ndim, hexals_or_features).\n        y_gt: The ground truth tensor with the same shape as y_est.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        The average endpoint error.\n    \"\"\"\n    return torch.sqrt(((y_est - y_gt) ** 2).sum(dim=2)).mean()\n</code></pre>"},{"location":"reference/utils/","title":"Utils","text":""},{"location":"reference/utils/#flyvisutilsactivity_utils","title":"flyvis.utils.activity_utils","text":""},{"location":"reference/utils/#classes","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.activity_utils.CellTypeActivity","title":"flyvis.utils.activity_utils.CellTypeActivity","text":"<p>               Bases: <code>dict</code></p> <p>Base class for attribute-style access to network activity based on cell types.</p> <p>Parameters:</p> Name Type Description Default <code>keepref</code> <code>bool</code> <p>Whether to keep a reference to the activity. This may not be desired during training to avoid memory issues.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>activity</code> <code>Union[ref, NDArray, Tensor]</code> <p>Weak reference to the activity.</p> <code>keepref</code> <p>Whether to keep a reference to the activity.</p> <code>unique_cell_types</code> <code>List[str]</code> <p>List of unique cell types.</p> <code>input_indices</code> <code>NDArray</code> <p>Indices of input cells.</p> <code>output_indices</code> <code>NDArray</code> <p>Indices of output cells.</p> Note <p>Activity is stored as a weakref by default for memory efficiency during training. Set keepref=True to keep a reference for analysis.</p> Source code in <code>flyvis/utils/activity_utils.py</code> <pre><code>class CellTypeActivity(dict):\n    \"\"\"Base class for attribute-style access to network activity based on cell types.\n\n    Args:\n        keepref: Whether to keep a reference to the activity. This may not be desired\n            during training to avoid memory issues.\n\n    Attributes:\n        activity: Weak reference to the activity.\n        keepref: Whether to keep a reference to the activity.\n        unique_cell_types: List of unique cell types.\n        input_indices: Indices of input cells.\n        output_indices: Indices of output cells.\n\n    Note:\n        Activity is stored as a weakref by default for memory efficiency\n        during training. Set keepref=True to keep a reference for analysis.\n    \"\"\"\n\n    def __init__(self, keepref: bool = False):\n        self.keepref = keepref\n        self.activity: Union[weakref.ref, NDArray, torch.Tensor] = None\n        self.unique_cell_types: List[str] = []\n        self.input_indices: NDArray = np.array([])\n        self.output_indices: NDArray = np.array([])\n\n    def __dir__(self) -&gt; List[str]:\n        return list(set([*dict.__dir__(self), *dict.__iter__(self)]))\n\n    def __len__(self) -&gt; int:\n        return len(self.unique_cell_types)\n\n    def __iter__(self):\n        yield from self.unique_cell_types\n\n    def __repr__(self) -&gt; str:\n        return \"Activity of: \\n{}\".format(\"\\n\".join(wrap(\", \".join(list(self)))))\n\n    def update(self, activity: Union[NDArray, torch.Tensor]) -&gt; None:\n        \"\"\"Update the activity reference.\"\"\"\n        self.activity = activity\n\n    def _slices(self, n: int) -&gt; tuple:\n        return tuple(slice(None) for _ in range(n))\n\n    def __getattr__(self, key):\n        activity = self.activity() if not self.keepref else self.activity\n        if activity is None:\n            return\n        if isinstance(key, list):\n            index = np.stack(list(map(lambda key: dict.__getitem__(self, key), key)))\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (index,)\n            return activity[slices]\n        elif key == slice(None):\n            return activity\n        elif key in self.unique_cell_types:\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (dict.__getitem__(self, key),)\n            return activity[slices]\n        elif key == \"output\":\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (self.output_indices,)\n            return activity[slices]\n        elif key == \"input\":\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (self.input_indices,)\n            return activity[slices]\n        elif key in self.__dict__:\n            return self.__dict__[key]\n        else:\n            raise ValueError(f\"{key}\")\n\n    def __getitem__(self, key):\n        return self.__getattr__(key)\n\n    def __setattr__(self, key, value):\n        if key == \"activity\" and value is not None:\n            if self.keepref is False:\n                value = weakref.ref(value)\n            object.__setattr__(self, key, value)\n        else:\n            object.__setattr__(self, key, value)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.activity_utils.CellTypeActivity.update","title":"update","text":"<pre><code>update(activity)\n</code></pre> <p>Update the activity reference.</p> Source code in <code>flyvis/utils/activity_utils.py</code> <pre><code>def update(self, activity: Union[NDArray, torch.Tensor]) -&gt; None:\n    \"\"\"Update the activity reference.\"\"\"\n    self.activity = activity\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.activity_utils.CentralActivity","title":"flyvis.utils.activity_utils.CentralActivity","text":"<p>               Bases: <code>CellTypeActivity</code></p> <p>Attribute-style access to central cell activity of a cell type.</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>Union[NDArray, Tensor]</code> <p>Activity of shape (\u2026, n_cells).</p> required <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory with reference to required attributes.</p> required <code>keepref</code> <code>bool</code> <p>Whether to keep a reference to the activity.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>activity</code> <p>Activity of shape (\u2026, n_cells).</p> <code>unique_cell_types</code> <p>Array of unique cell types.</p> <code>index</code> <p>NodeIndexer instance.</p> <code>input_indices</code> <p>Array of input indices.</p> <code>output_indices</code> <p>Array of output indices.</p> Source code in <code>flyvis/utils/activity_utils.py</code> <pre><code>class CentralActivity(CellTypeActivity):\n    \"\"\"Attribute-style access to central cell activity of a cell type.\n\n    Args:\n        activity: Activity of shape (..., n_cells).\n        connectome: Connectome directory with reference to required attributes.\n        keepref: Whether to keep a reference to the activity.\n\n    Attributes:\n        activity: Activity of shape (..., n_cells).\n        unique_cell_types: Array of unique cell types.\n        index: NodeIndexer instance.\n        input_indices: Array of input indices.\n        output_indices: Array of output indices.\n    \"\"\"\n\n    def __init__(\n        self,\n        activity: Union[NDArray, torch.Tensor],\n        connectome: ConnectomeFromAvgFilters,\n        keepref: bool = False,\n    ):\n        super().__init__(keepref)\n        self.index = nodes_edges_utils.NodeIndexer(connectome)\n\n        unique_cell_types = connectome.unique_cell_types[:]\n        input_cell_types = connectome.input_cell_types[:]\n        output_cell_types = connectome.output_cell_types[:]\n        self.input_indices = np.array([\n            np.nonzero(unique_cell_types == t)[0] for t in input_cell_types\n        ])\n        self.output_indices = np.array([\n            np.nonzero(unique_cell_types == t)[0] for t in output_cell_types\n        ])\n        self.activity = activity\n        self.unique_cell_types = unique_cell_types.astype(str)\n\n    def __getattr__(self, key):\n        activity = self.activity() if not self.keepref else self.activity\n        if activity is None:\n            return\n        if isinstance(key, list):\n            index = np.stack(list(map(lambda key: self.index[key], key)))\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (index,)\n            return activity[slices]\n        elif key == slice(None):\n            return activity\n        elif key in self.index.unique_cell_types:\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (self.index[key],)\n            return activity[slices]\n        elif key == \"output\":\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (self.output_indices,)\n            return activity[slices]\n        elif key == \"input\":\n            slices = self._slices(len(activity.shape) - 1)\n            slices += (self.input_indices,)\n            return activity[slices]\n        elif key in self.__dict__:\n            return self.__dict__[key]\n        else:\n            raise ValueError(f\"{key}\")\n\n    def __setattr__(self, key, value):\n        if key == \"activity\" and value is not None:\n            if len(self.index.unique_cell_types) != value.shape[-1]:\n                slices = self._slices(len(value.shape) - 1)\n                slices += (self.index.central_cells_index,)\n                value = value[slices]\n                self.keepref = True\n            if self.keepref is False:\n                value = weakref.ref(value)\n            object.__setattr__(self, key, value)\n        else:\n            object.__setattr__(self, key, value)\n\n    def __len__(self):\n        return len(self.unique_cell_types)\n\n    def __iter__(self):\n        for cell_type in self.unique_cell_types:\n            yield cell_type\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.activity_utils.LayerActivity","title":"flyvis.utils.activity_utils.LayerActivity","text":"<p>               Bases: <code>CellTypeActivity</code></p> <p>Attribute-style access to hex-lattice activity (cell-type specific).</p> <p>Parameters:</p> Name Type Description Default <code>activity</code> <code>Union[NDArray, Tensor]</code> <p>Activity of shape (\u2026, n_cells).</p> required <code>connectome</code> <code>ConnectomeFromAvgFilters</code> <p>Connectome directory with reference to required attributes.</p> required <code>keepref</code> <code>bool</code> <p>Whether to keep a reference to the activity.</p> <code>False</code> <code>use_central</code> <code>bool</code> <p>Whether to use central activity.</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>central</code> <p>CentralActivity instance for central nodes.</p> <code>activity</code> <p>Activity of shape (\u2026, n_cells).</p> <code>connectome</code> <p>Connectome directory.</p> <code>unique_cell_types</code> <p>Array of unique cell types.</p> <code>input_indices</code> <p>Array of input indices.</p> <code>output_indices</code> <p>Array of output indices.</p> <code>input_cell_types</code> <p>Array of input cell types.</p> <code>output_cell_types</code> <p>Array of output cell types.</p> <code>n_nodes</code> <p>Number of nodes.</p> Note <p>The name <code>LayerActivity</code> might change in future as it is misleading. This is not a feedforward layer in the machine learning sense but the activity of all cells of a certain cell-type.</p> <p>Example:</p> <pre><code>Central activity can be accessed by:\n```python\na = LayerActivity(activity, network.connectome)\ncentral_T4a = a.central.T4a\n```\n\nAlso allows 'virtual types' that are the sum of individuals:\n```python\na = LayerActivity(activity, network.connectome)\nsummed_a = a['L2+L4']\n```\n</code></pre> Source code in <code>flyvis/utils/activity_utils.py</code> <pre><code>class LayerActivity(CellTypeActivity):\n    \"\"\"Attribute-style access to hex-lattice activity (cell-type specific).\n\n    Args:\n        activity: Activity of shape (..., n_cells).\n        connectome: Connectome directory with reference to required attributes.\n        keepref: Whether to keep a reference to the activity.\n        use_central: Whether to use central activity.\n\n    Attributes:\n        central: CentralActivity instance for central nodes.\n        activity: Activity of shape (..., n_cells).\n        connectome: Connectome directory.\n        unique_cell_types: Array of unique cell types.\n        input_indices: Array of input indices.\n        output_indices: Array of output indices.\n        input_cell_types: Array of input cell types.\n        output_cell_types: Array of output cell types.\n        n_nodes: Number of nodes.\n\n    Note:\n        The name `LayerActivity` might change in future as it is misleading.\n        This is not a feedforward layer in the machine learning sense but the\n        activity of all cells of a certain cell-type.\n\n    Example:\n\n        Central activity can be accessed by:\n        ```python\n        a = LayerActivity(activity, network.connectome)\n        central_T4a = a.central.T4a\n        ```\n\n        Also allows 'virtual types' that are the sum of individuals:\n        ```python\n        a = LayerActivity(activity, network.connectome)\n        summed_a = a['L2+L4']\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        activity: Union[NDArray, torch.Tensor],\n        connectome: ConnectomeFromAvgFilters,\n        keepref: bool = False,\n        use_central: bool = True,\n    ):\n        super().__init__(keepref)\n        self.keepref = keepref\n\n        self.use_central = use_central\n        if use_central:\n            self.central = CentralActivity(activity, connectome, keepref)\n\n        self.activity = activity\n        self.connectome = connectome\n        self.unique_cell_types = connectome.unique_cell_types[:].astype(\"str\")\n        for cell_type in self.unique_cell_types:\n            index = connectome.nodes.layer_index[cell_type][:]\n            self[cell_type] = index\n\n        _cell_types = self.connectome.nodes.type[:]\n        self.input_indices = np.array([\n            np.nonzero(_cell_types == t)[0] for t in self.connectome.input_cell_types\n        ])\n        self.output_indices = np.array([\n            np.nonzero(_cell_types == t)[0] for t in self.connectome.output_cell_types\n        ])\n        self.input_cell_types = self.connectome.input_cell_types[:].astype(str)\n        self.output_cell_types = self.connectome.output_cell_types[:].astype(str)\n        self.n_nodes = len(self.connectome.nodes.type)\n\n    def __setattr__(self, key, value):\n        if key == \"activity\" and value is not None:\n            if self.keepref is False:\n                value = weakref.ref(value)\n\n            if self.use_central:\n                self.central.__setattr__(key, value)\n\n            object.__setattr__(self, key, value)\n        else:\n            object.__setattr__(self, key, value)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.activity_utils.SourceCurrentView","title":"flyvis.utils.activity_utils.SourceCurrentView","text":"<p>Create views of source currents for a target type.</p> <p>Parameters:</p> Name Type Description Default <code>rfs</code> <code>ReceptiveFields</code> <p>ReceptiveFields instance.</p> required <code>currents</code> <code>Union[NDArray, Tensor]</code> <p>Current values.</p> required <p>Attributes:</p> Name Type Description <code>target_type</code> <p>Target cell type.</p> <code>source_types</code> <p>List of source cell types.</p> <code>rfs</code> <p>ReceptiveFields instance.</p> <code>currents</code> <p>Current values.</p> Source code in <code>flyvis/utils/activity_utils.py</code> <pre><code>class SourceCurrentView:\n    \"\"\"Create views of source currents for a target type.\n\n    Args:\n        rfs: ReceptiveFields instance.\n        currents: Current values.\n\n    Attributes:\n        target_type: Target cell type.\n        source_types: List of source cell types.\n        rfs: ReceptiveFields instance.\n        currents: Current values.\n    \"\"\"\n\n    def __init__(self, rfs: ReceptiveFields, currents: Union[NDArray, torch.Tensor]):\n        self.target_type = rfs.target_type\n        self.source_types = list(rfs)\n        self.rfs = rfs\n        self.currents = currents\n\n    def __getattr__(self, key: str) -&gt; Union[NDArray, torch.Tensor]:\n        if key in self.source_types:\n            return np.take(self.currents, self.rfs[key].index, axis=-1)\n        return object.__getattr__(self, key)\n\n    def __getitem__(self, key: str) -&gt; Union[NDArray, torch.Tensor]:\n        return self.__getattr__(key)\n\n    def update(self, currents: Union[NDArray, torch.Tensor]) -&gt; None:\n        \"\"\"Update the currents.\"\"\"\n        self.currents = currents\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.activity_utils.SourceCurrentView.update","title":"update","text":"<pre><code>update(currents)\n</code></pre> <p>Update the currents.</p> Source code in <code>flyvis/utils/activity_utils.py</code> <pre><code>def update(self, currents: Union[NDArray, torch.Tensor]) -&gt; None:\n    \"\"\"Update the currents.\"\"\"\n    self.currents = currents\n</code></pre>"},{"location":"reference/utils/#flyvisutilscache_utils","title":"flyvis.utils.cache_utils","text":""},{"location":"reference/utils/#functions","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.cache_utils.context_aware_cache","title":"flyvis.utils.cache_utils.context_aware_cache","text":"<pre><code>context_aware_cache(func=None, context=lambda self: None)\n</code></pre> <p>Decorator to cache the result of a method based on its arguments and context.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., T]</code> <p>The function to be decorated.</p> <code>None</code> <code>context</code> <code>Callable[[Any], Any]</code> <p>A function that returns the context for caching.</p> <code>lambda self: None</code> <p>Returns:</p> Type Description <code>Callable[..., T]</code> <p>A wrapped function that implements caching based on arguments and context.</p> Example <pre><code>class MyClass:\n    def __init__(self):\n        self.cache = {}\n\n    @context_aware_cache(context=lambda self: self.some_attribute)\n    def my_method(self, arg1, arg2):\n        # Method implementation\n        pass\n</code></pre> Source code in <code>flyvis/utils/cache_utils.py</code> <pre><code>def context_aware_cache(\n    func: Callable[..., T] = None, context: Callable[[Any], Any] = lambda self: None\n) -&gt; Callable[..., T]:\n    \"\"\"\n    Decorator to cache the result of a method based on its arguments and context.\n\n    Args:\n        func: The function to be decorated.\n        context: A function that returns the context for caching.\n\n    Returns:\n        A wrapped function that implements caching based on arguments and context.\n\n    Example:\n        ```python\n        class MyClass:\n            def __init__(self):\n                self.cache = {}\n\n            @context_aware_cache(context=lambda self: self.some_attribute)\n            def my_method(self, arg1, arg2):\n                # Method implementation\n                pass\n        ```\n    \"\"\"\n    if func is None:\n\n        def decorator(f: Callable[..., T]) -&gt; Callable[..., T]:\n            @wraps(f)\n            def wrapper(self: Any, *args: Any, **kwargs: Any) -&gt; T:\n                context_key = make_hashable(context(self))\n                cache_key = hash(make_hashable((f.__name__, args, kwargs, context_key)))\n                if cache_key in self.cache:\n                    return self.cache[cache_key]\n                result = f(self, *args, **kwargs)\n                self.cache[cache_key] = result\n                return result\n\n            return wrapper\n\n        return decorator\n    else:\n\n        @wraps(func)\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -&gt; T:\n            context_key = make_hashable(context(self))\n            cache_key = hash(make_hashable((func.__name__, args, kwargs, context_key)))\n            if cache_key in self.cache:\n                return self.cache[cache_key]\n            result = func(self, *args, **kwargs)\n            self.cache[cache_key] = result\n            return result\n\n        return wrapper\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.cache_utils.make_hashable","title":"flyvis.utils.cache_utils.make_hashable","text":"<pre><code>make_hashable(obj)\n</code></pre> <p>Recursively converts an object into a hashable type.</p> Source code in <code>flyvis/utils/cache_utils.py</code> <pre><code>def make_hashable(obj: Any) -&gt; Any:\n    \"\"\"Recursively converts an object into a hashable type.\"\"\"\n    if isinstance(obj, (int, float, str, bool, type(None))):\n        return obj\n    elif isinstance(obj, (list, set)):\n        try:\n            # Try direct sorting first\n            return tuple(make_hashable(e) for e in sorted(obj))\n        except TypeError:\n            # Fall back to sorting by hash\n            return tuple(\n                make_hashable(e)\n                for e in sorted(obj, key=lambda x: hash(make_hashable(x)))\n            )\n    elif isinstance(obj, dict):\n        try:\n            # Try direct sorting of keys first\n            return tuple(sorted((k, make_hashable(v)) for k, v in obj.items()))\n        except TypeError:\n            # Fall back to sorting by hash of keys\n            return tuple(\n                sorted(\n                    ((k, make_hashable(v)) for k, v in obj.items()),\n                    key=lambda x: hash(make_hashable(x[0])),\n                )\n            )\n    elif isinstance(obj, (tuple, frozenset)):\n        return tuple(make_hashable(e) for e in obj)\n    elif isinstance(obj, slice):\n        return (obj.start, obj.stop, obj.step)\n    else:\n        # For other types, try to get a consistent string representation\n        return f\"{obj.__class__.__module__}.{obj.__class__.__name__}:{str(obj)}\"\n</code></pre>"},{"location":"reference/utils/#flyvisutilschkpt_utils","title":"flyvis.utils.chkpt_utils","text":""},{"location":"reference/utils/#classes_1","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.chkpt_utils.Checkpoints","title":"flyvis.utils.chkpt_utils.Checkpoints  <code>dataclass</code>","text":"<p>Dataclass to store checkpoint information.</p> <p>Attributes:</p> Name Type Description <code>indices</code> <code>List[int]</code> <p>List of checkpoint indices.</p> <code>paths</code> <code>List[Path]</code> <p>List of checkpoint paths.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>@dataclass\nclass Checkpoints:\n    \"\"\"\n    Dataclass to store checkpoint information.\n\n    Attributes:\n        indices: List of checkpoint indices.\n        paths: List of checkpoint paths.\n    \"\"\"\n\n    indices: List[int]\n    paths: List[Path]\n\n    def __repr__(self):\n        return (\n            f\"Checkpoints(\\n\"\n            f\"  indices={repr(self.indices)},\\n\"\n            f\"  paths={repr(self.paths)},\\n\"\n            f\")\"\n        )\n</code></pre>"},{"location":"reference/utils/#functions_1","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.chkpt_utils.recover_network","title":"flyvis.utils.chkpt_utils.recover_network","text":"<pre><code>recover_network(network, state_dict, ensemble_and_network_id=None)\n</code></pre> <p>Load network parameters from state dict.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>FlyVision network.</p> required <code>state_dict</code> <code>Union[Dict, Path, str]</code> <p>State or path to checkpoint containing the \u201cnetwork\u201d parameters.</p> required <code>ensemble_and_network_id</code> <code>str</code> <p>Optional identifier for the network.</p> <code>None</code> <p>Returns:</p> Type Description <code>Module</code> <p>The updated network.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def recover_network(\n    network: nn.Module,\n    state_dict: Union[Dict, Path, str],\n    ensemble_and_network_id: str = None,\n) -&gt; nn.Module:\n    \"\"\"\n    Load network parameters from state dict.\n\n    Args:\n        network: FlyVision network.\n        state_dict: State or path to checkpoint containing the \"network\" parameters.\n        ensemble_and_network_id: Optional identifier for the network.\n\n    Returns:\n        The updated network.\n    \"\"\"\n    state = get_from_state_dict(state_dict, \"network\")\n    if state is not None:\n        network.load_state_dict(state)\n        logging.info(\n            \"Recovered network state%s\",\n            f\" {ensemble_and_network_id}.\" if ensemble_and_network_id else \".\",\n        )\n    else:\n        logging.warning(\"Could not recover network state.\")\n    return network\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.recover_decoder","title":"flyvis.utils.chkpt_utils.recover_decoder","text":"<pre><code>recover_decoder(decoder, state_dict, strict=True)\n</code></pre> <p>Recover multiple decoders from state dict.</p> <p>Parameters:</p> Name Type Description Default <code>decoder</code> <code>Dict[str, Module]</code> <p>Dictionary of decoders.</p> required <code>state_dict</code> <code>Union[Dict, Path]</code> <p>State or path to checkpoint.</p> required <code>strict</code> <code>bool</code> <p>Whether to strictly enforce that the keys in state_dict match.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Module]</code> <p>The updated dictionary of decoders.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def recover_decoder(\n    decoder: Dict[str, nn.Module], state_dict: Union[Dict, Path], strict: bool = True\n) -&gt; Dict[str, nn.Module]:\n    \"\"\"\n    Recover multiple decoders from state dict.\n\n    Args:\n        decoder: Dictionary of decoders.\n        state_dict: State or path to checkpoint.\n        strict: Whether to strictly enforce that the keys in state_dict match.\n\n    Returns:\n        The updated dictionary of decoders.\n    \"\"\"\n    states = get_from_state_dict(state_dict, \"decoder\")\n    if states is not None:\n        for key, dec in decoder.items():\n            state = states.pop(key, None)\n            if state is not None:\n                dec.load_state_dict(state, strict=strict)\n                logging.info(\"Recovered %s decoder state.\", key)\n            else:\n                logging.warning(\"Could not recover state of %s decoder.\", key)\n    else:\n        logging.warning(\"Could not recover decoder states.\")\n    return decoder\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.recover_optimizer","title":"flyvis.utils.chkpt_utils.recover_optimizer","text":"<pre><code>recover_optimizer(optimizer, state_dict)\n</code></pre> <p>Recover optimizer state from state dict.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>Optimizer</code> <p>PyTorch optimizer.</p> required <code>state_dict</code> <code>Union[Dict, Path]</code> <p>State or path to checkpoint.</p> required <p>Returns:</p> Type Description <code>Optimizer</code> <p>The updated optimizer.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def recover_optimizer(\n    optimizer: torch.optim.Optimizer, state_dict: Union[Dict, Path]\n) -&gt; torch.optim.Optimizer:\n    \"\"\"\n    Recover optimizer state from state dict.\n\n    Args:\n        optimizer: PyTorch optimizer.\n        state_dict: State or path to checkpoint.\n\n    Returns:\n        The updated optimizer.\n    \"\"\"\n    state = get_from_state_dict(state_dict, \"optim\")\n    if state is not None:\n        optimizer.load_state_dict(state)\n        logging.info(\"Recovered optimizer state.\")\n    else:\n        logging.warning(\"Could not recover optimizer state.\")\n    return optimizer\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.recover_penalty_optimizers","title":"flyvis.utils.chkpt_utils.recover_penalty_optimizers","text":"<pre><code>recover_penalty_optimizers(optimizers, state_dict)\n</code></pre> <p>Recover penalty optimizers from state dict.</p> <p>Parameters:</p> Name Type Description Default <code>optimizers</code> <code>Dict[str, Optimizer]</code> <p>Dictionary of penalty optimizers.</p> required <code>state_dict</code> <code>Union[Dict, Path]</code> <p>State or path to checkpoint.</p> required <p>Returns:</p> Type Description <code>Dict[str, Optimizer]</code> <p>The updated dictionary of penalty optimizers.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def recover_penalty_optimizers(\n    optimizers: Dict[str, torch.optim.Optimizer], state_dict: Union[Dict, Path]\n) -&gt; Dict[str, torch.optim.Optimizer]:\n    \"\"\"\n    Recover penalty optimizers from state dict.\n\n    Args:\n        optimizers: Dictionary of penalty optimizers.\n        state_dict: State or path to checkpoint.\n\n    Returns:\n        The updated dictionary of penalty optimizers.\n    \"\"\"\n    states = get_from_state_dict(state_dict, \"penalty_optims\")\n    if states is not None:\n        for key, optim in optimizers.items():\n            state = states.pop(key, None)\n            if state is not None:\n                optim.load_state_dict(state)\n                logging.info(\"Recovered %s optimizer state.\", key)\n            else:\n                logging.warning(\"Could not recover state of %s optimizer.\", key)\n    else:\n        logging.warning(\"Could not recover penalty optimizer states.\")\n    return optimizers\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.get_from_state_dict","title":"flyvis.utils.chkpt_utils.get_from_state_dict","text":"<pre><code>get_from_state_dict(state_dict, key)\n</code></pre> <p>Get a specific key from the state dict.</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <code>Union[Dict, Path, str]</code> <p>State dict or path to checkpoint.</p> required <code>key</code> <code>str</code> <p>Key to retrieve from the state dict.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>The value associated with the key in the state dict.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If state_dict is not of type Path, str, or dict.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def get_from_state_dict(state_dict: Union[Dict, Path, str], key: str) -&gt; Dict:\n    \"\"\"\n    Get a specific key from the state dict.\n\n    Args:\n        state_dict: State dict or path to checkpoint.\n        key: Key to retrieve from the state dict.\n\n    Returns:\n        The value associated with the key in the state dict.\n\n    Raises:\n        TypeError: If state_dict is not of type Path, str, or dict.\n    \"\"\"\n    if state_dict is None:\n        return None\n    if isinstance(state_dict, (Path, str)):\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"ignore\", category=FutureWarning)\n            state = torch.load(\n                state_dict, map_location=flyvis.device, weights_only=False\n            ).pop(key, None)\n    elif isinstance(state_dict, dict):\n        state = state_dict.get(key, None)\n    else:\n        raise TypeError(\n            f\"state_dict must be of type Path, str or dict, but is {type(state_dict)}.\"\n        )\n    return state\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.resolve_checkpoints","title":"flyvis.utils.chkpt_utils.resolve_checkpoints","text":"<pre><code>resolve_checkpoints(networkdir)\n</code></pre> <p>Resolve checkpoints from network directory.</p> <p>Parameters:</p> Name Type Description Default <code>networkdir</code> <code>NetworkDir</code> <p>FlyVision network directory.</p> required <p>Returns:</p> Type Description <code>Checkpoints</code> <p>A Checkpoints object containing indices and paths of checkpoints.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def resolve_checkpoints(\n    networkdir: \"flyvis.network.NetworkDir\",\n) -&gt; Checkpoints:\n    \"\"\"\n    Resolve checkpoints from network directory.\n\n    Args:\n        networkdir: FlyVision network directory.\n\n    Returns:\n        A Checkpoints object containing indices and paths of checkpoints.\n    \"\"\"\n    indices, paths = checkpoint_index_to_path_map(networkdir.chkpts.path)\n    return Checkpoints(indices, paths)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.checkpoint_index_to_path_map","title":"flyvis.utils.chkpt_utils.checkpoint_index_to_path_map","text":"<pre><code>checkpoint_index_to_path_map(path, glob='chkpt_*')\n</code></pre> <p>Returns all numerical identifiers and paths to checkpoints stored in path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Checkpoint directory.</p> required <code>glob</code> <code>str</code> <p>Glob pattern for checkpoint files.</p> <code>'chkpt_*'</code> <p>Returns:</p> Type Description <code>Tuple[List[int], List[Path]]</code> <p>A tuple containing a list of indices and a list of paths to checkpoints.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def checkpoint_index_to_path_map(\n    path: Path, glob: str = \"chkpt_*\"\n) -&gt; Tuple[List[int], List[Path]]:\n    \"\"\"\n    Returns all numerical identifiers and paths to checkpoints stored in path.\n\n    Args:\n        path: Checkpoint directory.\n        glob: Glob pattern for checkpoint files.\n\n    Returns:\n        A tuple containing a list of indices and a list of paths to checkpoints.\n    \"\"\"\n    import re\n\n    path.mkdir(exist_ok=True)\n    paths = np.array(sorted(list((path).glob(glob))))\n    try:\n        _index = [int(re.findall(r\"\\d{1,10}\", p.parts[-1])[0]) for p in paths]\n        _sorting_index = np.argsort(_index)\n        paths = paths[_sorting_index].tolist()\n        index = np.array(_index)[_sorting_index].tolist()\n        return index, paths\n    except IndexError:\n        return [], paths\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.best_checkpoint_default_fn","title":"flyvis.utils.chkpt_utils.best_checkpoint_default_fn","text":"<pre><code>best_checkpoint_default_fn(path, validation_subdir='validation', loss_file_name='loss')\n</code></pre> <p>Find the best checkpoint based on the minimum loss.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the network directory.</p> required <code>validation_subdir</code> <code>str</code> <p>Subdirectory containing validation data.</p> <code>'validation'</code> <code>loss_file_name</code> <code>str</code> <p>Name of the loss file.</p> <code>'loss'</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the best checkpoint.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def best_checkpoint_default_fn(\n    path: Path,\n    validation_subdir: str = \"validation\",\n    loss_file_name: str = \"loss\",\n) -&gt; Path:\n    \"\"\"\n    Find the best checkpoint based on the minimum loss.\n\n    Args:\n        path: Path to the network directory.\n        validation_subdir: Subdirectory containing validation data.\n        loss_file_name: Name of the loss file.\n\n    Returns:\n        Path to the best checkpoint.\n    \"\"\"\n    networkdir = flyvis.NetworkDir(path)\n    checkpoint_dir = networkdir.chkpts.path\n    indices, paths = checkpoint_index_to_path_map(checkpoint_dir, glob=\"chkpt_*\")\n    loss_file_name = check_loss_name(networkdir[validation_subdir], loss_file_name)\n    index = np.argmin(networkdir[validation_subdir][loss_file_name][()])\n    index = indices[index]\n    path = paths[index]\n    return path\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.chkpt_utils.check_loss_name","title":"flyvis.utils.chkpt_utils.check_loss_name","text":"<pre><code>check_loss_name(loss_folder, loss_file_name)\n</code></pre> <p>Check if the loss file name exists in the loss folder.</p> <p>Parameters:</p> Name Type Description Default <code>loss_folder</code> <p>The folder containing loss files.</p> required <code>loss_file_name</code> <code>str</code> <p>The name of the loss file to check.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The validated loss file name.</p> Source code in <code>flyvis/utils/chkpt_utils.py</code> <pre><code>def check_loss_name(loss_folder, loss_file_name: str) -&gt; str:\n    \"\"\"\n    Check if the loss file name exists in the loss folder.\n\n    Args:\n        loss_folder: The folder containing loss files.\n        loss_file_name: The name of the loss file to check.\n\n    Returns:\n        The validated loss file name.\n    \"\"\"\n    if loss_file_name not in loss_folder and \"loss\" in loss_folder:\n        warn_once(\n            logging,\n            f\"{loss_file_name} not in {loss_folder.path}, but 'loss' is. \"\n            \"Falling back to 'loss'. You can rerun the ensemble validation to make \"\n            \"appropriate recordings of the losses.\",\n        )\n        loss_file_name = \"loss\"\n    return loss_file_name\n</code></pre>"},{"location":"reference/utils/#flyvisutilsclass_utils","title":"flyvis.utils.class_utils","text":""},{"location":"reference/utils/#functions_2","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.class_utils.find_subclass","title":"flyvis.utils.class_utils.find_subclass","text":"<pre><code>find_subclass(cls, target_subclass_name)\n</code></pre> <p>Recursively search for the target subclass.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type</code> <p>The base class to start the search from.</p> required <code>target_subclass_name</code> <code>str</code> <p>The name of the subclass to find.</p> required <p>Returns:</p> Type Description <code>Optional[Type]</code> <p>The found subclass, or None if not found.</p> Source code in <code>flyvis/utils/class_utils.py</code> <pre><code>def find_subclass(cls: Type, target_subclass_name: str) -&gt; Optional[Type]:\n    \"\"\"\n    Recursively search for the target subclass.\n\n    Args:\n        cls: The base class to start the search from.\n        target_subclass_name: The name of the subclass to find.\n\n    Returns:\n        The found subclass, or None if not found.\n    \"\"\"\n    for subclass in cls.__subclasses__():\n        if subclass.__qualname__ == target_subclass_name:\n            return subclass\n        # Recursively check the subclasses of the current subclass\n        found_subclass = find_subclass(subclass, target_subclass_name)\n        if found_subclass is not None:\n            return found_subclass\n    return None\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.class_utils.forward_subclass","title":"flyvis.utils.class_utils.forward_subclass","text":"<pre><code>forward_subclass(cls, config={}, subclass_key='type', unpack_kwargs=True)\n</code></pre> <p>Forward to a subclass based on the <code>&lt;subclass_key&gt;</code> key in <code>config</code>.</p> <p>Forwards to the parent class if <code>&lt;subclass_key&gt;</code> is not in <code>config</code>.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type</code> <p>The base class to forward from.</p> required <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary containing subclass information.</p> <code>{}</code> <code>subclass_key</code> <code>str</code> <p>Key in the config dictionary specifying the subclass.</p> <code>'type'</code> <code>unpack_kwargs</code> <code>bool</code> <p>Whether to unpack kwargs when initializing the instance.</p> <code>True</code> <p>Returns:</p> Type Description <code>Any</code> <p>An instance of the specified subclass or the base class.</p> Note <p>If the specified subclass is not found, a warning is issued and the base class is used instead.</p> Source code in <code>flyvis/utils/class_utils.py</code> <pre><code>def forward_subclass(\n    cls: Type,\n    config: Dict[str, Any] = {},\n    subclass_key: str = \"type\",\n    unpack_kwargs: bool = True,\n) -&gt; Any:\n    \"\"\"\n    Forward to a subclass based on the `&lt;subclass_key&gt;` key in `config`.\n\n    Forwards to the parent class if `&lt;subclass_key&gt;` is not in `config`.\n\n    Args:\n        cls: The base class to forward from.\n        config: Configuration dictionary containing subclass information.\n        subclass_key: Key in the config dictionary specifying the subclass.\n        unpack_kwargs: Whether to unpack kwargs when initializing the instance.\n\n    Returns:\n        An instance of the specified subclass or the base class.\n\n    Note:\n        If the specified subclass is not found, a warning is issued and the base\n        class is used instead.\n    \"\"\"\n    config = deepcopy(config)\n    target_subclass = config.pop(subclass_key, None)\n\n    # Prepare kwargs by removing the subclass_key if it exists\n    kwargs = {k: v for k, v in config.items() if k != subclass_key}\n\n    def init_with_kwargs(instance: Any) -&gt; None:\n        if unpack_kwargs:\n            instance.__init__(**kwargs)\n        else:\n            instance.__init__(kwargs)\n\n    if target_subclass is not None:\n        # Find the target subclass recursively\n        subclass = find_subclass(cls, target_subclass)\n        if subclass is not None:\n            instance = object.__new__(subclass)\n            init_with_kwargs(instance)\n            return instance\n        else:\n            warn(\n                f\"Unrecognized {subclass_key} {target_subclass}. \"\n                f\"Using {cls.__qualname__}.\",\n                stacklevel=2,\n            )\n    else:\n        warn(f\"Missing {subclass_key} in config. Using {cls.__qualname__}.\", stacklevel=2)\n\n    # Default case: create an instance of the base class\n    instance = object.__new__(cls)\n    init_with_kwargs(instance)\n    return instance\n</code></pre>"},{"location":"reference/utils/#flyvisutilscolor_utils","title":"flyvis.utils.color_utils","text":""},{"location":"reference/utils/#classes_2","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.color_utils.cmap_iter","title":"flyvis.utils.color_utils.cmap_iter","text":"<p>An iterator for colormap colors.</p> <p>Attributes:</p> Name Type Description <code>i</code> <code>int</code> <p>The current index.</p> <code>cmap</code> <p>The colormap to iterate over.</p> <code>stop</code> <code>int</code> <p>The number of colors in the colormap.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>class cmap_iter:\n    \"\"\"\n    An iterator for colormap colors.\n\n    Attributes:\n        i: The current index.\n        cmap: The colormap to iterate over.\n        stop: The number of colors in the colormap.\n    \"\"\"\n\n    def __init__(self, cmap: Union[LinearSegmentedColormap, ListedColormap]):\n        \"\"\"\n        Initialize the cmap_iter.\n\n        Args:\n            cmap: The colormap to iterate over.\n        \"\"\"\n        self.i: int = 0\n        self.cmap = cmap\n        self.stop: int = cmap.N\n\n    def __next__(self) -&gt; Tuple[float, float, float, float]:\n        \"\"\"\n        Get the next color from the colormap.\n\n        Returns:\n            The next color as an RGBA tuple.\n        \"\"\"\n        if self.i &lt; self.stop:\n            self.i += 1\n            return self.cmap(self.i - 1)\n\n    def _repr_html_(self) -&gt; str:\n        \"\"\"\n        Return the HTML representation of the colormap.\n\n        Returns:\n            The HTML representation of the colormap.\n        \"\"\"\n        return self.cmap._repr_html_()\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.cmap_iter.__init__","title":"__init__","text":"<pre><code>__init__(cmap)\n</code></pre> <p>Initialize the cmap_iter.</p> <p>Parameters:</p> Name Type Description Default <code>cmap</code> <code>Union[LinearSegmentedColormap, ListedColormap]</code> <p>The colormap to iterate over.</p> required Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def __init__(self, cmap: Union[LinearSegmentedColormap, ListedColormap]):\n    \"\"\"\n    Initialize the cmap_iter.\n\n    Args:\n        cmap: The colormap to iterate over.\n    \"\"\"\n    self.i: int = 0\n    self.cmap = cmap\n    self.stop: int = cmap.N\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.cmap_iter.__next__","title":"__next__","text":"<pre><code>__next__()\n</code></pre> <p>Get the next color from the colormap.</p> <p>Returns:</p> Type Description <code>Tuple[float, float, float, float]</code> <p>The next color as an RGBA tuple.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def __next__(self) -&gt; Tuple[float, float, float, float]:\n    \"\"\"\n    Get the next color from the colormap.\n\n    Returns:\n        The next color as an RGBA tuple.\n    \"\"\"\n    if self.i &lt; self.stop:\n        self.i += 1\n        return self.cmap(self.i - 1)\n</code></pre>"},{"location":"reference/utils/#functions_3","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.color_utils.is_hex","title":"flyvis.utils.color_utils.is_hex","text":"<pre><code>is_hex(color)\n</code></pre> <p>Check if the given color is in hexadecimal format.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>Union[str, Tuple[float, float, float]]</code> <p>The color to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the color is in hexadecimal format, False otherwise.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def is_hex(color: Union[str, Tuple[float, float, float]]) -&gt; bool:\n    \"\"\"\n    Check if the given color is in hexadecimal format.\n\n    Args:\n        color: The color to check.\n\n    Returns:\n        True if the color is in hexadecimal format, False otherwise.\n    \"\"\"\n    return \"#\" in color\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.is_integer_rgb","title":"flyvis.utils.color_utils.is_integer_rgb","text":"<pre><code>is_integer_rgb(color)\n</code></pre> <p>Check if the given color is in integer RGB format (0-255).</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>Union[Tuple[float, float, float], List[float]]</code> <p>The color to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the color is in integer RGB format, False otherwise.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def is_integer_rgb(color: Union[Tuple[float, float, float], List[float]]) -&gt; bool:\n    \"\"\"\n    Check if the given color is in integer RGB format (0-255).\n\n    Args:\n        color: The color to check.\n\n    Returns:\n        True if the color is in integer RGB format, False otherwise.\n    \"\"\"\n    try:\n        return any([c &gt; 1 for c in color])\n    except TypeError:\n        return False\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.single_color_cmap","title":"flyvis.utils.color_utils.single_color_cmap","text":"<pre><code>single_color_cmap(color)\n</code></pre> <p>Create a single color colormap.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>Union[str, Tuple[float, float, float]]</code> <p>The color to use for the colormap.</p> required <p>Returns:</p> Type Description <code>ListedColormap</code> <p>A ListedColormap object with the specified color.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def single_color_cmap(color: Union[str, Tuple[float, float, float]]) -&gt; ListedColormap:\n    \"\"\"\n    Create a single color colormap.\n\n    Args:\n        color: The color to use for the colormap.\n\n    Returns:\n        A ListedColormap object with the specified color.\n    \"\"\"\n    if is_hex(color):\n        color = to_rgba(color)\n    elif is_integer_rgb(color):\n        color = np.array(color) / 255\n    return ListedColormap(color)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.color_to_cmap","title":"flyvis.utils.color_utils.color_to_cmap","text":"<pre><code>color_to_cmap(end_color, start_color='#FFFFFF', name='custom_cmap', N=256)\n</code></pre> <p>Create a colormap from start and end colors.</p> <p>Parameters:</p> Name Type Description Default <code>end_color</code> <code>str</code> <p>The end color of the colormap.</p> required <code>start_color</code> <code>str</code> <p>The start color of the colormap.</p> <code>'#FFFFFF'</code> <code>name</code> <code>str</code> <p>The name of the colormap.</p> <code>'custom_cmap'</code> <code>N</code> <code>int</code> <p>The number of color segments.</p> <code>256</code> <p>Returns:</p> Type Description <code>LinearSegmentedColormap</code> <p>A LinearSegmentedColormap object.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def color_to_cmap(\n    end_color: str,\n    start_color: str = \"#FFFFFF\",\n    name: str = \"custom_cmap\",\n    N: int = 256,\n) -&gt; LinearSegmentedColormap:\n    \"\"\"\n    Create a colormap from start and end colors.\n\n    Args:\n        end_color: The end color of the colormap.\n        start_color: The start color of the colormap.\n        name: The name of the colormap.\n        N: The number of color segments.\n\n    Returns:\n        A LinearSegmentedColormap object.\n    \"\"\"\n    return LinearSegmentedColormap.from_list(\n        name,\n        [hex2color(start_color), hex2color(end_color)],\n        N=N,\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.get_alpha_colormap","title":"flyvis.utils.color_utils.get_alpha_colormap","text":"<pre><code>get_alpha_colormap(saturated_color, number_of_shades)\n</code></pre> <p>Create a colormap from a color and a number of shades.</p> <p>Parameters:</p> Name Type Description Default <code>saturated_color</code> <code>Union[str, Tuple[float, float, float]]</code> <p>The base color for the colormap.</p> required <code>number_of_shades</code> <code>int</code> <p>The number of shades to create.</p> required <p>Returns:</p> Type Description <code>ListedColormap</code> <p>A ListedColormap object with varying alpha values.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def get_alpha_colormap(\n    saturated_color: Union[str, Tuple[float, float, float]], number_of_shades: int\n) -&gt; ListedColormap:\n    \"\"\"\n    Create a colormap from a color and a number of shades.\n\n    Args:\n        saturated_color: The base color for the colormap.\n        number_of_shades: The number of shades to create.\n\n    Returns:\n        A ListedColormap object with varying alpha values.\n    \"\"\"\n    if is_hex(saturated_color):\n        rgba = [*hex2color(saturated_color)[:3], 0]\n    elif is_integer_rgb(saturated_color):\n        rgba = [*list(np.array(saturated_color) / 255.0), 0]\n\n    colors = []\n    alphas = np.linspace(1 / number_of_shades, 1, number_of_shades)[::-1]\n    for alpha in alphas:\n        rgba[-1] = alpha\n        colors.append(rgba.copy())\n\n    return ListedColormap(colors)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.adapt_color_alpha","title":"flyvis.utils.color_utils.adapt_color_alpha","text":"<pre><code>adapt_color_alpha(color, alpha)\n</code></pre> <p>Transform a color specification to RGBA and adapt the alpha value.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>Union[str, Tuple[float, float, float], Tuple[float, float, float, float]]</code> <p>Color specification in various formats: hex string, RGB tuple, or RGBA tuple.</p> required <code>alpha</code> <code>float</code> <p>New alpha value to be applied.</p> required <p>Returns:</p> Type Description <code>Tuple[float, float, float, float]</code> <p>The adapted color in RGBA format.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def adapt_color_alpha(\n    color: Union[str, Tuple[float, float, float], Tuple[float, float, float, float]],\n    alpha: float,\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"\n    Transform a color specification to RGBA and adapt the alpha value.\n\n    Args:\n        color: Color specification in various formats: hex string, RGB tuple, or\n            RGBA tuple.\n        alpha: New alpha value to be applied.\n\n    Returns:\n        The adapted color in RGBA format.\n    \"\"\"\n    color_rgb = to_rgba(color)\n    r, g, b, _ = color_rgb\n    return r, g, b, alpha\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.flash_response_color_labels","title":"flyvis.utils.color_utils.flash_response_color_labels","text":"<pre><code>flash_response_color_labels(ax)\n</code></pre> <p>Apply color labels for ON and OFF flash responses.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <p>The matplotlib axis to apply the labels to.</p> required <p>Returns:</p> Type Description <p>The modified matplotlib axis.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def flash_response_color_labels(ax):\n    \"\"\"\n    Apply color labels for ON and OFF flash responses.\n\n    Args:\n        ax: The matplotlib axis to apply the labels to.\n\n    Returns:\n        The modified matplotlib axis.\n    \"\"\"\n    on = [key for key, value in polarity.items() if value == 1]\n    off = [key for key, value in polarity.items() if value == -1]\n    color_labels(on, ON_FR, ax)\n    color_labels(off, OFF_FR, ax)\n    return ax\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.color_utils.truncate_colormap","title":"flyvis.utils.color_utils.truncate_colormap","text":"<pre><code>truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100)\n</code></pre> <p>Truncate a colormap to a specific range.</p> <p>Parameters:</p> Name Type Description Default <code>cmap</code> <code>Union[LinearSegmentedColormap, ListedColormap]</code> <p>The colormap to truncate.</p> required <code>minval</code> <code>float</code> <p>The minimum value of the new range.</p> <code>0.0</code> <code>maxval</code> <code>float</code> <p>The maximum value of the new range.</p> <code>1.0</code> <code>n</code> <code>int</code> <p>The number of color segments in the new colormap.</p> <code>100</code> <p>Returns:</p> Type Description <code>LinearSegmentedColormap</code> <p>A new LinearSegmentedColormap with the truncated range.</p> Source code in <code>flyvis/utils/color_utils.py</code> <pre><code>def truncate_colormap(\n    cmap: Union[LinearSegmentedColormap, ListedColormap],\n    minval: float = 0.0,\n    maxval: float = 1.0,\n    n: int = 100,\n) -&gt; LinearSegmentedColormap:\n    \"\"\"\n    Truncate a colormap to a specific range.\n\n    Args:\n        cmap: The colormap to truncate.\n        minval: The minimum value of the new range.\n        maxval: The maximum value of the new range.\n        n: The number of color segments in the new colormap.\n\n    Returns:\n        A new LinearSegmentedColormap with the truncated range.\n    \"\"\"\n    new_cmap = LinearSegmentedColormap.from_list(\n        \"trunc({n},{a:.2f},{b:.2f})\".format(n=cmap.name, a=minval, b=maxval),\n        cmap(np.linspace(minval, maxval, max(n, 2))),\n    )\n    return new_cmap.resampled(max(n, 2))\n</code></pre>"},{"location":"reference/utils/#flyvisutilscompute_cloud_utils","title":"flyvis.utils.compute_cloud_utils","text":""},{"location":"reference/utils/#classes_3","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.ClusterManager","title":"flyvis.utils.compute_cloud_utils.ClusterManager","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for cluster management operations.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>class ClusterManager(ABC):\n    \"\"\"Abstract base class for cluster management operations.\"\"\"\n\n    @abstractmethod\n    def run_job(self, command: str) -&gt; str:\n        \"\"\"\n        Run a job on the cluster.\n\n        Args:\n            command: The command to run.\n\n        Returns:\n            The job ID as a string.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def is_running(self, job_id: str) -&gt; bool:\n        \"\"\"\n        Check if a job is running.\n\n        Args:\n            job_id: The ID of the job to check.\n\n        Returns:\n            True if the job is running, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def kill_job(self, job_id: str) -&gt; str:\n        \"\"\"\n        Kill a running job.\n\n        Args:\n            job_id: The ID of the job to kill.\n\n        Returns:\n            The output of the kill command.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_submit_command(\n        self, job_name: str, n_cpus: int, output_file: str, gpu: str, queue: str\n    ) -&gt; str:\n        \"\"\"\n        Get the command to submit a job to the cluster.\n\n        Args:\n            job_name: The name of the job.\n            n_cpus: The number of CPUs to request.\n            output_file: The file to write job output to.\n            gpu: The GPU configuration.\n            queue: The queue to submit the job to.\n\n        Returns:\n            The submit command as a string.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_script_part(self, command: str) -&gt; str:\n        \"\"\"\n        Get the script part of the command.\n\n        Args:\n            command: The command to wrap.\n\n        Returns:\n            The wrapped command as a string.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.ClusterManager.run_job","title":"run_job  <code>abstractmethod</code>","text":"<pre><code>run_job(command)\n</code></pre> <p>Run a job on the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>The command to run.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job ID as a string.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>@abstractmethod\ndef run_job(self, command: str) -&gt; str:\n    \"\"\"\n    Run a job on the cluster.\n\n    Args:\n        command: The command to run.\n\n    Returns:\n        The job ID as a string.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.ClusterManager.is_running","title":"is_running  <code>abstractmethod</code>","text":"<pre><code>is_running(job_id)\n</code></pre> <p>Check if a job is running.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the job is running, False otherwise.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>@abstractmethod\ndef is_running(self, job_id: str) -&gt; bool:\n    \"\"\"\n    Check if a job is running.\n\n    Args:\n        job_id: The ID of the job to check.\n\n    Returns:\n        True if the job is running, False otherwise.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.ClusterManager.kill_job","title":"kill_job  <code>abstractmethod</code>","text":"<pre><code>kill_job(job_id)\n</code></pre> <p>Kill a running job.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job to kill.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The output of the kill command.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>@abstractmethod\ndef kill_job(self, job_id: str) -&gt; str:\n    \"\"\"\n    Kill a running job.\n\n    Args:\n        job_id: The ID of the job to kill.\n\n    Returns:\n        The output of the kill command.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.ClusterManager.get_submit_command","title":"get_submit_command  <code>abstractmethod</code>","text":"<pre><code>get_submit_command(job_name, n_cpus, output_file, gpu, queue)\n</code></pre> <p>Get the command to submit a job to the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>job_name</code> <code>str</code> <p>The name of the job.</p> required <code>n_cpus</code> <code>int</code> <p>The number of CPUs to request.</p> required <code>output_file</code> <code>str</code> <p>The file to write job output to.</p> required <code>gpu</code> <code>str</code> <p>The GPU configuration.</p> required <code>queue</code> <code>str</code> <p>The queue to submit the job to.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The submit command as a string.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>@abstractmethod\ndef get_submit_command(\n    self, job_name: str, n_cpus: int, output_file: str, gpu: str, queue: str\n) -&gt; str:\n    \"\"\"\n    Get the command to submit a job to the cluster.\n\n    Args:\n        job_name: The name of the job.\n        n_cpus: The number of CPUs to request.\n        output_file: The file to write job output to.\n        gpu: The GPU configuration.\n        queue: The queue to submit the job to.\n\n    Returns:\n        The submit command as a string.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.ClusterManager.get_script_part","title":"get_script_part  <code>abstractmethod</code>","text":"<pre><code>get_script_part(command)\n</code></pre> <p>Get the script part of the command.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>The command to wrap.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The wrapped command as a string.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>@abstractmethod\ndef get_script_part(self, command: str) -&gt; str:\n    \"\"\"\n    Get the script part of the command.\n\n    Args:\n        command: The command to wrap.\n\n    Returns:\n        The wrapped command as a string.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.LSFManager","title":"flyvis.utils.compute_cloud_utils.LSFManager","text":"<p>               Bases: <code>ClusterManager</code></p> <p>Cluster manager for LSF (Load Sharing Facility) systems.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>class LSFManager(ClusterManager):\n    \"\"\"Cluster manager for LSF (Load Sharing Facility) systems.\"\"\"\n\n    def run_job(self, command: str) -&gt; str:\n        answer = subprocess.getoutput(command)\n        job_id = re.findall(r\"(?&lt;=&lt;)\\d+(?=&gt;)\", answer)\n        assert len(job_id) == 1\n        return job_id[0]\n\n    def is_running(self, job_id: str) -&gt; bool:\n        job_info = subprocess.getoutput(\"bjobs -w\")\n        return job_id in job_info\n\n    def kill_job(self, job_id: str) -&gt; str:\n        return subprocess.getoutput(f\"bkill {job_id}\")\n\n    def get_submit_command(\n        self, job_name: str, n_cpus: int, output_file: str, gpu: str, queue: str\n    ) -&gt; str:\n        return f\"bsub -J {job_name} -n {n_cpus} -o {output_file} -gpu '{gpu}' -q {queue} \"\n\n    def get_script_part(self, command: str) -&gt; str:\n        return command\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.SLURMManager","title":"flyvis.utils.compute_cloud_utils.SLURMManager","text":"<p>               Bases: <code>ClusterManager</code></p> <p>Cluster manager for SLURM systems.</p> Warning <p>This is untested.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>class SLURMManager(ClusterManager):\n    \"\"\"Cluster manager for SLURM systems.\n\n    Warning:\n        This is untested.\n    \"\"\"\n\n    def run_job(self, command: str) -&gt; str:\n        answer = subprocess.getoutput(command)\n        job_id = re.findall(r\"\\d+\", answer)\n        assert len(job_id) == 1\n        return job_id[0]\n\n    def is_running(self, job_id: str) -&gt; bool:\n        cmd = f\"sacct -j {job_id} --format=State --noheader -X\"\n        state = subprocess.getoutput(cmd).strip()\n        return state in [\"PENDING\", \"RUNNING\", \"REQUEUED\"]\n\n    def kill_job(self, job_id: str) -&gt; str:\n        return subprocess.getoutput(f\"scancel {job_id}\")\n\n    def get_submit_command(\n        self, job_name: str, n_cpus: int, output_file: str, gpu: str, queue: str\n    ) -&gt; str:\n        return (\n            f\"sbatch --job-name={job_name} \"\n            f\"--cpus-per-task={n_cpus} \"\n            f\"--output={output_file} \"\n            f\"--gres=gpu:{gpu} \"\n            f\"--partition={queue} \"\n        )\n\n    def get_script_part(self, command: str) -&gt; str:\n        return f\"--wrap '{command}'\"\n</code></pre>"},{"location":"reference/utils/#functions_4","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.get_cluster_manager","title":"flyvis.utils.compute_cloud_utils.get_cluster_manager","text":"<pre><code>get_cluster_manager(dry=False)\n</code></pre> <p>Autodetect the cluster type and return the appropriate ClusterManager.</p> <p>Parameters:</p> Name Type Description Default <code>dry</code> <code>bool</code> <p>If True, return LSFManager even if no cluster is detected.</p> <code>False</code> <p>Returns:</p> Type Description <code>ClusterManager</code> <p>An instance of the appropriate ClusterManager subclass.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def get_cluster_manager(dry: bool = False) -&gt; ClusterManager:\n    \"\"\"\n    Autodetect the cluster type and return the appropriate ClusterManager.\n\n    Args:\n        dry: If True, return LSFManager even if no cluster is detected.\n\n    Returns:\n        An instance of the appropriate ClusterManager subclass.\n    \"\"\"\n    virtual = os.environ.get(\"VIRTUAL_CLUSTER\", \"\").lower() in (\"true\", \"1\", \"yes\", \"on\")\n    dry = dry or os.environ.get(\"DRYRUN_ONLY\", \"\").lower() in (\"true\", \"1\", \"yes\", \"on\")\n\n    if subprocess.getoutput(\"command -v bsub\"):\n        return LSFManager()\n    elif subprocess.getoutput(\"command -v sbatch\"):\n        return SLURMManager()\n    else:\n        if dry:\n            return LSFManager()\n        elif virtual:\n            warnings.warn(\n                \"No cluster management system detected. Using VirtualClusterManager for \"\n                \"local execution. This is not recommended for production use.\",\n                UserWarning,\n                stacklevel=2,\n            )\n            return VirtualClusterManager()\n        else:\n            raise RuntimeError(\"No cluster management system detected.\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.run_job","title":"flyvis.utils.compute_cloud_utils.run_job","text":"<pre><code>run_job(command, dry)\n</code></pre> <p>Run a job on the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>The command to run.</p> required <code>dry</code> <code>bool</code> <p>If True, perform a dry run without actually submitting the job.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The job ID as a string, or \u201cdry run\u201d for dry runs.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def run_job(command: str, dry: bool) -&gt; str:\n    \"\"\"\n    Run a job on the cluster.\n\n    Args:\n        command: The command to run.\n        dry: If True, perform a dry run without actually submitting the job.\n\n    Returns:\n        The job ID as a string, or \"dry run\" for dry runs.\n    \"\"\"\n    # TODO: dry handling currently not elegant but works for now\n    env_dry = os.environ.get(\"DRYRUN_ONLY\", \"\").lower() in (\"true\", \"1\", \"yes\", \"on\")\n    is_dry = dry or env_dry\n\n    if is_dry:\n        job_id = \"dry run\"\n        logger.info(\"Dry run command: %s\", command)\n        return job_id\n\n    return CLUSTER_MANAGER.run_job(command)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.is_running","title":"flyvis.utils.compute_cloud_utils.is_running","text":"<pre><code>is_running(job_id, dry)\n</code></pre> <p>Check if a job is running.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job to check.</p> required <code>dry</code> <code>bool</code> <p>If True, always return False.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the job is running, False otherwise.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def is_running(job_id: str, dry: bool) -&gt; bool:\n    \"\"\"\n    Check if a job is running.\n\n    Args:\n        job_id: The ID of the job to check.\n        dry: If True, always return False.\n\n    Returns:\n        True if the job is running, False otherwise.\n    \"\"\"\n    if dry:\n        return False\n    return CLUSTER_MANAGER.is_running(job_id)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.kill_job","title":"flyvis.utils.compute_cloud_utils.kill_job","text":"<pre><code>kill_job(job_id, dry)\n</code></pre> <p>Kill a running job.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job to kill.</p> required <code>dry</code> <code>bool</code> <p>If True, return a message without actually killing the job.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The output of the kill command or a dry run message.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def kill_job(job_id: str, dry: bool) -&gt; str:\n    \"\"\"\n    Kill a running job.\n\n    Args:\n        job_id: The ID of the job to kill.\n        dry: If True, return a message without actually killing the job.\n\n    Returns:\n        The output of the kill command or a dry run message.\n    \"\"\"\n    if dry:\n        return f\"Would kill job {job_id}\"\n    return CLUSTER_MANAGER.kill_job(job_id)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.wait_for_single","title":"flyvis.utils.compute_cloud_utils.wait_for_single","text":"<pre><code>wait_for_single(job_id, dry=False)\n</code></pre> <p>Wait for a single job to finish on the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>str</code> <p>The ID of the job to wait for.</p> required <code>job_name</code> <p>The name of the job.</p> required <code>dry</code> <code>bool</code> <p>If True, skip actual waiting.</p> <code>False</code> <p>Raises:</p> Type Description <code>KeyboardInterrupt</code> <p>If the waiting is interrupted by the user.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def wait_for_single(job_id: str, dry: bool = False) -&gt; None:\n    \"\"\"\n    Wait for a single job to finish on the cluster.\n\n    Args:\n        job_id: The ID of the job to wait for.\n        job_name: The name of the job.\n        dry: If True, skip actual waiting.\n\n    Raises:\n        KeyboardInterrupt: If the waiting is interrupted by the user.\n    \"\"\"\n    try:\n        if not dry:\n            sleep(60)\n        while is_running(job_id, dry):\n            if not dry:\n                sleep(60)\n    except KeyboardInterrupt as e:\n        logger.info(\"Killing job %s\", kill_job(job_id, dry))\n        raise KeyboardInterrupt from e\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.wait_for_many","title":"flyvis.utils.compute_cloud_utils.wait_for_many","text":"<pre><code>wait_for_many(job_id_names, dry=False)\n</code></pre> <p>Wait for multiple jobs to finish on the cluster.</p> <p>Parameters:</p> Name Type Description Default <code>job_id_names</code> <code>Dict[str, str]</code> <p>A dictionary mapping job IDs to job names.</p> required <code>dry</code> <code>bool</code> <p>If True, skip actual waiting.</p> <code>False</code> <p>Raises:</p> Type Description <code>KeyboardInterrupt</code> <p>If the waiting is interrupted by the user.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def wait_for_many(job_id_names: Dict[str, str], dry: bool = False) -&gt; None:\n    \"\"\"\n    Wait for multiple jobs to finish on the cluster.\n\n    Args:\n        job_id_names: A dictionary mapping job IDs to job names.\n        dry: If True, skip actual waiting.\n\n    Raises:\n        KeyboardInterrupt: If the waiting is interrupted by the user.\n    \"\"\"\n    try:\n        if not dry:\n            print(\"Jobs launched.. waiting 60s..\")\n            sleep(60)\n        while any(is_running(job_id, dry) for job_id in job_id_names):\n            if not dry:\n                print(\"Jobs still running.. waiting 60s..\")\n                sleep(60)\n    except KeyboardInterrupt as e:\n        for job_id in job_id_names:\n            logger.info(\"Killing job %s\", kill_job(job_id, dry))\n        raise KeyboardInterrupt from e\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.check_valid_host","title":"flyvis.utils.compute_cloud_utils.check_valid_host","text":"<pre><code>check_valid_host(blacklist)\n</code></pre> <p>Prevent running on certain blacklisted hosts, e.g., login nodes.</p> <p>Parameters:</p> Name Type Description Default <code>blacklist</code> <code>List[str]</code> <p>A list of blacklisted hostnames or substrings.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the current host is in the blacklist.</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def check_valid_host(blacklist: List[str]) -&gt; None:\n    \"\"\"\n    Prevent running on certain blacklisted hosts, e.g., login nodes.\n\n    Args:\n        blacklist: A list of blacklisted hostnames or substrings.\n\n    Raises:\n        ValueError: If the current host is in the blacklist.\n    \"\"\"\n    host = socket.gethostname()\n    if any(h in host for h in blacklist):\n        raise ValueError(f\"This script should not be run from {host}!\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.launch_range","title":"flyvis.utils.compute_cloud_utils.launch_range","text":"<pre><code>launch_range(start, end, ensemble_id, task_name, nP, gpu, q, script, dry, kwargs)\n</code></pre> <p>Launch a range of models.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int</code> <p>The starting index for the range.</p> required <code>end</code> <code>int</code> <p>The ending index for the range.</p> required <code>ensemble_id</code> <code>str</code> <p>The ID of the ensemble.</p> required <code>task_name</code> <code>str</code> <p>The name of the task.</p> required <code>nP</code> <code>int</code> <p>The number of processors to use.</p> required <code>gpu</code> <code>str</code> <p>The GPU configuration.</p> required <code>q</code> <code>str</code> <p>The queue to submit the job to.</p> required <code>script</code> <code>str</code> <p>The script to run.</p> required <code>dry</code> <code>bool</code> <p>If True, perform a dry run without actually submitting jobs.</p> required <code>kwargs</code> <code>List[str]</code> <p>A list of additional keyword arguments for the script.</p> required Note <p>kwargs is an ordered list of strings, either in the format [\u201c-kw\u201d, \u201cval\u201d, \u2026] or following hydra syntax, i.e. [\u201ckw=val\u201d, \u2026].</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def launch_range(\n    start: int,\n    end: int,\n    ensemble_id: str,\n    task_name: str,\n    nP: int,\n    gpu: str,\n    q: str,\n    script: str,\n    dry: bool,\n    kwargs: List[str],\n) -&gt; None:\n    \"\"\"\n    Launch a range of models.\n\n    Args:\n        start: The starting index for the range.\n        end: The ending index for the range.\n        ensemble_id: The ID of the ensemble.\n        task_name: The name of the task.\n        nP: The number of processors to use.\n        gpu: The GPU configuration.\n        q: The queue to submit the job to.\n        script: The script to run.\n        dry: If True, perform a dry run without actually submitting jobs.\n        kwargs: A list of additional keyword arguments for the script.\n\n    Note:\n        kwargs is an ordered list of strings, either in the format [\"-kw\", \"val\", ...]\n        or following hydra syntax, i.e. [\"kw=val\", ...].\n    \"\"\"\n    SCRIPT_PART = \"{} {} {}\"\n\n    CLUSTER_MANAGER.set_dry(dry)\n\n    job_id_names = {}\n    for i in range(start, end):\n        kw = kwargs.copy()\n        ensemble_and_network_id = f\"{ensemble_id:04}/{i:03}\"\n        assert \"_\" not in ensemble_and_network_id\n        network_dir = results_dir / task_name / ensemble_and_network_id\n        if not network_dir.parent.exists():\n            network_dir.parent.mkdir(parents=True)\n        log_file = (\n            network_dir.parent / f\"{i:04}_{script.split('/')[-1].split('.')[0]}.log\"\n        )\n        if log_file.exists():\n            log_file.unlink()\n\n        kw.extend([f\"ensemble_and_network_id={ensemble_and_network_id}\"])\n        kw.extend([f\"task_name={task_name}\"])\n\n        LSF_CMD = CLUSTER_MANAGER.get_submit_command(\n            f\"{task_name}_{ensemble_and_network_id}\", nP, log_file, gpu, q\n        )\n        SCRIPT_CMD = SCRIPT_PART.format(sys.executable, script, \" \".join(kw))\n        command = LSF_CMD + CLUSTER_MANAGER.get_script_part(SCRIPT_CMD)\n        logger.info(\"Launching command: %s\", command)\n        job_id = run_job(command, dry)\n        job_id_names[job_id] = f\"{task_name}_{ensemble_and_network_id}\"\n\n    wait_for_many(job_id_names, dry)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.compute_cloud_utils.launch_single","title":"flyvis.utils.compute_cloud_utils.launch_single","text":"<pre><code>launch_single(ensemble_id, task_name, nP, gpu, q, script, dry, kwargs)\n</code></pre> <p>Launch a single job for an ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble_id</code> <code>str</code> <p>The ID of the ensemble.</p> required <code>task_name</code> <code>str</code> <p>The name of the task.</p> required <code>nP</code> <code>int</code> <p>The number of processors to use.</p> required <code>gpu</code> <code>str</code> <p>The GPU configuration.</p> required <code>q</code> <code>str</code> <p>The queue to submit the job to.</p> required <code>script</code> <code>str</code> <p>The script to run.</p> required <code>dry</code> <code>bool</code> <p>If True, perform a dry run without actually submitting the job.</p> required <code>kwargs</code> <code>List[str]</code> <p>A list of additional keyword arguments for the script.</p> required Note <p>kwargs is an ordered list of strings, either in the format [\u201c-kw\u201d, \u201cval\u201d, \u2026] or following hydra syntax, i.e. [\u201ckw=val\u201d, \u2026].</p> Source code in <code>flyvis/utils/compute_cloud_utils.py</code> <pre><code>def launch_single(\n    ensemble_id: str,\n    task_name: str,\n    nP: int,\n    gpu: str,\n    q: str,\n    script: str,\n    dry: bool,\n    kwargs: List[str],\n) -&gt; None:\n    \"\"\"\n    Launch a single job for an ensemble.\n\n    Args:\n        ensemble_id: The ID of the ensemble.\n        task_name: The name of the task.\n        nP: The number of processors to use.\n        gpu: The GPU configuration.\n        q: The queue to submit the job to.\n        script: The script to run.\n        dry: If True, perform a dry run without actually submitting the job.\n        kwargs: A list of additional keyword arguments for the script.\n\n    Note:\n        kwargs is an ordered list of strings, either in the format [\"-kw\", \"val\", ...]\n        or following hydra syntax, i.e. [\"kw=val\", ...].\n    \"\"\"\n    SCRIPT_PART = \"{} {} {}\"\n\n    CLUSTER_MANAGER.set_dry(dry)\n\n    job_id_names = {}\n    kw = kwargs.copy()\n    ensemble_id = f\"{ensemble_id:04}\"\n    assert \"_\" not in ensemble_id\n    ensemble_dir = results_dir / task_name / ensemble_id\n\n    assert ensemble_dir.exists()\n    log_file = ensemble_dir / f\"{script.split('/')[-1].split('.')[0]}.log\"\n    if log_file.exists():\n        log_file.unlink()\n\n    kw.extend([f\"ensemble_id={ensemble_id}\"])\n    kw.extend([f\"task_name={task_name}\"])\n\n    LSF_CMD = CLUSTER_MANAGER.get_submit_command(\n        f\"{task_name}_{ensemble_id}\", nP, log_file, gpu, q\n    )\n    SCRIPT_CMD = SCRIPT_PART.format(sys.executable, script, \" \".join(kw))\n    command = LSF_CMD + CLUSTER_MANAGER.get_script_part(SCRIPT_CMD)\n    logger.info(\"Launching command: %s\", command)\n    job_id = run_job(command, dry)\n    job_id_names[job_id] = f\"{task_name}_{ensemble_id}\"\n\n    wait_for_many(job_id_names, dry)\n</code></pre>"},{"location":"reference/utils/#flyvisutilsconfig_utils","title":"flyvis.utils.config_utils","text":""},{"location":"reference/utils/#classes_4","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.config_utils.HybridArgumentParser","title":"flyvis.utils.config_utils.HybridArgumentParser","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Hybrid argument parser that can parse unknown arguments in basic key=value style.</p> <p>Attributes:</p> Name Type Description <code>hybrid_args</code> <p>Dictionary of hybrid arguments with their requirements and help texts.</p> <code>allow_unrecognized</code> <p>Whether to allow unrecognized arguments.</p> <code>drop_disjoint_from</code> <p>Path to a configuration file that can be used to filter out arguments that are present in the command line arguments but not in the configuration file. This is to pass through arguments through multiple scripts as hydra does not support this.</p> <p>Parameters:</p> Name Type Description Default <code>hybrid_args</code> <code>Optional[Dict[str, Dict[str, Any]]]</code> <p>Dictionary of hybrid arguments with their requirements and help texts.</p> <code>None</code> <code>allow_unrecognized</code> <code>bool</code> <p>Whether to allow unrecognized arguments.</p> <code>True</code> Source code in <code>flyvis/utils/config_utils.py</code> <pre><code>class HybridArgumentParser(argparse.ArgumentParser):\n    \"\"\"\n    Hybrid argument parser that can parse unknown arguments in basic key=value style.\n\n    Attributes:\n        hybrid_args: Dictionary of hybrid arguments with their requirements and\n            help texts.\n        allow_unrecognized: Whether to allow unrecognized arguments.\n        drop_disjoint_from: Path to a configuration file that can be used to filter\n            out arguments that are present in the command line arguments but not in\n            the configuration file. This is to pass through arguments through multiple\n            scripts as hydra does not support this.\n\n    Args:\n        hybrid_args: Dictionary of hybrid arguments with their requirements and\n            help texts.\n        allow_unrecognized: Whether to allow unrecognized arguments.\n    \"\"\"\n\n    def __init__(\n        self,\n        *args: Any,\n        hybrid_args: Optional[Dict[str, Dict[str, Any]]] = None,\n        allow_unrecognized: bool = True,\n        drop_disjoint_from: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(*args, **kwargs)\n        self.hybrid_args = hybrid_args or {}\n        self.allow_unrecognized = allow_unrecognized\n        self.drop_disjoint_from = drop_disjoint_from\n        self._add_hybrid_args_to_help()\n\n    def _add_hybrid_args_to_help(self) -&gt; None:\n        \"\"\"Add hybrid arguments to the help message.\"\"\"\n        if self.hybrid_args:\n            hybrid_group = self.add_argument_group('Hybrid Arguments')\n            for arg, config in self.hybrid_args.items():\n                help_text = config.get('help', '')\n                required = config.get('required', False)\n                arg_type = config.get('type', None)\n                arg_help = f\"{arg}=value: {help_text}\"\n                if arg_type:\n                    arg_help += f\" (type: {arg_type.__name__})\"\n                if required:\n                    arg_help += \" (Required)\"\n                hybrid_group.add_argument(f\"--{arg}\", help=arg_help, required=False)\n\n    def parse_with_hybrid_args(\n        self,\n        args: Optional[List[str]] = None,\n        namespace: Optional[argparse.Namespace] = None,\n    ) -&gt; argparse.Namespace:\n        \"\"\"\n        Parse arguments and set hybrid arguments as attributes in the namespace.\n\n        Args:\n            args: List of arguments to parse.\n            namespace: Namespace to populate with parsed arguments.\n\n        Returns:\n            Namespace with parsed arguments.\n\n        Raises:\n            argparse.ArgumentError: If required arguments are missing or invalid\n                values are provided.\n        \"\"\"\n        if args is None:\n            args = sys.argv[1:]\n\n        args_for_parser = []\n        key_value_args = []\n\n        # Separate key=value pairs from other arguments\n        for arg in args:\n            if '=' in arg and not arg.startswith('-'):\n                key_value_args.append(arg)\n            else:\n                args_for_parser.append(arg)\n\n        # Parse the known arguments\n        args, unknown_args = self.parse_known_args(args_for_parser, namespace)\n\n        # Combine key_value_args with unknown_args for processing\n        all_unknown_args = key_value_args + unknown_args\n\n        argv = []\n        for arg in all_unknown_args:\n            if \":\" in arg and \"=\" in arg:\n                keytype, value = arg.split(\"=\")\n                key, astype = keytype.split(\":\")\n                try:\n                    if value.lower() in [\"true\", \"1\", 'yes'] and astype == \"bool\":\n                        setattr(args, key, True)\n                    elif value.lower() in [\"false\", \"0\", 'no'] and astype == \"bool\":\n                        setattr(args, key, False)\n                    else:\n                        setattr(args, key, safe_cast(value, astype))\n                except (ValueError, TypeError):\n                    self.error(\n                        f\"Invalid type '{astype}' or value '{value}' for argument {key}\"\n                    )\n            elif \"=\" in arg:\n                key, value = arg.split(\"=\", 1)\n                if key in self.hybrid_args and 'type' in self.hybrid_args[key]:\n                    arg_type = self.hybrid_args[key]['type']\n                    try:\n                        typed_value = arg_type(value)\n                        setattr(args, key, typed_value)\n                    except ValueError:\n                        self.error(\n                            f\"Invalid {arg_type.__name__} value '{value}' \"\n                            f\"for argument {key}\"\n                        )\n                else:\n                    setattr(args, key, value)\n            else:\n                argv.append(arg)\n\n        # Apply type conversion for arguments parsed by argparse\n        for arg, config in self.hybrid_args.items():\n            if (\n                hasattr(args, arg)\n                and config.get('type')\n                and getattr(args, arg) is not None\n            ):\n                setattr(args, arg, config['type'](getattr(args, arg)))\n\n        # Check for required arguments\n        missing_required = []\n        for arg, config in self.hybrid_args.items():\n            if config.get('required', False) and getattr(args, arg) is None:\n                missing_required.append(arg)\n\n        if missing_required:\n            self.error(\n                f\"The following required arguments are missing: \"\n                f\"{', '.join(missing_required)}\"\n            )\n\n        if argv and not self.allow_unrecognized:\n            msg = \"unrecognized arguments: %s\"\n            self.error(msg % \" \".join(argv))\n\n        if self.drop_disjoint_from:\n            args = self._filter_args_based_on_config(args)\n\n        return args\n\n    def hydra_argv(self) -&gt; List[str]:\n        hybrid_args = self.parse_with_hybrid_args()\n        return [\n            f\"{key}={value}\" for key, value in vars(hybrid_args).items() if \":\" not in key\n        ]\n\n    def get_registered_args(self) -&gt; List[str]:\n        \"\"\"\n        Get a list of all argument names that were registered using add_argument.\n\n        Returns:\n            List of argument names (without the -- prefix)\n        \"\"\"\n        return [\n            action.dest\n            for action in self._actions\n            if action.dest != \"help\"  # Exclude the default help action\n        ]\n\n    def _filter_args_based_on_config(\n        self, args: argparse.Namespace\n    ) -&gt; argparse.Namespace:\n        \"\"\"\n        Filter arguments based on the Hydra config file specified in drop_disjoint_from.\n\n        Args:\n            args: Namespace containing all parsed arguments.\n\n        Returns:\n            Filtered Namespace with only arguments present in the config or with\n                Hydra syntax.\n        \"\"\"\n        if not self.drop_disjoint_from:\n            return args\n\n        config = OmegaConf.create(\n            get_config_from_file(self.drop_disjoint_from, resolve=False)\n        )\n\n        filtered_args = argparse.Namespace()\n        registered_args = self.get_registered_args()\n\n        for arg, value in vars(args).items():\n            if (\n                self._is_in_config(arg, config)\n                or arg.startswith('+')\n                or arg.startswith('++')\n                or arg.startswith('~')\n            ):\n                setattr(filtered_args, arg, value)\n            elif arg not in registered_args:\n                warnings.warn(\n                    f\"{Fore.YELLOW}Argument {Style.BRIGHT}{arg}={value}\"\n                    f\"{Style.RESET_ALL}{Fore.YELLOW} \"\n                    f\"does not affect the hydra config because it is not present in \"\n                    f\"the config file {Style.BRIGHT}{self.drop_disjoint_from}\"\n                    f\"{Style.RESET_ALL}{Fore.YELLOW}. \"\n                    f\"This may be unintended, like a typo, or intended, like a \"\n                    f\"hydra-style argument passed through to another script. \"\n                    f\"Check script docs and config file \"\n                    f\"for clarification.{Style.RESET_ALL}\",\n                    stacklevel=2,\n                )\n\n        return filtered_args\n\n    def _is_in_config(self, arg: str, config: Any) -&gt; bool:\n        \"\"\"\n        Check if an argument exists in the config, including nested structures.\n\n        Args:\n            arg: The argument to check.\n            config: The configuration object or sub-object.\n\n        Returns:\n            True if the argument is found in the config, False otherwise.\n        \"\"\"\n        try:\n            return OmegaConf.select(config, arg, throw_on_missing=True) is not None\n        except errors.MissingMandatoryValue:\n            return True\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.config_utils.HybridArgumentParser.parse_with_hybrid_args","title":"parse_with_hybrid_args","text":"<pre><code>parse_with_hybrid_args(args=None, namespace=None)\n</code></pre> <p>Parse arguments and set hybrid arguments as attributes in the namespace.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Optional[List[str]]</code> <p>List of arguments to parse.</p> <code>None</code> <code>namespace</code> <code>Optional[Namespace]</code> <p>Namespace to populate with parsed arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>Namespace</code> <p>Namespace with parsed arguments.</p> <p>Raises:</p> Type Description <code>ArgumentError</code> <p>If required arguments are missing or invalid values are provided.</p> Source code in <code>flyvis/utils/config_utils.py</code> <pre><code>def parse_with_hybrid_args(\n    self,\n    args: Optional[List[str]] = None,\n    namespace: Optional[argparse.Namespace] = None,\n) -&gt; argparse.Namespace:\n    \"\"\"\n    Parse arguments and set hybrid arguments as attributes in the namespace.\n\n    Args:\n        args: List of arguments to parse.\n        namespace: Namespace to populate with parsed arguments.\n\n    Returns:\n        Namespace with parsed arguments.\n\n    Raises:\n        argparse.ArgumentError: If required arguments are missing or invalid\n            values are provided.\n    \"\"\"\n    if args is None:\n        args = sys.argv[1:]\n\n    args_for_parser = []\n    key_value_args = []\n\n    # Separate key=value pairs from other arguments\n    for arg in args:\n        if '=' in arg and not arg.startswith('-'):\n            key_value_args.append(arg)\n        else:\n            args_for_parser.append(arg)\n\n    # Parse the known arguments\n    args, unknown_args = self.parse_known_args(args_for_parser, namespace)\n\n    # Combine key_value_args with unknown_args for processing\n    all_unknown_args = key_value_args + unknown_args\n\n    argv = []\n    for arg in all_unknown_args:\n        if \":\" in arg and \"=\" in arg:\n            keytype, value = arg.split(\"=\")\n            key, astype = keytype.split(\":\")\n            try:\n                if value.lower() in [\"true\", \"1\", 'yes'] and astype == \"bool\":\n                    setattr(args, key, True)\n                elif value.lower() in [\"false\", \"0\", 'no'] and astype == \"bool\":\n                    setattr(args, key, False)\n                else:\n                    setattr(args, key, safe_cast(value, astype))\n            except (ValueError, TypeError):\n                self.error(\n                    f\"Invalid type '{astype}' or value '{value}' for argument {key}\"\n                )\n        elif \"=\" in arg:\n            key, value = arg.split(\"=\", 1)\n            if key in self.hybrid_args and 'type' in self.hybrid_args[key]:\n                arg_type = self.hybrid_args[key]['type']\n                try:\n                    typed_value = arg_type(value)\n                    setattr(args, key, typed_value)\n                except ValueError:\n                    self.error(\n                        f\"Invalid {arg_type.__name__} value '{value}' \"\n                        f\"for argument {key}\"\n                    )\n            else:\n                setattr(args, key, value)\n        else:\n            argv.append(arg)\n\n    # Apply type conversion for arguments parsed by argparse\n    for arg, config in self.hybrid_args.items():\n        if (\n            hasattr(args, arg)\n            and config.get('type')\n            and getattr(args, arg) is not None\n        ):\n            setattr(args, arg, config['type'](getattr(args, arg)))\n\n    # Check for required arguments\n    missing_required = []\n    for arg, config in self.hybrid_args.items():\n        if config.get('required', False) and getattr(args, arg) is None:\n            missing_required.append(arg)\n\n    if missing_required:\n        self.error(\n            f\"The following required arguments are missing: \"\n            f\"{', '.join(missing_required)}\"\n        )\n\n    if argv and not self.allow_unrecognized:\n        msg = \"unrecognized arguments: %s\"\n        self.error(msg % \" \".join(argv))\n\n    if self.drop_disjoint_from:\n        args = self._filter_args_based_on_config(args)\n\n    return args\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.config_utils.HybridArgumentParser.get_registered_args","title":"get_registered_args","text":"<pre><code>get_registered_args()\n</code></pre> <p>Get a list of all argument names that were registered using add_argument.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of argument names (without the \u2013 prefix)</p> Source code in <code>flyvis/utils/config_utils.py</code> <pre><code>def get_registered_args(self) -&gt; List[str]:\n    \"\"\"\n    Get a list of all argument names that were registered using add_argument.\n\n    Returns:\n        List of argument names (without the -- prefix)\n    \"\"\"\n    return [\n        action.dest\n        for action in self._actions\n        if action.dest != \"help\"  # Exclude the default help action\n    ]\n</code></pre>"},{"location":"reference/utils/#functions_5","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.config_utils.get_default_config","title":"flyvis.utils.config_utils.get_default_config","text":"<pre><code>get_default_config(overrides, path='../../config/solver.yaml', as_namespace=True)\n</code></pre> <p>Get the default configuration using Hydra.</p> <p>Parameters:</p> Name Type Description Default <code>overrides</code> <code>List[str]</code> <p>List of configuration overrides.</p> required <code>path</code> <code>str</code> <p>Path to the configuration file.</p> <code>'../../config/solver.yaml'</code> <code>as_namespace</code> <code>bool</code> <p>Whether to return a namespaced configuration or the OmegaConf object.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[Dict[DictKeyType, Any], List[Any], None, str, Any, Namespace]</code> <p>The configuration object.</p> Note <p>Expected overrides are: - task_name - network_id</p> Source code in <code>flyvis/utils/config_utils.py</code> <pre><code>def get_default_config(\n    overrides: List[str],\n    path: str = \"../../config/solver.yaml\",\n    as_namespace: bool = True,\n) -&gt; Union[Dict[DictKeyType, Any], List[Any], None, str, Any, Namespace]:\n    \"\"\"\n    Get the default configuration using Hydra.\n\n    Args:\n        overrides: List of configuration overrides.\n        path: Path to the configuration file.\n        as_namespace: Whether to return a namespaced configuration or the\n            OmegaConf object.\n\n    Returns:\n        The configuration object.\n\n    Note:\n        Expected overrides are:\n        - task_name\n        - network_id\n    \"\"\"\n\n    config = get_config_from_file(path, overrides, resolve=True)\n    if as_namespace:\n        return namespacify(config)\n    return config\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.config_utils.parse_kwargs_to_dict","title":"flyvis.utils.config_utils.parse_kwargs_to_dict","text":"<pre><code>parse_kwargs_to_dict(values)\n</code></pre> <p>Parse a list of key-value pairs into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>List[str]</code> <p>List of key-value pairs in the format \u201ckey=value\u201d.</p> required <p>Returns:</p> Type Description <code>Namespace</code> <p>Namespace object with parsed key-value pairs as attributes.</p> Source code in <code>flyvis/utils/config_utils.py</code> <pre><code>def parse_kwargs_to_dict(values: List[str]) -&gt; argparse.Namespace:\n    \"\"\"\n    Parse a list of key-value pairs into a dictionary.\n\n    Args:\n        values: List of key-value pairs in the format \"key=value\".\n\n    Returns:\n        Namespace object with parsed key-value pairs as attributes.\n    \"\"\"\n    kwargs = argparse.Namespace()\n    for value in values:\n        key, value = value.split(\"=\")\n        setattr(kwargs, key, value)\n    return kwargs\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.config_utils.safe_cast","title":"flyvis.utils.config_utils.safe_cast","text":"<pre><code>safe_cast(value, type_name)\n</code></pre> <p>Safely cast a string value to a specified type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The string value to cast.</p> required <code>type_name</code> <code>str</code> <p>The name of the type to cast to.</p> required <p>Returns:</p> Type Description <code>Union[int, float, bool, str]</code> <p>The casted value.</p> Note <p>Supports casting to int, float, bool, and str.</p> Source code in <code>flyvis/utils/config_utils.py</code> <pre><code>def safe_cast(value: str, type_name: str) -&gt; Union[int, float, bool, str]:\n    \"\"\"\n    Safely cast a string value to a specified type.\n\n    Args:\n        value: The string value to cast.\n        type_name: The name of the type to cast to.\n\n    Returns:\n        The casted value.\n\n    Note:\n        Supports casting to int, float, bool, and str.\n    \"\"\"\n    if type_name == 'int':\n        return int(value)\n    elif type_name == 'float':\n        return float(value)\n    elif type_name == 'bool':\n        return value.lower() in ('true', 'yes', '1', 'on')\n    else:\n        return value  # Default to string\n</code></pre>"},{"location":"reference/utils/#flyvisutilsdataset_utils","title":"flyvis.utils.dataset_utils","text":""},{"location":"reference/utils/#classes_5","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.dataset_utils.CrossValIndices","title":"flyvis.utils.dataset_utils.CrossValIndices","text":"<p>Returns folds of indices for cross-validation.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>Total number of samples.</p> required <code>folds</code> <code>int</code> <p>Total number of folds.</p> required <code>shuffle</code> <code>bool</code> <p>Shuffles the indices.</p> <code>True</code> <code>seed</code> <code>int</code> <p>Seed for shuffling.</p> <code>0</code> <p>Attributes:</p> Name Type Description <code>n_samples</code> <p>Total number of samples.</p> <code>folds</code> <p>Total number of folds.</p> <code>indices</code> <p>Array of indices.</p> <code>random</code> <p>RandomState object for shuffling.</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>class CrossValIndices:\n    \"\"\"Returns folds of indices for cross-validation.\n\n    Args:\n        n_samples: Total number of samples.\n        folds: Total number of folds.\n        shuffle: Shuffles the indices.\n        seed: Seed for shuffling.\n\n    Attributes:\n        n_samples: Total number of samples.\n        folds: Total number of folds.\n        indices: Array of indices.\n        random: RandomState object for shuffling.\n\n    \"\"\"\n\n    def __init__(self, n_samples: int, folds: int, shuffle: bool = True, seed: int = 0):\n        self.n_samples = n_samples\n        self.folds = folds\n        self.indices = np.arange(n_samples)\n\n        if shuffle:\n            self.random = RandomState(seed)\n            self.random.shuffle(self.indices)\n\n    def __call__(self, fold: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Returns train and test indices for a fold.\n\n        Args:\n            fold: The fold number.\n\n        Returns:\n            A tuple containing train and test indices.\n        \"\"\"\n        fold_sizes = np.full(self.folds, self.n_samples // self.folds, dtype=int)\n        fold_sizes[: self.n_samples % self.folds] += 1\n        current = sum(fold_sizes[:fold])\n        start, stop = current, current + fold_sizes[fold]\n        test_index = self.indices[start:stop]\n        test_mask = np.zeros_like(self.indices, dtype=bool)\n        test_mask[test_index] = True\n        return self.indices[np.logical_not(test_mask)], self.indices[test_mask]\n\n    def iter(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Iterate over all folds.\n\n        Yields:\n            A tuple containing train and test indices for each fold.\n        \"\"\"\n        for fold in range(self.folds):\n            yield self(fold)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.dataset_utils.CrossValIndices.__call__","title":"__call__","text":"<pre><code>__call__(fold)\n</code></pre> <p>Returns train and test indices for a fold.</p> <p>Parameters:</p> Name Type Description Default <code>fold</code> <code>int</code> <p>The fold number.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing train and test indices.</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>def __call__(self, fold: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Returns train and test indices for a fold.\n\n    Args:\n        fold: The fold number.\n\n    Returns:\n        A tuple containing train and test indices.\n    \"\"\"\n    fold_sizes = np.full(self.folds, self.n_samples // self.folds, dtype=int)\n    fold_sizes[: self.n_samples % self.folds] += 1\n    current = sum(fold_sizes[:fold])\n    start, stop = current, current + fold_sizes[fold]\n    test_index = self.indices[start:stop]\n    test_mask = np.zeros_like(self.indices, dtype=bool)\n    test_mask[test_index] = True\n    return self.indices[np.logical_not(test_mask)], self.indices[test_mask]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.dataset_utils.CrossValIndices.iter","title":"iter","text":"<pre><code>iter()\n</code></pre> <p>Iterate over all folds.</p> <p>Yields:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing train and test indices for each fold.</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>def iter(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Iterate over all folds.\n\n    Yields:\n        A tuple containing train and test indices for each fold.\n    \"\"\"\n    for fold in range(self.folds):\n        yield self(fold)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.dataset_utils.IndexSampler","title":"flyvis.utils.dataset_utils.IndexSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Samples the provided indices in sequence.</p> Note <p>To be used with torch.utils.data.DataLoader.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>List[int]</code> <p>List of indices to sample.</p> required <p>Attributes:</p> Name Type Description <code>indices</code> <p>List of indices to sample.</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>class IndexSampler(Sampler):\n    \"\"\"Samples the provided indices in sequence.\n\n    Note:\n        To be used with torch.utils.data.DataLoader.\n\n    Args:\n        indices: List of indices to sample.\n\n    Attributes:\n        indices: List of indices to sample.\n    \"\"\"\n\n    def __init__(self, indices: List[int]):\n        self.indices = indices\n\n    def __iter__(self):\n        return (self.indices[i] for i in range(len(self.indices)))\n\n    def __len__(self) -&gt; int:\n        return len(self.indices)\n</code></pre>"},{"location":"reference/utils/#functions_6","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.dataset_utils.random_walk_of_blocks","title":"flyvis.utils.dataset_utils.random_walk_of_blocks","text":"<pre><code>random_walk_of_blocks(n_blocks=20, block_size=4, top_lum=0, bottom_lum=0, dataset_size=[3, 20, 64, 64], noise_mean=0.5, noise_std=0.1, step_size=4, p_random=0.6, p_center_attraction=0.3, p_edge_attraction=0.1, seed=42)\n</code></pre> <p>Generate a sequence dataset with blocks doing random walks.</p> <p>Parameters:</p> Name Type Description Default <code>n_blocks</code> <code>int</code> <p>Number of blocks.</p> <code>20</code> <code>block_size</code> <code>int</code> <p>Size of blocks.</p> <code>4</code> <code>top_lum</code> <code>float</code> <p>Luminance of the top of the block.</p> <code>0</code> <code>bottom_lum</code> <code>float</code> <p>Luminance of the bottom of the block.</p> <code>0</code> <code>dataset_size</code> <code>List[int]</code> <p>Size of the dataset. (n_sequences, n_frames, h, w)</p> <code>[3, 20, 64, 64]</code> <code>noise_mean</code> <code>float</code> <p>Mean of the background noise.</p> <code>0.5</code> <code>noise_std</code> <code>float</code> <p>Standard deviation of the background noise.</p> <code>0.1</code> <code>step_size</code> <code>int</code> <p>Number of pixels to move in each step.</p> <code>4</code> <code>p_random</code> <code>float</code> <p>Probability of moving randomly.</p> <code>0.6</code> <code>p_center_attraction</code> <code>float</code> <p>Probability of moving towards the center.</p> <code>0.3</code> <code>p_edge_attraction</code> <code>float</code> <p>Probability of moving towards the edge.</p> <code>0.1</code> <code>seed</code> <code>int</code> <p>Seed for the random number generator.</p> <code>42</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Dataset of shape (n_sequences, n_frames, h, w)</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>def random_walk_of_blocks(\n    n_blocks: int = 20,\n    block_size: int = 4,\n    top_lum: float = 0,\n    bottom_lum: float = 0,\n    dataset_size: List[int] = [3, 20, 64, 64],\n    noise_mean: float = 0.5,\n    noise_std: float = 0.1,\n    step_size: int = 4,\n    p_random: float = 0.6,\n    p_center_attraction: float = 0.3,\n    p_edge_attraction: float = 0.1,\n    seed: int = 42,\n) -&gt; np.ndarray:\n    \"\"\"Generate a sequence dataset with blocks doing random walks.\n\n    Args:\n        n_blocks: Number of blocks.\n        block_size: Size of blocks.\n        top_lum: Luminance of the top of the block.\n        bottom_lum: Luminance of the bottom of the block.\n        dataset_size: Size of the dataset. (n_sequences, n_frames, h, w)\n        noise_mean: Mean of the background noise.\n        noise_std: Standard deviation of the background noise.\n        step_size: Number of pixels to move in each step.\n        p_random: Probability of moving randomly.\n        p_center_attraction: Probability of moving towards the center.\n        p_edge_attraction: Probability of moving towards the edge.\n        seed: Seed for the random number generator.\n\n    Returns:\n        Dataset of shape (n_sequences, n_frames, h, w)\n    \"\"\"\n    np.random.seed(seed)\n    sequences = np.random.normal(loc=noise_mean, scale=noise_std, size=dataset_size)\n    h, w = sequences.shape[2:]\n    assert h == w\n\n    y_coordinates = np.arange(h)\n    x_coordinates = np.arange(w)\n\n    def step(coordinate: int) -&gt; int:\n        ps = np.array([p_random, p_center_attraction, p_edge_attraction])\n        ps /= ps.max()\n\n        q = np.random.rand()\n        if q &lt; p_center_attraction:\n            return (coordinate + np.sign(h // 2 - coordinate) * step_size) % h\n        elif q &gt; 1 - p_edge_attraction:\n            return (coordinate + np.sign(coordinate - h // 2) * step_size) % h\n        else:\n            return (coordinate + np.random.choice([-1, 1]) * step_size) % h\n\n    def block_at_coords(\n        y: int, x: int\n    ) -&gt; Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]:\n        mask_top = np.meshgrid(\n            np.arange(y - block_size // 2, y) % h,\n            np.arange(x - block_size // 2, x + block_size // 2) % w,\n        )\n        mask_bottom = np.meshgrid(\n            np.arange(y, y + block_size // 2) % h,\n            np.arange(x - block_size // 2, x + block_size // 2) % w,\n        )\n        return mask_bottom, mask_top\n\n    def initial_block() -&gt; (\n        Tuple[\n            int, int, Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]\n        ]\n    ):\n        initial_x = np.random.choice(x_coordinates)\n        initial_y = np.random.choice(y_coordinates)\n        return initial_x, initial_y, block_at_coords(initial_x, initial_y)\n\n    for _b in range(n_blocks):\n        for i in range(sequences.shape[0]):\n            for t in range(sequences.shape[1]):\n                if t == 0:\n                    x, y, (mask_bottom, mask_top) = initial_block()\n                else:\n                    x = step(x)\n                    y = step(y)\n                    mask_bottom, mask_top = block_at_coords(x, y)\n                sequences[i, t, mask_bottom[0], mask_bottom[1]] = bottom_lum\n                sequences[i, t, mask_top[0], mask_top[1]] = top_lum\n\n    return sequences / sequences.max()\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.dataset_utils.load_moving_mnist","title":"flyvis.utils.dataset_utils.load_moving_mnist","text":"<pre><code>load_moving_mnist(delete_if_exists=False)\n</code></pre> <p>Return Moving MNIST dataset.</p> <p>Parameters:</p> Name Type Description Default <code>delete_if_exists</code> <code>bool</code> <p>If True, delete the dataset if it exists.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Dataset of shape (n_sequences, n_frames, h, w)==(10000, 20, 64, 64).</p> Note <p>This dataset (0.78GB) will be downloaded if not present. The download is stored in flyvis.root_dir / \u201cmnist_test_seq.npy\u201d.</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>def load_moving_mnist(delete_if_exists: bool = False) -&gt; np.ndarray:\n    \"\"\"Return Moving MNIST dataset.\n\n    Args:\n        delete_if_exists: If True, delete the dataset if it exists.\n\n    Returns:\n        Dataset of shape (n_sequences, n_frames, h, w)==(10000, 20, 64, 64).\n\n    Note:\n        This dataset (0.78GB) will be downloaded if not present. The download\n        is stored in flyvis.root_dir / \"mnist_test_seq.npy\".\n    \"\"\"\n    moving_mnist_path = flyvis.root_dir / \"mnist_test_seq.npy\"\n    moving_mnist_url = (\n        \"https://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\"\n    )\n\n    if not moving_mnist_path.exists() or delete_if_exists:\n        download_url_to_file(moving_mnist_url, moving_mnist_path)\n    try:\n        sequences = np.load(moving_mnist_path)\n        return np.transpose(sequences, (1, 0, 2, 3)) / 255.0\n    except ValueError as e:\n        # delete broken download and load again\n        print(f\"broken file: {e}, restarting download...\")\n        return load_moving_mnist(delete_if_exists=True)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.dataset_utils.get_random_data_split","title":"flyvis.utils.dataset_utils.get_random_data_split","text":"<pre><code>get_random_data_split(fold, n_samples, n_folds, shuffle=True, seed=0)\n</code></pre> <p>Return indices to split the data.</p> <p>Parameters:</p> Name Type Description Default <code>fold</code> <code>int</code> <p>The fold number.</p> required <code>n_samples</code> <code>int</code> <p>Total number of samples.</p> required <code>n_folds</code> <code>int</code> <p>Total number of folds.</p> required <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the indices.</p> <code>True</code> <code>seed</code> <code>int</code> <p>Seed for shuffling.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing train and validation indices.</p> Source code in <code>flyvis/utils/dataset_utils.py</code> <pre><code>def get_random_data_split(\n    fold: int, n_samples: int, n_folds: int, shuffle: bool = True, seed: int = 0\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Return indices to split the data.\n\n    Args:\n        fold: The fold number.\n        n_samples: Total number of samples.\n        n_folds: Total number of folds.\n        shuffle: Whether to shuffle the indices.\n        seed: Seed for shuffling.\n\n    Returns:\n        A tuple containing train and validation indices.\n    \"\"\"\n    cv_split = CrossValIndices(\n        n_samples=n_samples,\n        folds=n_folds,\n        shuffle=shuffle,\n        seed=seed,\n    )\n    train_seq_index, val_seq_index = cv_split(fold)\n    return train_seq_index, val_seq_index\n</code></pre>"},{"location":"reference/utils/#flyvisutilsdf_utils","title":"flyvis.utils.df_utils","text":""},{"location":"reference/utils/#functions_7","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.df_utils.filter_by_column_values","title":"flyvis.utils.df_utils.filter_by_column_values","text":"<pre><code>filter_by_column_values(dataframe, column, values)\n</code></pre> <p>Return subset of dataframe based on list of values to appear in a column.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>DataFrame with key as column.</p> required <code>column</code> <code>str</code> <p>Column of the dataframe, e.g. <code>type</code>.</p> required <code>values</code> <code>Iterable</code> <p>Types of neurons e.g. R1, T4a, etc.</p> required <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>DataFrame</code> <p>Subset of the input dataframe.</p> Example <pre><code>filtered_df = filter_by_column_values(df, 'neuron_type', ['R1', 'T4a'])\n</code></pre> Source code in <code>flyvis/utils/df_utils.py</code> <pre><code>def filter_by_column_values(\n    dataframe: DataFrame, column: str, values: Iterable\n) -&gt; DataFrame:\n    \"\"\"\n    Return subset of dataframe based on list of values to appear in a column.\n\n    Args:\n        dataframe: DataFrame with key as column.\n        column: Column of the dataframe, e.g. `type`.\n        values: Types of neurons e.g. R1, T4a, etc.\n\n    Returns:\n        DataFrame: Subset of the input dataframe.\n\n    Example:\n        ```python\n        filtered_df = filter_by_column_values(df, 'neuron_type', ['R1', 'T4a'])\n        ```\n    \"\"\"\n    cond = \"\"\n    for t in values:\n        cond += f\"(dataframe.{column}=='{t}')\"\n        if t != values[-1]:\n            cond += \"|\"\n    return dataframe[eval(cond)]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.df_utils.where_dataframe","title":"flyvis.utils.df_utils.where_dataframe","text":"<pre><code>where_dataframe(arg_df, **kwargs)\n</code></pre> <p>Return indices of rows in a DataFrame where conditions are met.</p> <p>Conditions are passed as keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>arg_df</code> <code>DataFrame</code> <p>Input DataFrame.</p> required <code>**kwargs</code> <p>Keyword arguments representing conditions.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>DataFrame</code> <p>Indices of rows where conditions are met.</p> Example <pre><code>indices = where_dataframe(df, type='T4a', u=2, v=0)\n</code></pre> Note <p>The dataframe is expected to have columns matching the keyword arguments.</p> Source code in <code>flyvis/utils/df_utils.py</code> <pre><code>def where_dataframe(arg_df: DataFrame, **kwargs) -&gt; DataFrame:\n    \"\"\"\n    Return indices of rows in a DataFrame where conditions are met.\n\n    Conditions are passed as keyword arguments.\n\n    Args:\n        arg_df: Input DataFrame.\n        **kwargs: Keyword arguments representing conditions.\n\n    Returns:\n        DataFrame: Indices of rows where conditions are met.\n\n    Example:\n        ```python\n        indices = where_dataframe(df, type='T4a', u=2, v=0)\n        ```\n\n    Note:\n        The dataframe is expected to have columns matching the keyword arguments.\n    \"\"\"\n\n    def _query_from_kwargs(kwargs):\n        _query_start = \"{}=={}\"\n        _query_append = \"&amp; {}=={}\"\n\n        _query_elements = []\n        for i, (key, value) in enumerate(kwargs.items()):\n            if isinstance(value, str) and (\n                not value.startswith(\"'\") or value.startswith('\"')\n            ):\n                value = f\"'{value}'\"\n            if i == 0:\n                _query_elements.append(_query_start.format(key, value))\n            else:\n                _query_elements.append(_query_append.format(key, value))\n        return \"\".join(_query_elements)\n\n    query = _query_from_kwargs(kwargs)\n\n    return arg_df.query(query).index\n</code></pre>"},{"location":"reference/utils/#flyvisutilshex_utils","title":"flyvis.utils.hex_utils","text":""},{"location":"reference/utils/#classes_6","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal","title":"flyvis.utils.hex_utils.Hexal","text":"<p>Hexal representation containing u, v, z coordinates and value.</p> <p>Attributes:</p> Name Type Description <code>u</code> <p>Coordinate in u principal direction (0 degree axis).</p> <code>v</code> <p>Coordinate in v principal direction (60 degree axis).</p> <code>z</code> <p>Coordinate in z principal direction (-60 degree axis).</p> <code>value</code> <p>\u2018Hexal\u2019 value.</p> <code>u_stride</code> <p>Stride in u-direction.</p> <code>v_stride</code> <p>Stride in v-direction.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>class Hexal:\n    \"\"\"Hexal representation containing u, v, z coordinates and value.\n\n    Attributes:\n        u: Coordinate in u principal direction (0 degree axis).\n        v: Coordinate in v principal direction (60 degree axis).\n        z: Coordinate in z principal direction (-60 degree axis).\n        value: 'Hexal' value.\n        u_stride: Stride in u-direction.\n        v_stride: Stride in v-direction.\n    \"\"\"\n\n    def __init__(\n        self, u: int, v: int, value: float = np.nan, u_stride: int = 1, v_stride: int = 1\n    ):\n        self.u = u\n        self.v = v\n        self.z = -(u + v)\n        self.value = value\n        self.u_stride = u_stride\n        self.v_stride = v_stride\n\n    def __repr__(self):\n        return \"Hexal(u={}, v={}, value={}, u_stride={}, v_stride={})\".format(\n            self.u, self.v, self.value, self.u_stride, self.v_stride\n        )\n\n    def __eq__(self, other):\n        \"\"\"Compares coordinates (not values).\"\"\"\n        if isinstance(other, Hexal):\n            return all((self.u == other.u, self.v == other.v))\n        elif isinstance(other, Iterable):\n            return np.array([self == h for h in other])\n\n    def __add__(self, other):\n        \"\"\"Adds u and v coordinates, while keeping the value of the left hexal.\"\"\"\n        if isinstance(other, Hexal):\n            return Hexal(self.u + other.u, self.v + other.v, self.value)\n        elif isinstance(other, Iterable):\n            return np.array([self + h for h in other])\n\n    def __mul__(self, other):\n        \"\"\"Multiplies values, while preserving coordinates.\"\"\"\n        if isinstance(other, Hexal):\n            return Hexal(self.u, self.v, self.value * other.value)\n        elif isinstance(other, Iterable):\n            return np.array([self * h for h in other])\n        else:\n            return Hexal(self.u, self.v, self.value * other)\n\n    def eq_val(self, other):\n        \"\"\"Compares the values, not the coordinates.\"\"\"\n        if isinstance(other, Hexal):\n            return self.value == other.value\n        elif isinstance(other, Iterable):\n            return np.array([self.eq_val(h) for h in other])\n\n    # ----- Neighbour identification\n\n    @property\n    def east(self):\n        return Hexal(self.u + self.u_stride, self.v, 0)\n\n    @property\n    def north_east(self):\n        return Hexal(self.u, self.v + self.v_stride, 0)\n\n    @property\n    def north_west(self):\n        return Hexal(self.u - self.u_stride, self.v + self.v_stride, 0)\n\n    @property\n    def west(self):\n        return Hexal(self.u - self.u_stride, self.v, 0)\n\n    @property\n    def south_west(self):\n        return Hexal(self.u, self.v - self.v_stride, 0)\n\n    @property\n    def south_east(self):\n        return Hexal(self.u + self.u_stride, self.v - self.v_stride, 0)\n\n    def neighbours(self):\n        \"\"\"Returns 6 neighbours sorted CCW, starting from east.\"\"\"\n        return (\n            self.east,\n            self.north_east,\n            self.north_west,\n            self.west,\n            self.south_west,\n            self.south_east,\n        )\n\n    def is_neighbour(self, other):\n        \"\"\"Evaluates if other is a neighbour.\"\"\"\n        neighbours = self.neighbours()\n        if isinstance(other, Hexal):\n            return other in neighbours\n        elif isinstance(other, Iterable):\n            return np.array([self.neighbour(h) for h in other])\n\n    @staticmethod\n    def unit_directions():\n        \"\"\"Returns the six unit directions.\"\"\"\n        return HexArray(Hexal(0, 0, 0).neighbours())\n\n    def neighbour(self, angle):\n        neighbours = np.array(self.neighbours())\n        angles = np.array([h.angle(signed=True) for h in neighbours])\n        distance = (angles - angle) % np.pi\n        index = np.argsort(distance)\n        return HexArray(neighbours[index[:2]])\n\n    def direction(self, angle):\n        neighbours = HexArray(self.neighbour(angle))\n        angles = np.array([h.angle(signed=True) for h in neighbours])\n        distance = (angles - angle) % np.pi\n        index = np.argsort(distance)\n        return HexArray(self.unit_directions()[index[:2]])\n\n    # ----- Geometric methods\n\n    def interp(self, other, t):\n        \"\"\"Interpolates towards other.\n\n        Args:\n            other (Hexal)\n            t (float): interpolation step, 0&lt;t&lt;1.\n\n        Returns:\n            Hexal\n        \"\"\"\n\n        def hex_round(u, v):\n            z = -(u + v)\n            ru = round(u)\n            rv = round(v)\n            rz = round(z)\n            u_diff = abs(ru - u)\n            v_diff = abs(rv - v)\n            z_diff = abs(rz - z)\n            if u_diff &gt; v_diff and u_diff &gt; z_diff:\n                ru = -rv - rz\n            elif v_diff &gt; z_diff:\n                rv = -ru - rz\n            return ru, rv\n\n        uprime, vprime = (\n            self.u + (other.u - self.u) * t,\n            self.v + (other.v - self.v) * t,\n        )\n        uprime, vprime = hex_round(uprime, vprime)\n        return Hexal(uprime, vprime, 0)\n\n    def angle(self, other=None, non_negative=False):\n        \"\"\"\n        Returns the angle to other or the origin.\n\n        Args:\n            other (Hexal)\n            non_negative (bool): add 2pi if angle is negative.\n                Default: False.\n\n        Returns:\n            float: angle in radians.\n        \"\"\"\n\n        def _angle(p1, p2):\n            \"\"\"Counter clockwise angle from p1 to p2.\n\n            Returns:\n                float: angle in [0, np.pi]\n            \"\"\"\n            dot = p1[0] * p2[0] + p1[1] * p2[1]\n            det = p1[0] * p2[1] - p1[1] * p2[0]\n            angle = np.arctan2(det, dot)\n            return angle\n\n        x, y = self._to_pixel(self.u, self.v)\n        theta = np.arctan2(y, x)\n        if other is not None:\n            xother, yother = self._to_pixel(other.u, other.v)\n            theta = _angle([x, y], [xother, yother])\n        if non_negative:\n            theta += 2 * np.pi if theta &lt; 0 else 0\n        return theta\n\n    def distance(self, other=None):\n        \"\"\"Returns the columnar distance between to hexals.\"\"\"\n        if other is not None:\n            return int(\n                (\n                    abs(self.u - other.u)\n                    + abs(self.u + self.v - other.u - other.v)\n                    + abs(self.v - other.v)\n                )\n                / 2\n            )\n        return int((abs(self.u) + abs(self.u + self.v) + abs(self.v)) / 2)\n\n    @staticmethod\n    def _to_pixel(u, v, scale=1):\n        \"\"\"Converts to pixel coordinates.\"\"\"\n        return hex_to_pixel(u, v, scale)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Compares coordinates (not values).</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"Compares coordinates (not values).\"\"\"\n    if isinstance(other, Hexal):\n        return all((self.u == other.u, self.v == other.v))\n    elif isinstance(other, Iterable):\n        return np.array([self == h for h in other])\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.__add__","title":"__add__","text":"<pre><code>__add__(other)\n</code></pre> <p>Adds u and v coordinates, while keeping the value of the left hexal.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Adds u and v coordinates, while keeping the value of the left hexal.\"\"\"\n    if isinstance(other, Hexal):\n        return Hexal(self.u + other.u, self.v + other.v, self.value)\n    elif isinstance(other, Iterable):\n        return np.array([self + h for h in other])\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.__mul__","title":"__mul__","text":"<pre><code>__mul__(other)\n</code></pre> <p>Multiplies values, while preserving coordinates.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def __mul__(self, other):\n    \"\"\"Multiplies values, while preserving coordinates.\"\"\"\n    if isinstance(other, Hexal):\n        return Hexal(self.u, self.v, self.value * other.value)\n    elif isinstance(other, Iterable):\n        return np.array([self * h for h in other])\n    else:\n        return Hexal(self.u, self.v, self.value * other)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.eq_val","title":"eq_val","text":"<pre><code>eq_val(other)\n</code></pre> <p>Compares the values, not the coordinates.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def eq_val(self, other):\n    \"\"\"Compares the values, not the coordinates.\"\"\"\n    if isinstance(other, Hexal):\n        return self.value == other.value\n    elif isinstance(other, Iterable):\n        return np.array([self.eq_val(h) for h in other])\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.neighbours","title":"neighbours","text":"<pre><code>neighbours()\n</code></pre> <p>Returns 6 neighbours sorted CCW, starting from east.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def neighbours(self):\n    \"\"\"Returns 6 neighbours sorted CCW, starting from east.\"\"\"\n    return (\n        self.east,\n        self.north_east,\n        self.north_west,\n        self.west,\n        self.south_west,\n        self.south_east,\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.is_neighbour","title":"is_neighbour","text":"<pre><code>is_neighbour(other)\n</code></pre> <p>Evaluates if other is a neighbour.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def is_neighbour(self, other):\n    \"\"\"Evaluates if other is a neighbour.\"\"\"\n    neighbours = self.neighbours()\n    if isinstance(other, Hexal):\n        return other in neighbours\n    elif isinstance(other, Iterable):\n        return np.array([self.neighbour(h) for h in other])\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.unit_directions","title":"unit_directions  <code>staticmethod</code>","text":"<pre><code>unit_directions()\n</code></pre> <p>Returns the six unit directions.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>@staticmethod\ndef unit_directions():\n    \"\"\"Returns the six unit directions.\"\"\"\n    return HexArray(Hexal(0, 0, 0).neighbours())\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.interp","title":"interp","text":"<pre><code>interp(other, t)\n</code></pre> <p>Interpolates towards other.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>float</code> <p>interpolation step, 0&lt;t&lt;1.</p> required <p>Returns:</p> Type Description <p>Hexal</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def interp(self, other, t):\n    \"\"\"Interpolates towards other.\n\n    Args:\n        other (Hexal)\n        t (float): interpolation step, 0&lt;t&lt;1.\n\n    Returns:\n        Hexal\n    \"\"\"\n\n    def hex_round(u, v):\n        z = -(u + v)\n        ru = round(u)\n        rv = round(v)\n        rz = round(z)\n        u_diff = abs(ru - u)\n        v_diff = abs(rv - v)\n        z_diff = abs(rz - z)\n        if u_diff &gt; v_diff and u_diff &gt; z_diff:\n            ru = -rv - rz\n        elif v_diff &gt; z_diff:\n            rv = -ru - rz\n        return ru, rv\n\n    uprime, vprime = (\n        self.u + (other.u - self.u) * t,\n        self.v + (other.v - self.v) * t,\n    )\n    uprime, vprime = hex_round(uprime, vprime)\n    return Hexal(uprime, vprime, 0)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.angle","title":"angle","text":"<pre><code>angle(other=None, non_negative=False)\n</code></pre> <p>Returns the angle to other or the origin.</p> <p>Parameters:</p> Name Type Description Default <code>non_negative</code> <code>bool</code> <p>add 2pi if angle is negative. Default: False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>float</code> <p>angle in radians.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def angle(self, other=None, non_negative=False):\n    \"\"\"\n    Returns the angle to other or the origin.\n\n    Args:\n        other (Hexal)\n        non_negative (bool): add 2pi if angle is negative.\n            Default: False.\n\n    Returns:\n        float: angle in radians.\n    \"\"\"\n\n    def _angle(p1, p2):\n        \"\"\"Counter clockwise angle from p1 to p2.\n\n        Returns:\n            float: angle in [0, np.pi]\n        \"\"\"\n        dot = p1[0] * p2[0] + p1[1] * p2[1]\n        det = p1[0] * p2[1] - p1[1] * p2[0]\n        angle = np.arctan2(det, dot)\n        return angle\n\n    x, y = self._to_pixel(self.u, self.v)\n    theta = np.arctan2(y, x)\n    if other is not None:\n        xother, yother = self._to_pixel(other.u, other.v)\n        theta = _angle([x, y], [xother, yother])\n    if non_negative:\n        theta += 2 * np.pi if theta &lt; 0 else 0\n    return theta\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.Hexal.distance","title":"distance","text":"<pre><code>distance(other=None)\n</code></pre> <p>Returns the columnar distance between to hexals.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def distance(self, other=None):\n    \"\"\"Returns the columnar distance between to hexals.\"\"\"\n    if other is not None:\n        return int(\n            (\n                abs(self.u - other.u)\n                + abs(self.u + self.v - other.u - other.v)\n                + abs(self.v - other.v)\n            )\n            / 2\n        )\n    return int((abs(self.u) + abs(self.u + self.v) + abs(self.v)) / 2)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray","title":"flyvis.utils.hex_utils.HexArray","text":"<p>               Bases: <code>ndarray</code></p> <p>Flat array holding Hexal\u2019s as elements.</p> Can be constructed with <p>HexArray(hexals: Iterable, values: Optional[np.nan]) HexArray(u: Iterable, v: Iterable, values: Optional[np.nan])</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>class HexArray(np.ndarray):\n    \"\"\"Flat array holding Hexal's as elements.\n\n    Can be constructed with:\n        HexArray(hexals: Iterable, values: Optional[np.nan])\n        HexArray(u: Iterable, v: Iterable, values: Optional[np.nan])\n    \"\"\"\n\n    def __new__(cls, hexals=None, u=None, v=None, values=0):\n        if isinstance(hexals, Iterable):\n            u = np.array([h.u for h in hexals])\n            v = np.array([h.v for h in hexals])\n            values = np.array([h.value for h in hexals])\n        if not isinstance(values, Iterable):\n            values = np.ones_like(u) * values\n        u, v = HexArray.sort(u, v)\n        hexals = np.array(\n            [Hexal(_u, _v, _val) for _u, _v, _val in zip(u, v, values)],\n            dtype=Hexal,\n        ).view(cls)\n        return hexals\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n\n    def __eq__(self, other):\n        if isinstance(other, Hexal):\n            return other == self\n        else:\n            return super().__eq__(other)\n\n    def __getitem__(self, key):\n        if isinstance(key, HexArray):\n            mask = self.where_hexarray(key)\n            return self[mask]\n        else:\n            return super().__getitem__(key)\n\n    def __setitem__(self, key, value):\n        if isinstance(key, slice) and key == slice(None):\n            self.values = value\n        elif isinstance(key, HexArray):\n            mask = self.where_hexarray(key)\n            super().__setitem__(mask, value)\n        else:\n            super().__setitem__(key, value)\n\n    def where_hexarray(self, hexarray):\n        return matrix_mask_by_sub(\n            np.stack((hexarray.u, hexarray.v), axis=0).T,\n            np.stack((self.u, self.v), axis=0).T,\n        )\n\n    @staticmethod\n    def sort(u, v):\n        sort_index = np.lexsort((v, u))\n        u = u[sort_index]\n        v = v[sort_index]\n        return u, v\n\n    @staticmethod\n    def get_extent(hexals=None, u=None, v=None, center=Hexal(0, 0, 0)):\n        \"\"\"Returns the columnar extent.\"\"\"\n        from numbers import Number\n\n        if isinstance(u, Number) and isinstance(v, Number):\n            h = Hexal(u, v, 0)\n            return h.distance(center)\n        else:\n            ha = HexArray(hexals, u, v)\n            distance = max([h.distance(center) for h in ha])\n            return distance\n\n    @property\n    def u(self):\n        return np.array([h.u for h in self])\n\n    @property\n    def v(self):\n        return np.array([h.v for h in self])\n\n    @property\n    def values(self):\n        return np.array([h.value for h in self])\n\n    @values.setter\n    def values(self, values):\n        for h, val in zip(self, values):\n            h.value = val\n\n    @property\n    def extent(self):\n        return super().get_extent(self)\n\n    def with_stride(self, u_stride=None, v_stride=None):\n        \"\"\"Returns a sliced instance obeying strides in u- and v-direction.\"\"\"\n        new = []\n        for u, v, _ in zip(self.u, self.v, self.values):\n            new.append(u % u_stride == 0 and v % v_stride == 0)\n        return self[np.array(new)]\n\n    def where(self, value):\n        \"\"\"Returns a mask of where values are equal to the given one.\n\n        Note: value can be np.nan.\n        \"\"\"\n        return np.isclose(self.values, value, rtol=0, atol=0, equal_nan=True)\n\n    def fill(self, value):\n        \"\"\"Fills the values with the given one.\"\"\"\n        for h in self:\n            h.value = value\n\n    def to_pixel(self, scale=1, mode=\"default\"):\n        \"\"\"Converts to pixel coordinates.\"\"\"\n        return hex_to_pixel(self.u, self.v, scale, mode=mode)\n\n    def plot(self, figsize=[3, 3], fill=True):\n        \"\"\"Plots values in regular hexagonal lattice.\n\n        Meant for debugging.\n        \"\"\"\n        u = np.array([h.u for h in self])\n        v = np.array([h.v for h in self])\n        color = np.array([h.value for h in self])\n        return flyvis.plots.hex_scatter(\n            u,\n            v,\n            color,\n            fill=fill,\n            cmap=cm.get_cmap(\"binary\"),\n            edgecolor=\"black\",\n            figsize=figsize,\n        )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray.get_extent","title":"get_extent  <code>staticmethod</code>","text":"<pre><code>get_extent(hexals=None, u=None, v=None, center=Hexal(0, 0, 0))\n</code></pre> <p>Returns the columnar extent.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>@staticmethod\ndef get_extent(hexals=None, u=None, v=None, center=Hexal(0, 0, 0)):\n    \"\"\"Returns the columnar extent.\"\"\"\n    from numbers import Number\n\n    if isinstance(u, Number) and isinstance(v, Number):\n        h = Hexal(u, v, 0)\n        return h.distance(center)\n    else:\n        ha = HexArray(hexals, u, v)\n        distance = max([h.distance(center) for h in ha])\n        return distance\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray.with_stride","title":"with_stride","text":"<pre><code>with_stride(u_stride=None, v_stride=None)\n</code></pre> <p>Returns a sliced instance obeying strides in u- and v-direction.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def with_stride(self, u_stride=None, v_stride=None):\n    \"\"\"Returns a sliced instance obeying strides in u- and v-direction.\"\"\"\n    new = []\n    for u, v, _ in zip(self.u, self.v, self.values):\n        new.append(u % u_stride == 0 and v % v_stride == 0)\n    return self[np.array(new)]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray.where","title":"where","text":"<pre><code>where(value)\n</code></pre> <p>Returns a mask of where values are equal to the given one.</p> <p>Note: value can be np.nan.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def where(self, value):\n    \"\"\"Returns a mask of where values are equal to the given one.\n\n    Note: value can be np.nan.\n    \"\"\"\n    return np.isclose(self.values, value, rtol=0, atol=0, equal_nan=True)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray.fill","title":"fill","text":"<pre><code>fill(value)\n</code></pre> <p>Fills the values with the given one.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def fill(self, value):\n    \"\"\"Fills the values with the given one.\"\"\"\n    for h in self:\n        h.value = value\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray.to_pixel","title":"to_pixel","text":"<pre><code>to_pixel(scale=1, mode='default')\n</code></pre> <p>Converts to pixel coordinates.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def to_pixel(self, scale=1, mode=\"default\"):\n    \"\"\"Converts to pixel coordinates.\"\"\"\n    return hex_to_pixel(self.u, self.v, scale, mode=mode)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexArray.plot","title":"plot","text":"<pre><code>plot(figsize=[3, 3], fill=True)\n</code></pre> <p>Plots values in regular hexagonal lattice.</p> <p>Meant for debugging.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def plot(self, figsize=[3, 3], fill=True):\n    \"\"\"Plots values in regular hexagonal lattice.\n\n    Meant for debugging.\n    \"\"\"\n    u = np.array([h.u for h in self])\n    v = np.array([h.v for h in self])\n    color = np.array([h.value for h in self])\n    return flyvis.plots.hex_scatter(\n        u,\n        v,\n        color,\n        fill=fill,\n        cmap=cm.get_cmap(\"binary\"),\n        edgecolor=\"black\",\n        figsize=figsize,\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexLattice","title":"flyvis.utils.hex_utils.HexLattice","text":"<p>               Bases: <code>HexArray</code></p> <p>Flat array of Hexals.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <p>Extent of the regular hexagon grid.</p> required <code>hexals</code> <p>Existing hexals to initialize with.</p> required <code>center</code> <p>Center hexal of the lattice.</p> required <code>u_stride</code> <p>Stride in u-direction.</p> required <code>v_stride</code> <p>Stride in v-direction.</p> required Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>class HexLattice(HexArray):\n    \"\"\"Flat array of Hexals.\n\n    Args:\n        extent: Extent of the regular hexagon grid.\n        hexals: Existing hexals to initialize with.\n        center: Center hexal of the lattice.\n        u_stride: Stride in u-direction.\n        v_stride: Stride in v-direction.\n    \"\"\"\n\n    def __new__(\n        cls,\n        extent=15,\n        hexals=None,\n        center=Hexal(0, 0, 0),\n        u_stride=1,\n        v_stride=1,\n    ):\n        if isinstance(hexals, Iterable):\n            hexals = HexArray(hexals=hexals)\n            u = np.array([h.u for h in hexals])\n            v = np.array([h.v for h in hexals])\n            extent = extent or super().get_extent(hexals, center=center)\n            lattice = HexLattice(\n                extent=extent,\n                center=center,\n                u_stride=u_stride,\n                v_stride=v_stride,\n            )\n            for h in lattice:\n                if h in hexals:\n                    h.value = hexals[h == hexals][0].value\n        else:\n            u, v = flyvis.utils.hex_utils.get_hex_coords(extent)\n            u += center.u\n            v += center.v\n            values = [np.nan for _ in range(len(u))]  # np.ones_like(u) * np.nan\n            lattice = []\n            for _u, _v, _val in zip(u, v, values):\n                if _u % u_stride == 0 and _v % v_stride == 0:\n                    lattice.append(Hexal(_u, _v, _val, u_stride, v_stride))\n            lattice = np.array(lattice, dtype=Hexal).view(cls)\n        return lattice\n\n    @property\n    def center(self):\n        return self[len(self) // 2]\n\n    @property\n    def extent(self):\n        return super().get_extent(self, center=self.center)\n\n    # ----- Geometry\n\n    def circle(self, radius=None, center=Hexal(0, 0, 0), as_lattice=False):\n        \"\"\"Draws a circle in hex coordinates.\n\n        Args:\n            radius: Radius in columns of the circle.\n            center: Center of the circle.\n            as_lattice: Returns the circle on a constrained regular lattice.\n        \"\"\"\n        lattice = HexLattice(extent=max(radius or 0, self.extent), center=center)\n        radius = radius or self.extent\n        circle = []\n        for _, h in enumerate(lattice):\n            distance = center.distance(h)\n            if distance == radius:\n                h.value = 1\n                circle.append(h)\n        if as_lattice:\n            return HexLattice(hexals=circle)\n        return HexArray(hexals=circle)\n\n    @staticmethod\n    def filled_circle(radius=None, center=Hexal(0, 0, 0), as_lattice=False):\n        \"\"\"Draws a circle in hex coordinates.\n\n        Args:\n            radius: Radius in columns of the circle.\n            center: Center of the circle.\n            as_lattice: Returns the circle on a constrained regular lattice.\n        \"\"\"\n        lattice = HexLattice(extent=radius or 0, center=center)\n        radius = radius\n        circle = []\n        for _, h in enumerate(lattice):\n            distance = center.distance(h)\n            if distance &lt;= radius:\n                h.value = 1\n                circle.append(h)\n        if as_lattice:\n            return HexLattice(hexals=circle)\n        return HexArray(hexals=circle)\n\n    def hull(self):\n        \"\"\"Returns the hull of the regular lattice.\"\"\"\n        return self.circle(radius=self.extent, center=self.center)\n\n    def _line_span(self, angle):\n        \"\"\"Returns two points spanning a line with given angle wrt. origin.\n\n        Args:\n            angle: In [0, np.pi]\n\n        Returns:\n            HexArray\n        \"\"\"\n        # To offset the line by simple addition of the offset,\n        # radius=2 * self.extent spans the line in ways that each valid offset\n        # can be added.\n        distant_hull = self.ring(radius=2 * self.extent)\n        angles = np.array([h.angle(signed=True) for h in distant_hull])\n        distance = (angles - angle) % np.pi\n        index = np.argsort(distance)\n        span = distant_hull[index[0:2]]\n        for h in span:\n            h.value = 1\n        return HexArray(hexals=span)\n\n    def line(self, angle, center=Hexal(0, 0, 1), as_lattice=False):\n        \"\"\"Returns a line on a HexLattice or HexArray.\n\n        Args:\n            angle: In [0, np.pi]\n            center: Midpoint of the line\n            as_lattice: Returns the ring on a constrained regular lattice.\n\n        Returns:\n            HexArray or constrained HexLattice\n        \"\"\"\n        line_span = self._line_span(angle)\n        distance = line_span[0].distance(line_span[1])\n        line = []\n        for i in range(distance + 1):\n            _next = line_span[0].interp(line_span[1], 1 / distance * i)\n            line.append(_next)\n        for h in line:\n            h.value = 1\n        if as_lattice:\n            return HexLattice(extent=self.extent, hexals=center + line)\n        return HexArray(hexals=center + line)\n\n    def _get_neighbour_indices(self, index):\n        _neighbours = self[index].neighbours()\n        neighbours = ()\n        for n in _neighbours:\n            valid = self == n\n            if valid.any():\n                neighbours += (np.where(valid)[0][0],)\n        return neighbours\n\n    def valid_neighbours(self):\n        neighbours = ()\n        for i in range(len(self)):\n            neighbours += (self._get_neighbour_indices(i),)\n        return neighbours\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexLattice.circle","title":"circle","text":"<pre><code>circle(radius=None, center=Hexal(0, 0, 0), as_lattice=False)\n</code></pre> <p>Draws a circle in hex coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <p>Radius in columns of the circle.</p> <code>None</code> <code>center</code> <p>Center of the circle.</p> <code>Hexal(0, 0, 0)</code> <code>as_lattice</code> <p>Returns the circle on a constrained regular lattice.</p> <code>False</code> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def circle(self, radius=None, center=Hexal(0, 0, 0), as_lattice=False):\n    \"\"\"Draws a circle in hex coordinates.\n\n    Args:\n        radius: Radius in columns of the circle.\n        center: Center of the circle.\n        as_lattice: Returns the circle on a constrained regular lattice.\n    \"\"\"\n    lattice = HexLattice(extent=max(radius or 0, self.extent), center=center)\n    radius = radius or self.extent\n    circle = []\n    for _, h in enumerate(lattice):\n        distance = center.distance(h)\n        if distance == radius:\n            h.value = 1\n            circle.append(h)\n    if as_lattice:\n        return HexLattice(hexals=circle)\n    return HexArray(hexals=circle)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexLattice.filled_circle","title":"filled_circle  <code>staticmethod</code>","text":"<pre><code>filled_circle(radius=None, center=Hexal(0, 0, 0), as_lattice=False)\n</code></pre> <p>Draws a circle in hex coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <p>Radius in columns of the circle.</p> <code>None</code> <code>center</code> <p>Center of the circle.</p> <code>Hexal(0, 0, 0)</code> <code>as_lattice</code> <p>Returns the circle on a constrained regular lattice.</p> <code>False</code> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>@staticmethod\ndef filled_circle(radius=None, center=Hexal(0, 0, 0), as_lattice=False):\n    \"\"\"Draws a circle in hex coordinates.\n\n    Args:\n        radius: Radius in columns of the circle.\n        center: Center of the circle.\n        as_lattice: Returns the circle on a constrained regular lattice.\n    \"\"\"\n    lattice = HexLattice(extent=radius or 0, center=center)\n    radius = radius\n    circle = []\n    for _, h in enumerate(lattice):\n        distance = center.distance(h)\n        if distance &lt;= radius:\n            h.value = 1\n            circle.append(h)\n    if as_lattice:\n        return HexLattice(hexals=circle)\n    return HexArray(hexals=circle)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexLattice.hull","title":"hull","text":"<pre><code>hull()\n</code></pre> <p>Returns the hull of the regular lattice.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def hull(self):\n    \"\"\"Returns the hull of the regular lattice.\"\"\"\n    return self.circle(radius=self.extent, center=self.center)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.HexLattice.line","title":"line","text":"<pre><code>line(angle, center=Hexal(0, 0, 1), as_lattice=False)\n</code></pre> <p>Returns a line on a HexLattice or HexArray.</p> <p>Parameters:</p> Name Type Description Default <code>angle</code> <p>In [0, np.pi]</p> required <code>center</code> <p>Midpoint of the line</p> <code>Hexal(0, 0, 1)</code> <code>as_lattice</code> <p>Returns the ring on a constrained regular lattice.</p> <code>False</code> <p>Returns:</p> Type Description <p>HexArray or constrained HexLattice</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def line(self, angle, center=Hexal(0, 0, 1), as_lattice=False):\n    \"\"\"Returns a line on a HexLattice or HexArray.\n\n    Args:\n        angle: In [0, np.pi]\n        center: Midpoint of the line\n        as_lattice: Returns the ring on a constrained regular lattice.\n\n    Returns:\n        HexArray or constrained HexLattice\n    \"\"\"\n    line_span = self._line_span(angle)\n    distance = line_span[0].distance(line_span[1])\n    line = []\n    for i in range(distance + 1):\n        _next = line_span[0].interp(line_span[1], 1 / distance * i)\n        line.append(_next)\n    for h in line:\n        h.value = 1\n    if as_lattice:\n        return HexLattice(extent=self.extent, hexals=center + line)\n    return HexArray(hexals=center + line)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.LatticeMask","title":"flyvis.utils.hex_utils.LatticeMask","text":"<p>Boolean masks for lattice dimension.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of the hexagonal lattice.</p> <code>15</code> <code>u_stride</code> <code>int</code> <p>Stride in u-direction.</p> <code>1</code> <code>v_stride</code> <code>int</code> <p>Stride in v-direction.</p> <code>1</code> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>class LatticeMask:\n    \"\"\"Boolean masks for lattice dimension.\n\n    Args:\n        extent: Extent of the hexagonal lattice.\n        u_stride: Stride in u-direction.\n        v_stride: Stride in v-direction.\n    \"\"\"\n\n    def __init__(self, extent: int = 15, u_stride: int = 1, v_stride: int = 1):\n        self._lattice = HexLattice(extent=extent, u_stride=u_stride, v_stride=v_stride)\n\n    @property\n    def center(self):\n        return self._lattice.center == self._lattice\n\n    @property\n    def center_east(self):\n        return self._lattice.center.east == self._lattice\n\n    @property\n    def center_north_east(self):\n        return self._lattice.center.north_east == self._lattice\n\n    @property\n    def center_north_west(self):\n        return self._lattice.center.north_west == self._lattice\n\n    @property\n    def center_west(self):\n        return self._lattice.center.west == self._lattice\n\n    @property\n    def center_south_west(self):\n        return self._lattice.center.south_west == self._lattice\n\n    @property\n    def center_south_east(self):\n        return self._lattice.center.south_east == self._lattice\n</code></pre>"},{"location":"reference/utils/#functions_8","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.hex_utils.get_hex_coords","title":"flyvis.utils.hex_utils.get_hex_coords","text":"<pre><code>get_hex_coords(extent, astensor=False)\n</code></pre> <p>Construct hexagonal coordinates for a regular hex-lattice with extent.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Integer radius of hexagonal lattice. 0 returns the single center coordinate.</p> required <code>astensor</code> <code>bool</code> <p>If True, returns torch.Tensor, else np.array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray]</code> <p>A tuple containing: u: Hex-coordinates in u-direction. v: Hex-coordinates in v-direction.</p> Note <p>Will return <code>get_num_hexals(extent)</code> coordinates.</p> See Also <p>https://www.redblobgames.com/grids/hexagons/#range-coordinate</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def get_hex_coords(extent: int, astensor: bool = False) -&gt; Tuple[NDArray, NDArray]:\n    \"\"\"Construct hexagonal coordinates for a regular hex-lattice with extent.\n\n    Args:\n        extent: Integer radius of hexagonal lattice. 0 returns the single\n            center coordinate.\n        astensor: If True, returns torch.Tensor, else np.array.\n\n    Returns:\n        A tuple containing:\n            u: Hex-coordinates in u-direction.\n            v: Hex-coordinates in v-direction.\n\n    Note:\n        Will return `get_num_hexals(extent)` coordinates.\n\n    See Also:\n        https://www.redblobgames.com/grids/hexagons/#range-coordinate\n    \"\"\"\n    u = []\n    v = []\n    for q in range(-extent, extent + 1):\n        for r in range(max(-extent, -extent - q), min(extent, extent - q) + 1):\n            u.append(q)\n            v.append(r)\n    if astensor:\n        return torch.tensor(u, dtype=torch.long), torch.tensor(v, dtype=torch.long)\n    return np.array(u), np.array(v)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.hex_to_pixel","title":"flyvis.utils.hex_utils.hex_to_pixel","text":"<pre><code>hex_to_pixel(u, v, size=1, mode='default')\n</code></pre> <p>Returns pixel coordinates from hex coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>Hex-coordinates in u-direction.</p> required <code>v</code> <code>NDArray</code> <p>Hex-coordinates in v-direction.</p> required <code>size</code> <code>float</code> <p>Size of hexagon.</p> <code>1</code> <code>mode</code> <code>Literal['default', 'flat', 'pointy']</code> <p>Coordinate system convention.</p> <code>'default'</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray]</code> <p>A tuple containing: x: Pixel-coordinates in x-direction. y: Pixel-coordinates in y-direction.</p> See Also <p>https://www.redblobgames.com/grids/hexagons/#hex-to-pixel</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def hex_to_pixel(\n    u: NDArray,\n    v: NDArray,\n    size: float = 1,\n    mode: Literal[\"default\", \"flat\", \"pointy\"] = \"default\",\n) -&gt; Tuple[NDArray, NDArray]:\n    \"\"\"Returns pixel coordinates from hex coordinates.\n\n    Args:\n        u: Hex-coordinates in u-direction.\n        v: Hex-coordinates in v-direction.\n        size: Size of hexagon.\n        mode: Coordinate system convention.\n\n    Returns:\n        A tuple containing:\n            x: Pixel-coordinates in x-direction.\n            y: Pixel-coordinates in y-direction.\n\n    See Also:\n        https://www.redblobgames.com/grids/hexagons/#hex-to-pixel\n    \"\"\"\n    if isinstance(u, list) and isinstance(v, list):\n        u = np.array(u)\n        v = np.array(v)\n    if mode == \"default\":\n        return 3 / 2 * v, -np.sqrt(3) * (u + v / 2)\n    elif mode == \"flat\":\n        return (3 / 2 * u) * size, (np.sqrt(3) / 2 * u + np.sqrt(3) * v) * size\n    elif mode == \"pointy\":\n        return (np.sqrt(3) * u + np.sqrt(3) / 2 * v) * size, (3 / 2 * v) * size\n    else:\n        raise ValueError(f\"{mode} not recognized.\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.hex_rows","title":"flyvis.utils.hex_utils.hex_rows","text":"<pre><code>hex_rows(n_rows, n_columns, eps=0.1, mode='pointy')\n</code></pre> <p>Return a hex grid in pixel coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>n_rows</code> <code>int</code> <p>Number of rows.</p> required <code>n_columns</code> <code>int</code> <p>Number of columns.</p> required <code>eps</code> <code>float</code> <p>Small offset to avoid overlapping hexagons.</p> <code>0.1</code> <code>mode</code> <code>Literal['pointy', 'flat']</code> <p>Orientation of hexagons.</p> <code>'pointy'</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray]</code> <p>A tuple containing: x: X-coordinates of hexagon centers. y: Y-coordinates of hexagon centers.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def hex_rows(\n    n_rows: int,\n    n_columns: int,\n    eps: float = 0.1,\n    mode: Literal[\"pointy\", \"flat\"] = \"pointy\",\n) -&gt; Tuple[NDArray, NDArray]:\n    \"\"\"Return a hex grid in pixel coordinates.\n\n    Args:\n        n_rows: Number of rows.\n        n_columns: Number of columns.\n        eps: Small offset to avoid overlapping hexagons.\n        mode: Orientation of hexagons.\n\n    Returns:\n        A tuple containing:\n            x: X-coordinates of hexagon centers.\n            y: Y-coordinates of hexagon centers.\n    \"\"\"\n    u = []\n    v = []\n    for r in range(n_rows):\n        for c in range(n_columns):\n            u.append(c)\n            v.append(r)\n    u = np.array(u)\n    v = np.array(v)\n    x, y = hex_to_pixel(u, v, mode=mode)\n    x += eps\n    y += eps\n    return x, y\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.pixel_to_hex","title":"flyvis.utils.hex_utils.pixel_to_hex","text":"<pre><code>pixel_to_hex(x, y, size=1, mode='default')\n</code></pre> <p>Returns hex coordinates from pixel coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>NDArray</code> <p>Pixel-coordinates in x-direction.</p> required <code>y</code> <code>NDArray</code> <p>Pixel-coordinates in y-direction.</p> required <code>size</code> <code>float</code> <p>Size of hexagon.</p> <code>1</code> <code>mode</code> <code>Literal['default', 'flat', 'pointy']</code> <p>Coordinate system convention.</p> <code>'default'</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray]</code> <p>A tuple containing: u: Hex-coordinates in u-direction. v: Hex-coordinates in v-direction.</p> See Also <p>https://www.redblobgames.com/grids/hexagons/#hex-to-pixel</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def pixel_to_hex(\n    x: NDArray,\n    y: NDArray,\n    size: float = 1,\n    mode: Literal[\"default\", \"flat\", \"pointy\"] = \"default\",\n) -&gt; Tuple[NDArray, NDArray]:\n    \"\"\"Returns hex coordinates from pixel coordinates.\n\n    Args:\n        x: Pixel-coordinates in x-direction.\n        y: Pixel-coordinates in y-direction.\n        size: Size of hexagon.\n        mode: Coordinate system convention.\n\n    Returns:\n        A tuple containing:\n            u: Hex-coordinates in u-direction.\n            v: Hex-coordinates in v-direction.\n\n    See Also:\n        https://www.redblobgames.com/grids/hexagons/#hex-to-pixel\n    \"\"\"\n    if mode == \"default\":\n        return -x / 3 - y / np.sqrt(3), 2 / 3 * x\n    elif mode == \"flat\":\n        return (2 / 3 * x) / size, (-1 / 3 * x + np.sqrt(3) / 3 * y) / size\n    elif mode == \"pointy\":\n        return (np.sqrt(3) / 3 * x - 1 / 3 * y) / size, (2 / 3 * y) / size\n    else:\n        raise ValueError(f\"{mode} not recognized.\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.pad_to_regular_hex","title":"flyvis.utils.hex_utils.pad_to_regular_hex","text":"<pre><code>pad_to_regular_hex(u, v, values, extent, value=np.nan)\n</code></pre> <p>Pad hexals with coordinates to a regular hex lattice.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>U-coordinate of hexal.</p> required <code>v</code> <code>NDArray</code> <p>V-coordinate of hexal.</p> required <code>values</code> <code>NDArray</code> <p>Value of hexal with arbitrary shape but last axis must match the hexal dimension.</p> required <code>extent</code> <code>int</code> <p>Extent of regular hex grid to pad to.</p> required <code>value</code> <code>float</code> <p>The pad value.</p> <code>nan</code> <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray, NDArray]</code> <p>A tuple containing: u_padded: Padded u-coordinate. v_padded: Padded v-coordinate. values_padded: Padded value.</p> Note <p>The canonical use case here is to pad a filter, receptive field, or postsynaptic current field for visualization.</p> Example <pre><code>u = np.array([1, 0, -1, 0, 1, 2])\nv = np.array([-2, -1, 0, 0, 0, 0])\nvalues = np.array([0.05, 0.1, 0.3, 0.5, 0.7, 0.9])\nhexals = pad_to_regular_hex(u, v, values, 6)\nhex_scatter(*hexals, edgecolor='k', cmap=plt.cm.Blues, vmin=0, vmax=1)\n</code></pre> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def pad_to_regular_hex(\n    u: NDArray,\n    v: NDArray,\n    values: NDArray,\n    extent: int,\n    value: float = np.nan,\n) -&gt; Tuple[NDArray, NDArray, NDArray]:\n    \"\"\"Pad hexals with coordinates to a regular hex lattice.\n\n    Args:\n        u: U-coordinate of hexal.\n        v: V-coordinate of hexal.\n        values: Value of hexal with arbitrary shape but last axis\n            must match the hexal dimension.\n        extent: Extent of regular hex grid to pad to.\n        value: The pad value.\n\n    Returns:\n        A tuple containing:\n            u_padded: Padded u-coordinate.\n            v_padded: Padded v-coordinate.\n            values_padded: Padded value.\n\n    Note:\n        The canonical use case here is to pad a filter, receptive field, or\n        postsynaptic current field for visualization.\n\n    Example:\n        ```python\n        u = np.array([1, 0, -1, 0, 1, 2])\n        v = np.array([-2, -1, 0, 0, 0, 0])\n        values = np.array([0.05, 0.1, 0.3, 0.5, 0.7, 0.9])\n        hexals = pad_to_regular_hex(u, v, values, 6)\n        hex_scatter(*hexals, edgecolor='k', cmap=plt.cm.Blues, vmin=0, vmax=1)\n        ```\n    \"\"\"\n    u_padded, v_padded = flyvis.utils.hex_utils.get_hex_coords(extent)\n    slices = tuple()\n    if len(values.shape) &gt; 1:\n        values_padded = np.ones([*values.shape[:-1], len(u_padded)]) * value\n        for _ in range(len(values.shape[:-1])):\n            slices += (slice(None),)\n    else:\n        values_padded = np.ones([len(u_padded)]) * value\n    index = flyvis.utils.tensor_utils.where_equal_rows(\n        np.stack((u, v), axis=1), np.stack((u_padded, v_padded), axis=1)\n    )\n    slices += (index,)\n    values_padded[slices] = values\n    return u_padded, v_padded, values_padded\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.max_extent_index","title":"flyvis.utils.hex_utils.max_extent_index","text":"<pre><code>max_extent_index(u, v, max_extent)\n</code></pre> <p>Returns a mask to constrain u and v axial-hex-coordinates by max_extent.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>Hex-coordinates in u-direction.</p> required <code>v</code> <code>NDArray</code> <p>Hex-coordinates in v-direction.</p> required <code>max_extent</code> <code>int</code> <p>Maximal extent.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>Boolean mask.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def max_extent_index(u: NDArray, v: NDArray, max_extent: int) -&gt; NDArray:\n    \"\"\"Returns a mask to constrain u and v axial-hex-coordinates by max_extent.\n\n    Args:\n        u: Hex-coordinates in u-direction.\n        v: Hex-coordinates in v-direction.\n        max_extent: Maximal extent.\n\n    Returns:\n        Boolean mask.\n    \"\"\"\n    return (\n        (-max_extent &lt;= u)\n        &amp; (u &lt;= max_extent)\n        &amp; (-max_extent &lt;= v)\n        &amp; (v &lt;= max_extent)\n        &amp; (-max_extent &lt;= u + v)\n        &amp; (u + v &lt;= max_extent)\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.get_num_hexals","title":"flyvis.utils.hex_utils.get_num_hexals","text":"<pre><code>get_num_hexals(extent)\n</code></pre> <p>Returns the absolute number of hexals in a hexagonal grid with extent.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of hex-lattice.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of hexals.</p> Note <p>Inverse of get_hextent.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def get_num_hexals(extent: int) -&gt; int:\n    \"\"\"Returns the absolute number of hexals in a hexagonal grid with extent.\n\n    Args:\n        extent: Extent of hex-lattice.\n\n    Returns:\n        Number of hexals.\n\n    Note:\n        Inverse of get_hextent.\n    \"\"\"\n    return 1 + 3 * extent * (extent + 1)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.get_hextent","title":"flyvis.utils.hex_utils.get_hextent","text":"<pre><code>get_hextent(num_hexals)\n</code></pre> <p>Computes the hex-lattice extent from the number of hexals.</p> <p>Parameters:</p> Name Type Description Default <code>num_hexals</code> <code>int</code> <p>Number of hexals.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Extent of hex-lattice.</p> Note <p>Inverse of get_num_hexals.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def get_hextent(num_hexals: int) -&gt; int:\n    \"\"\"Computes the hex-lattice extent from the number of hexals.\n\n    Args:\n        num_hexals: Number of hexals.\n\n    Returns:\n        Extent of hex-lattice.\n\n    Note:\n        Inverse of get_num_hexals.\n    \"\"\"\n\n    return np.floor(np.sqrt(num_hexals / 3)).astype(\"int\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.sort_u_then_v","title":"flyvis.utils.hex_utils.sort_u_then_v","text":"<pre><code>sort_u_then_v(u, v, values)\n</code></pre> <p>Sorts u, v, and values by u and then v.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>U-coordinate of hexal.</p> required <code>v</code> <code>NDArray</code> <p>V-coordinate of hexal.</p> required <code>values</code> <code>NDArray</code> <p>Value of hexal.</p> required <p>Returns:</p> Type Description <code>Tuple[NDArray, NDArray, NDArray]</code> <p>A tuple containing: u: Sorted u-coordinate of hexal. v: Sorted v-coordinate of hexal. values: Sorted value of hexal.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def sort_u_then_v(\n    u: NDArray, v: NDArray, values: NDArray\n) -&gt; Tuple[NDArray, NDArray, NDArray]:\n    \"\"\"Sorts u, v, and values by u and then v.\n\n    Args:\n        u: U-coordinate of hexal.\n        v: V-coordinate of hexal.\n        values: Value of hexal.\n\n    Returns:\n        A tuple containing:\n            u: Sorted u-coordinate of hexal.\n            v: Sorted v-coordinate of hexal.\n            values: Sorted value of hexal.\n    \"\"\"\n    index = np.lexsort((v, u))\n    return u[index], v[index], values[index]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.sort_u_then_v_index","title":"flyvis.utils.hex_utils.sort_u_then_v_index","text":"<pre><code>sort_u_then_v_index(u, v)\n</code></pre> <p>Index to sort u, v by u and then v.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>U-coordinate of hexal.</p> required <code>v</code> <code>NDArray</code> <p>V-coordinate of hexal.</p> required <p>Returns:</p> Type Description <code>NDArray</code> <p>Index to sort u and v.</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def sort_u_then_v_index(u: NDArray, v: NDArray) -&gt; NDArray:\n    \"\"\"Index to sort u, v by u and then v.\n\n    Args:\n        u: U-coordinate of hexal.\n        v: V-coordinate of hexal.\n\n    Returns:\n        Index to sort u and v.\n    \"\"\"\n    return np.lexsort((v, u))\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.hex_utils.get_extent","title":"flyvis.utils.hex_utils.get_extent","text":"<pre><code>get_extent(u, v, astype=int)\n</code></pre> <p>Returns extent (integer distance to origin) of arbitrary u, v coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>U-coordinate of hexal.</p> required <code>v</code> <code>NDArray</code> <p>V-coordinate of hexal.</p> required <code>astype</code> <code>type</code> <p>Type to cast to.</p> <code>int</code> <p>Returns:</p> Type Description <code>int</code> <p>Extent of hex-lattice.</p> Note <p>If u and v are arrays, returns the maximum extent.</p> See Also <p>https://www.redblobgames.com/grids/hexagons/#distances</p> Source code in <code>flyvis/utils/hex_utils.py</code> <pre><code>def get_extent(u: NDArray, v: NDArray, astype: type = int) -&gt; int:\n    \"\"\"Returns extent (integer distance to origin) of arbitrary u, v coordinates.\n\n    Args:\n        u: U-coordinate of hexal.\n        v: V-coordinate of hexal.\n        astype: Type to cast to.\n\n    Returns:\n        Extent of hex-lattice.\n\n    Note:\n        If u and v are arrays, returns the maximum extent.\n\n    See Also:\n        https://www.redblobgames.com/grids/hexagons/#distances\n    \"\"\"\n    if isinstance(u, Number) and isinstance(v, Number):\n        u, v = np.array((u,)), np.array((v,))\n    uv = np.stack((u, v), 1)\n    extent = (\n        abs(0 - uv[:, 0]) + abs(0 + 0 - uv[:, 0] - uv[:, 1]) + abs(0 - uv[:, 1])\n    ) / 2\n    return np.max(extent).astype(astype)\n</code></pre>"},{"location":"reference/utils/#flyvisutilslog_utils","title":"flyvis.utils.log_utils","text":""},{"location":"reference/utils/#classes_7","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.log_utils.Status","title":"flyvis.utils.log_utils.Status  <code>dataclass</code>","text":"<p>Status object from log files of model runs.</p> <p>Attributes:</p> Name Type Description <code>ensemble_name</code> <code>str</code> <p>Name of the ensemble.</p> <code>log_files</code> <code>List[Path]</code> <p>List of all log files.</p> <code>train_logs</code> <code>List[Path]</code> <p>List of train logs.</p> <code>model_id_to_train_log_file</code> <code>Dict[str, Path]</code> <p>Mapping of model ID to log file.</p> <code>status</code> <code>Dict[str, str]</code> <p>Mapping of model ID to status.</p> <code>user_input</code> <code>Dict[str, str]</code> <p>Mapping of model ID to user input (behind LSF command).</p> <code>hosts</code> <code>Dict[str, List[str]]</code> <p>Mapping of model ID to host.</p> <code>rerun_failed_runs</code> <code>Dict[str, List[str]]</code> <p>Formatted submission commands to restart failed models.</p> <code>lsf_part</code> <code>str</code> <p>LSF command part.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>@dataclass\nclass Status:\n    \"\"\"Status object from log files of model runs.\n\n    Attributes:\n        ensemble_name: Name of the ensemble.\n        log_files: List of all log files.\n        train_logs: List of train logs.\n        model_id_to_train_log_file: Mapping of model ID to log file.\n        status: Mapping of model ID to status.\n        user_input: Mapping of model ID to user input (behind LSF command).\n        hosts: Mapping of model ID to host.\n        rerun_failed_runs: Formatted submission commands to restart failed models.\n        lsf_part: LSF command part.\n    \"\"\"\n\n    ensemble_name: str\n    log_files: List[Path]\n    train_logs: List[Path]\n    model_id_to_train_log_file: Dict[str, Path]\n    status: Dict[str, str]\n    user_input: Dict[str, str]\n    hosts: Dict[str, List[str]]\n    rerun_failed_runs: Dict[str, List[str]]\n    lsf_part: str\n\n    def print_for_rerun(\n        self, exclude_failed_hosts: bool = True, model_ids: List[str] = None\n    ) -&gt; None:\n        \"\"\"Print formatted submission commands to restart failed models.\n\n        Args:\n            exclude_failed_hosts: Whether to exclude failed hosts.\n            model_ids: List of model IDs to rerun. If None, all failed models are\n                included.\n        \"\"\"\n        model_ids = model_ids or list(self.rerun_failed_runs.keys())\n        for model_id in model_ids:\n            command = \"\"\n            subcmds = self.rerun_failed_runs[model_id]\n            if exclude_failed_hosts:\n                command += f\"{subcmds[0]}{subcmds[1]}{subcmds[2]}\"\n            else:\n                command += f\"{subcmds[0]}{subcmds[2]}\"\n            print(command)\n\n    def get_hosts(self) -&gt; List[str]:\n        \"\"\"Get hosts on which the job was executed.\"\"\"\n        return list(set(flatten_list(self.hosts.values())))\n\n    def bad_hosts(self) -&gt; List[str]:\n        \"\"\"Get hosts on which the job failed.\"\"\"\n        host_lists = [\n            host\n            for model_id, host in self.hosts.items()\n            if self.status[model_id] not in [\"Successfully completed.\", \"running\"]\n        ]\n        return list(set(flatten_list(host_lists)))\n\n    def successful_runs(self) -&gt; int:\n        \"\"\"Get number of successful runs.\"\"\"\n        return sum(1 for v in self.status.values() if v == \"Successfully completed.\")\n\n    def running_runs(self) -&gt; int:\n        \"\"\"Get number of running runs.\"\"\"\n        return sum(1 for v in self.status.values() if v == \"running\")\n\n    def failed_runs(self) -&gt; int:\n        \"\"\"Get number of failed runs.\"\"\"\n        return sum(1 for v in self.status.values() if \"Exited with exit code\" in v)\n\n    def successful_model_ids(self) -&gt; List[str]:\n        \"\"\"Get model IDs of successful runs.\"\"\"\n        return [k for k, v in self.status.items() if v == \"Successfully completed.\"]\n\n    def running_model_ids(self) -&gt; List[str]:\n        \"\"\"Get model IDs of running runs.\"\"\"\n        return [k for k, v in self.status.items() if v == \"running\"]\n\n    def failed_model_ids(self) -&gt; List[str]:\n        \"\"\"Get model IDs of failed runs.\"\"\"\n        return [k for k, v in self.status.items() if \"Exited with exit code\" in v]\n\n    def lookup_log(\n        self, model_id: str, log_type: str = \"train_single\", last_n_lines: int = 20\n    ) -&gt; List[str]:\n        \"\"\"Lookup log for a model ID.\n\n        Args:\n            model_id: ID of the model.\n            log_type: Type of log to lookup.\n            last_n_lines: Number of lines to return from the end of the log.\n\n        Returns:\n            List of log lines.\n        \"\"\"\n        log_file = [\n            p\n            for p in self.log_files\n            if log_type in str(p) and p.name.split(\"_\")[0] == model_id\n        ][0]\n        return log_file.read_text().split(\"\\n\")[-last_n_lines:]\n\n    def extract_error_trace(\n        self, model_id: str, check_last_n_lines: int = 100, log_type: str = \"train_single\"\n    ) -&gt; str:\n        \"\"\"Extract the Python error message and traceback from a given log string.\n\n        Args:\n            model_id: ID of the model.\n            check_last_n_lines: Number of lines to check from the end of the log.\n            log_type: Type of log to extract error from.\n\n        Returns:\n            Extracted error message and traceback, or a message if no error is found.\n        \"\"\"\n        log_string = \"\\n\".join(\n            self.lookup_log(model_id, last_n_lines=check_last_n_lines, log_type=log_type)\n        )\n        pattern = r\"Traceback \\(most recent call last\\):(.+?)(?=\\n\\n|\\Z)\"\n        match = re.search(pattern, log_string, re.DOTALL)\n        return match.group(0).strip() if match else \"No Python error found in the log.\"\n\n    def extract_error_type(\n        self, model_id: str, log_type: str = \"train_single\", check_last_n_lines: int = 100\n    ) -&gt; str:\n        \"\"\"Extract the type of error from a given log string.\n\n        Args:\n            model_id: ID of the model.\n            log_type: Type of log to extract error from.\n            check_last_n_lines: Number of lines to check from the end of the log.\n\n        Returns:\n            Extracted error type, or a message if no specific error type is found.\n        \"\"\"\n        log_string = \"\\n\".join(\n            self.lookup_log(model_id, last_n_lines=check_last_n_lines, log_type=log_type)\n        )\n        pattern = r\"\\b[A-Z]\\w*Error\\b\"\n        match = re.search(pattern, log_string)\n        return match.group(0) if match else \"No specific error type found.\"\n\n    def all_errors(\n        self, check_last_n_lines: int = 100, log_type: str = \"train_single\"\n    ) -&gt; set:\n        \"\"\"Get all unique errors from failed runs.\n\n        Args:\n            check_last_n_lines: Number of lines to check from the end of the log.\n            log_type: Type of log to extract errors from.\n\n        Returns:\n            Set of unique error messages.\n        \"\"\"\n        return set(\n            self.extract_error_trace(\n                model_id,\n                check_last_n_lines=check_last_n_lines,\n                log_type=log_type,\n            )\n            for model_id in self.failed_model_ids()\n        )\n\n    def all_error_types(self, log_type: str = \"train_single\") -&gt; set:\n        \"\"\"Get all unique error types from failed runs.\n\n        Args:\n            log_type: Type of log to extract error types from.\n\n        Returns:\n            Set of unique error types.\n        \"\"\"\n        return set(\n            self.extract_error_type(model_id, log_type=log_type)\n            for model_id in self.failed_model_ids()\n        )\n\n    def print_all_errors(\n        self, check_last_n_lines: int = 100, log_type: str = \"train_single\"\n    ) -&gt; None:\n        \"\"\"Print all errors and tracebacks from failed runs.\n\n        Args:\n            check_last_n_lines: Number of lines to check from the end of the log.\n            log_type: Type of log to extract errors from.\n        \"\"\"\n        for model_id in self.failed_model_ids():\n            print(\n                f\"Model {model_id} failed with the following error message \"\n                \"and traceback:\\n\"\n            )\n            print(\n                self.extract_error_trace(\n                    model_id,\n                    check_last_n_lines=check_last_n_lines,\n                    log_type=log_type,\n                )\n            )\n            print(\"\\n\")\n\n    def __getitem__(self, key: str) -&gt; str:\n        \"\"\"Get status for a specific model ID.\"\"\"\n        if key in self.status:\n            return self.status[key]\n        return object.__getitem__(self, key)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the Status object.\"\"\"\n        _repr = f\"Status of ensemble {self.ensemble_name}.\"\n        _repr += f\"\\n{len(self.status)} models.\"\n        _repr += f\"\\nHosts: {','.join(self.get_hosts())}.\"\n        _repr += f\"\\n  {self.successful_runs()} successful runs.\"\n        _repr += f\"\\n  {self.running_runs()} running runs.\"\n        _repr += f\"\\n  {self.failed_runs()} failed runs.\"\n        if self.failed_runs() &gt; 0:\n            _repr += f\"\\n  Bad hosts: {','.join(self.bad_hosts())}.\"\n            _repr += \"\\n  Use .print_for_rerun() to print formatted submission commands\"\n            _repr += \" to restart failed models.\"\n            _repr += \"\\nError types:\"\n            for error in self.all_error_types():\n                _repr += f\"\\n  {error}\"\n            _repr += (\n                \"\\n  Run .print_all_errors() to print the error messages and tracebacks.\"\n            )\n        return _repr\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.print_for_rerun","title":"print_for_rerun","text":"<pre><code>print_for_rerun(exclude_failed_hosts=True, model_ids=None)\n</code></pre> <p>Print formatted submission commands to restart failed models.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_failed_hosts</code> <code>bool</code> <p>Whether to exclude failed hosts.</p> <code>True</code> <code>model_ids</code> <code>List[str]</code> <p>List of model IDs to rerun. If None, all failed models are included.</p> <code>None</code> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def print_for_rerun(\n    self, exclude_failed_hosts: bool = True, model_ids: List[str] = None\n) -&gt; None:\n    \"\"\"Print formatted submission commands to restart failed models.\n\n    Args:\n        exclude_failed_hosts: Whether to exclude failed hosts.\n        model_ids: List of model IDs to rerun. If None, all failed models are\n            included.\n    \"\"\"\n    model_ids = model_ids or list(self.rerun_failed_runs.keys())\n    for model_id in model_ids:\n        command = \"\"\n        subcmds = self.rerun_failed_runs[model_id]\n        if exclude_failed_hosts:\n            command += f\"{subcmds[0]}{subcmds[1]}{subcmds[2]}\"\n        else:\n            command += f\"{subcmds[0]}{subcmds[2]}\"\n        print(command)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.get_hosts","title":"get_hosts","text":"<pre><code>get_hosts()\n</code></pre> <p>Get hosts on which the job was executed.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def get_hosts(self) -&gt; List[str]:\n    \"\"\"Get hosts on which the job was executed.\"\"\"\n    return list(set(flatten_list(self.hosts.values())))\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.bad_hosts","title":"bad_hosts","text":"<pre><code>bad_hosts()\n</code></pre> <p>Get hosts on which the job failed.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def bad_hosts(self) -&gt; List[str]:\n    \"\"\"Get hosts on which the job failed.\"\"\"\n    host_lists = [\n        host\n        for model_id, host in self.hosts.items()\n        if self.status[model_id] not in [\"Successfully completed.\", \"running\"]\n    ]\n    return list(set(flatten_list(host_lists)))\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.successful_runs","title":"successful_runs","text":"<pre><code>successful_runs()\n</code></pre> <p>Get number of successful runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def successful_runs(self) -&gt; int:\n    \"\"\"Get number of successful runs.\"\"\"\n    return sum(1 for v in self.status.values() if v == \"Successfully completed.\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.running_runs","title":"running_runs","text":"<pre><code>running_runs()\n</code></pre> <p>Get number of running runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def running_runs(self) -&gt; int:\n    \"\"\"Get number of running runs.\"\"\"\n    return sum(1 for v in self.status.values() if v == \"running\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.failed_runs","title":"failed_runs","text":"<pre><code>failed_runs()\n</code></pre> <p>Get number of failed runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def failed_runs(self) -&gt; int:\n    \"\"\"Get number of failed runs.\"\"\"\n    return sum(1 for v in self.status.values() if \"Exited with exit code\" in v)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.successful_model_ids","title":"successful_model_ids","text":"<pre><code>successful_model_ids()\n</code></pre> <p>Get model IDs of successful runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def successful_model_ids(self) -&gt; List[str]:\n    \"\"\"Get model IDs of successful runs.\"\"\"\n    return [k for k, v in self.status.items() if v == \"Successfully completed.\"]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.running_model_ids","title":"running_model_ids","text":"<pre><code>running_model_ids()\n</code></pre> <p>Get model IDs of running runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def running_model_ids(self) -&gt; List[str]:\n    \"\"\"Get model IDs of running runs.\"\"\"\n    return [k for k, v in self.status.items() if v == \"running\"]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.failed_model_ids","title":"failed_model_ids","text":"<pre><code>failed_model_ids()\n</code></pre> <p>Get model IDs of failed runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def failed_model_ids(self) -&gt; List[str]:\n    \"\"\"Get model IDs of failed runs.\"\"\"\n    return [k for k, v in self.status.items() if \"Exited with exit code\" in v]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.lookup_log","title":"lookup_log","text":"<pre><code>lookup_log(model_id, log_type='train_single', last_n_lines=20)\n</code></pre> <p>Lookup log for a model ID.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>log_type</code> <code>str</code> <p>Type of log to lookup.</p> <code>'train_single'</code> <code>last_n_lines</code> <code>int</code> <p>Number of lines to return from the end of the log.</p> <code>20</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of log lines.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def lookup_log(\n    self, model_id: str, log_type: str = \"train_single\", last_n_lines: int = 20\n) -&gt; List[str]:\n    \"\"\"Lookup log for a model ID.\n\n    Args:\n        model_id: ID of the model.\n        log_type: Type of log to lookup.\n        last_n_lines: Number of lines to return from the end of the log.\n\n    Returns:\n        List of log lines.\n    \"\"\"\n    log_file = [\n        p\n        for p in self.log_files\n        if log_type in str(p) and p.name.split(\"_\")[0] == model_id\n    ][0]\n    return log_file.read_text().split(\"\\n\")[-last_n_lines:]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.extract_error_trace","title":"extract_error_trace","text":"<pre><code>extract_error_trace(model_id, check_last_n_lines=100, log_type='train_single')\n</code></pre> <p>Extract the Python error message and traceback from a given log string.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>check_last_n_lines</code> <code>int</code> <p>Number of lines to check from the end of the log.</p> <code>100</code> <code>log_type</code> <code>str</code> <p>Type of log to extract error from.</p> <code>'train_single'</code> <p>Returns:</p> Type Description <code>str</code> <p>Extracted error message and traceback, or a message if no error is found.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def extract_error_trace(\n    self, model_id: str, check_last_n_lines: int = 100, log_type: str = \"train_single\"\n) -&gt; str:\n    \"\"\"Extract the Python error message and traceback from a given log string.\n\n    Args:\n        model_id: ID of the model.\n        check_last_n_lines: Number of lines to check from the end of the log.\n        log_type: Type of log to extract error from.\n\n    Returns:\n        Extracted error message and traceback, or a message if no error is found.\n    \"\"\"\n    log_string = \"\\n\".join(\n        self.lookup_log(model_id, last_n_lines=check_last_n_lines, log_type=log_type)\n    )\n    pattern = r\"Traceback \\(most recent call last\\):(.+?)(?=\\n\\n|\\Z)\"\n    match = re.search(pattern, log_string, re.DOTALL)\n    return match.group(0).strip() if match else \"No Python error found in the log.\"\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.extract_error_type","title":"extract_error_type","text":"<pre><code>extract_error_type(model_id, log_type='train_single', check_last_n_lines=100)\n</code></pre> <p>Extract the type of error from a given log string.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>ID of the model.</p> required <code>log_type</code> <code>str</code> <p>Type of log to extract error from.</p> <code>'train_single'</code> <code>check_last_n_lines</code> <code>int</code> <p>Number of lines to check from the end of the log.</p> <code>100</code> <p>Returns:</p> Type Description <code>str</code> <p>Extracted error type, or a message if no specific error type is found.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def extract_error_type(\n    self, model_id: str, log_type: str = \"train_single\", check_last_n_lines: int = 100\n) -&gt; str:\n    \"\"\"Extract the type of error from a given log string.\n\n    Args:\n        model_id: ID of the model.\n        log_type: Type of log to extract error from.\n        check_last_n_lines: Number of lines to check from the end of the log.\n\n    Returns:\n        Extracted error type, or a message if no specific error type is found.\n    \"\"\"\n    log_string = \"\\n\".join(\n        self.lookup_log(model_id, last_n_lines=check_last_n_lines, log_type=log_type)\n    )\n    pattern = r\"\\b[A-Z]\\w*Error\\b\"\n    match = re.search(pattern, log_string)\n    return match.group(0) if match else \"No specific error type found.\"\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.all_errors","title":"all_errors","text":"<pre><code>all_errors(check_last_n_lines=100, log_type='train_single')\n</code></pre> <p>Get all unique errors from failed runs.</p> <p>Parameters:</p> Name Type Description Default <code>check_last_n_lines</code> <code>int</code> <p>Number of lines to check from the end of the log.</p> <code>100</code> <code>log_type</code> <code>str</code> <p>Type of log to extract errors from.</p> <code>'train_single'</code> <p>Returns:</p> Type Description <code>set</code> <p>Set of unique error messages.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def all_errors(\n    self, check_last_n_lines: int = 100, log_type: str = \"train_single\"\n) -&gt; set:\n    \"\"\"Get all unique errors from failed runs.\n\n    Args:\n        check_last_n_lines: Number of lines to check from the end of the log.\n        log_type: Type of log to extract errors from.\n\n    Returns:\n        Set of unique error messages.\n    \"\"\"\n    return set(\n        self.extract_error_trace(\n            model_id,\n            check_last_n_lines=check_last_n_lines,\n            log_type=log_type,\n        )\n        for model_id in self.failed_model_ids()\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.all_error_types","title":"all_error_types","text":"<pre><code>all_error_types(log_type='train_single')\n</code></pre> <p>Get all unique error types from failed runs.</p> <p>Parameters:</p> Name Type Description Default <code>log_type</code> <code>str</code> <p>Type of log to extract error types from.</p> <code>'train_single'</code> <p>Returns:</p> Type Description <code>set</code> <p>Set of unique error types.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def all_error_types(self, log_type: str = \"train_single\") -&gt; set:\n    \"\"\"Get all unique error types from failed runs.\n\n    Args:\n        log_type: Type of log to extract error types from.\n\n    Returns:\n        Set of unique error types.\n    \"\"\"\n    return set(\n        self.extract_error_type(model_id, log_type=log_type)\n        for model_id in self.failed_model_ids()\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.print_all_errors","title":"print_all_errors","text":"<pre><code>print_all_errors(check_last_n_lines=100, log_type='train_single')\n</code></pre> <p>Print all errors and tracebacks from failed runs.</p> <p>Parameters:</p> Name Type Description Default <code>check_last_n_lines</code> <code>int</code> <p>Number of lines to check from the end of the log.</p> <code>100</code> <code>log_type</code> <code>str</code> <p>Type of log to extract errors from.</p> <code>'train_single'</code> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def print_all_errors(\n    self, check_last_n_lines: int = 100, log_type: str = \"train_single\"\n) -&gt; None:\n    \"\"\"Print all errors and tracebacks from failed runs.\n\n    Args:\n        check_last_n_lines: Number of lines to check from the end of the log.\n        log_type: Type of log to extract errors from.\n    \"\"\"\n    for model_id in self.failed_model_ids():\n        print(\n            f\"Model {model_id} failed with the following error message \"\n            \"and traceback:\\n\"\n        )\n        print(\n            self.extract_error_trace(\n                model_id,\n                check_last_n_lines=check_last_n_lines,\n                log_type=log_type,\n            )\n        )\n        print(\"\\n\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Get status for a specific model ID.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def __getitem__(self, key: str) -&gt; str:\n    \"\"\"Get status for a specific model ID.\"\"\"\n    if key in self.status:\n        return self.status[key]\n    return object.__getitem__(self, key)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.Status.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Return a string representation of the Status object.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the Status object.\"\"\"\n    _repr = f\"Status of ensemble {self.ensemble_name}.\"\n    _repr += f\"\\n{len(self.status)} models.\"\n    _repr += f\"\\nHosts: {','.join(self.get_hosts())}.\"\n    _repr += f\"\\n  {self.successful_runs()} successful runs.\"\n    _repr += f\"\\n  {self.running_runs()} running runs.\"\n    _repr += f\"\\n  {self.failed_runs()} failed runs.\"\n    if self.failed_runs() &gt; 0:\n        _repr += f\"\\n  Bad hosts: {','.join(self.bad_hosts())}.\"\n        _repr += \"\\n  Use .print_for_rerun() to print formatted submission commands\"\n        _repr += \" to restart failed models.\"\n        _repr += \"\\nError types:\"\n        for error in self.all_error_types():\n            _repr += f\"\\n  {error}\"\n        _repr += (\n            \"\\n  Run .print_all_errors() to print the error messages and tracebacks.\"\n        )\n    return _repr\n</code></pre>"},{"location":"reference/utils/#functions_9","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.log_utils.find_host","title":"flyvis.utils.log_utils.find_host","text":"<pre><code>find_host(log_string)\n</code></pre> <p>Find the host(s) on which the job was executed.</p> <p>Parameters:</p> Name Type Description Default <code>log_string</code> <code>str</code> <p>The log string to search for host information.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of host names.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def find_host(log_string: str) -&gt; List[str]:\n    \"\"\"Find the host(s) on which the job was executed.\n\n    Args:\n        log_string: The log string to search for host information.\n\n    Returns:\n        List of host names.\n    \"\"\"\n    pattern = r\"executed on host\\(s\\) &lt;(?:\\d*\\*)?(.+?)&gt;,\"\n    return re.findall(pattern, log_string)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.get_exclude_host_part","title":"flyvis.utils.log_utils.get_exclude_host_part","text":"<pre><code>get_exclude_host_part(log_string, exclude_hosts)\n</code></pre> <p>Get the part of the LSF command that excludes hosts.</p> <p>Parameters:</p> Name Type Description Default <code>log_string</code> <code>str</code> <p>The log string to search for host information.</p> required <code>exclude_hosts</code> <code>Union[str, List[str]]</code> <p>Host(s) to exclude. Can be \u2018auto\u2019, a single host name, or a list of host names.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The LSF command part for excluding hosts.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def get_exclude_host_part(log_string: str, exclude_hosts: Union[str, List[str]]) -&gt; str:\n    \"\"\"Get the part of the LSF command that excludes hosts.\n\n    Args:\n        log_string: The log string to search for host information.\n        exclude_hosts: Host(s) to exclude. Can be 'auto', a single host name, or a list\n            of host names.\n\n    Returns:\n        The LSF command part for excluding hosts.\n    \"\"\"\n    if exclude_hosts is None:\n        return \"\"\n\n    exclude_host_part = '-R \"select[{}]\" '\n\n    if isinstance(exclude_hosts, str) and exclude_hosts == \"auto\":\n        exclude_hosts = find_host(log_string)\n    elif isinstance(exclude_hosts, str):\n        exclude_hosts = [exclude_hosts]\n\n    exclusion_strings = [f\"hname!='{host}'\" for host in exclude_hosts]\n    return exclude_host_part.format(\" &amp;&amp; \".join(exclusion_strings))\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.get_status","title":"flyvis.utils.log_utils.get_status","text":"<pre><code>get_status(ensemble_name, nP=4, gpu='num=1', queue='gpu_l4', exclude_hosts='auto')\n</code></pre> <p>Get Status object for the ensemble of models with formatting for rerun.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble_name</code> <code>str</code> <p>Ensemble name (e.g. \u201cflow/\u201c). required <code>nP</code> <code>int</code> <p>Number of processors.</p> <code>4</code> <code>gpu</code> <code>str</code> <p>Number of GPUs.</p> <code>'num=1'</code> <code>queue</code> <code>str</code> <p>Queue name.</p> <code>'gpu_l4'</code> <code>exclude_hosts</code> <code>Union[str, List[str]]</code> <p>Host(s) to exclude. Can be \u2018auto\u2019, a single host name, or a list of host names.</p> <code>'auto'</code> <p>Returns:</p> Type Description <code>Status</code> <p>Status object containing information about the ensemble runs.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def get_status(\n    ensemble_name: str,\n    nP: int = 4,\n    gpu: str = \"num=1\",\n    queue: str = \"gpu_l4\",\n    exclude_hosts: Union[str, List[str]] = \"auto\",\n) -&gt; Status:\n    \"\"\"Get Status object for the ensemble of models with formatting for rerun.\n\n    Args:\n        ensemble_name: Ensemble name (e.g. \"flow/&lt;id&gt;\").\n        nP: Number of processors.\n        gpu: Number of GPUs.\n        queue: Queue name.\n        exclude_hosts: Host(s) to exclude. Can be 'auto', a single host name, or a\n            list of host names.\n\n    Returns:\n        Status object containing information about the ensemble runs.\n    \"\"\"\n    _lsf_part = \"bsub -J {} -n {} -o {} -gpu '{}' -q {} \"\n\n    tnn_paths, path = model_paths_from_parent(flyvis.results_dir / ensemble_name)\n    log_files = [p for p in path.iterdir() if p.suffix == \".log\"]\n    train_logs = [p for p in log_files if \"train_single\" in str(p)]\n    model_id_to_train_log_file = {p.name.split(\"_\")[0]: p for p in train_logs}\n\n    status = {}\n    user_input = {}\n    hosts = {}\n    log_strings = {}\n    for p in train_logs:\n        model_id = p.name.split(\"_\")[0]\n        log_str = p.read_text()\n        log_strings[model_id] = log_str\n        if log_str.split(\"\\n\")[-3] == \"The output (if any) is above this job summary.\":\n            status[model_id] = log_str.split(\"\\n\")[-18]\n            user_input[model_id] = log_str.split(\"\\n\")[-21]\n        else:\n            status[model_id] = \"running\"\n            user_input[model_id] = \"\"\n\n        hosts[model_id] = find_host(log_str)\n\n    _lfs_cmd = _lsf_part\n    rerun_failed_runs = {}\n    for model_id, stat in status.items():\n        if stat not in [\"Successfully completed.\", \"running\"]:\n            _lsf_cmd = _lsf_part.format(\n                f\"{ensemble_name}/{model_id}\",\n                nP,\n                model_id_to_train_log_file[model_id],\n                gpu,\n                queue,\n            )\n            exclude_host_part = get_exclude_host_part(\n                log_strings[model_id], exclude_hosts\n            )\n            rerun_failed_runs[model_id] = [\n                _lsf_cmd,\n                exclude_host_part,\n                user_input[model_id],\n            ]\n    return Status(\n        ensemble_name,\n        log_files,\n        train_logs,\n        model_id_to_train_log_file,\n        status,\n        user_input,\n        hosts,\n        rerun_failed_runs,\n        _lfs_cmd,\n    )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.log_utils.flatten_list","title":"flyvis.utils.log_utils.flatten_list","text":"<pre><code>flatten_list(nested_list)\n</code></pre> <p>Flatten a nested list of lists into a single list with all elements.</p> <p>Parameters:</p> Name Type Description Default <code>nested_list</code> <code>List</code> <p>A nested list of lists to be flattened.</p> required <p>Returns:</p> Type Description <code>List</code> <p>A single flattened list with all elements.</p> Source code in <code>flyvis/utils/log_utils.py</code> <pre><code>def flatten_list(nested_list: List) -&gt; List:\n    \"\"\"Flatten a nested list of lists into a single list with all elements.\n\n    Args:\n        nested_list: A nested list of lists to be flattened.\n\n    Returns:\n        A single flattened list with all elements.\n    \"\"\"\n    flattened = []\n    for item in nested_list:\n        if isinstance(item, list):\n            flattened.extend(flatten_list(item))\n        else:\n            flattened.append(item)\n    return flattened\n</code></pre>"},{"location":"reference/utils/#flyvisutilslogging_utils","title":"flyvis.utils.logging_utils","text":""},{"location":"reference/utils/#functions_10","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.logging_utils.warn_once","title":"flyvis.utils.logging_utils.warn_once  <code>cached</code>","text":"<pre><code>warn_once(logger, msg)\n</code></pre> <p>Log a warning message only once for a given logger and message combination.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>The logger object to use for logging.</p> required <code>msg</code> <code>str</code> <p>The warning message to log.</p> required Note <p>This function uses an LRU cache to ensure each unique combination of logger and message is only logged once.</p> Source code in <code>flyvis/utils/logging_utils.py</code> <pre><code>@lru_cache(100)\ndef warn_once(logger: logging.Logger, msg: str) -&gt; None:\n    \"\"\"\n    Log a warning message only once for a given logger and message combination.\n\n    Args:\n        logger: The logger object to use for logging.\n        msg: The warning message to log.\n\n    Note:\n        This function uses an LRU cache to ensure each unique combination of\n        logger and message is only logged once.\n    \"\"\"\n    logger.warning(msg)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.logging_utils.save_conda_environment","title":"flyvis.utils.logging_utils.save_conda_environment","text":"<pre><code>save_conda_environment(path)\n</code></pre> <p>Save the current Conda environment to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path where the JSON file will be saved.</p> required Note <p>The function appends \u2018.json\u2019 to the provided path.</p> Source code in <code>flyvis/utils/logging_utils.py</code> <pre><code>def save_conda_environment(path: Path) -&gt; None:\n    \"\"\"\n    Save the current Conda environment to a JSON file.\n\n    Args:\n        path: The path where the JSON file will be saved.\n\n    Note:\n        The function appends '.json' to the provided path.\n    \"\"\"\n    result = subprocess.run(\n        [\"conda\", \"list\", \"--json\"], stdout=subprocess.PIPE, text=True, check=False\n    )\n\n    installed_packages = json.loads(result.stdout)\n\n    with open(path.with_suffix(\".json\"), \"w\") as json_file:\n        json.dump(installed_packages, json_file, indent=4)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.logging_utils.all_logging_disabled","title":"flyvis.utils.logging_utils.all_logging_disabled","text":"<pre><code>all_logging_disabled(highest_level=logging.CRITICAL)\n</code></pre> <p>A context manager that prevents any logging messages from being processed.</p> <p>Parameters:</p> Name Type Description Default <code>highest_level</code> <code>int</code> <p>The maximum logging level to disable. Only needs to be changed if a custom level greater than CRITICAL is defined.</p> <code>CRITICAL</code> Example <pre><code>with all_logging_disabled():\n    # Code here will not produce any log output\n    logging.warning(\"This warning will not be logged\")\n</code></pre> Reference <p>https://gist.github.com/simon-weber/7853144</p> Source code in <code>flyvis/utils/logging_utils.py</code> <pre><code>@contextmanager\ndef all_logging_disabled(highest_level: int = logging.CRITICAL) -&gt; Any:\n    \"\"\"\n    A context manager that prevents any logging messages from being processed.\n\n    Args:\n        highest_level: The maximum logging level to disable. Only needs to be\n            changed if a custom level greater than CRITICAL is defined.\n\n    Example:\n        ```python\n        with all_logging_disabled():\n            # Code here will not produce any log output\n            logging.warning(\"This warning will not be logged\")\n        ```\n\n    Reference:\n        https://gist.github.com/simon-weber/7853144\n    \"\"\"\n    previous_level = logging.root.manager.disable\n\n    logging.disable(highest_level)\n\n    try:\n        yield\n    finally:\n        logging.disable(previous_level)\n</code></pre>"},{"location":"reference/utils/#flyvisutilsnn_utils","title":"flyvis.utils.nn_utils","text":""},{"location":"reference/utils/#classes_8","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.nn_utils.NumberOfParams","title":"flyvis.utils.nn_utils.NumberOfParams  <code>dataclass</code>","text":"<p>Dataclass to store the number of free and fixed parameters.</p> <p>Attributes:</p> Name Type Description <code>free</code> <code>int</code> <p>The number of trainable parameters.</p> <code>fixed</code> <code>int</code> <p>The number of non-trainable parameters.</p> Source code in <code>flyvis/utils/nn_utils.py</code> <pre><code>@dataclass\nclass NumberOfParams:\n    \"\"\"\n    Dataclass to store the number of free and fixed parameters.\n\n    Attributes:\n        free: The number of trainable parameters.\n        fixed: The number of non-trainable parameters.\n    \"\"\"\n\n    free: int\n    fixed: int\n</code></pre>"},{"location":"reference/utils/#functions_11","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.nn_utils.simulation","title":"flyvis.utils.nn_utils.simulation","text":"<pre><code>simulation(network)\n</code></pre> <p>Context manager to turn off training mode and require_grad for a network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>Module</code> <p>The neural network module to simulate.</p> required <p>Yields:</p> Type Description <code>None</code> <p>None</p> Example <pre><code>model = MyNeuralNetwork()\nwith simulation(model):\n    # Perform inference or evaluation\n    output = model(input_data)\n</code></pre> Note <p>This context manager temporarily disables gradient computation and sets the network to evaluation mode. It restores the original state after exiting the context.</p> Source code in <code>flyvis/utils/nn_utils.py</code> <pre><code>@contextmanager\ndef simulation(network: nn.Module) -&gt; Generator[None, None, None]:\n    \"\"\"\n    Context manager to turn off training mode and require_grad for a network.\n\n    Args:\n        network: The neural network module to simulate.\n\n    Yields:\n        None\n\n    Example:\n        ```python\n        model = MyNeuralNetwork()\n        with simulation(model):\n            # Perform inference or evaluation\n            output = model(input_data)\n        ```\n\n    Note:\n        This context manager temporarily disables gradient computation and sets\n        the network to evaluation mode. It restores the original state after\n        exiting the context.\n    \"\"\"\n    _training = network.training\n    network.training = False\n    params_require_grad = {}\n    for name, p in network.named_parameters():\n        params_require_grad[name] = p.requires_grad\n        p.requires_grad = False\n    try:\n        yield\n    finally:\n        network.training = _training\n        for name, p in network.named_parameters():\n            p.requires_grad = params_require_grad[name]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.nn_utils.n_params","title":"flyvis.utils.nn_utils.n_params","text":"<pre><code>n_params(nnmodule)\n</code></pre> <p>Returns the numbers of free and fixed parameters in a PyTorch module.</p> <p>Parameters:</p> Name Type Description Default <code>nnmodule</code> <code>Module</code> <p>The PyTorch module to analyze.</p> required <p>Returns:</p> Type Description <code>NumberOfParams</code> <p>A NumberOfParams object containing the count of free and fixed parameters.</p> Example <pre><code>model = MyNeuralNetwork()\nparam_count = n_params(model)\nprint(f\"Free parameters: {param_count.free}\")\nprint(f\"Fixed parameters: {param_count.fixed}\")\n</code></pre> Source code in <code>flyvis/utils/nn_utils.py</code> <pre><code>def n_params(nnmodule: nn.Module) -&gt; NumberOfParams:\n    \"\"\"\n    Returns the numbers of free and fixed parameters in a PyTorch module.\n\n    Args:\n        nnmodule: The PyTorch module to analyze.\n\n    Returns:\n        A NumberOfParams object containing the count of free and fixed parameters.\n\n    Example:\n        ```python\n        model = MyNeuralNetwork()\n        param_count = n_params(model)\n        print(f\"Free parameters: {param_count.free}\")\n        print(f\"Fixed parameters: {param_count.fixed}\")\n        ```\n    \"\"\"\n    n_free = 0\n    n_fixed = 0\n    for param in nnmodule.parameters():\n        if param.requires_grad:\n            n_free += param.nelement()\n        else:\n            n_fixed += param.nelement()\n    return NumberOfParams(n_free, n_fixed)\n</code></pre>"},{"location":"reference/utils/#flyvisutilsnodes_edges_utils","title":"flyvis.utils.nodes_edges_utils","text":""},{"location":"reference/utils/#classes_9","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.nodes_edges_utils.NodeIndexer","title":"flyvis.utils.nodes_edges_utils.NodeIndexer","text":"<p>               Bases: <code>dict</code></p> <p>Attribute-style accessible map from cell types to indices.</p> <p>Parameters:</p> Name Type Description Default <code>connectome</code> <code>Optional[ConnectomeFromAvgFilters]</code> <p>Connectome object. The cell types are taken from the connectome and references are created in order.</p> <code>None</code> <code>unique_cell_types</code> <code>Optional[NDArray[str]]</code> <p>Array of unique cell types. Optional. To specify the mapping from cell types to indices in provided order.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>unique_cell_types</code> <code>NDArray[str]</code> <p>Array of unique cell types.</p> <code>central_cells_index</code> <code>Optional[NDArray[int]]</code> <p>Array of indices of central cells.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither connectome nor unique_cell_types is provided.</p> Source code in <code>flyvis/utils/nodes_edges_utils.py</code> <pre><code>class NodeIndexer(dict):\n    \"\"\"Attribute-style accessible map from cell types to indices.\n\n    Args:\n        connectome: Connectome object. The cell types are taken from the\n            connectome and references are created in order.\n        unique_cell_types: Array of unique cell types. Optional.\n            To specify the mapping from cell types to indices in provided order.\n\n    Attributes:\n        unique_cell_types (NDArray[str]): Array of unique cell types.\n        central_cells_index (Optional[NDArray[int]]): Array of indices of central cells.\n\n    Raises:\n        ValueError: If neither connectome nor unique_cell_types is provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome: Optional[\"connectome.ConnectomeFromAvgFilters\"] = None,\n        unique_cell_types: Optional[NDArray[str]] = None,\n    ):\n        # if connectome is specified, the indices are taken from the connectome\n        # and reference to positions in the entire list of nodes/cells\n        if connectome is not None and unique_cell_types is None:\n            self.unique_cell_types = connectome.unique_cell_types[:].astype(\"str\")\n            self.central_cells_index = connectome.central_cells_index[:]\n        # alternatively the mapping can be specified from a list of cell types\n        # and reference to positions in order of the list\n        elif connectome is None and unique_cell_types is not None:\n            self.unique_cell_types = unique_cell_types\n            self.central_cells_index = None\n        else:\n            raise ValueError(\"either cell types or connectome must be specified\")\n        for index, cell_type in enumerate(self.unique_cell_types):\n            super().__setitem__(cell_type, index)\n\n    def __dir__(self):\n        return list(set([*dict.__dir__(self), *dict.__iter__(self)]))\n\n    def __len__(self):\n        return len(self.unique_cell_types)\n\n    def __iter__(self):\n        for cell_type in self.unique_cell_types:\n            yield cell_type\n\n    def __getattr__(self, key):\n        if isinstance(key, str):\n            pass\n        elif isinstance(key, Iterable):\n            return [dict.__getitem__(self, _key) for _key in key]\n        return dict.__getitem__(self, key)\n\n    def __getitem__(self, key):\n        return self.__getattr__(key)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.nodes_edges_utils.CellTypeArray","title":"flyvis.utils.nodes_edges_utils.CellTypeArray","text":"<p>Attribute-style accessible map from cell types to coordinates in array.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>Union[NDArray, Tensor]</code> <p>Has the dim-th axis corresponding to unique cell types in the connectome or provided cell types.</p> required <code>connectome</code> <code>Optional[ConnectomeFromAvgFilters]</code> <p>Connectome object.</p> <code>None</code> <code>cell_types</code> <code>Optional[NDArray[str]]</code> <p>Array of cell types.</p> <code>None</code> <code>dim</code> <code>int</code> <p>Axis corresponding to unique cell types.</p> <code>-1</code> <p>Attributes:</p> Name Type Description <code>node_indexer</code> <code>NodeIndexer</code> <p>Indexer for cell types.</p> <code>array</code> <code>NDArray</code> <p>The array of cell type data.</p> <code>dim</code> <code>int</code> <p>Dimension corresponding to cell types.</p> <code>cell_types</code> <code>NDArray[str]</code> <p>Array of unique cell types.</p> Source code in <code>flyvis/utils/nodes_edges_utils.py</code> <pre><code>class CellTypeArray:\n    \"\"\"Attribute-style accessible map from cell types to coordinates in array.\n\n    Args:\n        array: Has the dim-th axis corresponding to unique cell types\n            in the connectome or provided cell types.\n        connectome: Connectome object.\n        cell_types: Array of cell types.\n        dim: Axis corresponding to unique cell types.\n\n    Attributes:\n        node_indexer (NodeIndexer): Indexer for cell types.\n        array (NDArray): The array of cell type data.\n        dim (int): Dimension corresponding to cell types.\n        cell_types (NDArray[str]): Array of unique cell types.\n    \"\"\"\n\n    node_indexer: NodeIndexer = None\n    array: NDArray = None\n    dim: float = None\n\n    def __init__(\n        self,\n        array: Union[NDArray, torch.Tensor],\n        connectome: Optional[\"connectome.ConnectomeFromAvgFilters\"] = None,\n        cell_types: Optional[NDArray[str]] = None,\n        dim: int = -1,\n    ):\n        self.array = array\n        self.dim = dim\n        self.node_indexer = NodeIndexer(connectome, cell_types)\n        self.cell_types = self.node_indexer.unique_cell_types\n\n    def __bool__(self):\n        return self.array is not None\n\n    def __iter__(self):\n        for cell_type in self.node_indexer.unique_cell_types:\n            yield cell_type\n\n    def __dir__(self):\n        return list(\n            set([\n                *object.__dir__(self),\n                *dict.__dir__(self.node_indexer),\n                *dict.__iter__(self.node_indexer),\n            ])\n        )\n\n    @property\n    def shape(self):\n        if self.array is not None:\n            return self.array.shape\n        return []\n\n    def __repr__(self):\n        shape = list(self.shape)\n        desc = f\"Array({tuple(shape)})\"\n        return {k: desc for k in self}.__repr__()\n\n    def values(self):\n        return [self[k] for k in self]\n\n    def keys(self):\n        return [k for k in self]\n\n    def items(self):\n        return [(k, self[k]) for k in self]\n\n    def __len__(self):\n        return len(self.node_indexer.unique_cell_types)\n\n    def __getattr__(self, key):\n        if self.node_indexer is not None:\n            if isinstance(key, slice) and key == slice(None):\n                return self.array\n            elif isinstance(key, str) and key in self.node_indexer.unique_cell_types:\n                indices = np.int_([dict.__getitem__(self.node_indexer, key)])\n            elif isinstance(key, Iterable) and all([\n                _key in self.node_indexer.unique_cell_types for _key in key\n            ]):\n                indices = np.int_([\n                    dict.__getitem__(self.node_indexer, _key) for _key in key\n                ])\n            elif key in self.node_indexer.__dir__():\n                return object.__getattribute__(self.node_indexer, key)\n            else:\n                return object.__getattribute__(self, key)\n            return np.take(self.array, indices, axis=self.dim)\n        return object.__getattribute__(self, key)\n\n    def __getitem__(self, key):\n        return self.__getattr__(key)\n\n    def __setitem__(self, key, value):\n        if self.node_indexer is not None and key in self.node_indexer.unique_cell_types:\n            if value.shape[-1] != 1:\n                value = np.expand_dims(value, self.dim)\n            if self.array is None:\n                n_cell_types = len(self.node_indexer.unique_cell_types)\n                shape = list(value.shape)\n                shape[self.dim] = n_cell_types\n                self.array = np.zeros(shape)\n            # breakpoint()\n            index = dict.__getitem__(self.node_indexer, key)\n            np.put_along_axis(\n                self.array,\n                np.expand_dims(np.array([index]), list(range(len(self.array.shape[1:])))),\n                value,\n                self.dim,\n            )\n        else:\n            object.__setattr__(self, key, value)\n\n    def __setattr__(self, key, value):\n        return self.__setitem__(key, value)\n\n    def from_cell_types(self, cell_types):\n        activity = self[cell_types]\n        return CellTypeArray(\n            activity,\n            cell_types=cell_types,\n            dim=self.dim,\n        )\n</code></pre>"},{"location":"reference/utils/#functions_12","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.nodes_edges_utils.order_node_type_list","title":"flyvis.utils.nodes_edges_utils.order_node_type_list","text":"<pre><code>order_node_type_list(node_types, groups=['R\\\\d', 'L\\\\d', 'Lawf\\\\d', 'A', 'C\\\\d', 'CT\\\\d.*', 'Mi\\\\d{1,2}', 'T\\\\d{1,2}.*', 'Tm.*\\\\d{1,2}.*'])\n</code></pre> <p>Orders a list of node types by the regular expressions defined in groups.</p> <p>Parameters:</p> Name Type Description Default <code>node_types</code> <code>List[str]</code> <p>Messy list of nodes.</p> required <code>groups</code> <code>List[str]</code> <p>Ordered list of regular expressions to sort node_types.</p> <code>['R\\\\d', 'L\\\\d', 'Lawf\\\\d', 'A', 'C\\\\d', 'CT\\\\d.*', 'Mi\\\\d{1,2}', 'T\\\\d{1,2}.*', 'Tm.*\\\\d{1,2}.*']</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A tuple containing:</p> <code>List[int]</code> <ul> <li>Ordered node type list</li> </ul> <code>Tuple[List[str], List[int]]</code> <ul> <li>Corresponding sorting indices</li> </ul> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If sorting doesn\u2019t include all cell types.</p> <code>ValueError</code> <p>If sorting fails due to length mismatch.</p> Source code in <code>flyvis/utils/nodes_edges_utils.py</code> <pre><code>def order_node_type_list(\n    node_types: List[str],\n    groups: List[str] = [\n        r\"R\\d\",\n        r\"L\\d\",\n        r\"Lawf\\d\",\n        r\"A\",\n        r\"C\\d\",\n        r\"CT\\d.*\",\n        r\"Mi\\d{1,2}\",\n        r\"T\\d{1,2}.*\",\n        r\"Tm.*\\d{1,2}.*\",\n    ],\n) -&gt; Tuple[List[str], List[int]]:\n    \"\"\"Orders a list of node types by the regular expressions defined in groups.\n\n    Args:\n        node_types: Messy list of nodes.\n        groups: Ordered list of regular expressions to sort node_types.\n\n    Returns:\n        A tuple containing:\n        - Ordered node type list\n        - Corresponding sorting indices\n\n    Raises:\n        AssertionError: If sorting doesn't include all cell types.\n        ValueError: If sorting fails due to length mismatch.\n    \"\"\"\n    if node_types is None:\n        return None, None\n\n    _len = len(node_types)\n\n    def sort_numeric(string):\n        \"\"\"Used in sorted(list, key=sort_fn) for sorting\n        lists including 0 to 4 digits after the character.\n        \"\"\"\n        regular_expression = r\"\\d+\"\n        match = re.search(regular_expression, string)\n        if not match:\n            # For example Am types are not numbered.\n            return string\n        return re.sub(regular_expression, f\"{int(match.group()):04}\", string)\n\n    #     breakpoint()\n    type_groups = {index: [] for index in range(len(groups))}\n    type_groups.update({len(groups) + 1: []})  # for unmatched types.\n    matched = {cell_type: False for cell_type in node_types}\n    for node_index, cell_type in enumerate(node_types):\n        for group_index, regular_expression in enumerate(groups):\n            if re.match(regular_expression, cell_type):\n                type_groups[group_index].append((node_index, cell_type))\n                matched[cell_type] = True\n        if matched[cell_type]:\n            pass\n        else:\n            type_groups[len(groups) + 1].append((node_index, cell_type))\n\n    # ordered = [y for x in type_groups.values() for y in sorted(x, key=lambda z:\n    # sort_fn(z[1]))]\n    ordered = []\n    for x in type_groups.values():\n        for y in sorted(x, key=lambda z: sort_numeric(z[1])):\n            ordered.append(y)\n    index = [y[0] for y in ordered]\n    nodes = [y[1] for y in ordered]\n\n    if set(node_types) - set(nodes):\n        print(set(node_types) - set(nodes))\n        raise AssertionError(\n            \"Defined sorting through regular expressions does not include all cell\"\n            \" types.\"\n        )\n\n    if _len != len(nodes) or _len != len(index):\n        raise ValueError(\n            \"sorting failed because the resulting array if of \" \" different length\"\n        )\n\n    return nodes, index\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.nodes_edges_utils.get_index_mapping_lists","title":"flyvis.utils.nodes_edges_utils.get_index_mapping_lists","text":"<pre><code>get_index_mapping_lists(from_list, to_list)\n</code></pre> <p>Get indices to sort and filter from_list by occurrence of items in to_list.</p> <p>The indices are useful to sort or filter another list or tensor that is an ordered mapping to items in from_list to the order of items in to_list.</p> <p>Parameters:</p> Name Type Description Default <code>from_list</code> <code>List[str]</code> <p>Original list of items.</p> required <code>to_list</code> <code>List[str]</code> <p>Target list of items.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List of indices for sorting.</p> Example <pre><code>from_list = [\"a\", \"b\", \"c\"]\nmapping_to_from_list = [1, 2, 3]\nto_list = [\"c\", \"a\", \"b\"]\nsort_index = get_index_mapping_lists(from_list, to_list)\nsorted_list = [mapping_to_from_list[i] for i in sort_index]\n# sorted_list will be [3, 1, 2]\n</code></pre> Source code in <code>flyvis/utils/nodes_edges_utils.py</code> <pre><code>def get_index_mapping_lists(from_list: List[str], to_list: List[str]) -&gt; List[int]:\n    \"\"\"Get indices to sort and filter from_list by occurrence of items in to_list.\n\n    The indices are useful to sort or filter another list or tensor that\n    is an ordered mapping to items in from_list to the order of items in to_list.\n\n    Args:\n        from_list: Original list of items.\n        to_list: Target list of items.\n\n    Returns:\n        List of indices for sorting.\n\n    Example:\n        ```python\n        from_list = [\"a\", \"b\", \"c\"]\n        mapping_to_from_list = [1, 2, 3]\n        to_list = [\"c\", \"a\", \"b\"]\n        sort_index = get_index_mapping_lists(from_list, to_list)\n        sorted_list = [mapping_to_from_list[i] for i in sort_index]\n        # sorted_list will be [3, 1, 2]\n        ```\n    \"\"\"\n    if isinstance(from_list, np.ndarray):\n        from_list = from_list.tolist()\n    if isinstance(to_list, np.ndarray):\n        to_list = to_list.tolist()\n    return [from_list.index(item) for item in to_list]\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.nodes_edges_utils.sort_by_mapping_lists","title":"flyvis.utils.nodes_edges_utils.sort_by_mapping_lists","text":"<pre><code>sort_by_mapping_lists(from_list, to_list, tensor, axis=0)\n</code></pre> <p>Sort and filter a tensor along an axis indexed by from_list to match to_list.</p> <p>Parameters:</p> Name Type Description Default <code>from_list</code> <code>List[str]</code> <p>Original list of items.</p> required <code>to_list</code> <code>List[str]</code> <p>Target list of items.</p> required <code>tensor</code> <code>Union[ndarray, Tensor]</code> <p>Tensor to be sorted.</p> required <code>axis</code> <code>int</code> <p>Axis along which to sort the tensor.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Sorted numpy array.</p> Source code in <code>flyvis/utils/nodes_edges_utils.py</code> <pre><code>def sort_by_mapping_lists(\n    from_list: List[str],\n    to_list: List[str],\n    tensor: Union[np.ndarray, torch.Tensor],\n    axis: int = 0,\n) -&gt; np.ndarray:\n    \"\"\"Sort and filter a tensor along an axis indexed by from_list to match to_list.\n\n    Args:\n        from_list: Original list of items.\n        to_list: Target list of items.\n        tensor: Tensor to be sorted.\n        axis: Axis along which to sort the tensor.\n\n    Returns:\n        Sorted numpy array.\n    \"\"\"\n    tensor = np.array(tensor)\n    if axis != 0:\n        tensor = np.transpose(tensor, axes=(axis, 0))\n    sort_index = get_index_mapping_lists(from_list, to_list)\n    tensor = np.array([tensor[i] for i in sort_index])\n    if axis != 0:\n        tensor = np.transpose(tensor, axes=(axis, 0))\n    return tensor\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.nodes_edges_utils.nodes_list_sorting_on_off_unknown","title":"flyvis.utils.nodes_edges_utils.nodes_list_sorting_on_off_unknown","text":"<pre><code>nodes_list_sorting_on_off_unknown(cell_types=None)\n</code></pre> <p>Sort node list based on on/off/unknown polarity.</p> <p>Parameters:</p> Name Type Description Default <code>cell_types</code> <code>Optional[List[str]]</code> <p>List of cell types to sort. If None, uses all types from         groundtruth_utils.polarity.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>Sorted list of cell types.</p> Source code in <code>flyvis/utils/nodes_edges_utils.py</code> <pre><code>def nodes_list_sorting_on_off_unknown(\n    cell_types: Optional[List[str]] = None,\n) -&gt; List[str]:\n    \"\"\"Sort node list based on on/off/unknown polarity.\n\n    Args:\n        cell_types: List of cell types to sort. If None, uses all types from\n                    groundtruth_utils.polarity.\n\n    Returns:\n        Sorted list of cell types.\n    \"\"\"\n    value = {1: 1, -1: 2, 0: 3}\n    preferred_contrasts = groundtruth_utils.polarity\n    cell_types = list(preferred_contrasts) if cell_types is None else cell_types\n    preferred_contrasts = {\n        k: value[v] for k, v in preferred_contrasts.items() if k in cell_types\n    }\n    preferred_contrasts = dict(sorted(preferred_contrasts.items(), key=lambda k: k[1]))\n    nodes_list = list(preferred_contrasts.keys())\n    return nodes_list\n</code></pre>"},{"location":"reference/utils/#flyvisutilstensor_utils","title":"flyvis.utils.tensor_utils","text":""},{"location":"reference/utils/#classes_10","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.tensor_utils.RefTensor","title":"flyvis.utils.tensor_utils.RefTensor","text":"<p>A tensor with reference indices along the last dimension.</p> <p>Attributes:</p> Name Type Description <code>values</code> <code>Tensor</code> <p>The tensor values.</p> <code>indices</code> <code>Tensor</code> <p>The reference indices.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>class RefTensor:\n    \"\"\"A tensor with reference indices along the last dimension.\n\n    Attributes:\n        values (torch.Tensor): The tensor values.\n        indices (torch.Tensor): The reference indices.\n    \"\"\"\n\n    def __init__(self, values: torch.Tensor, indices: torch.Tensor) -&gt; None:\n        self.values = values\n        self.indices = indices\n\n    def deref(self) -&gt; torch.Tensor:\n        \"\"\"Index the values with the given indices in the last dimension.\"\"\"\n        return self.values.index_select(-1, self.indices)\n\n    def __len__(self) -&gt; int:\n        return len(self.values)\n\n    def __repr__(self) -&gt; str:\n        return f\"RefTensor(values={self.values.data}, indices={self.indices})\"\n\n    def clone(self) -&gt; \"RefTensor\":\n        \"\"\"Return a copy of the RefTensor cloning values.\"\"\"\n        return RefTensor(self.values.clone(), self.indices)\n\n    def detach(self) -&gt; \"RefTensor\":\n        \"\"\"Return a copy of the RefTensor detaching values.\"\"\"\n        return RefTensor(self.values.detach(), self.indices)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.RefTensor.deref","title":"deref","text":"<pre><code>deref()\n</code></pre> <p>Index the values with the given indices in the last dimension.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def deref(self) -&gt; torch.Tensor:\n    \"\"\"Index the values with the given indices in the last dimension.\"\"\"\n    return self.values.index_select(-1, self.indices)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.RefTensor.clone","title":"clone","text":"<pre><code>clone()\n</code></pre> <p>Return a copy of the RefTensor cloning values.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def clone(self) -&gt; \"RefTensor\":\n    \"\"\"Return a copy of the RefTensor cloning values.\"\"\"\n    return RefTensor(self.values.clone(), self.indices)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.RefTensor.detach","title":"detach","text":"<pre><code>detach()\n</code></pre> <p>Return a copy of the RefTensor detaching values.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def detach(self) -&gt; \"RefTensor\":\n    \"\"\"Return a copy of the RefTensor detaching values.\"\"\"\n    return RefTensor(self.values.detach(), self.indices)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.AutoDeref","title":"flyvis.utils.tensor_utils.AutoDeref","text":"<p>               Bases: <code>dict</code></p> <p>An auto-dereferencing namespace.</p> <p>Dereferencing means that if attributes are RefTensors, getitem will call RefTensor.deref() to obtain the values at the given indices.</p> Note <p>Constructed at each forward call in Network. A cache speeds up processing, e.g., for when a parameter is referenced multiple times in the dynamics.</p> <p>Attributes:</p> Name Type Description <code>_cache</code> <code>Dict[str, object]</code> <p>Cache for dereferenced values.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>class AutoDeref(dict):\n    \"\"\"An auto-dereferencing namespace.\n\n    Dereferencing means that if attributes are RefTensors,\n    __getitem__ will call RefTensor.deref() to obtain the values at the\n    given indices.\n\n    Note:\n        Constructed at each forward call in Network. A cache speeds up\n        processing, e.g., for when a parameter is referenced multiple times in the\n        dynamics.\n\n    Attributes:\n        _cache (Dict[str, object]): Cache for dereferenced values.\n    \"\"\"\n\n    _cache: Dict[str, object]\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"_cache\", {})\n\n    def __setitem__(self, key: str, value: object) -&gt; None:\n        self._cache.pop(key, None)\n        super().__setitem__(key, value)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        try:\n            val = super().__getitem__(key)\n        except AttributeError as e:\n            raise e\n        if isinstance(val, RefTensor):\n            if key not in self._cache:\n                self._cache[key] = val.deref()\n            val = self._cache[key]\n        return val\n\n    def __setattr__(self, key: str, value: object) -&gt; None:\n        self.__setitem__(key, value)\n\n    def __getattr__(self, key: str) -&gt; Any:\n        return self.__getitem__(key)\n\n    def __repr__(self) -&gt; str:\n        def single_line_repr(elem: object) -&gt; str:\n            if isinstance(elem, list):\n                return \"[\" + \", \".join(map(single_line_repr, elem)) + \"]\"\n            elif isinstance(elem, AutoDeref):\n                return (\n                    f\"{elem.__class__.__name__}(\"\n                    + \", \".join(f\"{k}={single_line_repr(v)}\" for k, v in elem.items())\n                    + \")\"\n                )\n            else:\n                return repr(elem).replace(\"\\n\", \" \")\n\n        def repr_in_context(elem: object, curr_col: int, indent: int) -&gt; str:\n            sl_repr = single_line_repr(elem)\n            if len(sl_repr) &lt;= 80 - curr_col:\n                return sl_repr\n            elif isinstance(elem, list):\n                return (\n                    \"[\\n\"\n                    + \" \" * (indent + 2)\n                    + (\",\\n\" + \" \" * (indent + 2)).join(\n                        repr_in_context(e, indent + 2, indent + 2) for e in elem\n                    )\n                    + \"\\n\"\n                    + \" \" * indent\n                    + \"]\"\n                )\n            elif isinstance(elem, AutoDeref):\n                return (\n                    f\"{elem.__class__.__name__}(\\n\"\n                    + \" \" * (indent + 2)\n                    + (\",\\n\" + \" \" * (indent + 2)).join(\n                        f\"{k} = \" + repr_in_context(v, indent + 5 + len(k), indent + 2)\n                        for k, v in elem.items()\n                    )\n                    + \"\\n\"\n                    + \" \" * indent\n                    + \")\"\n                )\n            else:\n                return repr(elem)\n\n        return repr_in_context(self, 0, 0)\n\n    def get_as_reftensor(self, key: str) -&gt; RefTensor:\n        \"\"\"Get the original RefTensor without dereferencing.\"\"\"\n        return dict.__getitem__(self, key)\n\n    def clear_cache(self) -&gt; \"AutoDeref\":\n        \"\"\"Clear the cache and return a cloned instance.\"\"\"\n        object.__setattr__(self, \"_cache\", {})\n        return clone(self)\n\n    def detach(self) -&gt; \"AutoDeref\":\n        \"\"\"Return a detached copy of the AutoDeref instance.\"\"\"\n        return detach(self)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.AutoDeref.get_as_reftensor","title":"get_as_reftensor","text":"<pre><code>get_as_reftensor(key)\n</code></pre> <p>Get the original RefTensor without dereferencing.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def get_as_reftensor(self, key: str) -&gt; RefTensor:\n    \"\"\"Get the original RefTensor without dereferencing.\"\"\"\n    return dict.__getitem__(self, key)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.AutoDeref.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache()\n</code></pre> <p>Clear the cache and return a cloned instance.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def clear_cache(self) -&gt; \"AutoDeref\":\n    \"\"\"Clear the cache and return a cloned instance.\"\"\"\n    object.__setattr__(self, \"_cache\", {})\n    return clone(self)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.AutoDeref.detach","title":"detach","text":"<pre><code>detach()\n</code></pre> <p>Return a detached copy of the AutoDeref instance.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def detach(self) -&gt; \"AutoDeref\":\n    \"\"\"Return a detached copy of the AutoDeref instance.\"\"\"\n    return detach(self)\n</code></pre>"},{"location":"reference/utils/#functions_13","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.tensor_utils.detach","title":"flyvis.utils.tensor_utils.detach","text":"<pre><code>detach(obj)\n</code></pre> <p>Recursively detach AutoDeref mappings.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>AutoDeref</code> <p>The object to detach.</p> required <p>Returns:</p> Type Description <code>AutoDeref</code> <p>A detached copy of the input object.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object type is not supported.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def detach(obj: AutoDeref) -&gt; AutoDeref:\n    \"\"\"Recursively detach AutoDeref mappings.\n\n    Args:\n        obj: The object to detach.\n\n    Returns:\n        A detached copy of the input object.\n\n    Raises:\n        TypeError: If the object type is not supported.\n    \"\"\"\n    if isinstance(obj, (type(None), bool, int, float, str, type)):\n        return obj\n    elif isinstance(obj, (RefTensor, torch.Tensor)):\n        return obj.detach()\n    elif isinstance(obj, (list, tuple)):\n        return [detach(v) for v in obj]\n    elif isinstance(obj, Mapping):\n        return AutoDeref({k: detach(dict.__getitem__(obj, k)) for k in obj})\n    else:\n        try:\n            return detach(vars(obj))\n        except TypeError as e:\n            raise TypeError(f\"{obj} of type {type(obj)} as {e}.\") from None\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.clone","title":"flyvis.utils.tensor_utils.clone","text":"<pre><code>clone(obj)\n</code></pre> <p>Recursively clone AutoDeref mappings.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>AutoDeref</code> <p>The object to clone.</p> required <p>Returns:</p> Type Description <code>AutoDeref</code> <p>A cloned copy of the input object.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object type is not supported.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def clone(obj: AutoDeref) -&gt; AutoDeref:\n    \"\"\"Recursively clone AutoDeref mappings.\n\n    Args:\n        obj: The object to clone.\n\n    Returns:\n        A cloned copy of the input object.\n\n    Raises:\n        TypeError: If the object type is not supported.\n    \"\"\"\n    if isinstance(obj, (type(None), bool, int, float, str, type)):\n        return obj\n    elif isinstance(obj, (RefTensor, torch.Tensor)):\n        return obj.clone()\n    elif isinstance(obj, (list, tuple)):\n        return [clone(v) for v in obj]\n    elif isinstance(obj, Mapping):\n        return AutoDeref({k: clone(dict.__getitem__(obj, k)) for k in obj})\n    else:\n        try:\n            print(\"reached\")\n            return clone(vars(obj))\n        except TypeError as e:\n            raise TypeError(f\"{obj} of type {type(obj)} as {e}.\") from None\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.to_numpy","title":"flyvis.utils.tensor_utils.to_numpy","text":"<pre><code>to_numpy(array)\n</code></pre> <p>Convert array-like to numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>Union[ndarray, Tensor, List]</code> <p>The input array-like object.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input type cannot be cast to a numpy array.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def to_numpy(array: Union[np.ndarray, torch.Tensor, List]) -&gt; np.ndarray:\n    \"\"\"Convert array-like to numpy array.\n\n    Args:\n        array: The input array-like object.\n\n    Returns:\n        A numpy array.\n\n    Raises:\n        ValueError: If the input type cannot be cast to a numpy array.\n    \"\"\"\n    if isinstance(array, np.ndarray):\n        return array\n    elif isinstance(array, torch.Tensor):\n        return array.detach().cpu().numpy()\n    elif isinstance(array, list):\n        return np.array(array)\n    else:\n        raise ValueError(f\"type {type(array)} cannot be cast to numpy array\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.atleast_column_vector","title":"flyvis.utils.tensor_utils.atleast_column_vector","text":"<pre><code>atleast_column_vector(array)\n</code></pre> <p>Convert 1d-array-like to column vector n x 1 or return the original.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>The input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A column vector or the original array if it\u2019s already 2D or higher.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def atleast_column_vector(array: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Convert 1d-array-like to column vector n x 1 or return the original.\n\n    Args:\n        array: The input array.\n\n    Returns:\n        A column vector or the original array if it's already 2D or higher.\n    \"\"\"\n    array = np.array(array)\n    if array.ndim == 1:\n        return array.reshape(-1, 1)\n    return array\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.matrix_mask_by_sub","title":"flyvis.utils.tensor_utils.matrix_mask_by_sub","text":"<pre><code>matrix_mask_by_sub(sub_matrix, matrix)\n</code></pre> <p>Create a mask of rows in matrix that are contained in sub_matrix.</p> <p>Parameters:</p> Name Type Description Default <code>sub_matrix</code> <code>ndarray</code> <p>Shape (n_rows1, n_columns)</p> required <code>matrix</code> <code>ndarray</code> <p>Shape (n_rows2, n_columns)</p> required <p>Returns:</p> Type Description <code>NDArray[bool]</code> <p>1D boolean array of length n_rows2</p> Note <p>n_rows1 !&lt;= n_rows2</p> Example <pre><code>sub_matrix = np.array([[1, 2, 3],\n                       [4, 3, 1]])\nmatrix = np.array([[3, 4, 1],\n                   [4, 3, 1],\n                   [1, 2, 3]])\nmatrix_mask_by_sub(sub_matrix, matrix)\n# array([False, True, True])\n</code></pre> <p>Typically, indexing a tensor with indices instead of booleans is faster. Therefore, see also where_equal_rows.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def matrix_mask_by_sub(sub_matrix: np.ndarray, matrix: np.ndarray) -&gt; NDArray[bool]:\n    \"\"\"Create a mask of rows in matrix that are contained in sub_matrix.\n\n    Args:\n        sub_matrix: Shape (n_rows1, n_columns)\n        matrix: Shape (n_rows2, n_columns)\n\n    Returns:\n        1D boolean array of length n_rows2\n\n    Note:\n        n_rows1 !&lt;= n_rows2\n\n    Example:\n        ```python\n        sub_matrix = np.array([[1, 2, 3],\n                               [4, 3, 1]])\n        matrix = np.array([[3, 4, 1],\n                           [4, 3, 1],\n                           [1, 2, 3]])\n        matrix_mask_by_sub(sub_matrix, matrix)\n        # array([False, True, True])\n        ```\n\n    Typically, indexing a tensor with indices instead of booleans is\n    faster. Therefore, see also where_equal_rows.\n    \"\"\"\n    from functools import reduce\n\n    n_rows, n_columns = sub_matrix.shape\n    n_rows2 = matrix.shape[0]\n    if not n_rows &lt;= n_rows2:\n        raise ValueError(\"sub_matrix must have fewer or equal rows as matrix\")\n    row_mask = []\n    for i in range(n_rows):\n        column_mask = []\n        for j in range(n_columns):\n            column_mask.append(sub_matrix[i, j] == matrix[:, j])\n        row_mask.append(reduce(np.logical_and, column_mask))\n    return reduce(np.logical_or, row_mask)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.where_equal_rows","title":"flyvis.utils.tensor_utils.where_equal_rows","text":"<pre><code>where_equal_rows(matrix1, matrix2, as_mask=False, astype='|S64')\n</code></pre> <p>Find indices where matrix1 rows are in matrix2.</p> <p>Parameters:</p> Name Type Description Default <code>matrix1</code> <code>ndarray</code> <p>First input matrix.</p> required <code>matrix2</code> <code>ndarray</code> <p>Second input matrix.</p> required <code>as_mask</code> <code>bool</code> <p>If True, return a boolean mask instead of indices.</p> <code>False</code> <code>astype</code> <code>str</code> <p>Data type to use for comparison.</p> <code>'|S64'</code> <p>Returns:</p> Type Description <code>NDArray[int]</code> <p>Array of indices or boolean mask.</p> Example <pre><code>matrix1 = np.array([[1, 2, 3],\n                    [4, 3, 1]])\nmatrix2 = np.array([[3, 4, 1],\n                    [4, 3, 1],\n                    [1, 2, 3],\n                    [0, 0, 0]])\nwhere_equal_rows(matrix1, matrix2)\n# array([2, 1])\nmatrix2[where_equal_rows(matrix1, matrix2)]\n# array([[1, 2, 3],\n#        [4, 3, 1]])\n</code></pre> See also <p>matrix_mask_by_sub</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def where_equal_rows(\n    matrix1: np.ndarray,\n    matrix2: np.ndarray,\n    as_mask: bool = False,\n    astype: str = \"|S64\",\n) -&gt; NDArray[int]:\n    \"\"\"Find indices where matrix1 rows are in matrix2.\n\n    Args:\n        matrix1: First input matrix.\n        matrix2: Second input matrix.\n        as_mask: If True, return a boolean mask instead of indices.\n        astype: Data type to use for comparison.\n\n    Returns:\n        Array of indices or boolean mask.\n\n    Example:\n        ```python\n        matrix1 = np.array([[1, 2, 3],\n                            [4, 3, 1]])\n        matrix2 = np.array([[3, 4, 1],\n                            [4, 3, 1],\n                            [1, 2, 3],\n                            [0, 0, 0]])\n        where_equal_rows(matrix1, matrix2)\n        # array([2, 1])\n        matrix2[where_equal_rows(matrix1, matrix2)]\n        # array([[1, 2, 3],\n        #        [4, 3, 1]])\n        ```\n\n    See also:\n        matrix_mask_by_sub\n    \"\"\"\n    matrix1 = atleast_column_vector(matrix1)\n    matrix2 = atleast_column_vector(matrix2)\n    matrix1 = matrix1.astype(astype)\n    matrix2 = matrix2.astype(astype)\n\n    if as_mask:\n        return matrix_mask_by_sub(matrix1, matrix2)\n\n    n_rows1, n_cols1 = matrix1.shape\n    n_rows2, n_cols2 = matrix2.shape\n\n    if not n_rows1 &lt;= n_rows2:\n        raise ValueError(\"matrix1 must have less or equal as many rows as matrix2\")\n    if not n_cols1 == n_cols2:\n        raise ValueError(\"cannot compare matrices with different number of columns\")\n\n    where = []\n    rows = np.arange(matrix2.shape[0])\n    for row in matrix1:\n        equal_rows = (row == matrix2).all(axis=1)\n        for index in rows[equal_rows]:\n            where.append(index)\n    return np.array(where)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.broadcast","title":"flyvis.utils.tensor_utils.broadcast","text":"<pre><code>broadcast(src, other, dim)\n</code></pre> <p>Broadcast <code>src</code> to the shape of <code>other</code> along dimension <code>dim</code>.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>Source tensor to broadcast.</p> required <code>other</code> <code>Tensor</code> <p>Target tensor to broadcast to.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to broadcast.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Broadcasted tensor.</p> Note <p>From https://github.com/rusty1s/pytorch_scatter/.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def broadcast(src: torch.Tensor, other: torch.Tensor, dim: int) -&gt; torch.Tensor:\n    \"\"\"Broadcast `src` to the shape of `other` along dimension `dim`.\n\n    Args:\n        src: Source tensor to broadcast.\n        other: Target tensor to broadcast to.\n        dim: Dimension along which to broadcast.\n\n    Returns:\n        Broadcasted tensor.\n\n    Note:\n        From https://github.com/rusty1s/pytorch_scatter/.\n    \"\"\"\n    if dim &lt; 0:\n        dim = other.dim() + dim\n    if src.dim() == 1:\n        for _ in range(0, dim):\n            src = src.unsqueeze(0)\n    for _ in range(src.dim(), other.dim()):\n        src = src.unsqueeze(-1)\n    src = src.expand(other.size())\n    return src\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.scatter_reduce","title":"flyvis.utils.tensor_utils.scatter_reduce","text":"<pre><code>scatter_reduce(src, index, dim=-1, mode='mean')\n</code></pre> <p>Reduce along dimension <code>dim</code> using values in the <code>index</code> tensor.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>Source tensor.</p> required <code>index</code> <code>Tensor</code> <p>Index tensor.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to reduce.</p> <code>-1</code> <code>mode</code> <code>Literal['mean', 'sum']</code> <p>Reduction mode, either \u201cmean\u201d or \u201csum\u201d.</p> <code>'mean'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Reduced tensor.</p> Note <p>Convenience function for <code>torch.scatter_reduce</code> that broadcasts <code>index</code> to the shape of <code>src</code> along dimension <code>dim</code> to cohere to pytorch_scatter API.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def scatter_reduce(\n    src: torch.Tensor,\n    index: torch.Tensor,\n    dim: int = -1,\n    mode: Literal[\"mean\", \"sum\"] = \"mean\",\n) -&gt; torch.Tensor:\n    \"\"\"Reduce along dimension `dim` using values in the `index` tensor.\n\n    Args:\n        src: Source tensor.\n        index: Index tensor.\n        dim: Dimension along which to reduce.\n        mode: Reduction mode, either \"mean\" or \"sum\".\n\n    Returns:\n        Reduced tensor.\n\n    Note:\n        Convenience function for `torch.scatter_reduce` that broadcasts `index` to\n        the shape of `src` along dimension `dim` to cohere to pytorch_scatter API.\n    \"\"\"\n    index = broadcast(index.long(), src, dim)\n    return torch.scatter_reduce(src, dim, index, reduce=mode)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.scatter_mean","title":"flyvis.utils.tensor_utils.scatter_mean","text":"<pre><code>scatter_mean(src, index, dim=-1)\n</code></pre> <p>Average along dimension <code>dim</code> using values in the <code>index</code> tensor.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>Source tensor.</p> required <code>index</code> <code>Tensor</code> <p>Index tensor.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to average.</p> <code>-1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Averaged tensor.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def scatter_mean(src: torch.Tensor, index: torch.Tensor, dim: int = -1) -&gt; torch.Tensor:\n    \"\"\"Average along dimension `dim` using values in the `index` tensor.\n\n    Args:\n        src: Source tensor.\n        index: Index tensor.\n        dim: Dimension along which to average.\n\n    Returns:\n        Averaged tensor.\n    \"\"\"\n    return scatter_reduce(src, index, dim, \"mean\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.scatter_add","title":"flyvis.utils.tensor_utils.scatter_add","text":"<pre><code>scatter_add(src, index, dim=-1)\n</code></pre> <p>Sum along dimension <code>dim</code> using values in the <code>index</code> tensor.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Tensor</code> <p>Source tensor.</p> required <code>index</code> <code>Tensor</code> <p>Index tensor.</p> required <code>dim</code> <code>int</code> <p>Dimension along which to sum.</p> <code>-1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Summed tensor.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def scatter_add(src: torch.Tensor, index: torch.Tensor, dim: int = -1) -&gt; torch.Tensor:\n    \"\"\"Sum along dimension `dim` using values in the `index` tensor.\n\n    Args:\n        src: Source tensor.\n        index: Index tensor.\n        dim: Dimension along which to sum.\n\n    Returns:\n        Summed tensor.\n    \"\"\"\n    return scatter_reduce(src, index, dim, \"sum\")\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.select_along_axes","title":"flyvis.utils.tensor_utils.select_along_axes","text":"<pre><code>select_along_axes(array, indices, dims)\n</code></pre> <p>Select indices from array along dims.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Array to take indices from.</p> required <code>indices</code> <code>Union[int, Iterable[int]]</code> <p>Indices to take.</p> required <code>dims</code> <code>Union[int, Iterable[int]]</code> <p>Dimensions to take indices from.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array with selected indices along specified dimensions.</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def select_along_axes(\n    array: np.ndarray,\n    indices: Union[int, Iterable[int]],\n    dims: Union[int, Iterable[int]],\n) -&gt; np.ndarray:\n    \"\"\"Select indices from array along dims.\n\n    Args:\n        array: Array to take indices from.\n        indices: Indices to take.\n        dims: Dimensions to take indices from.\n\n    Returns:\n        Array with selected indices along specified dimensions.\n    \"\"\"\n    if not isinstance(indices, Iterable):\n        indices = [indices]\n    if not isinstance(dims, Iterable):\n        dims = [dims]\n\n    for index, dim in zip(indices, dims):\n        if not isinstance(index, Iterable):\n            index = [index]\n        array = array.take(index, axis=dim)\n    return array\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.tensor_utils.asymmetric_weighting","title":"flyvis.utils.tensor_utils.asymmetric_weighting","text":"<pre><code>asymmetric_weighting(tensor, gamma=1.0, delta=0.1)\n</code></pre> <p>Apply asymmetric weighting to the positive and negative elements of a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Union[NDArray, Tensor]</code> <p>Input tensor.</p> required <code>gamma</code> <code>float</code> <p>Positive weighting factor.</p> <code>1.0</code> <code>delta</code> <code>float</code> <p>Negative weighting factor.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Union[NDArray, Tensor]</code> <p>Weighted tensor.</p> Note <p>The function is defined as: f(x) = gamma * x if x &gt; 0 else delta * x</p> Source code in <code>flyvis/utils/tensor_utils.py</code> <pre><code>def asymmetric_weighting(\n    tensor: Union[NDArray, torch.Tensor], gamma: float = 1.0, delta: float = 0.1\n) -&gt; Union[NDArray, torch.Tensor]:\n    \"\"\"\n    Apply asymmetric weighting to the positive and negative elements of a tensor.\n\n    Args:\n        tensor: Input tensor.\n        gamma: Positive weighting factor.\n        delta: Negative weighting factor.\n\n    Returns:\n        Weighted tensor.\n\n    Note:\n        The function is defined as:\n        f(x) = gamma * x if x &gt; 0 else delta * x\n    \"\"\"\n    return gamma * nn.functional.relu(tensor) - delta * nn.functional.relu(-tensor)\n</code></pre>"},{"location":"reference/utils/#flyvisutilstype_utils","title":"flyvis.utils.type_utils","text":""},{"location":"reference/utils/#functions_14","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.type_utils.byte_to_str","title":"flyvis.utils.type_utils.byte_to_str","text":"<pre><code>byte_to_str(obj)\n</code></pre> <p>Cast byte elements to string types recursively.</p> <p>This function recursively converts byte elements to string types in nested data structures.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object to be processed. Can be of various types including Mapping, numpy.ndarray, list, tuple, bytes, str, or Number.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The input object with all byte elements converted to strings.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input object cannot be cast to a string type.</p> Note <p>This function will cast all byte elements in nested lists or tuples.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; byte_to_str(b\"hello\")\n'hello'\n&gt;&gt;&gt; byte_to_str([b\"world\", 42, {b\"key\": b\"value\"}])\n['world', 42, {'key': 'value'}]\n</code></pre> Source code in <code>flyvis/utils/type_utils.py</code> <pre><code>def byte_to_str(obj: Any) -&gt; Any:\n    \"\"\"Cast byte elements to string types recursively.\n\n    This function recursively converts byte elements to string types in nested\n    data structures.\n\n    Args:\n        obj: The object to be processed. Can be of various types including\n            Mapping, numpy.ndarray, list, tuple, bytes, str, or Number.\n\n    Returns:\n        The input object with all byte elements converted to strings.\n\n    Raises:\n        TypeError: If the input object cannot be cast to a string type.\n\n    Note:\n        This function will cast all byte elements in nested lists or tuples.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; byte_to_str(b\"hello\")\n        'hello'\n        &gt;&gt;&gt; byte_to_str([b\"world\", 42, {b\"key\": b\"value\"}])\n        ['world', 42, {'key': 'value'}]\n        ```\n    \"\"\"\n    if isinstance(obj, Mapping):\n        return type(obj)({k: byte_to_str(v) for k, v in obj.items()})\n    elif isinstance(obj, np.ndarray):\n        if np.issubdtype(obj.dtype, np.dtype(\"S\")):\n            return obj.astype(\"U\")\n        return obj\n    elif isinstance(obj, list):\n        return [byte_to_str(item) for item in obj]\n    elif isinstance(obj, tuple):\n        return tuple(byte_to_str(item) for item in obj)\n    elif isinstance(obj, bytes):\n        return obj.decode()\n    elif isinstance(obj, (str, Number)):\n        return obj\n    else:\n        raise TypeError(f\"can't cast {obj} of type {type(obj)} to str\")\n</code></pre>"},{"location":"reference/utils/#flyvisutilsxarray_joblib_backend","title":"flyvis.utils.xarray_joblib_backend","text":""},{"location":"reference/utils/#classes_11","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.xarray_joblib_backend.H5XArrayDatasetStoreBackend","title":"flyvis.utils.xarray_joblib_backend.H5XArrayDatasetStoreBackend","text":"<p>               Bases: <code>FileSystemStoreBackend</code></p> <p>FileSystemStoreBackend subclass for handling xarray.Dataset objects.</p> <p>This class uses xarray\u2019s to_netcdf and open_dataset methods for Dataset objects and .h5 files.</p> <p>Attributes:</p> Name Type Description <code>location</code> <code>str</code> <p>The base directory for storing items.</p> Source code in <code>flyvis/utils/xarray_joblib_backend.py</code> <pre><code>class H5XArrayDatasetStoreBackend(FileSystemStoreBackend):\n    \"\"\"FileSystemStoreBackend subclass for handling xarray.Dataset objects.\n\n    This class uses xarray's to_netcdf and open_dataset methods for Dataset objects and\n    .h5 files.\n\n    Attributes:\n        location (str): The base directory for storing items.\n    \"\"\"\n\n    def dump_item(self, path: List[str], item: Any, *args, **kwargs) -&gt; None:\n        \"\"\"Dump an item to the store.\n\n        If the item is an xarray.Dataset or the path ends with '.h5', use\n        xarray.Dataset.to_netcdf. Otherwise, use the superclass method.\n\n        Args:\n            path: The identifier for the item in the store.\n            item: The item to be stored.\n            *args: Variable positional arguments passed to parent class or to_netcdf\n            **kwargs: Variable keyword arguments passed to parent class or to_netcdf\n        \"\"\"\n        is_dataset = isinstance(item, xr.Dataset)\n        is_h5_file = path[-1].endswith('.h5') if path else False\n\n        if is_dataset or is_h5_file:\n            item_path = os.path.join(self.location, *path)\n            nc_path = item_path if is_h5_file else os.path.join(item_path, 'output.h5')\n\n            verbose = kwargs.get('verbose', 1)\n            if verbose &gt; 10:\n                logger.info('Persisting Dataset to h5 at %s', nc_path)\n\n            try:\n                self.create_location(os.path.dirname(nc_path))\n                logger.info(\"Store item %s\", nc_path)\n                # Ensure mode='w' by default but allow override through kwargs\n                kwargs.setdefault('mode', 'w')\n                item.to_netcdf(nc_path)\n            except Exception as e:\n                warnings.warn(\n                    f\"Unable to cache Dataset to h5. Exception: {e}.\",\n                    CacheWarning,\n                    stacklevel=2,\n                )\n        else:\n            super().dump_item(path, item, *args, **kwargs)\n\n    def load_item(self, path: List[str], *args, **kwargs) -&gt; Any:\n        \"\"\"Load an item from the store.\n\n        If the path ends with '.h5' or the store contains a h5 file, use\n        xarray.open_dataset. Otherwise, use the superclass method.\n\n        Args:\n            path: The identifier for the item in the store.\n            *args: Variable positional arguments passed to parent class or xr.open_dataset\n            **kwargs: Variable keyword arguments passed to parent class or xr.open_dataset\n\n        Returns:\n            The loaded item, either an xarray.Dataset or the original object.\n        \"\"\"\n        item_path = os.path.join(self.location, *path)\n        nc_path = (\n            item_path\n            if path[-1].endswith('.h5')\n            else os.path.join(item_path, 'output.h5')\n        )\n        print(nc_path)\n        if self._item_exists(nc_path):\n            verbose = kwargs.get('verbose', 1)\n            if verbose &gt; 1:\n                logger.info('Loading Dataset from h5 at %s', nc_path)\n            try:\n                return xr.open_dataset(nc_path)\n            except Exception as e:\n                warnings.warn(\n                    f\"Unable to load Dataset from h5. Exception: {e}.\",\n                    CacheWarning,\n                    stacklevel=2,\n                )\n        return super().load_item(path, *args, **kwargs)\n\n    def contains_item(self, path: List[str]) -&gt; bool:\n        \"\"\"Check if there is an item at the given path.\n\n        This method checks for both h5 and pickle files.\n\n        Args:\n            path: The identifier for the item in the store.\n\n        Returns:\n            True if the item exists in either h5 or pickle format, False otherwise.\n        \"\"\"\n        item_path = os.path.join(self.location, *path)\n        nc_filename = (\n            item_path\n            if path[-1].endswith('.h5')\n            else os.path.join(item_path, 'output.h5')\n        )\n        super_filename = os.path.join(item_path, 'output.pkl')\n\n        return self._item_exists(nc_filename) or super()._item_exists(super_filename)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.xarray_joblib_backend.H5XArrayDatasetStoreBackend.dump_item","title":"dump_item","text":"<pre><code>dump_item(path, item, *args, **kwargs)\n</code></pre> <p>Dump an item to the store.</p> <p>If the item is an xarray.Dataset or the path ends with \u2018.h5\u2019, use xarray.Dataset.to_netcdf. Otherwise, use the superclass method.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>List[str]</code> <p>The identifier for the item in the store.</p> required <code>item</code> <code>Any</code> <p>The item to be stored.</p> required <code>*args</code> <p>Variable positional arguments passed to parent class or to_netcdf</p> <code>()</code> <code>**kwargs</code> <p>Variable keyword arguments passed to parent class or to_netcdf</p> <code>{}</code> Source code in <code>flyvis/utils/xarray_joblib_backend.py</code> <pre><code>def dump_item(self, path: List[str], item: Any, *args, **kwargs) -&gt; None:\n    \"\"\"Dump an item to the store.\n\n    If the item is an xarray.Dataset or the path ends with '.h5', use\n    xarray.Dataset.to_netcdf. Otherwise, use the superclass method.\n\n    Args:\n        path: The identifier for the item in the store.\n        item: The item to be stored.\n        *args: Variable positional arguments passed to parent class or to_netcdf\n        **kwargs: Variable keyword arguments passed to parent class or to_netcdf\n    \"\"\"\n    is_dataset = isinstance(item, xr.Dataset)\n    is_h5_file = path[-1].endswith('.h5') if path else False\n\n    if is_dataset or is_h5_file:\n        item_path = os.path.join(self.location, *path)\n        nc_path = item_path if is_h5_file else os.path.join(item_path, 'output.h5')\n\n        verbose = kwargs.get('verbose', 1)\n        if verbose &gt; 10:\n            logger.info('Persisting Dataset to h5 at %s', nc_path)\n\n        try:\n            self.create_location(os.path.dirname(nc_path))\n            logger.info(\"Store item %s\", nc_path)\n            # Ensure mode='w' by default but allow override through kwargs\n            kwargs.setdefault('mode', 'w')\n            item.to_netcdf(nc_path)\n        except Exception as e:\n            warnings.warn(\n                f\"Unable to cache Dataset to h5. Exception: {e}.\",\n                CacheWarning,\n                stacklevel=2,\n            )\n    else:\n        super().dump_item(path, item, *args, **kwargs)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.xarray_joblib_backend.H5XArrayDatasetStoreBackend.load_item","title":"load_item","text":"<pre><code>load_item(path, *args, **kwargs)\n</code></pre> <p>Load an item from the store.</p> <p>If the path ends with \u2018.h5\u2019 or the store contains a h5 file, use xarray.open_dataset. Otherwise, use the superclass method.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>List[str]</code> <p>The identifier for the item in the store.</p> required <code>*args</code> <p>Variable positional arguments passed to parent class or xr.open_dataset</p> <code>()</code> <code>**kwargs</code> <p>Variable keyword arguments passed to parent class or xr.open_dataset</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The loaded item, either an xarray.Dataset or the original object.</p> Source code in <code>flyvis/utils/xarray_joblib_backend.py</code> <pre><code>def load_item(self, path: List[str], *args, **kwargs) -&gt; Any:\n    \"\"\"Load an item from the store.\n\n    If the path ends with '.h5' or the store contains a h5 file, use\n    xarray.open_dataset. Otherwise, use the superclass method.\n\n    Args:\n        path: The identifier for the item in the store.\n        *args: Variable positional arguments passed to parent class or xr.open_dataset\n        **kwargs: Variable keyword arguments passed to parent class or xr.open_dataset\n\n    Returns:\n        The loaded item, either an xarray.Dataset or the original object.\n    \"\"\"\n    item_path = os.path.join(self.location, *path)\n    nc_path = (\n        item_path\n        if path[-1].endswith('.h5')\n        else os.path.join(item_path, 'output.h5')\n    )\n    print(nc_path)\n    if self._item_exists(nc_path):\n        verbose = kwargs.get('verbose', 1)\n        if verbose &gt; 1:\n            logger.info('Loading Dataset from h5 at %s', nc_path)\n        try:\n            return xr.open_dataset(nc_path)\n        except Exception as e:\n            warnings.warn(\n                f\"Unable to load Dataset from h5. Exception: {e}.\",\n                CacheWarning,\n                stacklevel=2,\n            )\n    return super().load_item(path, *args, **kwargs)\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.xarray_joblib_backend.H5XArrayDatasetStoreBackend.contains_item","title":"contains_item","text":"<pre><code>contains_item(path)\n</code></pre> <p>Check if there is an item at the given path.</p> <p>This method checks for both h5 and pickle files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>List[str]</code> <p>The identifier for the item in the store.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the item exists in either h5 or pickle format, False otherwise.</p> Source code in <code>flyvis/utils/xarray_joblib_backend.py</code> <pre><code>def contains_item(self, path: List[str]) -&gt; bool:\n    \"\"\"Check if there is an item at the given path.\n\n    This method checks for both h5 and pickle files.\n\n    Args:\n        path: The identifier for the item in the store.\n\n    Returns:\n        True if the item exists in either h5 or pickle format, False otherwise.\n    \"\"\"\n    item_path = os.path.join(self.location, *path)\n    nc_filename = (\n        item_path\n        if path[-1].endswith('.h5')\n        else os.path.join(item_path, 'output.h5')\n    )\n    super_filename = os.path.join(item_path, 'output.pkl')\n\n    return self._item_exists(nc_filename) or super()._item_exists(super_filename)\n</code></pre>"},{"location":"reference/utils/#flyvisutilsxarray_utils","title":"flyvis.utils.xarray_utils","text":""},{"location":"reference/utils/#classes_12","title":"Classes","text":""},{"location":"reference/utils/#flyvis.utils.xarray_utils.CustomAccessor","title":"flyvis.utils.xarray_utils.CustomAccessor","text":"<p>Custom accessor for xarray objects providing additional functionality.</p> <p>Attributes:</p> Name Type Description <code>_obj</code> <p>The xarray object being accessed.</p> Source code in <code>flyvis/utils/xarray_utils.py</code> <pre><code>class CustomAccessor:\n    \"\"\"Custom accessor for xarray objects providing additional functionality.\n\n    Attributes:\n        _obj: The xarray object being accessed.\n    \"\"\"\n\n    def __init__(self, xarray_obj: xr.Dataset | xr.DataArray):\n        self._obj = xarray_obj\n\n    @wraps(where_xarray)\n    def where(self, **kwargs) -&gt; xr.Dataset | xr.DataArray:\n        return where_xarray(self._obj, **kwargs)\n\n    @wraps(plot_traces)\n    def plot_traces(\n        self,\n        x: str,\n        key: str = \"\",\n        legend_labels: List[str] = [],\n        extra_legend_coords: List[str] = [],\n        plot_kwargs: dict = {},\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"Plot traces from the xarray object.\n\n        Args:\n            x: The dimension to use as the x-axis.\n            key: The key of the data to plot if the dataset is a Dataset.\n            legend_labels: List of coordinates to include in the legend.\n            extra_legend_coords: Additional coordinates to include in the legend.\n            plot_kwargs: Additional keyword arguments to pass to the plot function.\n            **kwargs: Query-like conditions on coordinates.\n\n        Returns:\n            The matplotlib axes object containing the plot.\n\n        Example:\n            Overlay stimulus and response traces:\n            ```python\n            fig, ax = plt.subplots()\n            r.custom.plot_traces(\n                key='stimulus',\n                x='time',\n                speed=[19, 25],\n                intensity=1,\n                angle=90,\n                u_in=0,\n                v_in=0,\n                plot_kwargs=dict(ax=ax),\n                time='&gt;0,&lt;1.0'\n            )\n            r.custom.plot_traces(\n                key='responses',\n                x='time',\n                speed=[19, 25],\n                cell_type='T4c',\n                intensity=1,\n                angle=90,\n                network_id=0,\n                plot_kwargs=dict(ax=ax),\n                time='&gt;0,&lt;1.0'\n            )\n            ```\n\n            Polar plot:\n            ```python\n            prs = peak_responses(stims_and_resps_moving_edges).custom.where(\n                cell_type=\"T4c\",\n                intensity=1,\n                speed=19,\n            )\n            prs['angle'] = np.radians(prs.angle)\n            ax = plt.subplots(subplot_kw={\"projection\": \"polar\"})[1]\n            prs.custom.plot_traces(\n                x=\"angle\",\n                legend_labels=[\"network_id\"],\n                plot_kwargs={\"add_legend\": False, \"ax\": ax, \"color\": \"b\"},\n            )\n            ```\n        \"\"\"\n        return plot_traces(\n            self._obj,\n            key,\n            x,\n            legend_labels,\n            extra_legend_coords,\n            plot_kwargs,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.xarray_utils.CustomAccessor.plot_traces","title":"plot_traces","text":"<pre><code>plot_traces(x, key='', legend_labels=[], extra_legend_coords=[], plot_kwargs={}, **kwargs)\n</code></pre> <p>Plot traces from the xarray object.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The dimension to use as the x-axis.</p> required <code>key</code> <code>str</code> <p>The key of the data to plot if the dataset is a Dataset.</p> <code>''</code> <code>legend_labels</code> <code>List[str]</code> <p>List of coordinates to include in the legend.</p> <code>[]</code> <code>extra_legend_coords</code> <code>List[str]</code> <p>Additional coordinates to include in the legend.</p> <code>[]</code> <code>plot_kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to the plot function.</p> <code>{}</code> <code>**kwargs</code> <p>Query-like conditions on coordinates.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The matplotlib axes object containing the plot.</p> Example <p>Overlay stimulus and response traces: <pre><code>fig, ax = plt.subplots()\nr.custom.plot_traces(\n    key='stimulus',\n    x='time',\n    speed=[19, 25],\n    intensity=1,\n    angle=90,\n    u_in=0,\n    v_in=0,\n    plot_kwargs=dict(ax=ax),\n    time='&gt;0,&lt;1.0'\n)\nr.custom.plot_traces(\n    key='responses',\n    x='time',\n    speed=[19, 25],\n    cell_type='T4c',\n    intensity=1,\n    angle=90,\n    network_id=0,\n    plot_kwargs=dict(ax=ax),\n    time='&gt;0,&lt;1.0'\n)\n</code></pre></p> <p>Polar plot: <pre><code>prs = peak_responses(stims_and_resps_moving_edges).custom.where(\n    cell_type=\"T4c\",\n    intensity=1,\n    speed=19,\n)\nprs['angle'] = np.radians(prs.angle)\nax = plt.subplots(subplot_kw={\"projection\": \"polar\"})[1]\nprs.custom.plot_traces(\n    x=\"angle\",\n    legend_labels=[\"network_id\"],\n    plot_kwargs={\"add_legend\": False, \"ax\": ax, \"color\": \"b\"},\n)\n</code></pre></p> Source code in <code>flyvis/utils/xarray_utils.py</code> <pre><code>@wraps(plot_traces)\ndef plot_traces(\n    self,\n    x: str,\n    key: str = \"\",\n    legend_labels: List[str] = [],\n    extra_legend_coords: List[str] = [],\n    plot_kwargs: dict = {},\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot traces from the xarray object.\n\n    Args:\n        x: The dimension to use as the x-axis.\n        key: The key of the data to plot if the dataset is a Dataset.\n        legend_labels: List of coordinates to include in the legend.\n        extra_legend_coords: Additional coordinates to include in the legend.\n        plot_kwargs: Additional keyword arguments to pass to the plot function.\n        **kwargs: Query-like conditions on coordinates.\n\n    Returns:\n        The matplotlib axes object containing the plot.\n\n    Example:\n        Overlay stimulus and response traces:\n        ```python\n        fig, ax = plt.subplots()\n        r.custom.plot_traces(\n            key='stimulus',\n            x='time',\n            speed=[19, 25],\n            intensity=1,\n            angle=90,\n            u_in=0,\n            v_in=0,\n            plot_kwargs=dict(ax=ax),\n            time='&gt;0,&lt;1.0'\n        )\n        r.custom.plot_traces(\n            key='responses',\n            x='time',\n            speed=[19, 25],\n            cell_type='T4c',\n            intensity=1,\n            angle=90,\n            network_id=0,\n            plot_kwargs=dict(ax=ax),\n            time='&gt;0,&lt;1.0'\n        )\n        ```\n\n        Polar plot:\n        ```python\n        prs = peak_responses(stims_and_resps_moving_edges).custom.where(\n            cell_type=\"T4c\",\n            intensity=1,\n            speed=19,\n        )\n        prs['angle'] = np.radians(prs.angle)\n        ax = plt.subplots(subplot_kw={\"projection\": \"polar\"})[1]\n        prs.custom.plot_traces(\n            x=\"angle\",\n            legend_labels=[\"network_id\"],\n            plot_kwargs={\"add_legend\": False, \"ax\": ax, \"color\": \"b\"},\n        )\n        ```\n    \"\"\"\n    return plot_traces(\n        self._obj,\n        key,\n        x,\n        legend_labels,\n        extra_legend_coords,\n        plot_kwargs,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/utils/#functions_15","title":"Functions","text":""},{"location":"reference/utils/#flyvis.utils.xarray_utils.where_xarray","title":"flyvis.utils.xarray_utils.where_xarray","text":"<pre><code>where_xarray(dataset, rtol=1e-05, atol=1e-08, **kwargs)\n</code></pre> <p>Return a subset of the xarray Dataset or DataArray where coordinates meet specified query-like conditions.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset | DataArray</code> <p>The dataset or data array to filter.</p> required <code>rtol</code> <code>float</code> <p>Relative tolerance for floating point comparisons.</p> <code>1e-05</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for floating point comparisons.</p> <code>1e-08</code> <code>**kwargs</code> <p>Query-like conditions on coordinates. Conditions can be specified as: - Strings with comma-separated conditions (interpreted as AND). - Iterables (lists, tuples) representing multiple conditions     (interpreted as OR). - Single values for equality conditions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dataset | DataArray</code> <p>The filtered dataset or data array.</p> Example <pre><code>filtered_ds = where_xarray(\n    ds,\n    cell_type=[\"T4a\", \"T4b\"],\n    time=\"&lt;1.0,&gt;0\",\n    intensity=1.0,\n    radius=6,\n    width=2.4\n)\n</code></pre> Source code in <code>flyvis/utils/xarray_utils.py</code> <pre><code>def where_xarray(\n    dataset: xr.Dataset | xr.DataArray,\n    rtol: float = 1.0e-5,\n    atol: float = 1.0e-8,\n    **kwargs,\n) -&gt; xr.Dataset | xr.DataArray:\n    \"\"\"Return a subset of the xarray Dataset or DataArray where coordinates meet\n    specified query-like conditions.\n\n    Args:\n        dataset: The dataset or data array to filter.\n        rtol: Relative tolerance for floating point comparisons.\n        atol: Absolute tolerance for floating point comparisons.\n        **kwargs: Query-like conditions on coordinates. Conditions can be specified as:\n            - Strings with comma-separated conditions (interpreted as AND).\n            - Iterables (lists, tuples) representing multiple conditions\n                (interpreted as OR).\n            - Single values for equality conditions.\n\n    Returns:\n        The filtered dataset or data array.\n\n    Example:\n        ```python\n        filtered_ds = where_xarray(\n            ds,\n            cell_type=[\"T4a\", \"T4b\"],\n            time=\"&lt;1.0,&gt;0\",\n            intensity=1.0,\n            radius=6,\n            width=2.4\n        )\n        ```\n    \"\"\"\n    # Force evaluation of coordinates\n    # Heisenbug, strangely required for the where() method to work\n    # to circumvent AttributeError: 'ScipyArrayWrapper' object has no attribute 'oindex'\n    for _, coord in dataset.coords.items():\n        _ = coord.values.dtype\n\n    # Define a mapping of operators from string to functions\n    operators = {\n        '&gt;=': operator.ge,\n        '&lt;=': operator.le,\n        '==': operator.eq,\n        '!=': operator.ne,\n        '&gt;': operator.gt,\n        '&lt;': operator.lt,\n    }\n\n    # Sort operators by length in descending order to match multi-character operators\n    # first\n    sorted_operators = sorted(operators.keys(), key=len, reverse=True)\n\n    def parse_condition(cond_str):\n        \"\"\"Parse a single condition string into (operator_function, target_value).\"\"\"\n        cond_str = cond_str.strip()\n        for op_str in sorted_operators:\n            if cond_str.startswith(op_str):\n                target = cond_str[len(op_str) :].strip()\n                with contextlib.suppress(ValueError):\n                    target = float(target)\n                return (operators[op_str], target)\n        # If no operator is found, assume equality\n        try:\n            target = float(cond_str)\n        except ValueError:\n            target = cond_str\n        return (operator.eq, target)\n\n    filtered_dataset = dataset\n\n    for coord_name, condition in kwargs.items():\n        # Check if coord_name is a coordinate in the dataset\n        if coord_name not in dataset.coords:\n            raise ValueError(f\"Coordinate '{coord_name}' not found in the dataset.\")\n\n        coord_values = dataset.coords[coord_name]\n        coord_mask = xr.ones_like(coord_values, dtype=bool)  # Initialize mask as all True\n\n        if isinstance(condition, str):\n            # String conditions: multiple conditions separated by commas (AND logic)\n            condition_strings = [c.strip() for c in condition.split(',') if c.strip()]\n            for cond_str in condition_strings:\n                op_func, target_value = parse_condition(cond_str)\n\n                if np.issubdtype(coord_values.dtype, np.floating):\n                    if op_func == operator.eq:\n                        mask = np.isclose(\n                            coord_values, target_value, atol=atol, rtol=rtol\n                        )\n                    else:\n                        mask = op_func(coord_values, target_value)\n                else:\n                    mask = op_func(coord_values, target_value)\n\n                # Combine masks using logical AND\n                coord_mask &amp;= xr.DataArray(\n                    mask, dims=coord_values.dims, coords=coord_values.coords\n                )\n\n        elif isinstance(condition, Iterable) and not isinstance(condition, (str, bytes)):\n            # Iterable conditions: each element is a separate condition (OR logic)\n            temp_mask = xr.zeros_like(\n                coord_values, dtype=bool\n            )  # Initialize mask as all False\n            for item in condition:\n                if isinstance(item, str):\n                    # Parse condition string\n                    op_func, target_value = parse_condition(item)\n                else:\n                    # Assume equality if not a string condition\n                    op_func, target_value = operator.eq, item\n\n                if np.issubdtype(coord_values.dtype, np.floating):\n                    if op_func == operator.eq:\n                        mask = np.isclose(\n                            coord_values, target_value, atol=atol, rtol=rtol\n                        )\n                    else:\n                        mask = op_func(coord_values, target_value)\n                else:\n                    mask = op_func(coord_values, target_value)\n\n                # Combine masks using logical OR\n                temp_mask |= xr.DataArray(\n                    mask, dims=coord_values.dims, coords=coord_values.coords\n                )\n            coord_mask &amp;= temp_mask  # Apply OR mask with existing mask\n        else:\n            # Single non-string, non-iterable value: assume equality\n            op_func, target_value = operator.eq, condition\n            if np.issubdtype(coord_values.dtype, np.floating):\n                if op_func == operator.eq:\n                    mask = np.isclose(coord_values, target_value, atol=atol, rtol=rtol)\n                else:\n                    mask = op_func(coord_values, target_value)\n            else:\n                mask = op_func(coord_values, target_value)\n            coord_mask &amp;= xr.DataArray(\n                mask, dims=coord_values.dims, coords=coord_values.coords\n            )\n\n        # Apply the combined mask\n        filtered_dataset = filtered_dataset.where(coord_mask, drop=True)\n\n    return filtered_dataset\n</code></pre>"},{"location":"reference/utils/#flyvis.utils.xarray_utils.plot_traces","title":"flyvis.utils.xarray_utils.plot_traces","text":"<pre><code>plot_traces(dataset, key, x, legend_labels=[], extra_legend_coords=[], plot_kwargs={}, **kwargs)\n</code></pre> <p>Plot the flash response traces from the dataset, optionally filtered by various parameters.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DataArray | Dataset</code> <p>The dataset containing the responses to plot.</p> required <code>key</code> <code>str</code> <p>The key of the data to plot if the dataset is a Dataset.</p> required <code>x</code> <code>str</code> <p>The dimension to use as the x-axis.</p> required <code>legend_labels</code> <code>List[str]</code> <p>List of coordinates to include in the legend.</p> <code>[]</code> <code>extra_legend_coords</code> <code>List[str]</code> <p>Additional coordinates to include in the legend.</p> <code>[]</code> <code>plot_kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to the plot function.</p> <code>{}</code> <code>**kwargs</code> <p>Query-like conditions on coordinates.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The matplotlib axes object containing the plot.</p> Note <p>Query-like conditions can be specified as:</p> <ul> <li>Strings with comma-separated conditions (e.g., time=\u2019&lt;0.5,&gt;0.1\u2019)</li> <li>Lists for equality conditions (e.g., cell_type=[\u201cT4a\u201d, \u201cT4b\u201d])</li> <li>Single values for equality conditions (e.g., intensity=1.0)</li> </ul> Source code in <code>flyvis/utils/xarray_utils.py</code> <pre><code>def plot_traces(\n    dataset: xr.DataArray | xr.Dataset,\n    key: str,\n    x: str,\n    legend_labels: List[str] = [],\n    extra_legend_coords: List[str] = [],\n    plot_kwargs: dict = {},\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot the flash response traces from the dataset, optionally filtered by various\n    parameters.\n\n    Args:\n        dataset: The dataset containing the responses to plot.\n        key: The key of the data to plot if the dataset is a Dataset.\n        x: The dimension to use as the x-axis.\n        legend_labels: List of coordinates to include in the legend.\n        extra_legend_coords: Additional coordinates to include in the legend.\n        plot_kwargs: Additional keyword arguments to pass to the plot function.\n        **kwargs: Query-like conditions on coordinates.\n\n    Returns:\n        The matplotlib axes object containing the plot.\n\n    Note:\n        Query-like conditions can be specified as:\n\n        - Strings with comma-separated conditions (e.g., time='&lt;0.5,&gt;0.1')\n        - Lists for equality conditions (e.g., cell_type=[\"T4a\", \"T4b\"])\n        - Single values for equality conditions (e.g., intensity=1.0)\n    \"\"\"\n    traces = dataset.custom.where(**kwargs)\n\n    if key:\n        traces = traces[key]\n\n    arg_df = traces.sample.to_dataframe()\n\n    # Stack all dims besides x\n    stack_dims = [dim for dim in traces.dims if dim not in list(traces[x].coords.keys())]\n    # logging.info(\"Stacking dimensions: %s\", stack_dims)\n    traces = traces.stack(traces=stack_dims)\n\n    num_stacks = traces.sizes.get('traces', 0)\n    if num_stacks &gt; 250:\n        warnings.warn(\n            f\"The traces stack has {num_stacks} elements.\",\n            UserWarning,\n            stacklevel=2,\n        )\n\n    original_legend_labels = [col for col in arg_df.columns if col != 'sample']\n    if x in original_legend_labels:\n        # cannot set legend for x-axis values\n        original_legend_labels = []\n\n    stacked_legend_labels = list(stack_dims)\n\n    legend_labels = (\n        legend_labels\n        or stacked_legend_labels + extra_legend_coords + original_legend_labels\n    )\n    legend_table = [np.atleast_1d(traces[col].data) for col in legend_labels]\n\n    # Confirm all elements are 1D arrays of equal length\n    try:\n        legend_table = np.column_stack(legend_table)\n    except ValueError as e:\n        raise ValueError(\n            \"All elements in legend_coords must be 1D arrays of equal length. \"\n            \"Specify legend_labels to use only a subset of the coordinates.\"\n        ) from e\n\n    legend_info = np.array([\n        \", \".join([f\"{col}: {value}\" for col, value in zip(legend_labels, row)])\n        for row in legend_table\n    ])\n    traces = traces.assign_coords(legend_info=(\"traces\", legend_info))\n\n    traces.plot.line(x=x, hue=\"legend_info\", **plot_kwargs)\n\n    ax = plt.gca()\n\n    legend = ax.get_legend()\n    if legend is not None:\n        legend.set_title(None)\n\n    return ax\n</code></pre>"},{"location":"reference/visualization/","title":"Visualization","text":""},{"location":"reference/visualization/#flyvisanalysisvisualizationfigsize_utils","title":"flyvis.analysis.visualization.figsize_utils","text":""},{"location":"reference/visualization/#functions","title":"Functions","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.figsize_from_n_items","title":"flyvis.analysis.visualization.figsize_utils.figsize_from_n_items","text":"<pre><code>figsize_from_n_items(n_panels, max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, dw_cm=0.1)\n</code></pre> <p>Calculate figure size based on the number of panels.</p> <p>Parameters:</p> Name Type Description Default <code>n_panels</code> <code>int</code> <p>Number of panels in the figure.</p> required <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>3.6</code> <code>dw_cm</code> <code>float</code> <p>Decrement width in centimeters for panel size adjustment.</p> <code>0.1</code> <p>Returns:</p> Name Type Description <code>FigsizeCM</code> <code>FigsizeCM</code> <p>Calculated figure size.</p> Source code in <code>flyvis/analysis/visualization/figsize_utils.py</code> <pre><code>def figsize_from_n_items(\n    n_panels: int,\n    max_figure_height_cm: float = 22,\n    panel_height_cm: float = 3,\n    max_figure_width_cm: float = 18,\n    panel_width_cm: float = 3.6,\n    dw_cm: float = 0.1,\n) -&gt; \"FigsizeCM\":\n    \"\"\"\n    Calculate figure size based on the number of panels.\n\n    Args:\n        n_panels: Number of panels in the figure.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        dw_cm: Decrement width in centimeters for panel size adjustment.\n\n    Returns:\n        FigsizeCM: Calculated figure size.\n    \"\"\"\n    n_columns = int(max_figure_width_cm / panel_width_cm)\n    n_rows = 1\n    while n_columns * n_rows &lt; n_panels:\n        n_rows += 1\n    return fit_panel_size(\n        n_rows,\n        n_columns,\n        max_figure_height_cm,\n        panel_height_cm,\n        max_figure_width_cm,\n        panel_width_cm,\n        dw_cm,\n    )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.figure_size_cm","title":"flyvis.analysis.visualization.figsize_utils.figure_size_cm","text":"<pre><code>figure_size_cm(n_panel_rows, n_panel_columns, max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, allow_rearranging=True)\n</code></pre> <p>Calculate figure size in centimeters.</p> <p>Parameters:</p> Name Type Description Default <code>n_panel_rows</code> <code>int</code> <p>Number of panel rows.</p> required <code>n_panel_columns</code> <code>int</code> <p>Number of panel columns.</p> required <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>3.6</code> <code>allow_rearranging</code> <code>bool</code> <p>Whether to allow rearranging panels.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>FigsizeCM</code> <code>FigsizeCM</code> <p>Calculated figure size.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the figure size is not realizable under given constraints.</p> Source code in <code>flyvis/analysis/visualization/figsize_utils.py</code> <pre><code>def figure_size_cm(\n    n_panel_rows: int,\n    n_panel_columns: int,\n    max_figure_height_cm: float = 22,\n    panel_height_cm: float = 3,\n    max_figure_width_cm: float = 18,\n    panel_width_cm: float = 3.6,\n    allow_rearranging: bool = True,\n) -&gt; FigsizeCM:\n    \"\"\"\n    Calculate figure size in centimeters.\n\n    Args:\n        n_panel_rows: Number of panel rows.\n        n_panel_columns: Number of panel columns.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        allow_rearranging: Whether to allow rearranging panels.\n\n    Returns:\n        FigsizeCM: Calculated figure size.\n\n    Raises:\n        ValueError: If the figure size is not realizable under given constraints.\n    \"\"\"\n    width = n_panel_columns * panel_width_cm\n    height = n_panel_rows * panel_height_cm\n    n_panels = n_panel_rows * n_panel_columns\n\n    if width &gt; max_figure_width_cm and height &gt; max_figure_height_cm:\n        raise ValueError(\"Not realizable under given size constraints\")\n    elif width &gt; max_figure_width_cm and allow_rearranging:\n        n_panel_columns -= 1\n        while n_panel_columns * n_panel_rows &lt; n_panels:\n            n_panel_rows += 1\n        return figure_size_cm(\n            n_panel_rows=n_panel_rows,\n            n_panel_columns=n_panel_columns,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n    elif height &gt; max_figure_height_cm and allow_rearranging:\n        n_panel_rows -= 1\n        while n_panel_columns * n_panel_rows &lt; n_panels:\n            n_panel_columns += 1\n        return figure_size_cm(\n            n_panel_rows=n_panel_rows,\n            n_panel_columns=n_panel_columns,\n            max_figure_height_cm=max_figure_height_cm,\n            panel_height_cm=panel_height_cm,\n            max_figure_width_cm=max_figure_width_cm,\n            panel_width_cm=panel_width_cm,\n        )\n    elif not allow_rearranging and (\n        width &gt; max_figure_width_cm or height &gt; max_figure_height_cm\n    ):\n        raise ValueError(\"Not realizable under given size constraints\")\n\n    return FigsizeCM(n_panel_rows, n_panel_columns, height, width)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.fit_panel_size","title":"flyvis.analysis.visualization.figsize_utils.fit_panel_size","text":"<pre><code>fit_panel_size(n_panel_rows, n_panel_columns, max_figure_height_cm=22, panel_height_cm=3, max_figure_width_cm=18, panel_width_cm=3.6, dw_cm=0.1, allow_rearranging=True)\n</code></pre> <p>Fit panel size to figure constraints.</p> <p>Parameters:</p> Name Type Description Default <code>n_panel_rows</code> <code>int</code> <p>Number of panel rows.</p> required <code>n_panel_columns</code> <code>int</code> <p>Number of panel columns.</p> required <code>max_figure_height_cm</code> <code>float</code> <p>Maximum figure height in centimeters.</p> <code>22</code> <code>panel_height_cm</code> <code>float</code> <p>Height of each panel in centimeters.</p> <code>3</code> <code>max_figure_width_cm</code> <code>float</code> <p>Maximum figure width in centimeters.</p> <code>18</code> <code>panel_width_cm</code> <code>float</code> <p>Width of each panel in centimeters.</p> <code>3.6</code> <code>dw_cm</code> <code>float</code> <p>Decrement width in centimeters for panel size adjustment.</p> <code>0.1</code> <code>allow_rearranging</code> <code>bool</code> <p>Whether to allow rearranging panels.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>FigsizeCM</code> <code>FigsizeCM</code> <p>Fitted figure size.</p> Source code in <code>flyvis/analysis/visualization/figsize_utils.py</code> <pre><code>def fit_panel_size(\n    n_panel_rows: int,\n    n_panel_columns: int,\n    max_figure_height_cm: float = 22,\n    panel_height_cm: float = 3,\n    max_figure_width_cm: float = 18,\n    panel_width_cm: float = 3.6,\n    dw_cm: float = 0.1,\n    allow_rearranging: bool = True,\n) -&gt; FigsizeCM:\n    \"\"\"\n    Fit panel size to figure constraints.\n\n    Args:\n        n_panel_rows: Number of panel rows.\n        n_panel_columns: Number of panel columns.\n        max_figure_height_cm: Maximum figure height in centimeters.\n        panel_height_cm: Height of each panel in centimeters.\n        max_figure_width_cm: Maximum figure width in centimeters.\n        panel_width_cm: Width of each panel in centimeters.\n        dw_cm: Decrement width in centimeters for panel size adjustment.\n        allow_rearranging: Whether to allow rearranging panels.\n\n    Returns:\n        FigsizeCM: Fitted figure size.\n    \"\"\"\n    ratio = panel_width_cm / panel_height_cm\n\n    try:\n        return figure_size_cm(\n            n_panel_rows,\n            n_panel_columns,\n            max_figure_height_cm,\n            panel_height_cm,\n            max_figure_width_cm,\n            panel_width_cm,\n            allow_rearranging=allow_rearranging,\n        )\n    except ValueError:\n        new_panel_width_cm = panel_width_cm - dw_cm\n        new_panel_height_cm = new_panel_width_cm / ratio\n        return fit_panel_size(\n            n_panel_rows,\n            n_panel_columns,\n            max_figure_height_cm,\n            new_panel_height_cm,\n            max_figure_width_cm,\n            new_panel_width_cm,\n            dw_cm,\n            allow_rearranging=allow_rearranging,\n        )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.cm_to_inch","title":"flyvis.analysis.visualization.figsize_utils.cm_to_inch","text":"<pre><code>cm_to_inch(*args)\n</code></pre> <p>Convert centimeters to inches.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Union[Tuple[float, float], float]</code> <p>Either a tuple of (width, height) or separate width and height values.</p> <code>()</code> <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Tuple of width and height in inches.</p> Source code in <code>flyvis/analysis/visualization/figsize_utils.py</code> <pre><code>def cm_to_inch(*args: Union[Tuple[float, float], float]) -&gt; Tuple[float, float]:\n    \"\"\"\n    Convert centimeters to inches.\n\n    Args:\n        *args: Either a tuple of (width, height) or separate width and height values.\n\n    Returns:\n        Tuple of width and height in inches.\n    \"\"\"\n    if len(args) == 1:\n        width, height = args[0]\n    elif len(args) == 2:\n        width, height = args\n    else:\n        raise ValueError(\"Invalid number of arguments\")\n    return width / 2.54, height / 2.54\n</code></pre>"},{"location":"reference/visualization/#classes","title":"Classes","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.FigsizeCM","title":"flyvis.analysis.visualization.figsize_utils.FigsizeCM  <code>dataclass</code>","text":"<p>Represents figure size in centimeters.</p> <p>Attributes:</p> Name Type Description <code>n_rows</code> <code>int</code> <p>Number of rows in the figure.</p> <code>n_columns</code> <code>int</code> <p>Number of columns in the figure.</p> <code>height</code> <code>float</code> <p>Height of the figure in centimeters.</p> <code>width</code> <code>float</code> <p>Width of the figure in centimeters.</p> <code>pad</code> <code>float</code> <p>Padding in centimeters.</p> Source code in <code>flyvis/analysis/visualization/figsize_utils.py</code> <pre><code>@dataclass\nclass FigsizeCM:\n    \"\"\"\n    Represents figure size in centimeters.\n\n    Attributes:\n        n_rows: Number of rows in the figure.\n        n_columns: Number of columns in the figure.\n        height: Height of the figure in centimeters.\n        width: Width of the figure in centimeters.\n        pad: Padding in centimeters.\n    \"\"\"\n\n    n_rows: int\n    n_columns: int\n    height: float\n    width: float\n    pad: float = 0.5\n\n    @property\n    def inches_wh(self) -&gt; Tuple[float, float]:\n        \"\"\"Convert width and height to inches.\"\"\"\n        return cm_to_inch(self.width + self.pad, self.height + self.pad)\n\n    @property\n    def panel_height_cm(self) -&gt; float:\n        \"\"\"Calculate panel height in centimeters.\"\"\"\n        return self.height / self.n_rows\n\n    @property\n    def panel_width_cm(self) -&gt; float:\n        \"\"\"Calculate panel width in centimeters.\"\"\"\n        return self.width / self.n_columns\n\n    def axis_grid(\n        self,\n        projection: Union[str, None] = None,\n        as_matrix: bool = False,\n        fontsize: int = 5,\n        wspace: float = 0.1,\n        hspace: float = 0.3,\n        alpha: float = 1,\n        unmask_n: Union[int, None] = None,\n    ) -&gt; Tuple:\n        \"\"\"\n        Create an axis grid for the figure.\n\n        Args:\n            projection: Type of projection for the axes.\n            as_matrix: Whether to return axes as a matrix.\n            fontsize: Font size for the axes.\n            wspace: Width space between subplots.\n            hspace: Height space between subplots.\n            alpha: Alpha value for the axes.\n            unmask_n: Number of axes to unmask.\n\n        Returns:\n            Tuple containing the figure and axes.\n        \"\"\"\n        fig, axes, _ = plt_utils.get_axis_grid(\n            gridwidth=self.n_columns,\n            gridheight=self.n_rows,\n            figsize=self.inches_wh,\n            projection=projection,\n            as_matrix=as_matrix,\n            fontsize=fontsize,\n            wspace=wspace,\n            hspace=hspace,\n            alpha=alpha,\n            unmask_n=unmask_n,\n        )\n        return fig, axes\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.FigsizeCM.inches_wh","title":"inches_wh  <code>property</code>","text":"<pre><code>inches_wh\n</code></pre> <p>Convert width and height to inches.</p>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.FigsizeCM.panel_height_cm","title":"panel_height_cm  <code>property</code>","text":"<pre><code>panel_height_cm\n</code></pre> <p>Calculate panel height in centimeters.</p>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.FigsizeCM.panel_width_cm","title":"panel_width_cm  <code>property</code>","text":"<pre><code>panel_width_cm\n</code></pre> <p>Calculate panel width in centimeters.</p>"},{"location":"reference/visualization/#flyvis.analysis.visualization.figsize_utils.FigsizeCM.axis_grid","title":"axis_grid","text":"<pre><code>axis_grid(projection=None, as_matrix=False, fontsize=5, wspace=0.1, hspace=0.3, alpha=1, unmask_n=None)\n</code></pre> <p>Create an axis grid for the figure.</p> <p>Parameters:</p> Name Type Description Default <code>projection</code> <code>Union[str, None]</code> <p>Type of projection for the axes.</p> <code>None</code> <code>as_matrix</code> <code>bool</code> <p>Whether to return axes as a matrix.</p> <code>False</code> <code>fontsize</code> <code>int</code> <p>Font size for the axes.</p> <code>5</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0.1</code> <code>hspace</code> <code>float</code> <p>Height space between subplots.</p> <code>0.3</code> <code>alpha</code> <code>float</code> <p>Alpha value for the axes.</p> <code>1</code> <code>unmask_n</code> <code>Union[int, None]</code> <p>Number of axes to unmask.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>Tuple containing the figure and axes.</p> Source code in <code>flyvis/analysis/visualization/figsize_utils.py</code> <pre><code>def axis_grid(\n    self,\n    projection: Union[str, None] = None,\n    as_matrix: bool = False,\n    fontsize: int = 5,\n    wspace: float = 0.1,\n    hspace: float = 0.3,\n    alpha: float = 1,\n    unmask_n: Union[int, None] = None,\n) -&gt; Tuple:\n    \"\"\"\n    Create an axis grid for the figure.\n\n    Args:\n        projection: Type of projection for the axes.\n        as_matrix: Whether to return axes as a matrix.\n        fontsize: Font size for the axes.\n        wspace: Width space between subplots.\n        hspace: Height space between subplots.\n        alpha: Alpha value for the axes.\n        unmask_n: Number of axes to unmask.\n\n    Returns:\n        Tuple containing the figure and axes.\n    \"\"\"\n    fig, axes, _ = plt_utils.get_axis_grid(\n        gridwidth=self.n_columns,\n        gridheight=self.n_rows,\n        figsize=self.inches_wh,\n        projection=projection,\n        as_matrix=as_matrix,\n        fontsize=fontsize,\n        wspace=wspace,\n        hspace=hspace,\n        alpha=alpha,\n        unmask_n=unmask_n,\n    )\n    return fig, axes\n</code></pre>"},{"location":"reference/visualization/#flyvisanalysisvisualizationnetwork_fig","title":"flyvis.analysis.visualization.network_fig","text":""},{"location":"reference/visualization/#classes_1","title":"Classes","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.network_fig.WholeNetworkFigure","title":"flyvis.analysis.visualization.network_fig.WholeNetworkFigure","text":"<p>Class for creating a whole network figure.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>DataFrame</code> <p>DataFrame containing node information.</p> <code>edges</code> <code>DataFrame</code> <p>DataFrame containing edge information.</p> <code>layout</code> <code>Dict[str, str]</code> <p>Dictionary mapping node types to layout positions.</p> <code>cell_types</code> <code>List[str]</code> <p>List of unique cell types.</p> <code>video</code> <code>bool</code> <p>Whether to include video node.</p> <code>rendering</code> <code>bool</code> <p>Whether to include rendering node.</p> <code>motion_decoder</code> <code>bool</code> <p>Whether to include motion decoder node.</p> <code>decoded_motion</code> <code>bool</code> <p>Whether to include decoded motion node.</p> <code>pixel_accurate_motion</code> <code>bool</code> <p>Whether to include pixel-accurate motion node.</p> Source code in <code>flyvis/analysis/visualization/network_fig.py</code> <pre><code>class WholeNetworkFigure:\n    \"\"\"\n    Class for creating a whole network figure.\n\n    Attributes:\n        nodes (pd.DataFrame): DataFrame containing node information.\n        edges (pd.DataFrame): DataFrame containing edge information.\n        layout (Dict[str, str]): Dictionary mapping node types to layout positions.\n        cell_types (List[str]): List of unique cell types.\n        video (bool): Whether to include video node.\n        rendering (bool): Whether to include rendering node.\n        motion_decoder (bool): Whether to include motion decoder node.\n        decoded_motion (bool): Whether to include decoded motion node.\n        pixel_accurate_motion (bool): Whether to include pixel-accurate motion node.\n    \"\"\"\n\n    def __init__(\n        self,\n        connectome,\n        video: bool = False,\n        rendering: bool = False,\n        motion_decoder: bool = False,\n        decoded_motion: bool = False,\n        pixel_accurate_motion: bool = False,\n    ):\n        self.nodes = connectome.nodes.to_df()\n        self.edges = connectome.edges.to_df()\n        self.layout = dict(connectome.layout[:].astype(str))\n        self.cell_types = connectome.unique_cell_types[:].astype(str)\n\n        layout = {}\n        if video:\n            layout.update({\"video\": \"cartesian\"})\n        if rendering:\n            layout.update({\"rendering\": \"hexagonal\"})\n        layout.update(dict(connectome.layout[:].astype(str)))\n        if motion_decoder:\n            layout.update({\"motion decoder\": \"decoder\"})\n        if decoded_motion:\n            layout.update({\"decoded motion\": \"motion\"})\n        if pixel_accurate_motion:\n            layout.update({\"pixel-accurate motion\": \"motion\"})\n        self.layout = layout\n        self.video = video\n        self.rendering = rendering\n        self.motion_decoder = motion_decoder\n        self.decoded_motion = decoded_motion\n        self.pixel_accurate_motion = pixel_accurate_motion\n\n    def init_figure(\n        self,\n        figsize: List[int] = [15, 6],\n        fontsize: int = 6,\n        decoder_box: bool = True,\n        cell_type_labels: bool = True,\n        neuropil_labels: bool = True,\n        network_layout_axes_kwargs: Dict = {},\n        add_graph_kwargs: Dict = {},\n    ) -&gt; None:\n        \"\"\"\n        Initialize the figure with various components.\n\n        Args:\n            figsize: Size of the figure.\n            fontsize: Font size for labels.\n            decoder_box: Whether to add a decoder box.\n            cell_type_labels: Whether to add cell type labels.\n            neuropil_labels: Whether to add neuropil labels.\n            network_layout_axes_kwargs: Additional kwargs for network_layout_axes.\n            add_graph_kwargs: Additional kwargs for add_graph.\n        \"\"\"\n        self.fig, self.axes, self.axes_centers = network_layout_axes(\n            self.layout, figsize=figsize, **network_layout_axes_kwargs\n        )\n        self.ax_dict = {ax.get_label(): ax for ax in self.axes}\n        self.add_graph(**add_graph_kwargs)\n\n        self.add_retina_box()\n\n        if decoder_box:\n            self.add_decoded_box()\n\n        if cell_type_labels:\n            self.add_cell_type_labels(fontsize=fontsize)\n\n        if neuropil_labels:\n            self.add_neuropil_labels(fontsize=fontsize)\n\n        if self.motion_decoder:\n            self.add_decoder_sketch()\n\n        self.add_arrows()\n\n    def add_graph(\n        self,\n        edge_color_key: Optional[str] = None,\n        arrows: bool = True,\n        edge_alpha: float = 1.0,\n        edge_width: float = 1.0,\n        constant_edge_width: Optional[float] = 0.25,\n        constant_edge_color: str = \"#c5c5c5\",\n        edge_cmap: Optional[str] = None,\n        nx_kwargs: Dict = {},\n    ) -&gt; None:\n        \"\"\"\n        Add the graph to the figure.\n\n        Args:\n            edge_color_key: Key for edge color.\n            arrows: Whether to add arrows to edges.\n            edge_alpha: Alpha value for edges.\n            edge_width: Width of edges.\n            constant_edge_width: Constant width for all edges.\n            constant_edge_color: Constant color for all edges.\n            edge_cmap: Colormap for edges.\n            nx_kwargs: Additional kwargs for networkx drawing.\n        \"\"\"\n\n        def _network_graph(nodes, edges):\n            \"\"\"Transform graph from df to list to create networkx.Graph object.\"\"\"\n            nodes = nodes.groupby(by=[\"type\"], sort=False, as_index=False).first().type\n            edges = list(\n                map(\n                    lambda x: x.split(\",\"),\n                    (edges.source_type + \",\" + edges.target_type).unique(),\n                )\n            )\n            return nodes, edges\n\n        axes = {\n            cell_type: [ax for ax in self.axes if ax.get_label() == cell_type][0]\n            for cell_type in self.cell_types\n        }\n\n        (\n            (lefts, bottoms, rights, tops),\n            (\n                centers,\n                widths,\n                height,\n            ),\n        ) = plt_utils.get_ax_positions(list(axes.values()))\n        edge_ax = self.fig.add_axes([\n            lefts.min(),\n            bottoms.min(),\n            rights.max() - lefts.min(),\n            tops.max() - bottoms.min(),\n        ])\n        edge_ax.set_zorder(0)\n        edge_ax = plt_utils.rm_spines(edge_ax, rm_xticks=True, rm_yticks=True)\n        edge_ax.patch.set_alpha(0.0)\n        edge_ax.set_ylim(0, 1)\n        edge_ax.set_xlim(0, 1)\n\n        fig_to_edge_ax = self.fig.transFigure + edge_ax.transData.inverted()\n        positions = {\n            key: fig_to_edge_ax.transform(value)\n            for key, value in self.axes_centers.items()\n        }\n\n        nodes, edge_list = _network_graph(self.nodes, self.edges)\n\n        if edge_color_key is not None and not constant_edge_color:\n            grouped = self.edges.groupby(\n                by=[\"source_type\", \"target_type\"], sort=False, as_index=False\n            ).mean(numeric_only=True)\n            edge_color = {\n                (row.source_type, row.target_type): row.sign\n                for i, row in grouped.iterrows()\n            }\n            _edge_color = np.array(list(edge_color.values()))\n            edge_vmin = -np.max(_edge_color) if np.any(_edge_color &lt; 0) else 0\n            edge_vmax = np.max(_edge_color)\n        else:\n            edge_color = {tuple(edge): constant_edge_color for edge in edge_list}\n            edge_vmin = None\n            edge_vmax = None\n\n        grouped = self.edges.groupby(\n            by=[\"source_type\", \"target_type\"], sort=False, as_index=False\n        ).mean(numeric_only=True)\n\n        if constant_edge_width is None:\n            edge_width = {\n                (row.source_type, row.target_type): edge_width * (np.log(row.n_syn) + 1)\n                for i, row in grouped.iterrows()\n            }\n        else:\n            edge_width = {\n                (row.source_type, row.target_type): constant_edge_width\n                for i, row in grouped.iterrows()\n            }\n\n        graph = nx.DiGraph()\n        graph.add_nodes_from(nodes)\n        graph.add_edges_from(edge_list)\n\n        draw_networkx_edges(\n            graph,\n            pos=positions,\n            ax=edge_ax,\n            edge_color=np.array([edge_color[tuple(edge)] for edge in edge_list]),\n            edge_cmap=edge_cmap,\n            edge_vmin=edge_vmin,\n            edge_vmax=edge_vmax,\n            alpha=edge_alpha,\n            arrows=arrows,\n            arrowstyle=(\n                \"-|&gt;, head_length=0.4, head_width=0.075, widthA=1.0, \"\n                \"widthB=1.0, lengthA=0.2, lengthB=0.2\"\n            ),\n            width=np.array([edge_width[tuple(edge)] for edge in edge_list]),\n            **nx_kwargs,\n        )\n        self.edge_ax = edge_ax\n\n    def add_retina_box(self):\n        retina_node_types = valfilter(lambda v: v == \"retina\", self.layout)\n        axes = {\n            node_type: [ax for ax in self.axes if ax.get_label() == node_type][0]\n            for node_type in retina_node_types\n        }\n        (\n            (lefts, bottoms, rights, tops),\n            (\n                centers,\n                widths,\n                height,\n            ),\n        ) = plt_utils.get_ax_positions(list(axes.values()))\n        retina_box_ax = self.fig.add_axes(\n            [\n                lefts.min(),\n                bottoms.min(),\n                rights.max() - lefts.min(),\n                tops.max() - bottoms.min(),\n            ],\n            label=\"retina_box\",\n        )\n        retina_box_ax.patch.set_alpha(0)\n        plt_utils.rm_spines(retina_box_ax)\n        self.ax_dict[\"retina box\"] = retina_box_ax\n\n    def add_decoded_box(self):\n        output_cell_types = valfilter(lambda v: v == \"output\", self.layout)\n        axes = {\n            cell_type: [ax for ax in self.axes if ax.get_label() == cell_type][0]\n            for cell_type in output_cell_types\n        }\n        (lefts, bottoms, rights, tops), _ = plt_utils.get_ax_positions(\n            list(axes.values())\n        )\n        bottom, top = plt_utils.get_lims((bottoms, tops), 0.02)\n        left, right = plt_utils.get_lims((lefts, rights), 0.01)\n        decoded_box_ax = self.fig.add_axes(\n            [\n                left,\n                bottom,\n                right - left,\n                top - bottom,\n            ],\n            label=\"decoded_box\",\n        )\n        decoded_box_ax.patch.set_alpha(0)\n        decoded_box_ax.spines[\"top\"].set_visible(True)\n        decoded_box_ax.spines[\"right\"].set_visible(True)\n        decoded_box_ax.spines[\"left\"].set_visible(True)\n        decoded_box_ax.spines[\"bottom\"].set_visible(True)\n        decoded_box_ax.set_xticks([])\n        decoded_box_ax.set_yticks([])\n        self.ax_dict[\"decoded box\"] = decoded_box_ax\n\n    def add_decoder_sketch(self):\n        ax = self.ax_dict[\"motion decoder\"]\n        nodes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n        edges = [\n            (1, 11),\n            (2, 10),\n            (2, 12),\n            (3, 10),\n            (3, 11),\n            (3, 12),\n            (4, 11),\n            (4, 12),\n            (4, 14),\n            (5, 10),\n            (5, 12),\n            (5, 13),\n            (6, 11),\n            (6, 13),\n            (6, 14),\n            (7, 12),\n            (7, 14),\n            (8, 13),\n            (9, 14),\n            (10, 15),\n            (11, 16),\n            (12, 15),\n            (13, 15),\n            (13, 16),\n            (14, 16),\n        ]\n        graph = nx.Graph()\n        graph.add_nodes_from(nodes)\n        graph.add_edges_from(edges)\n        x = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2]\n        y = [9, 8, 7, 6, 5, 4, 3, 2, 1, 7.3, 6.3, 5.3, 4.3, 3.3, 5.7, 4.7]\n        x, y, width, height = plt_utils.scale(x, y)\n        nx.draw_networkx(\n            graph,\n            pos=dict(zip(nodes, zip(x, y))),\n            node_shape=\"H\",\n            node_size=50,\n            node_color=\"#5a5b5b\",\n            edge_color=\"#C5C4C4\",\n            width=0.25,\n            with_labels=False,\n            ax=ax,\n            arrows=False,\n        )\n        plt_utils.rm_spines(ax)\n\n    def add_arrows(self):\n        def arrow_between_axes(axA, axB):\n            # Create the arrow\n            # 1. Get transformation operators for axis and figure\n            ax0tr = axA.transAxes  # Axis 0 -&gt; Display\n            ax1tr = axB.transAxes  # Axis 1 -&gt; Display\n            figtr = self.fig.transFigure.inverted()  # Display -&gt; Figure\n            # 2. Transform arrow start point from axis 0 to figure coordinates\n            ptA = figtr.transform(ax0tr.transform((1, 0.5)))\n            # 3. Transform arrow end point from axis 1 to figure coordinates\n            ptB = figtr.transform(ax1tr.transform((0, 0.5)))\n            # 4. Create the patch\n            arrow = matplotlib.patches.FancyArrowPatch(\n                ptA,\n                ptB,\n                transform=self.fig.transFigure,  # Place arrow in figure coord system\n                # fc=self.fontcolor,\n                # ec=self.fontcolor,\n                #     connectionstyle=\"arc3\",\n                arrowstyle=\"simple, head_width=3, head_length=6, tail_width=0.15\",\n                alpha=1,\n                mutation_scale=1.0,\n            )\n            arrow.set_lw(0.25)\n            # 5. Add patch to list of objects to draw onto the figure\n            self.fig.patches.append(arrow)\n\n        if self.video and self.rendering:\n            arrow_between_axes(self.ax_dict[\"video\"], self.ax_dict[\"rendering\"])\n            arrow_between_axes(self.ax_dict[\"rendering\"], self.ax_dict[\"retina box\"])\n        elif self.video:\n            arrow_between_axes(self.ax_dict[\"video\"], self.ax_dict[\"retina box\"])\n        elif self.rendering:\n            arrow_between_axes(self.ax_dict[\"rendering\"], self.ax_dict[\"retina box\"])\n\n        if self.motion_decoder and self.decoded_motion:\n            arrow_between_axes(\n                self.ax_dict[\"decoded box\"], self.ax_dict[\"motion decoder\"]\n            )\n            arrow_between_axes(\n                self.ax_dict[\"motion decoder\"], self.ax_dict[\"decoded motion\"]\n            )\n        elif self.motion_decoder:\n            arrow_between_axes(\n                self.ax_dict[\"decoded box\"], self.ax_dict[\"motion decoder\"]\n            )\n        elif self.decoded_motion:\n            arrow_between_axes(\n                self.ax_dict[\"decoded box\"], self.ax_dict[\"decoded motion\"]\n            )\n\n    def add_cell_type_labels(self, fontsize=5):\n        for label, ax in self.ax_dict.items():\n            if label in self.cell_types:\n                ax.annotate(\n                    label,\n                    (0, 0.9),\n                    xycoords=\"axes fraction\",\n                    va=\"bottom\",\n                    ha=\"right\",\n                    fontsize=fontsize,\n                )\n\n    def add_neuropil_labels(self, fontsize=5):\n        retina_cell_types = valfilter(lambda v: v == \"retina\", self.layout)\n        axes = {\n            cell_type: [ax for ax in self.axes if ax.get_label() == cell_type][0]\n            for cell_type in retina_cell_types\n        }\n        (lefts, bottoms, rights, tops), _ = plt_utils.get_ax_positions(\n            list(axes.values())\n        )\n        self.fig.text(\n            lefts.min() + (rights.max() - lefts.min()) / 2,\n            0,\n            \"retina\",\n            fontsize=fontsize,\n            va=\"top\",\n            ha=\"center\",\n        )\n\n        intermediate_cell_types = valfilter(lambda v: v == \"intermediate\", self.layout)\n        axes = {\n            cell_type: [ax for ax in self.axes if ax.get_label() == cell_type][0]\n            for cell_type in intermediate_cell_types\n        }\n        (\n            (lefts, bottoms, rights, tops),\n            (\n                centers,\n                widths,\n                height,\n            ),\n        ) = plt_utils.get_ax_positions(list(axes.values()))\n        self.fig.text(\n            lefts.min() + (rights.max() - lefts.min()) / 2,\n            0,\n            \"lamina, medulla intrinsic cells, CT1\",\n            fontsize=fontsize,\n            va=\"top\",\n            ha=\"center\",\n        )\n\n        output_cell_types = valfilter(lambda v: v == \"output\", self.layout)\n        axes = {\n            cell_type: [ax for ax in self.axes if ax.get_label() == cell_type][0]\n            for cell_type in output_cell_types\n        }\n        (\n            (lefts, bottoms, rights, tops),\n            (\n                centers,\n                widths,\n                height,\n            ),\n        ) = plt_utils.get_ax_positions(list(axes.values()))\n        self.fig.text(\n            lefts.min() + (rights.max() - lefts.min()) / 2,\n            0,\n            \"T-shaped, transmedullary cells\",\n            fontsize=fontsize,\n            va=\"top\",\n            ha=\"center\",\n        )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.network_fig.WholeNetworkFigure.init_figure","title":"init_figure","text":"<pre><code>init_figure(figsize=[15, 6], fontsize=6, decoder_box=True, cell_type_labels=True, neuropil_labels=True, network_layout_axes_kwargs={}, add_graph_kwargs={})\n</code></pre> <p>Initialize the figure with various components.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>List[int]</code> <p>Size of the figure.</p> <code>[15, 6]</code> <code>fontsize</code> <code>int</code> <p>Font size for labels.</p> <code>6</code> <code>decoder_box</code> <code>bool</code> <p>Whether to add a decoder box.</p> <code>True</code> <code>cell_type_labels</code> <code>bool</code> <p>Whether to add cell type labels.</p> <code>True</code> <code>neuropil_labels</code> <code>bool</code> <p>Whether to add neuropil labels.</p> <code>True</code> <code>network_layout_axes_kwargs</code> <code>Dict</code> <p>Additional kwargs for network_layout_axes.</p> <code>{}</code> <code>add_graph_kwargs</code> <code>Dict</code> <p>Additional kwargs for add_graph.</p> <code>{}</code> Source code in <code>flyvis/analysis/visualization/network_fig.py</code> <pre><code>def init_figure(\n    self,\n    figsize: List[int] = [15, 6],\n    fontsize: int = 6,\n    decoder_box: bool = True,\n    cell_type_labels: bool = True,\n    neuropil_labels: bool = True,\n    network_layout_axes_kwargs: Dict = {},\n    add_graph_kwargs: Dict = {},\n) -&gt; None:\n    \"\"\"\n    Initialize the figure with various components.\n\n    Args:\n        figsize: Size of the figure.\n        fontsize: Font size for labels.\n        decoder_box: Whether to add a decoder box.\n        cell_type_labels: Whether to add cell type labels.\n        neuropil_labels: Whether to add neuropil labels.\n        network_layout_axes_kwargs: Additional kwargs for network_layout_axes.\n        add_graph_kwargs: Additional kwargs for add_graph.\n    \"\"\"\n    self.fig, self.axes, self.axes_centers = network_layout_axes(\n        self.layout, figsize=figsize, **network_layout_axes_kwargs\n    )\n    self.ax_dict = {ax.get_label(): ax for ax in self.axes}\n    self.add_graph(**add_graph_kwargs)\n\n    self.add_retina_box()\n\n    if decoder_box:\n        self.add_decoded_box()\n\n    if cell_type_labels:\n        self.add_cell_type_labels(fontsize=fontsize)\n\n    if neuropil_labels:\n        self.add_neuropil_labels(fontsize=fontsize)\n\n    if self.motion_decoder:\n        self.add_decoder_sketch()\n\n    self.add_arrows()\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.network_fig.WholeNetworkFigure.add_graph","title":"add_graph","text":"<pre><code>add_graph(edge_color_key=None, arrows=True, edge_alpha=1.0, edge_width=1.0, constant_edge_width=0.25, constant_edge_color='#c5c5c5', edge_cmap=None, nx_kwargs={})\n</code></pre> <p>Add the graph to the figure.</p> <p>Parameters:</p> Name Type Description Default <code>edge_color_key</code> <code>Optional[str]</code> <p>Key for edge color.</p> <code>None</code> <code>arrows</code> <code>bool</code> <p>Whether to add arrows to edges.</p> <code>True</code> <code>edge_alpha</code> <code>float</code> <p>Alpha value for edges.</p> <code>1.0</code> <code>edge_width</code> <code>float</code> <p>Width of edges.</p> <code>1.0</code> <code>constant_edge_width</code> <code>Optional[float]</code> <p>Constant width for all edges.</p> <code>0.25</code> <code>constant_edge_color</code> <code>str</code> <p>Constant color for all edges.</p> <code>'#c5c5c5'</code> <code>edge_cmap</code> <code>Optional[str]</code> <p>Colormap for edges.</p> <code>None</code> <code>nx_kwargs</code> <code>Dict</code> <p>Additional kwargs for networkx drawing.</p> <code>{}</code> Source code in <code>flyvis/analysis/visualization/network_fig.py</code> <pre><code>def add_graph(\n    self,\n    edge_color_key: Optional[str] = None,\n    arrows: bool = True,\n    edge_alpha: float = 1.0,\n    edge_width: float = 1.0,\n    constant_edge_width: Optional[float] = 0.25,\n    constant_edge_color: str = \"#c5c5c5\",\n    edge_cmap: Optional[str] = None,\n    nx_kwargs: Dict = {},\n) -&gt; None:\n    \"\"\"\n    Add the graph to the figure.\n\n    Args:\n        edge_color_key: Key for edge color.\n        arrows: Whether to add arrows to edges.\n        edge_alpha: Alpha value for edges.\n        edge_width: Width of edges.\n        constant_edge_width: Constant width for all edges.\n        constant_edge_color: Constant color for all edges.\n        edge_cmap: Colormap for edges.\n        nx_kwargs: Additional kwargs for networkx drawing.\n    \"\"\"\n\n    def _network_graph(nodes, edges):\n        \"\"\"Transform graph from df to list to create networkx.Graph object.\"\"\"\n        nodes = nodes.groupby(by=[\"type\"], sort=False, as_index=False).first().type\n        edges = list(\n            map(\n                lambda x: x.split(\",\"),\n                (edges.source_type + \",\" + edges.target_type).unique(),\n            )\n        )\n        return nodes, edges\n\n    axes = {\n        cell_type: [ax for ax in self.axes if ax.get_label() == cell_type][0]\n        for cell_type in self.cell_types\n    }\n\n    (\n        (lefts, bottoms, rights, tops),\n        (\n            centers,\n            widths,\n            height,\n        ),\n    ) = plt_utils.get_ax_positions(list(axes.values()))\n    edge_ax = self.fig.add_axes([\n        lefts.min(),\n        bottoms.min(),\n        rights.max() - lefts.min(),\n        tops.max() - bottoms.min(),\n    ])\n    edge_ax.set_zorder(0)\n    edge_ax = plt_utils.rm_spines(edge_ax, rm_xticks=True, rm_yticks=True)\n    edge_ax.patch.set_alpha(0.0)\n    edge_ax.set_ylim(0, 1)\n    edge_ax.set_xlim(0, 1)\n\n    fig_to_edge_ax = self.fig.transFigure + edge_ax.transData.inverted()\n    positions = {\n        key: fig_to_edge_ax.transform(value)\n        for key, value in self.axes_centers.items()\n    }\n\n    nodes, edge_list = _network_graph(self.nodes, self.edges)\n\n    if edge_color_key is not None and not constant_edge_color:\n        grouped = self.edges.groupby(\n            by=[\"source_type\", \"target_type\"], sort=False, as_index=False\n        ).mean(numeric_only=True)\n        edge_color = {\n            (row.source_type, row.target_type): row.sign\n            for i, row in grouped.iterrows()\n        }\n        _edge_color = np.array(list(edge_color.values()))\n        edge_vmin = -np.max(_edge_color) if np.any(_edge_color &lt; 0) else 0\n        edge_vmax = np.max(_edge_color)\n    else:\n        edge_color = {tuple(edge): constant_edge_color for edge in edge_list}\n        edge_vmin = None\n        edge_vmax = None\n\n    grouped = self.edges.groupby(\n        by=[\"source_type\", \"target_type\"], sort=False, as_index=False\n    ).mean(numeric_only=True)\n\n    if constant_edge_width is None:\n        edge_width = {\n            (row.source_type, row.target_type): edge_width * (np.log(row.n_syn) + 1)\n            for i, row in grouped.iterrows()\n        }\n    else:\n        edge_width = {\n            (row.source_type, row.target_type): constant_edge_width\n            for i, row in grouped.iterrows()\n        }\n\n    graph = nx.DiGraph()\n    graph.add_nodes_from(nodes)\n    graph.add_edges_from(edge_list)\n\n    draw_networkx_edges(\n        graph,\n        pos=positions,\n        ax=edge_ax,\n        edge_color=np.array([edge_color[tuple(edge)] for edge in edge_list]),\n        edge_cmap=edge_cmap,\n        edge_vmin=edge_vmin,\n        edge_vmax=edge_vmax,\n        alpha=edge_alpha,\n        arrows=arrows,\n        arrowstyle=(\n            \"-|&gt;, head_length=0.4, head_width=0.075, widthA=1.0, \"\n            \"widthB=1.0, lengthA=0.2, lengthB=0.2\"\n        ),\n        width=np.array([edge_width[tuple(edge)] for edge in edge_list]),\n        **nx_kwargs,\n    )\n    self.edge_ax = edge_ax\n</code></pre>"},{"location":"reference/visualization/#functions_1","title":"Functions","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.network_fig.network_layout_axes","title":"flyvis.analysis.visualization.network_fig.network_layout_axes","text":"<pre><code>network_layout_axes(layout, cell_types=None, fig=None, figsize=[16, 10], types_per_column=8, region_spacing=2, wspace=0, hspace=0, as_dict=False, pos=None)\n</code></pre> <p>Create axes for network layout.</p> <p>Parameters:</p> Name Type Description Default <code>layout</code> <code>Dict[str, str]</code> <p>Dictionary mapping node types to layout positions.</p> required <code>cell_types</code> <code>Optional[List[str]]</code> <p>List of cell types to include.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to use.</p> <code>None</code> <code>figsize</code> <code>List[int]</code> <p>Size of the figure.</p> <code>[16, 10]</code> <code>types_per_column</code> <code>int</code> <p>Number of types per column.</p> <code>8</code> <code>region_spacing</code> <code>int</code> <p>Spacing between regions.</p> <code>2</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0</code> <code>hspace</code> <code>float</code> <p>Height space between subplots.</p> <code>0</code> <code>as_dict</code> <code>bool</code> <p>Whether to return axes as a dictionary.</p> <code>False</code> <code>pos</code> <code>Optional[Dict[str, List[float]]]</code> <p>Pre-computed positions for nodes.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Union[List[Axes], Dict[str, Axes]], Dict[str, List[float]]]</code> <p>Tuple containing the figure, axes, and node positions.</p> Source code in <code>flyvis/analysis/visualization/network_fig.py</code> <pre><code>def network_layout_axes(\n    layout: Dict[str, str],\n    cell_types: Optional[List[str]] = None,\n    fig: Optional[plt.Figure] = None,\n    figsize: List[int] = [16, 10],\n    types_per_column: int = 8,\n    region_spacing: int = 2,\n    wspace: float = 0,\n    hspace: float = 0,\n    as_dict: bool = False,\n    pos: Optional[Dict[str, List[float]]] = None,\n) -&gt; Tuple[\n    plt.Figure, Union[List[plt.Axes], Dict[str, plt.Axes]], Dict[str, List[float]]\n]:\n    \"\"\"\n    Create axes for network layout.\n\n    Args:\n        layout: Dictionary mapping node types to layout positions.\n        cell_types: List of cell types to include.\n        fig: Existing figure to use.\n        figsize: Size of the figure.\n        types_per_column: Number of types per column.\n        region_spacing: Spacing between regions.\n        wspace: Width space between subplots.\n        hspace: Height space between subplots.\n        as_dict: Whether to return axes as a dictionary.\n        pos: Pre-computed positions for nodes.\n\n    Returns:\n        Tuple containing the figure, axes, and node positions.\n    \"\"\"\n    fig = fig or plt.figure(figsize=figsize)\n\n    pos = pos or _network_graph_node_pos(\n        layout, region_spacing=region_spacing, types_per_column=types_per_column\n    )\n    pos = {\n        key: value\n        for key, value in pos.items()\n        if (cell_types is None or key in cell_types)\n    }\n    xy = np.array(list(pos.values()))\n    # why pad this?\n    # hpad = 0.05\n    # wpad = 0.05\n    hpad = 0.0\n    wpad = 0.0\n    fig, axes, xy_scaled = plt_utils.ax_scatter(\n        xy[:, 0],\n        xy[:, 1],\n        fig=fig,\n        wspace=wspace,\n        hspace=hspace,\n        hpad=hpad,\n        wpad=wpad,\n        alpha=0,\n        labels=list(pos.keys()),\n    )\n    new_pos = {key: xy_scaled[i] for i, key in enumerate(pos.keys())}\n    if as_dict:\n        return (\n            fig,\n            {cell_type: axes[i] for i, cell_type in enumerate(new_pos)},\n            new_pos,\n        )\n    return fig, axes, new_pos\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.network_fig._network_graph_node_pos","title":"flyvis.analysis.visualization.network_fig._network_graph_node_pos","text":"<pre><code>_network_graph_node_pos(layout, region_spacing=2, types_per_column=8)\n</code></pre> <p>Compute (x, y) coordinates for nodes in a network graph.</p> <p>Parameters:</p> Name Type Description Default <code>layout</code> <code>Dict[str, str]</code> <p>Dictionary mapping node types to layout positions.</p> required <code>region_spacing</code> <code>float</code> <p>Spacing between regions.</p> <code>2</code> <code>types_per_column</code> <code>int</code> <p>Number of types per column.</p> <code>8</code> <p>Returns:</p> Type Description <code>Dict[str, List[float]]</code> <p>Dictionary mapping node types to their (x, y) coordinates.</p> Note <p>Special nodes like \u2018video\u2019, \u2018rendering\u2019, etc. are positioned at the middle y-coordinate of their respective columns.</p> Source code in <code>flyvis/analysis/visualization/network_fig.py</code> <pre><code>def _network_graph_node_pos(\n    layout: Dict[str, str], region_spacing: float = 2, types_per_column: int = 8\n) -&gt; Dict[str, List[float]]:\n    \"\"\"\n    Compute (x, y) coordinates for nodes in a network graph.\n\n    Args:\n        layout: Dictionary mapping node types to layout positions.\n        region_spacing: Spacing between regions.\n        types_per_column: Number of types per column.\n\n    Returns:\n        Dictionary mapping node types to their (x, y) coordinates.\n\n    Note:\n        Special nodes like 'video', 'rendering', etc. are positioned at the middle\n        y-coordinate of their respective columns.\n    \"\"\"\n    x_coordinate = 0\n    region_0 = \"retina\"\n    pos = {}\n    j = 0\n    special_nodes = [\n        \"video\",\n        \"rendering\",\n        \"motion decoder\",\n        \"decoded motion\",\n        \"pixel-accurate motion\",\n    ]\n\n    for typ in layout:\n        if typ in special_nodes:\n            region_spacing = 1.25\n        if layout[typ] != region_0:\n            x_coordinate += region_spacing\n            j = 0\n        elif (j % types_per_column) == 0 and j != 0:\n            x_coordinate += 1\n        y_coordinate = types_per_column - 1 - j % types_per_column\n        pos[typ] = [x_coordinate, y_coordinate]\n        region_0 = layout[typ]\n        j += 1\n\n    y_mid = (types_per_column - 1) / 2\n\n    for node in special_nodes:\n        if node in layout:\n            pos[node][1] = y_mid\n\n    if \"pixel-accurate motion\" in layout:\n        pos[\"pixel-accurate motion\"][1] = y_mid - 1.5\n\n    return pos\n</code></pre>"},{"location":"reference/visualization/#flyvisanalysisvisualizationplots","title":"flyvis.analysis.visualization.plots","text":""},{"location":"reference/visualization/#functions_2","title":"Functions","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.heatmap","title":"flyvis.analysis.visualization.plots.heatmap","text":"<pre><code>heatmap(matrix, xlabels, ylabels=None, size_scale='auto', cmap=cm.get_cmap('seismic'), origin='upper', ax=None, fig=None, vmin=None, vmax=None, symlog=None, cbar_label='', log=None, cbar_height=0.5, cbar_width=0.01, title='', figsize=[5, 4], fontsize=4, midpoint=None, cbar=True, grid_linewidth=0.5, **kwargs)\n</code></pre> <p>Create a heatmap scatter plot of the matrix.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>ndarray</code> <p>2D matrix to be plotted.</p> required <code>xlabels</code> <code>List[str]</code> <p>List of x-axis labels.</p> required <code>ylabels</code> <code>Optional[List[str]]</code> <p>List of y-axis labels. If not provided, xlabels will be used.</p> <code>None</code> <code>size_scale</code> <code>Union[str, float]</code> <p>Size scale of the scatter points. If \u201cauto\u201d, uses 0.005 * prod(figsize).</p> <code>'auto'</code> <code>cmap</code> <code>Colormap</code> <p>Colormap for the heatmap.</p> <code>get_cmap('seismic')</code> <code>origin</code> <code>Literal['upper', 'lower']</code> <p>Origin of the matrix. Either \u201cupper\u201d or \u201clower\u201d.</p> <code>'upper'</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Matplotlib Axes object to plot on.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Matplotlib Figure object to use.</p> <code>None</code> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for color scaling.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for color scaling.</p> <code>None</code> <code>symlog</code> <code>Optional[bool]</code> <p>Whether to use symmetric log normalization.</p> <code>None</code> <code>cbar_label</code> <code>str</code> <p>Label for the colorbar.</p> <code>''</code> <code>log</code> <code>Optional[bool]</code> <p>Whether to use logarithmic color scaling.</p> <code>None</code> <code>cbar_height</code> <code>float</code> <p>Height of the colorbar.</p> <code>0.5</code> <code>cbar_width</code> <code>float</code> <p>Width of the colorbar.</p> <code>0.01</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>[5, 4]</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and ticks.</p> <code>4</code> <code>midpoint</code> <code>Optional[float]</code> <p>Midpoint for diverging colormaps.</p> <code>None</code> <code>cbar</code> <code>bool</code> <p>Whether to show the colorbar.</p> <code>True</code> <code>grid_linewidth</code> <code>float</code> <p>Width of the grid lines.</p> <code>0.5</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Optional[Colorbar], ndarray]</code> <p>A tuple containing the Figure, Axes, Colorbar (if shown), and the input matrix.</p> Note <p>This function creates a heatmap scatter plot with various customization options. The size of scatter points can be scaled based on the absolute value of the matrix elements.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def heatmap(\n    matrix: np.ndarray,\n    xlabels: List[str],\n    ylabels: Optional[List[str]] = None,\n    size_scale: Union[str, float] = \"auto\",\n    cmap: mpl.colors.Colormap = cm.get_cmap(\"seismic\"),\n    origin: Literal[\"upper\", \"lower\"] = \"upper\",\n    ax: Optional[Axes] = None,\n    fig: Optional[Figure] = None,\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    symlog: Optional[bool] = None,\n    cbar_label: str = \"\",\n    log: Optional[bool] = None,\n    cbar_height: float = 0.5,\n    cbar_width: float = 0.01,\n    title: str = \"\",\n    figsize: Tuple[float, float] = [5, 4],\n    fontsize: int = 4,\n    midpoint: Optional[float] = None,\n    cbar: bool = True,\n    grid_linewidth: float = 0.5,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes, Optional[Colorbar], np.ndarray]:\n    \"\"\"\n    Create a heatmap scatter plot of the matrix.\n\n    Args:\n        matrix: 2D matrix to be plotted.\n        xlabels: List of x-axis labels.\n        ylabels: List of y-axis labels. If not provided, xlabels will be used.\n        size_scale: Size scale of the scatter points. If \"auto\",\n            uses 0.005 * prod(figsize).\n        cmap: Colormap for the heatmap.\n        origin: Origin of the matrix. Either \"upper\" or \"lower\".\n        ax: Existing Matplotlib Axes object to plot on.\n        fig: Existing Matplotlib Figure object to use.\n        vmin: Minimum value for color scaling.\n        vmax: Maximum value for color scaling.\n        symlog: Whether to use symmetric log normalization.\n        cbar_label: Label for the colorbar.\n        log: Whether to use logarithmic color scaling.\n        cbar_height: Height of the colorbar.\n        cbar_width: Width of the colorbar.\n        title: Title of the plot.\n        figsize: Size of the figure.\n        fontsize: Font size for labels and ticks.\n        midpoint: Midpoint for diverging colormaps.\n        cbar: Whether to show the colorbar.\n        grid_linewidth: Width of the grid lines.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing the Figure, Axes, Colorbar (if shown), and the input matrix.\n\n    Note:\n        This function creates a heatmap scatter plot with various customization options.\n        The size of scatter points can be scaled based on the absolute value of the matrix\n        elements.\n    \"\"\"\n    y, x = np.nonzero(matrix)\n    value = matrix[y, x]\n\n    fig, ax = plt_utils.init_plot(figsize, title, fontsize, ax=ax, fig=fig, offset=0)\n\n    norm = plt_utils.get_norm(\n        symlog=symlog,\n        vmin=vmin if vmin is not None else np.nanmin(matrix),\n        vmax=vmax if vmax is not None else np.nanmax(matrix),\n        log=log,\n        midpoint=midpoint,\n    )\n\n    size = np.abs(value) * (\n        size_scale if size_scale != \"auto\" else 0.005 * np.prod(figsize)\n    )\n\n    ax.scatter(\n        x=x,\n        y=matrix.shape[0] - y - 1 if origin == \"upper\" else y,\n        s=size,\n        c=value,\n        cmap=cmap,\n        norm=norm,\n        marker=\"s\",\n        edgecolors=\"none\",\n    )\n\n    ax.set_xticks(np.arange(matrix.shape[1]))\n    ax.set_xticklabels(xlabels, rotation=90, fontsize=fontsize)\n    ax.set_yticks(np.arange(matrix.shape[0]))\n    ylabels = ylabels if ylabels is not None else xlabels\n    ax.set_yticklabels(ylabels[::-1] if origin == \"upper\" else ylabels, fontsize=fontsize)\n\n    ax.grid(False, \"major\")\n    ax.grid(True, \"minor\", linewidth=grid_linewidth)\n    ax.set_xticks([t + 0.5 for t in ax.get_xticks()[:-1]], minor=True)\n    ax.set_yticks([t + 0.5 for t in ax.get_yticks()[:-1]], minor=True)\n\n    ax.set_xlim([-0.5, matrix.shape[1]])\n    ax.set_ylim([-0.5, matrix.shape[0]])\n    ax.tick_params(axis=\"x\", which=\"minor\", bottom=False)\n    ax.tick_params(axis=\"y\", which=\"minor\", left=False)\n\n    cbar_obj = None\n    if cbar:\n        cbar_obj = plt_utils.add_colorbar_to_fig(\n            fig,\n            height=cbar_height,\n            width=cbar_width,\n            cmap=cmap,\n            norm=norm,\n            fontsize=fontsize,\n            label=cbar_label,\n            x_offset=15,\n        )\n\n    return fig, ax, cbar_obj, matrix\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.hex_scatter","title":"flyvis.analysis.visualization.plots.hex_scatter","text":"<pre><code>hex_scatter(u, v, values, max_extent=None, fig=None, ax=None, figsize=(1, 1), title='', title_y=None, fontsize=5, label='', labelxy='auto', label_color='black', edgecolor=None, edgewidth=0.5, alpha=1, fill=False, scalarmapper=None, norm=None, radius=1, origin='lower', vmin=None, vmax=None, midpoint=None, mode='default', orientation=np.radians(30), cmap=cm.get_cmap('seismic'), cbar=True, cbar_label='', cbar_height=None, cbar_width=None, cbar_x_offset=0.05, annotate=False, annotate_coords=False, annotate_indices=False, frame=False, frame_hex_width=1, frame_color=None, nan_linestyle='-', text_color_hsv_threshold=0.8, **kwargs)\n</code></pre> <p>Plot a hexagonally arranged data points with coordinates u, v, and coloring color.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>Array of hex coordinates in u direction.</p> required <code>v</code> <code>NDArray</code> <p>Array of hex coordinates in v direction.</p> required <code>values</code> <code>NDArray</code> <p>Array of pixel values per point (u_i, v_i).</p> required <code>fill</code> <code>Union[bool, int]</code> <p>Whether to fill the hex grid around u, v, values.</p> <code>False</code> <code>max_extent</code> <code>Optional[int]</code> <p>Maximum extent of the hex lattice shown. When fill=True, the hex grid is padded to the maximum extent when above the extent of u, v.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Matplotlib Figure object.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib Axes object.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(1, 1)</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>title_y</code> <code>Optional[float]</code> <p>Y-position of the title.</p> <code>None</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>5</code> <code>label</code> <code>str</code> <p>Label for the plot.</p> <code>''</code> <code>labelxy</code> <code>Union[str, Tuple[float, float]]</code> <p>Position of the label. Either \u201cauto\u201d or a tuple of (x, y) coordinates.</p> <code>'auto'</code> <code>label_color</code> <code>str</code> <p>Color of the label.</p> <code>'black'</code> <code>edgecolor</code> <code>Optional[str]</code> <p>Color of the hexagon edges.</p> <code>None</code> <code>edgewidth</code> <code>float</code> <p>Width of the hexagon edges.</p> <code>0.5</code> <code>alpha</code> <code>float</code> <p>Alpha value for transparency.</p> <code>1</code> <code>scalarmapper</code> <code>Optional[ScalarMappable]</code> <p>ScalarMappable object for color mapping.</p> <code>None</code> <code>norm</code> <code>Optional[Normalize]</code> <p>Normalization for color mapping.</p> <code>None</code> <code>radius</code> <code>float</code> <p>Radius of the hexagons.</p> <code>1</code> <code>origin</code> <code>Literal['lower', 'upper']</code> <p>Origin of the plot. Either \u201clower\u201d or \u201cupper\u201d.</p> <code>'lower'</code> <code>vmin</code> <code>Optional[float]</code> <p>Minimum value for color mapping.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value for color mapping.</p> <code>None</code> <code>midpoint</code> <code>Optional[float]</code> <p>Midpoint for color mapping.</p> <code>None</code> <code>mode</code> <code>str</code> <p>Hex coordinate system mode.</p> <code>'default'</code> <code>orientation</code> <code>float</code> <p>Orientation of the hexagons in radians.</p> <code>radians(30)</code> <code>cmap</code> <code>Colormap</code> <p>Colormap for the plot.</p> <code>get_cmap('seismic')</code> <code>cbar</code> <code>bool</code> <p>Whether to show a colorbar.</p> <code>True</code> <code>cbar_label</code> <code>str</code> <p>Label for the colorbar.</p> <code>''</code> <code>cbar_height</code> <code>Optional[float]</code> <p>Height of the colorbar.</p> <code>None</code> <code>cbar_width</code> <code>Optional[float]</code> <p>Width of the colorbar.</p> <code>None</code> <code>cbar_x_offset</code> <code>float</code> <p>X-offset of the colorbar.</p> <code>0.05</code> <code>annotate</code> <code>bool</code> <p>Whether to annotate hexagons with values.</p> <code>False</code> <code>annotate_coords</code> <code>bool</code> <p>Whether to annotate hexagons with coordinates.</p> <code>False</code> <code>annotate_indices</code> <code>bool</code> <p>Whether to annotate hexagons with indices.</p> <code>False</code> <code>frame</code> <code>bool</code> <p>Whether to add a frame around the plot.</p> <code>False</code> <code>frame_hex_width</code> <code>int</code> <p>Width of the frame in hexagon units.</p> <code>1</code> <code>frame_color</code> <code>Optional[Union[str, Tuple[float, float, float, float]]]</code> <p>Color of the frame.</p> <code>None</code> <code>nan_linestyle</code> <code>str</code> <p>Line style for NaN values.</p> <code>'-'</code> <code>text_color_hsv_threshold</code> <code>float</code> <p>Threshold for text color in HSV space.</p> <code>0.8</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Tuple[Optional[Line2D], ScalarMappable]]</code> <p>A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def hex_scatter(\n    u: NDArray,\n    v: NDArray,\n    values: NDArray,\n    max_extent: Optional[int] = None,\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    figsize: Tuple[float, float] = (1, 1),\n    title: str = \"\",\n    title_y: Optional[float] = None,\n    fontsize: int = 5,\n    label: str = \"\",\n    labelxy: Union[str, Tuple[float, float]] = \"auto\",\n    label_color: str = \"black\",\n    edgecolor: Optional[str] = None,\n    edgewidth: float = 0.5,\n    alpha: float = 1,\n    fill: Union[bool, int] = False,\n    scalarmapper: Optional[mpl.cm.ScalarMappable] = None,\n    norm: Optional[mpl.colors.Normalize] = None,\n    radius: float = 1,\n    origin: Literal[\"lower\", \"upper\"] = \"lower\",\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    midpoint: Optional[float] = None,\n    mode: str = \"default\",\n    orientation: float = np.radians(30),\n    cmap: mpl.colors.Colormap = cm.get_cmap(\"seismic\"),\n    cbar: bool = True,\n    cbar_label: str = \"\",\n    cbar_height: Optional[float] = None,\n    cbar_width: Optional[float] = None,\n    cbar_x_offset: float = 0.05,\n    annotate: bool = False,\n    annotate_coords: bool = False,\n    annotate_indices: bool = False,\n    frame: bool = False,\n    frame_hex_width: int = 1,\n    frame_color: Optional[Union[str, Tuple[float, float, float, float]]] = None,\n    nan_linestyle: str = \"-\",\n    text_color_hsv_threshold: float = 0.8,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes, Tuple[Optional[Line2D], mpl.cm.ScalarMappable]]:\n    \"\"\"\n    Plot a hexagonally arranged data points with coordinates u, v, and coloring color.\n\n    Args:\n        u: Array of hex coordinates in u direction.\n        v: Array of hex coordinates in v direction.\n        values: Array of pixel values per point (u_i, v_i).\n        fill: Whether to fill the hex grid around u, v, values.\n        max_extent: Maximum extent of the hex lattice shown. When fill=True, the hex\n            grid is padded to the maximum extent when above the extent of u, v.\n        fig: Matplotlib Figure object.\n        ax: Matplotlib Axes object.\n        figsize: Size of the figure.\n        title: Title of the plot.\n        title_y: Y-position of the title.\n        fontsize: Font size for text elements.\n        label: Label for the plot.\n        labelxy: Position of the label. Either \"auto\" or a tuple of (x, y) coordinates.\n        label_color: Color of the label.\n        edgecolor: Color of the hexagon edges.\n        edgewidth: Width of the hexagon edges.\n        alpha: Alpha value for transparency.\n        scalarmapper: ScalarMappable object for color mapping.\n        norm: Normalization for color mapping.\n        radius: Radius of the hexagons.\n        origin: Origin of the plot. Either \"lower\" or \"upper\".\n        vmin: Minimum value for color mapping.\n        vmax: Maximum value for color mapping.\n        midpoint: Midpoint for color mapping.\n        mode: Hex coordinate system mode.\n        orientation: Orientation of the hexagons in radians.\n        cmap: Colormap for the plot.\n        cbar: Whether to show a colorbar.\n        cbar_label: Label for the colorbar.\n        cbar_height: Height of the colorbar.\n        cbar_width: Width of the colorbar.\n        cbar_x_offset: X-offset of the colorbar.\n        annotate: Whether to annotate hexagons with values.\n        annotate_coords: Whether to annotate hexagons with coordinates.\n        annotate_indices: Whether to annotate hexagons with indices.\n        frame: Whether to add a frame around the plot.\n        frame_hex_width: Width of the frame in hexagon units.\n        frame_color: Color of the frame.\n        nan_linestyle: Line style for NaN values.\n        text_color_hsv_threshold: Threshold for text color in HSV space.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).\n    \"\"\"\n\n    def init_plot_and_validate_input(fig, ax):\n        nonlocal values, u, v\n        fig, ax = plt_utils.init_plot(\n            figsize, title, fontsize, ax=ax, fig=fig, title_y=title_y, **kwargs\n        )\n        ax.set_aspect(\"equal\")\n        values = values * np.ones_like(u) if not isinstance(values, Iterable) else values\n        if u.shape != v.shape or u.shape != values.shape:\n            raise ValueError(\"shape mismatch of hexal values and coordinates\")\n        u, v, values = hex_utils.sort_u_then_v(u, v, values)\n        return fig, ax\n\n    def apply_max_extent():\n        nonlocal u, v, values\n        extent = hex_utils.get_extent(u, v) or 1\n        if fill:\n            u, v, values = hex_utils.pad_to_regular_hex(u, v, values, extent=extent)\n        if max_extent is not None and extent &gt; max_extent:\n            u, v, values = hex_utils.crop_to_extent(u, v, values, max_extent)\n        elif max_extent is not None and extent &lt; max_extent and fill:\n            u, v, values = hex_utils.pad_to_regular_hex(u, v, values, extent=max_extent)\n\n    def setup_color_mapping(scalarmapper, norm):\n        nonlocal vmin, vmax\n        if np.any(values):\n            vmin = vmin - 1e-10 if vmin is not None else np.nanmin(values) - 1e-10\n            vmax = vmax + 1e-10 if vmax is not None else np.nanmax(values) + 1e-10\n        else:\n            vmin = 0\n            vmax = 1\n\n        if (\n            midpoint == 0\n            and np.isclose(vmin, vmax, atol=1e-10)\n            and np.sign(vmin) == np.sign(vmax)\n        ):\n            sign = np.sign(vmax)\n            if sign &gt; 0:\n                vmin = -vmax\n            elif sign &lt; 0:\n                vmax = -vmin\n            else:\n                raise ValueError\n\n        if midpoint == 0 and np.isnan(values).all():\n            vmin = 0\n            vmax = 0\n\n        scalarmapper, norm = plt_utils.get_scalarmapper(\n            scalarmapper=scalarmapper,\n            cmap=cmap,\n            norm=norm,\n            vmin=vmin,\n            vmax=vmax,\n            midpoint=midpoint,\n        )\n        return scalarmapper.to_rgba(values), scalarmapper, norm\n\n    def apply_frame():\n        nonlocal u, v, values, color_rgba\n        if frame:\n            extent = hex_utils.get_extent(u, v) or 1\n            _u, _v = hex_utils.get_hex_coords(extent + frame_hex_width)\n            framed_color = np.zeros([len(_u)])\n            framed_color_rgba = np.zeros([len(_u), 4])\n            uv = np.stack((_u, _v), 1)\n            _rings = (\n                abs(0 - uv[:, 0]) + abs(0 + 0 - uv[:, 0] - uv[:, 1]) + abs(0 - uv[:, 1])\n            ) / 2\n            mask = np.where(_rings &lt;= extent, True, False)\n            framed_color[mask] = values\n            framed_color[~mask] = 0.0\n            framed_color_rgba[mask] = color_rgba\n            framed_color_rgba[~mask] = (\n                frame_color if frame_color else np.array([0, 0, 0, 1])\n            )\n            u, v, color_rgba, values = _u, _v, framed_color_rgba, framed_color\n\n    def draw_hexagons():\n        x, y = hex_utils.hex_to_pixel(u, v, mode=mode)\n        if origin == \"upper\":\n            y = y[::-1]\n        c_mask = np.ma.masked_invalid(values)\n        for i, (_x, _y, fc) in enumerate(zip(x, y, color_rgba)):\n            if c_mask.mask[i]:\n                _hex = RegularPolygon(\n                    (_x, _y),\n                    numVertices=6,\n                    radius=radius,\n                    linewidth=edgewidth,\n                    orientation=orientation,\n                    edgecolor=edgecolor,\n                    facecolor=\"white\",\n                    alpha=alpha,\n                    ls=nan_linestyle,\n                )\n            else:\n                _hex = RegularPolygon(\n                    (_x, _y),\n                    numVertices=6,\n                    radius=radius,\n                    linewidth=edgewidth,\n                    orientation=orientation,\n                    edgecolor=edgecolor or fc,\n                    facecolor=fc,\n                    alpha=alpha,\n                )\n            ax.add_patch(_hex)\n        return x, y, c_mask\n\n    def add_colorbar():\n        if cbar:\n            plt_utils.add_colorbar_to_fig(\n                fig,\n                label=cbar_label,\n                width=cbar_width or 0.03,\n                height=cbar_height or 0.5,\n                x_offset=cbar_x_offset or -2,\n                cmap=cmap,\n                norm=norm,\n                fontsize=fontsize,\n                tick_length=1,\n                tick_width=0.25,\n                rm_outline=True,\n            )\n\n    def set_plot_limits(x, y):\n        extent = hex_utils.get_extent(u, v) or 1\n        if fill:\n            u_cs, v_cs = hex_utils.get_hex_coords(extent)\n            x_cs, y_cs = hex_utils.hex_to_pixel(u_cs, v_cs, mode=mode)\n            if origin == \"upper\":\n                y_cs = y_cs[::-1]\n            xmin, xmax = plt_utils.get_lims(x_cs, 1 / extent)\n            ymin, ymax = plt_utils.get_lims(y_cs, 1 / extent)\n        else:\n            xmin, xmax = plt_utils.get_lims(x, 1 / extent)\n            ymin, ymax = plt_utils.get_lims(y, 1 / extent)\n        if xmin != xmax and ymin != ymax:\n            ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax])\n\n    def annotate_hexagons(x, y, c_mask):\n        if annotate:\n            for i, (_label, _x, _y) in enumerate(zip(values, x, y)):\n                if not c_mask.mask[i] and not np.isnan(_label):\n                    _textcolor = (\n                        \"black\"\n                        if mpl.colors.rgb_to_hsv(color_rgba[i][:-1])[-1]\n                        &gt; text_color_hsv_threshold\n                        else \"white\"\n                    )\n                    ax.annotate(\n                        f\"{_label:.1F}\",\n                        fontsize=fontsize,\n                        xy=(_x, _y),\n                        xytext=(0, 0),\n                        textcoords=\"offset points\",\n                        ha=\"center\",\n                        va=\"center\",\n                        color=_textcolor,\n                    )\n        if annotate_coords:\n            for _x, _y, _u, _v in zip(x, y, u, v):\n                ax.text(\n                    _x - 0.45,\n                    _y + 0.2,\n                    _u,\n                    ha=\"center\",\n                    va=\"center\",\n                    fontsize=fontsize,\n                )\n                ax.text(\n                    _x + 0.45,\n                    _y + 0.2,\n                    _v,\n                    ha=\"center\",\n                    va=\"center\",\n                    fontsize=fontsize,\n                )\n        if annotate_indices:\n            for i, (_x, _y) in enumerate(zip(x, y)):\n                ax.text(_x, _y, i, ha=\"center\", va=\"center\", fontsize=fontsize)\n\n    def add_label():\n        if labelxy == \"auto\":\n            extent = hex_utils.get_extent(u, v) or 1\n            u_cs, v_cs = hex_utils.get_hex_coords(extent)\n            z = -u_cs + v_cs\n            labelu, labelv = min(u_cs[z == 0]) - 1, min(v_cs[z == 0]) - 1\n            labelx, labely = hex_utils.hex_to_pixel(labelu, labelv)\n            ha = \"right\" if len(label) &lt; 4 else \"center\"\n            label_text = ax.annotate(\n                label,\n                (labelx, labely),\n                ha=ha,\n                va=\"bottom\",\n                fontsize=fontsize,\n                zorder=1000,\n                xycoords=\"data\",\n                color=label_color,\n            )\n        else:\n            label_text = ax.text(\n                labelxy[0],\n                labelxy[1],\n                label,\n                transform=ax.transAxes,\n                ha=\"left\",\n                va=\"center\",\n                fontsize=fontsize,\n                zorder=100,\n                color=label_color,\n            )\n        return label_text\n\n    # Main execution\n    fig, ax = init_plot_and_validate_input(fig, ax)\n    apply_max_extent()\n    color_rgba, scalarmapper, norm = setup_color_mapping(scalarmapper, norm)\n    apply_frame()\n    x, y, c_mask = draw_hexagons()\n    add_colorbar()\n    set_plot_limits(x, y)\n    ax = plt_utils.rm_spines(ax, rm_xticks=True, rm_yticks=True)\n    annotate_hexagons(x, y, c_mask)\n    label_text = add_label()\n\n    (xmin, ymin, xmax, ymax) = ax.dataLim.extents\n    ax.set_xlim(plt_utils.get_lims((xmin, xmax), 0.01))\n    ax.set_ylim(plt_utils.get_lims((ymin, ymax), 0.01))\n\n    return fig, ax, (label_text, scalarmapper)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.kernel","title":"flyvis.analysis.visualization.plots.kernel","text":"<pre><code>kernel(u, v, values, fontsize=5, cbar=True, edgecolor='k', fig=None, ax=None, figsize=(1, 1), midpoint=0, annotate=True, alpha=0.8, annotate_coords=False, coord_fs=8, cbar_height=0.3, cbar_x_offset=-1, **kwargs)\n</code></pre> <p>Plot receptive fields with hex_scatter.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>Array of hex coordinates in u direction.</p> required <code>v</code> <code>NDArray</code> <p>Array of hex coordinates in v direction.</p> required <code>color</code> <p>Array of pixel values per point (u_i, v_i).</p> required <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>5</code> <code>cbar</code> <code>bool</code> <p>Whether to show a colorbar.</p> <code>True</code> <code>edgecolor</code> <code>str</code> <p>Color of the hexagon edges.</p> <code>'k'</code> <code>fig</code> <code>Optional[Figure]</code> <p>Matplotlib Figure object.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib Axes object.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(1, 1)</code> <code>midpoint</code> <code>float</code> <p>Midpoint for color mapping.</p> <code>0</code> <code>annotate</code> <code>bool</code> <p>Whether to annotate hexagons with values.</p> <code>True</code> <code>alpha</code> <code>float</code> <p>Alpha value for transparency.</p> <code>0.8</code> <code>annotate_coords</code> <code>bool</code> <p>Whether to annotate hexagons with coordinates.</p> <code>False</code> <code>coord_fs</code> <code>int</code> <p>Font size for coordinate annotations.</p> <code>8</code> <code>cbar_height</code> <code>float</code> <p>Height of the colorbar.</p> <code>0.3</code> <code>cbar_x_offset</code> <code>float</code> <p>X-offset of the colorbar.</p> <code>-1</code> <code>**kwargs</code> <p>Additional keyword arguments passed to hex_scatter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Tuple[Optional[Line2D], ScalarMappable]]</code> <p>A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).</p> <p>Raises:</p> Type Description <code>SignError</code> <p>If signs in the kernel are inconsistent.</p> Note <p>Assigns <code>seismic</code> as colormap and checks that signs are consistent. All arguments except <code>cmap</code> can be passed to hex_scatter.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>@wraps(hex_scatter)\ndef kernel(\n    u: NDArray,\n    v: NDArray,\n    values: NDArray,\n    fontsize: int = 5,\n    cbar: bool = True,\n    edgecolor: str = \"k\",\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    figsize: Tuple[float, float] = (1, 1),\n    midpoint: float = 0,\n    annotate: bool = True,\n    alpha: float = 0.8,\n    annotate_coords: bool = False,\n    coord_fs: int = 8,\n    cbar_height: float = 0.3,\n    cbar_x_offset: float = -1,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes, Tuple[Optional[Line2D], mpl.cm.ScalarMappable]]:\n    \"\"\"Plot receptive fields with hex_scatter.\n\n    Args:\n        u: Array of hex coordinates in u direction.\n        v: Array of hex coordinates in v direction.\n        color: Array of pixel values per point (u_i, v_i).\n        fontsize: Font size for text elements.\n        cbar: Whether to show a colorbar.\n        edgecolor: Color of the hexagon edges.\n        fig: Matplotlib Figure object.\n        ax: Matplotlib Axes object.\n        figsize: Size of the figure.\n        midpoint: Midpoint for color mapping.\n        annotate: Whether to annotate hexagons with values.\n        alpha: Alpha value for transparency.\n        annotate_coords: Whether to annotate hexagons with coordinates.\n        coord_fs: Font size for coordinate annotations.\n        cbar_height: Height of the colorbar.\n        cbar_x_offset: X-offset of the colorbar.\n        **kwargs: Additional keyword arguments passed to hex_scatter.\n\n    Returns:\n        A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).\n\n    Raises:\n        SignError: If signs in the kernel are inconsistent.\n\n    Note:\n        Assigns `seismic` as colormap and checks that signs are consistent.\n        All arguments except `cmap` can be passed to hex_scatter.\n    \"\"\"\n\n    def check_sign_consistency(values: NDArray) -&gt; None:\n        non_zero_signs = set(np.sign(values[np.nonzero(values)]))\n        if len(non_zero_signs) &gt; 1:\n            raise SignError(f\"Inconsistent kernel with signs {non_zero_signs}\")\n\n    check_sign_consistency(values)\n\n    hex_scatter_kwargs = {\n        'u': u,\n        'v': v,\n        'values': values,\n        'fontsize': fontsize,\n        'cbar': cbar,\n        'edgecolor': edgecolor,\n        'fig': fig,\n        'ax': ax,\n        'figsize': figsize,\n        'midpoint': midpoint,\n        'annotate': annotate,\n        'alpha': alpha,\n        'annotate_coords': annotate_coords,\n        'coord_fs': coord_fs,\n        'cbar_height': cbar_height,\n        'cbar_x_offset': cbar_x_offset,\n        'cmap': cm.get_cmap(\"seismic\"),\n        **kwargs,\n    }\n\n    return hex_scatter(**hex_scatter_kwargs)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.hex_cs","title":"flyvis.analysis.visualization.plots.hex_cs","text":"<pre><code>hex_cs(extent=5, mode='default', annotate_coords=True, edgecolor='black', **kwargs)\n</code></pre> <p>Plot a hexagonal coordinate system.</p> <p>Parameters:</p> Name Type Description Default <code>extent</code> <code>int</code> <p>Extent of the hexagonal grid.</p> <code>5</code> <code>mode</code> <code>Literal['default', 'flat']</code> <p>Hex coordinate system mode.</p> <code>'default'</code> <code>annotate_coords</code> <code>bool</code> <p>Whether to annotate hexagons with coordinates.</p> <code>True</code> <code>edgecolor</code> <code>str</code> <p>Color of the hexagon edges.</p> <code>'black'</code> <code>**kwargs</code> <p>Additional keyword arguments passed to hex_scatter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Tuple[Optional[Line2D], ScalarMappable]]</code> <p>A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def hex_cs(\n    extent: int = 5,\n    mode: Literal[\"default\", \"flat\"] = \"default\",\n    annotate_coords: bool = True,\n    edgecolor: str = \"black\",\n    **kwargs,\n) -&gt; Tuple[Figure, Axes, Tuple[Optional[Line2D], mpl.cm.ScalarMappable]]:\n    \"\"\"Plot a hexagonal coordinate system.\n\n    Args:\n        extent: Extent of the hexagonal grid.\n        mode: Hex coordinate system mode.\n        annotate_coords: Whether to annotate hexagons with coordinates.\n        edgecolor: Color of the hexagon edges.\n        **kwargs: Additional keyword arguments passed to hex_scatter.\n\n    Returns:\n        A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).\n    \"\"\"\n    u, v = hex_utils.get_hex_coords(extent)\n    return hex_scatter(\n        u,\n        v,\n        1,\n        cmap=cm.get_cmap(\"binary_r\"),\n        annotate_coords=annotate_coords,\n        vmin=0,\n        vmax=1,\n        edgecolor=edgecolor,\n        cbar=False,\n        mode=mode,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.quick_hex_scatter","title":"flyvis.analysis.visualization.plots.quick_hex_scatter","text":"<pre><code>quick_hex_scatter(values, cmap=cm.get_cmap('binary_r'), **kwargs)\n</code></pre> <p>Create a hex scatter plot with implicit coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>NDArray</code> <p>Array of pixel values.</p> required <code>cmap</code> <code>Colormap</code> <p>Colormap for the plot.</p> <code>get_cmap('binary_r')</code> <code>**kwargs</code> <p>Additional keyword arguments passed to hex_scatter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Tuple[Optional[Line2D], ScalarMappable]]</code> <p>A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def quick_hex_scatter(\n    values: NDArray, cmap: mpl.colors.Colormap = cm.get_cmap(\"binary_r\"), **kwargs\n) -&gt; Tuple[Figure, Axes, Tuple[Optional[Line2D], mpl.cm.ScalarMappable]]:\n    \"\"\"Create a hex scatter plot with implicit coordinates.\n\n    Args:\n        values: Array of pixel values.\n        cmap: Colormap for the plot.\n        **kwargs: Additional keyword arguments passed to hex_scatter.\n\n    Returns:\n        A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper).\n    \"\"\"\n    values = utils.tensor_utils.to_numpy(values.squeeze())\n    u, v = hex_utils.get_hex_coords(hex_utils.get_hextent(len(values)))\n    return hex_scatter(u, v, values, cmap=cmap, **kwargs)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.hex_flow","title":"flyvis.analysis.visualization.plots.hex_flow","text":"<pre><code>hex_flow(u, v, flow, fig=None, ax=None, figsize=(1, 1), title='', cmap=plt_utils.cm_uniform_2d, max_extent=None, cwheelradius=0.25, mode='default', orientation=np.radians(30), origin='lower', fontsize=5, cwheel=True, cwheelxy=(), cwheelpos='southeast', cwheellabelpad=-5, annotate_r=False, annotate_theta=False, annotate_coords=False, coord_fs=3, label='', labelxy=(0, 1), vmin=-np.pi, vmax=np.pi, edgecolor=None, **kwargs)\n</code></pre> <p>Plot a hexagonal lattice with coordinates u, v, and flow.</p> <p>Parameters:</p> Name Type Description Default <code>u</code> <code>NDArray</code> <p>Array of hex coordinates in u direction.</p> required <code>v</code> <code>NDArray</code> <p>Array of hex coordinates in v direction.</p> required <code>flow</code> <code>NDArray</code> <p>Array of flow per point (u_i, v_i), shape [2, len(u)].</p> required <code>fig</code> <code>Optional[Figure]</code> <p>Matplotlib Figure object.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib Axes object.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(1, 1)</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>cmap</code> <code>Colormap</code> <p>Colormap for the plot.</p> <code>cm_uniform_2d</code> <code>max_extent</code> <code>Optional[int]</code> <p>Maximum extent of the hex lattice.</p> <code>None</code> <code>cwheelradius</code> <code>float</code> <p>Radius of the colorwheel.</p> <code>0.25</code> <code>mode</code> <code>Literal['default', 'flat']</code> <p>Hex coordinate system mode.</p> <code>'default'</code> <code>orientation</code> <code>float</code> <p>Orientation of hexagons in radians.</p> <code>radians(30)</code> <code>origin</code> <code>Literal['lower', 'upper']</code> <p>Origin of the plot.</p> <code>'lower'</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>5</code> <code>cwheel</code> <code>bool</code> <p>Whether to show a colorwheel.</p> <code>True</code> <code>cwheelxy</code> <code>Tuple[float, float]</code> <p>Position of the colorwheel.</p> <code>()</code> <code>cwheelpos</code> <code>str</code> <p>Position of the colorwheel.</p> <code>'southeast'</code> <code>cwheellabelpad</code> <code>float</code> <p>Padding for colorwheel labels.</p> <code>-5</code> <code>annotate_r</code> <code>bool</code> <p>Whether to annotate hexagons with magnitude.</p> <code>False</code> <code>annotate_theta</code> <code>bool</code> <p>Whether to annotate hexagons with angle.</p> <code>False</code> <code>annotate_coords</code> <code>bool</code> <p>Whether to annotate hexagons with coordinates.</p> <code>False</code> <code>coord_fs</code> <code>int</code> <p>Font size for coordinate annotations.</p> <code>3</code> <code>label</code> <code>str</code> <p>Label for the plot.</p> <code>''</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Position of the label.</p> <code>(0, 1)</code> <code>vmin</code> <code>float</code> <p>Minimum value for color mapping.</p> <code>-pi</code> <code>vmax</code> <code>float</code> <p>Maximum value for color mapping.</p> <code>pi</code> <code>edgecolor</code> <code>Optional[str]</code> <p>Color of the hexagon edges.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Tuple[Optional[Line2D], ScalarMappable, Optional[Colorbar], Optional[PathCollection]]]</code> <p>A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper, colorbar, scatter).</p> Note <p>Works largely like hex_scatter, but with 2d-flow instead of 1d-intensities.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def hex_flow(\n    u: NDArray,\n    v: NDArray,\n    flow: NDArray,\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    figsize: Tuple[float, float] = (1, 1),\n    title: str = \"\",\n    cmap: mpl.colors.Colormap = plt_utils.cm_uniform_2d,\n    max_extent: Optional[int] = None,\n    cwheelradius: float = 0.25,\n    mode: Literal[\"default\", \"flat\"] = \"default\",\n    orientation: float = np.radians(30),\n    origin: Literal[\"lower\", \"upper\"] = \"lower\",\n    fontsize: int = 5,\n    cwheel: bool = True,\n    cwheelxy: Tuple[float, float] = (),\n    cwheelpos: str = \"southeast\",\n    cwheellabelpad: float = -5,\n    annotate_r: bool = False,\n    annotate_theta: bool = False,\n    annotate_coords: bool = False,\n    coord_fs: int = 3,\n    label: str = \"\",\n    labelxy: Tuple[float, float] = (0, 1),\n    vmin: float = -np.pi,\n    vmax: float = np.pi,\n    edgecolor: Optional[str] = None,\n    **kwargs,\n) -&gt; Tuple[\n    Figure,\n    Axes,\n    Tuple[\n        Optional[Line2D],\n        mpl.cm.ScalarMappable,\n        Optional[mpl.colorbar.Colorbar],\n        Optional[mpl.collections.PathCollection],\n    ],\n]:\n    \"\"\"Plot a hexagonal lattice with coordinates u, v, and flow.\n\n    Args:\n        u: Array of hex coordinates in u direction.\n        v: Array of hex coordinates in v direction.\n        flow: Array of flow per point (u_i, v_i), shape [2, len(u)].\n        fig: Matplotlib Figure object.\n        ax: Matplotlib Axes object.\n        figsize: Size of the figure.\n        title: Title of the plot.\n        cmap: Colormap for the plot.\n        max_extent: Maximum extent of the hex lattice.\n        cwheelradius: Radius of the colorwheel.\n        mode: Hex coordinate system mode.\n        orientation: Orientation of hexagons in radians.\n        origin: Origin of the plot.\n        fontsize: Font size for text elements.\n        cwheel: Whether to show a colorwheel.\n        cwheelxy: Position of the colorwheel.\n        cwheelpos: Position of the colorwheel.\n        cwheellabelpad: Padding for colorwheel labels.\n        annotate_r: Whether to annotate hexagons with magnitude.\n        annotate_theta: Whether to annotate hexagons with angle.\n        annotate_coords: Whether to annotate hexagons with coordinates.\n        coord_fs: Font size for coordinate annotations.\n        label: Label for the plot.\n        labelxy: Position of the label.\n        vmin: Minimum value for color mapping.\n        vmax: Maximum value for color mapping.\n        edgecolor: Color of the hexagon edges.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing the Figure, Axes, and a tuple of\n            (label_text, scalarmapper, colorbar, scatter).\n\n    Note:\n        Works largely like hex_scatter, but with 2d-flow instead of 1d-intensities.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(figsize, title, fontsize, ax, fig)\n    ax.set_aspect(\"equal\")\n\n    if max_extent:\n        max_extent_index = hex_utils.max_extent_index(u, v, max_extent=max_extent)\n        flow = flow[:, max_extent_index]\n        u = u[max_extent_index]\n        v = v[max_extent_index]\n\n    r = np.linalg.norm(flow, axis=0)\n    r /= r.max()\n    theta = np.arctan2(flow[1], flow[0])\n\n    vmin = vmin if vmin else theta.min()\n    vmax = vmax if vmax else theta.max()\n    scalarmapper, _ = plt_utils.get_scalarmapper(\n        cmap=cmap, vmin=vmin, vmax=vmax, midpoint=0.0\n    )\n    color_rgba = scalarmapper.to_rgba(theta)\n    color_rgba[:, -1] = r\n\n    x, y = hex_utils.hex_to_pixel(u, v, mode=mode)\n    if origin == \"upper\":\n        y = y[::-1]\n\n    def draw_hexagons():\n        for _x, _y, c in zip(x, y, color_rgba):\n            _hex = RegularPolygon(\n                (_x, _y),\n                numVertices=6,\n                radius=1,\n                linewidth=0.5,\n                orientation=orientation,\n                edgecolor=edgecolor or c,\n                facecolor=c,\n            )\n            ax.add_patch(_hex)\n\n    draw_hexagons()\n\n    if cwheel:\n        x_offset, y_offset = cwheelxy or (0, 0)\n        cb, cs = plt_utils.add_colorwheel_2d(\n            fig,\n            [ax],\n            radius=cwheelradius,\n            pos=cwheelpos,\n            sm=scalarmapper,\n            fontsize=fontsize,\n            x_offset=x_offset,\n            y_offset=y_offset,\n            N=1024,\n            labelpad=cwheellabelpad,\n        )\n\n    extent = hex_utils.get_extent(u, v)\n    ax.set_xlim(x.min() + x.min() / extent, x.max() + x.max() / extent)\n    ax.set_ylim(y.min() + y.min() / extent, y.max() + y.max() / extent)\n\n    ax = plt_utils.rm_spines(ax, rm_xticks=True, rm_yticks=True)\n\n    if annotate_r:\n        for _r, _x, _y in zip(r, x, y):\n            ax.annotate(\n                f\"{_r:.2G}\",\n                fontsize=fontsize,\n                xy=(_x, _y),\n                xytext=(0, 0),\n                textcoords=\"offset points\",\n                ha=\"center\",\n                va=\"center\",\n            )\n\n    if annotate_theta:\n        for _theta, _x, _y in zip(np.degrees(theta), x, y):\n            ax.annotate(\n                f\"{_theta:.2f}\",\n                fontsize=fontsize,\n                xy=(_x, _y),\n                xytext=(0, 0),\n                textcoords=\"offset points\",\n                ha=\"center\",\n                va=\"center\",\n            )\n\n    if annotate_coords:\n        for _x, _y, _u, _v in zip(x, y, u, v):\n            ax.annotate(\n                _u,\n                fontsize=coord_fs,\n                xy=(_x, _y),\n                xytext=np.array([-0.25, 0.25]),\n                textcoords=\"offset points\",\n                ha=\"center\",\n                va=\"center\",\n            )\n            ax.annotate(\n                _v,\n                fontsize=coord_fs,\n                xy=(_x, _y),\n                xytext=np.array([0.25, 0.25]),\n                textcoords=\"offset points\",\n                ha=\"center\",\n                va=\"center\",\n            )\n\n    label_text = None\n    if label:\n        label_text = ax.text(\n            labelxy[0],\n            labelxy[1],\n            label,\n            transform=ax.transAxes,\n            ha=\"left\",\n            va=\"center\",\n            fontsize=fontsize,\n        )\n\n    if cwheel:\n        return fig, ax, (label_text, scalarmapper, cb, cs)\n    return fig, ax, (label_text, scalarmapper, None, None)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.quick_hex_flow","title":"flyvis.analysis.visualization.plots.quick_hex_flow","text":"<pre><code>quick_hex_flow(flow, **kwargs)\n</code></pre> <p>Plot a flow field on a hexagonal lattice with implicit coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <code>NDArray</code> <p>Array of flow values.</p> required <code>**kwargs</code> <p>Additional keyword arguments passed to hex_flow.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, Tuple[Optional[Line2D], ScalarMappable, Optional[Colorbar], Optional[PathCollection]]]</code> <p>A tuple containing the Figure, Axes, and a tuple of (label_text, scalarmapper, colorbar, scatter).</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def quick_hex_flow(\n    flow: NDArray, **kwargs\n) -&gt; Tuple[\n    Figure,\n    Axes,\n    Tuple[\n        Optional[Line2D],\n        mpl.cm.ScalarMappable,\n        Optional[mpl.colorbar.Colorbar],\n        Optional[mpl.collections.PathCollection],\n    ],\n]:\n    \"\"\"Plot a flow field on a hexagonal lattice with implicit coordinates.\n\n    Args:\n        flow: Array of flow values.\n        **kwargs: Additional keyword arguments passed to hex_flow.\n\n    Returns:\n        A tuple containing the Figure, Axes, and a tuple of\n            (label_text, scalarmapper, colorbar, scatter).\n    \"\"\"\n    flow = utils.tensor_utils.to_numpy(flow.squeeze())\n    u, v = hex_utils.get_hex_coords(hex_utils.get_hextent(flow.shape[-1]))\n    return hex_flow(u, v, flow, **kwargs)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.flow_to_rgba","title":"flyvis.analysis.visualization.plots.flow_to_rgba","text":"<pre><code>flow_to_rgba(flow)\n</code></pre> <p>Map cartesian flow to RGBA colors.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <code>Union[ndarray, Tensor]</code> <p>Flow field of shape (2, h, w).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>RGBA color representation of the flow field.</p> Note <p>The flow magnitude is mapped to the alpha channel, while the flow direction is mapped to the color using a uniform 2D colormap.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def flow_to_rgba(flow: Union[np.ndarray, torch.Tensor]) -&gt; np.ndarray:\n    \"\"\"Map cartesian flow to RGBA colors.\n\n    Args:\n        flow: Flow field of shape (2, h, w).\n\n    Returns:\n        RGBA color representation of the flow field.\n\n    Note:\n        The flow magnitude is mapped to the alpha channel, while the flow\n        direction is mapped to the color using a uniform 2D colormap.\n    \"\"\"\n    if isinstance(flow, torch.Tensor):\n        flow = flow.cpu().numpy()\n\n    X, Y = flow[0], flow[1]\n    R = np.sqrt(X * X + Y * Y)\n    PHI = np.arctan2(Y, X)\n    scalarmapper, _ = plt_utils.get_scalarmapper(\n        cmap=plt_utils.cm_uniform_2d, vmin=-np.pi, vmax=np.pi\n    )\n    rgba = scalarmapper.to_rgba(PHI)\n    rgba[:, :, -1] = R / R.max()\n    return rgba\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.plot_flow","title":"flyvis.analysis.visualization.plots.plot_flow","text":"<pre><code>plot_flow(flow)\n</code></pre> <p>Plot cartesian flow.</p> <p>Parameters:</p> Name Type Description Default <code>flow</code> <code>Union[ndarray, Tensor]</code> <p>Flow field of shape (2, h, w).</p> required Note <p>This function displays the flow field using matplotlib\u2019s imshow and immediately shows the plot.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def plot_flow(flow: Union[np.ndarray, torch.Tensor]) -&gt; None:\n    \"\"\"Plot cartesian flow.\n\n    Args:\n        flow: Flow field of shape (2, h, w).\n\n    Note:\n        This function displays the flow field using matplotlib's imshow\n        and immediately shows the plot.\n    \"\"\"\n    rgba = flow_to_rgba(flow)\n    plt.imshow(rgba)\n    plt.show()\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.traces","title":"flyvis.analysis.visualization.plots.traces","text":"<pre><code>traces(trace, x=None, contour=None, legend=(), smooth=None, stim_line=None, contour_cmap=cm.get_cmap('bone'), color=None, label='', labelxy=(0, 1), linewidth=1, ax=None, fig=None, title='', highlight_mean=False, figsize=(7, 4), fontsize=10, ylim=None, ylabel='', xlabel='', legend_frame_alpha=0, contour_mode='full', contour_y_rel=0.06, fancy=False, scale_pos=None, scale_label='100ms', null_line=False, zorder_traces=None, zorder_mean=None, **kwargs)\n</code></pre> <p>Create a line plot with optional contour and smoothing.</p> <p>Parameters:</p> Name Type Description Default <code>trace</code> <code>NDArray</code> <p>2D array (n_traces, n_points) of trace values.</p> required <code>x</code> <code>Optional[NDArray]</code> <p>X-axis values.</p> <code>None</code> <code>contour</code> <code>Optional[NDArray]</code> <p>Array of contour values.</p> <code>None</code> <code>legend</code> <code>Tuple[str, ...]</code> <p>Legend for each trace.</p> <code>()</code> <code>smooth</code> <code>Optional[float]</code> <p>Size of smoothing window in percent of #points.</p> <code>None</code> <code>stim_line</code> <code>Optional[NDArray]</code> <p>Stimulus line data.</p> <code>None</code> <code>contour_cmap</code> <code>Colormap</code> <p>Colormap for the contour.</p> <code>get_cmap('bone')</code> <code>color</code> <code>Optional[Union[str, List[str]]]</code> <p>Color(s) for the traces.</p> <code>None</code> <code>label</code> <code>str</code> <p>Label for the plot.</p> <code>''</code> <code>labelxy</code> <code>Tuple[float, float]</code> <p>Position of the label.</p> <code>(0, 1)</code> <code>linewidth</code> <code>float</code> <p>Width of the trace lines.</p> <code>1</code> <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib Axes object.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Matplotlib Figure object.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>highlight_mean</code> <code>bool</code> <p>Whether to highlight the mean trace.</p> <code>False</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(7, 4)</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>10</code> <code>ylim</code> <code>Optional[Tuple[float, float]]</code> <p>Y-axis limits.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> <code>''</code> <code>xlabel</code> <code>str</code> <p>X-axis label.</p> <code>''</code> <code>legend_frame_alpha</code> <code>float</code> <p>Alpha value for the legend frame.</p> <code>0</code> <code>contour_mode</code> <code>Literal['full', 'top', 'bottom']</code> <p>Mode for contour plotting.</p> <code>'full'</code> <code>contour_y_rel</code> <code>float</code> <p>Relative Y position for contour in \u201ctop\u201d or \u201cbottom\u201d mode.</p> <code>0.06</code> <code>fancy</code> <code>bool</code> <p>Whether to use fancy styling.</p> <code>False</code> <code>scale_pos</code> <code>Optional[str]</code> <p>Position of the scale bar.</p> <code>None</code> <code>scale_label</code> <code>str</code> <p>Label for the scale bar.</p> <code>'100ms'</code> <code>null_line</code> <code>bool</code> <p>Whether to draw a null line at y=0.</p> <code>False</code> <code>zorder_traces</code> <code>Optional[int]</code> <p>Z-order for traces.</p> <code>None</code> <code>zorder_mean</code> <code>Optional[int]</code> <p>Z-order for mean trace.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes, NDArray, Optional[Line2D]]</code> <p>A tuple containing the Figure, Axes, smoothed trace, and label text.</p> Note <p>This function creates a line plot with various options for customization, including contour plotting and trace smoothing.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def traces(\n    trace: NDArray,\n    x: Optional[NDArray] = None,\n    contour: Optional[NDArray] = None,\n    legend: Tuple[str, ...] = (),\n    smooth: Optional[float] = None,\n    stim_line: Optional[NDArray] = None,\n    contour_cmap: mpl.colors.Colormap = cm.get_cmap(\"bone\"),\n    color: Optional[Union[str, List[str]]] = None,\n    label: str = \"\",\n    labelxy: Tuple[float, float] = (0, 1),\n    linewidth: float = 1,\n    ax: Optional[Axes] = None,\n    fig: Optional[Figure] = None,\n    title: str = \"\",\n    highlight_mean: bool = False,\n    figsize: Tuple[float, float] = (7, 4),\n    fontsize: int = 10,\n    ylim: Optional[Tuple[float, float]] = None,\n    ylabel: str = \"\",\n    xlabel: str = \"\",\n    legend_frame_alpha: float = 0,\n    contour_mode: Literal[\"full\", \"top\", \"bottom\"] = \"full\",\n    contour_y_rel: float = 0.06,\n    fancy: bool = False,\n    scale_pos: Optional[str] = None,\n    scale_label: str = \"100ms\",\n    null_line: bool = False,\n    zorder_traces: Optional[int] = None,\n    zorder_mean: Optional[int] = None,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes, NDArray, Optional[Line2D]]:\n    \"\"\"Create a line plot with optional contour and smoothing.\n\n    Args:\n        trace: 2D array (n_traces, n_points) of trace values.\n        x: X-axis values.\n        contour: Array of contour values.\n        legend: Legend for each trace.\n        smooth: Size of smoothing window in percent of #points.\n        stim_line: Stimulus line data.\n        contour_cmap: Colormap for the contour.\n        color: Color(s) for the traces.\n        label: Label for the plot.\n        labelxy: Position of the label.\n        linewidth: Width of the trace lines.\n        ax: Matplotlib Axes object.\n        fig: Matplotlib Figure object.\n        title: Title of the plot.\n        highlight_mean: Whether to highlight the mean trace.\n        figsize: Size of the figure.\n        fontsize: Font size for text elements.\n        ylim: Y-axis limits.\n        ylabel: Y-axis label.\n        xlabel: X-axis label.\n        legend_frame_alpha: Alpha value for the legend frame.\n        contour_mode: Mode for contour plotting.\n        contour_y_rel: Relative Y position for contour in \"top\" or \"bottom\" mode.\n        fancy: Whether to use fancy styling.\n        scale_pos: Position of the scale bar.\n        scale_label: Label for the scale bar.\n        null_line: Whether to draw a null line at y=0.\n        zorder_traces: Z-order for traces.\n        zorder_mean: Z-order for mean trace.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing the Figure, Axes, smoothed trace, and label text.\n\n    Note:\n        This function creates a line plot with various options for customization,\n        including contour plotting and trace smoothing.\n    \"\"\"\n    trace = np.atleast_2d(np.array(trace))\n\n    if np.ma.masked_invalid(trace).mask.any():\n        logging.debug(\"Invalid values encountered in trace.\")\n\n    # Smooth traces.\n    if smooth:\n        smooth = int(smooth * trace.shape[1])\n        ylabel += \" (smoothed)\"\n        trace = plt_utils.avg_pool(trace, smooth)\n        if x is not None:\n            x = x[0::smooth][: trace.shape[1]]\n\n    shape = trace.shape\n\n    fig, ax = plt_utils.init_plot(figsize, title, fontsize, ax=ax, fig=fig)\n\n    legends = legend if len(legend) == shape[0] else (\"\",) * shape[0]\n\n    if len(np.shape(color)) &lt;= 1:\n        colors = (color,) * shape[0]\n    elif len(color) == shape[0]:\n        colors = color\n    else:\n        colors = (None,) * shape[0]\n\n    # Plot traces.\n    iterations = np.arange(trace.shape[1]) if x is None else x\n    for i, _trace in enumerate(trace):\n        ax.plot(\n            iterations,\n            _trace,\n            label=legends[i],\n            c=colors[i],\n            linewidth=linewidth,\n            zorder=zorder_traces,\n        )\n\n    if highlight_mean:\n        ax.plot(\n            iterations,\n            np.mean(trace, axis=0),\n            linewidth=0.5,\n            c=\"k\",\n            label=\"average\",\n            zorder=zorder_mean,\n        )\n\n    if contour is not None and contour_mode is not None:\n        ylim = ylim or plt_utils.get_lims(\n            np.array([\n                min(contour.min(), trace.min()),\n                max(contour.max(), trace.max()),\n            ]),\n            0.1,\n        )\n\n        _x = np.arange(len(contour)) if x is None or len(x) != len(contour) else x\n        if contour_mode == \"full\":\n            contour_y_range = (-20_000, 20_000)\n        elif contour_mode == \"top\":\n            yrange = ylim[1] - ylim[0]\n            contour_y_range = (ylim[1], ylim[1] + yrange * contour_y_rel)\n            ylim = (ylim[0], contour_y_range[1])\n        elif contour_mode == \"bottom\":\n            yrange = ylim[1] - ylim[0]\n            contour_y_range = (ylim[0] - yrange * contour_y_rel, ylim[0])\n            ylim = (contour_y_range[0], ylim[1])\n\n        _y = np.linspace(*contour_y_range, 100)\n        Z = np.tile(contour, (len(_y), 1))\n        ax.contourf(\n            _x,\n            _y,\n            Z,\n            cmap=contour_cmap,\n            levels=2,\n            alpha=0.3,\n            vmin=0,\n            vmax=1,\n        )\n\n        if stim_line is not None:\n            ax.plot(x, contour, color=\"k\", linestyle=\"--\")\n\n    # Cosmetics.\n    ax.set_xlabel(xlabel, fontsize=fontsize)\n    ax.set_ylabel(ylabel, fontsize=fontsize)\n    if null_line:\n        ax.hlines(\n            0,\n            -20_000,\n            20_000,\n            color=\"0.5\",\n            zorder=-1,\n            linewidth=0.5,\n        )\n    ax.set_xlim(*plt_utils.get_lims(iterations, 0.01))\n    ax.tick_params(labelsize=fontsize)\n    if legend:\n        ax.legend(\n            fontsize=fontsize,\n            edgecolor=\"white\",\n            **dict(\n                labelspacing=0.0,\n                framealpha=legend_frame_alpha,\n                borderaxespad=0.1,\n                borderpad=0.1,\n                handlelength=1,\n                handletextpad=0.3,\n            ),\n        )\n    if ylim is not None:\n        ax.set_ylim(*ylim)\n\n    label_text = None\n    if label != \"\":\n        label_text = ax.text(\n            labelxy[0],\n            labelxy[1],\n            label,\n            transform=ax.transAxes,\n            ha=\"left\",\n            va=\"center\",\n            fontsize=fontsize,\n        )\n\n    if scale_pos and not any([isinstance(a, AnchoredSizeBar) for a in ax.artists]):\n        scalebar = AnchoredSizeBar(\n            ax.transData,\n            size=0.1,\n            label=scale_label,\n            loc=scale_pos,\n            pad=0.4,\n            frameon=False,\n            size_vertical=0.01 * (ax.get_ylim()[1] - ax.get_ylim()[0]),\n            fontproperties=dict(size=fontsize),\n        )\n        ax.add_artist(scalebar)\n\n    if fancy:\n        plt_utils.rm_spines(ax, (\"left\", \"bottom\"), rm_yticks=True, rm_xticks=True)\n\n    return fig, ax, trace, label_text\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.grouped_traces","title":"flyvis.analysis.visualization.plots.grouped_traces","text":"<pre><code>grouped_traces(trace_groups, x=None, legend=(), color=None, linewidth=1, ax=None, fig=None, title='', highlight_mean=False, figsize=(7, 4), fontsize=10, ylim=None, ylabel='', xlabel='', legend_frame_alpha=0, **kwargs)\n</code></pre> <p>Create a line plot with grouped traces.</p> <p>Parameters:</p> Name Type Description Default <code>trace_groups</code> <code>List[ndarray]</code> <p>List of 2D arrays, each containing trace values.</p> required <code>x</code> <code>Optional[ndarray]</code> <p>X-axis values.</p> <code>None</code> <code>legend</code> <code>Tuple[str, ...]</code> <p>Legend for each trace group.</p> <code>()</code> <code>color</code> <code>Optional[Union[str, List[str]]]</code> <p>Color(s) for the trace groups.</p> <code>None</code> <code>linewidth</code> <code>float</code> <p>Width of the trace lines.</p> <code>1</code> <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib Axes object.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Matplotlib Figure object.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>highlight_mean</code> <code>bool</code> <p>Whether to highlight the mean trace.</p> <code>False</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(7, 4)</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>10</code> <code>ylim</code> <code>Optional[Tuple[float, float]]</code> <p>Y-axis limits.</p> <code>None</code> <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> <code>''</code> <code>xlabel</code> <code>str</code> <p>X-axis label.</p> <code>''</code> <code>legend_frame_alpha</code> <code>float</code> <p>Alpha value for the legend frame.</p> <code>0</code> <code>**kwargs</code> <p>Additional keyword arguments passed to traces().</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def grouped_traces(\n    trace_groups: List[np.ndarray],\n    x: Optional[np.ndarray] = None,\n    legend: Tuple[str, ...] = (),\n    color: Optional[Union[str, List[str]]] = None,\n    linewidth: float = 1,\n    ax: Optional[Axes] = None,\n    fig: Optional[Figure] = None,\n    title: str = \"\",\n    highlight_mean: bool = False,\n    figsize: Tuple[float, float] = (7, 4),\n    fontsize: int = 10,\n    ylim: Optional[Tuple[float, float]] = None,\n    ylabel: str = \"\",\n    xlabel: str = \"\",\n    legend_frame_alpha: float = 0,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"Create a line plot with grouped traces.\n\n    Args:\n        trace_groups: List of 2D arrays, each containing trace values.\n        x: X-axis values.\n        legend: Legend for each trace group.\n        color: Color(s) for the trace groups.\n        linewidth: Width of the trace lines.\n        ax: Matplotlib Axes object.\n        fig: Matplotlib Figure object.\n        title: Title of the plot.\n        highlight_mean: Whether to highlight the mean trace.\n        figsize: Size of the figure.\n        fontsize: Font size for text elements.\n        ylim: Y-axis limits.\n        ylabel: Y-axis label.\n        xlabel: X-axis label.\n        legend_frame_alpha: Alpha value for the legend frame.\n        **kwargs: Additional keyword arguments passed to traces().\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(figsize, title, fontsize, ax=ax, fig=fig)\n\n    legends = legend if len(legend) == len(trace_groups) else (\"\",) * len(trace_groups)\n\n    if color is None:\n        color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n        colors = [color_cycle[i % len(color_cycle)] for i in range(len(trace_groups))]\n    elif len(np.shape(color)) &lt;= 1:\n        colors = (color,) * len(trace_groups)\n    elif len(color) == len(trace_groups) or (\n        len(trace_groups) == 1 and len(color) == trace_groups[0].shape[0]\n    ):\n        colors = color\n    else:\n        raise ValueError(\n            \"`color` should be a single value, an iterable of length \"\n            f\"`traces.shape[0]`, or None. Got {color} of shape {np.shape(color)}. \"\n            f\"Expected {np.shape(trace_groups)}.\"\n        )\n\n    for i, _trace in enumerate(trace_groups):\n        fig, ax, *_ = traces(\n            trace=_trace,\n            x=x,\n            legend=(),\n            color=colors[i],\n            linewidth=linewidth,\n            ax=ax,\n            fig=fig,\n            title=title,\n            highlight_mean=highlight_mean,\n            figsize=figsize,\n            fontsize=fontsize,\n            ylim=ylim,\n            ylabel=ylabel,\n            xlabel=xlabel,\n            legend_frame_alpha=legend_frame_alpha,\n            **kwargs,\n        )\n    if legend:\n        custom_lines = [Line2D([0], [0], color=c) for c in colors]\n        ax.legend(\n            custom_lines,\n            legends,\n            fontsize=fontsize,\n            edgecolor=\"white\",\n            **dict(\n                labelspacing=0.0,\n                framealpha=legend_frame_alpha,\n                borderaxespad=0.1,\n                borderpad=0.1,\n                handlelength=1,\n                handletextpad=0.3,\n            ),\n        )\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.get_violin_x_locations","title":"flyvis.analysis.visualization.plots.get_violin_x_locations","text":"<pre><code>get_violin_x_locations(n_groups, n_random_variables, violin_width)\n</code></pre> <p>Calculate x-axis locations for violin plots.</p> <p>Parameters:</p> Name Type Description Default <code>n_groups</code> <code>int</code> <p>Number of groups.</p> required <code>n_random_variables</code> <code>int</code> <p>Number of random variables.</p> required <code>violin_width</code> <code>float</code> <p>Width of each violin plot.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A tuple containing:</p> <code>ndarray</code> <ul> <li>np.ndarray: 2D array of violin locations.</li> </ul> <code>Tuple[ndarray, ndarray]</code> <ul> <li>np.ndarray: 1D array of first violin locations.</li> </ul> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def get_violin_x_locations(\n    n_groups: int, n_random_variables: int, violin_width: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate x-axis locations for violin plots.\n\n    Args:\n        n_groups: Number of groups.\n        n_random_variables: Number of random variables.\n        violin_width: Width of each violin plot.\n\n    Returns:\n        A tuple containing:\n        - np.ndarray: 2D array of violin locations.\n        - np.ndarray: 1D array of first violin locations.\n    \"\"\"\n    violin_locations = np.zeros([n_groups, n_random_variables])\n    first_violins_location = np.arange(0, n_groups * n_random_variables, n_groups)\n    for j in range(n_groups):\n        violin_locations[j] = first_violins_location + j * violin_width\n\n    return violin_locations, first_violins_location\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.violin_groups","title":"flyvis.analysis.visualization.plots.violin_groups","text":"<pre><code>violin_groups(values, xticklabels=None, pvalues=None, display_pvalues_kwargs={}, legend=False, legend_kwargs={}, as_bars=False, colors=None, cmap=mpl.colormaps['tab10'], cstart=0, cdist=1, figsize=(10, 1), title='', ylabel=None, ylim=None, rotation=90, width=0.7, fontsize=6, ax=None, fig=None, showmeans=False, showmedians=True, grid=False, scatter=True, scatter_radius=3, scatter_edge_color=None, scatter_edge_width=0.5, violin_alpha=0.5, violin_marker_lw=0.5, violin_marker_color='k', color_by='groups', zorder_mean_median=5, zorder_min_max=5, mean_median_linewidth=0.5, mean_median_color='k', mean_median_bar_length=None, **kwargs)\n</code></pre> <p>Create violin plots or bar plots for grouped data.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>Array of shape (n_random_variables, n_groups, n_samples).</p> required <code>xticklabels</code> <code>Optional[List[str]]</code> <p>Labels for the x-axis ticks (random variables).</p> <code>None</code> <code>pvalues</code> <code>Optional[ndarray]</code> <p>Array of p-values for statistical significance.</p> <code>None</code> <code>display_pvalues_kwargs</code> <code>dict</code> <p>Keyword arguments for displaying p-values.</p> <code>{}</code> <code>legend</code> <code>Union[bool, List[str]]</code> <p>If True or a list, display a legend with group labels.</p> <code>False</code> <code>legend_kwargs</code> <code>dict</code> <p>Keyword arguments for the legend.</p> <code>{}</code> <code>as_bars</code> <code>bool</code> <p>If True, create bar plots instead of violin plots.</p> <code>False</code> <code>colors</code> <code>Optional[List[str]]</code> <p>List of colors for the violins or bars.</p> <code>None</code> <code>cmap</code> <code>Colormap</code> <p>Colormap to use when colors are not provided.</p> <code>colormaps['tab10']</code> <code>cstart</code> <code>float</code> <p>Starting point in the colormap.</p> <code>0</code> <code>cdist</code> <code>float</code> <p>Distance between colors in the colormap.</p> <code>1</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure (width, height).</p> <code>(10, 1)</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>ylabel</code> <code>Optional[str]</code> <p>Label for the y-axis.</p> <code>None</code> <code>ylim</code> <code>Optional[Tuple[float, float]]</code> <p>Limits for the y-axis (min, max).</p> <code>None</code> <code>rotation</code> <code>float</code> <p>Rotation angle for x-axis labels.</p> <code>90</code> <code>width</code> <code>float</code> <p>Width of the violins or bars.</p> <code>0.7</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and ticks.</p> <code>6</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axes object to plot on.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure object to use.</p> <code>None</code> <code>showmeans</code> <code>bool</code> <p>If True, show mean lines on violins.</p> <code>False</code> <code>showmedians</code> <code>bool</code> <p>If True, show median lines on violins.</p> <code>True</code> <code>grid</code> <code>bool</code> <p>If True, display a grid.</p> <code>False</code> <code>scatter</code> <code>bool</code> <p>If True, scatter individual data points.</p> <code>True</code> <code>scatter_radius</code> <code>float</code> <p>Size of scattered points.</p> <code>3</code> <code>scatter_edge_color</code> <code>Optional[str]</code> <p>Color of scattered point edges.</p> <code>None</code> <code>scatter_edge_width</code> <code>float</code> <p>Width of scattered point edges.</p> <code>0.5</code> <code>violin_alpha</code> <code>float</code> <p>Alpha (transparency) of violin plots.</p> <code>0.5</code> <code>violin_marker_lw</code> <code>float</code> <p>Line width of violin markers.</p> <code>0.5</code> <code>violin_marker_color</code> <code>str</code> <p>Color of violin markers.</p> <code>'k'</code> <code>color_by</code> <code>Literal['groups', 'experiments']</code> <p>Whether to color by \u201cgroups\u201d or \u201cexperiments\u201d.</p> <code>'groups'</code> <code>zorder_mean_median</code> <code>int</code> <p>Z-order for mean and median lines.</p> <code>5</code> <code>zorder_min_max</code> <code>int</code> <p>Z-order for min and max lines.</p> <code>5</code> <code>mean_median_linewidth</code> <code>float</code> <p>Line width for mean and median lines.</p> <code>0.5</code> <code>mean_median_color</code> <code>str</code> <p>Color for mean and median lines.</p> <code>'k'</code> <code>mean_median_bar_length</code> <code>Optional[float]</code> <p>Length of mean and median bars.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>A tuple containing:</p> <code>Axes</code> <ul> <li>Figure: The matplotlib Figure object.</li> </ul> <code>ViolinData</code> <ul> <li>Axes: The matplotlib Axes object.</li> </ul> <code>Tuple[Figure, Axes, ViolinData]</code> <ul> <li>ViolinData: A custom object containing plot data.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If color specifications are invalid.</p> Note <p>This function creates either violin plots or bar plots for grouped data, with options for customizing colors, scatter plots, and statistical annotations.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def violin_groups(\n    values: np.ndarray,\n    xticklabels: Optional[List[str]] = None,\n    pvalues: Optional[np.ndarray] = None,\n    display_pvalues_kwargs: dict = {},\n    legend: Union[bool, List[str]] = False,\n    legend_kwargs: dict = {},\n    as_bars: bool = False,\n    colors: Optional[List[str]] = None,\n    cmap: mpl.colors.Colormap = mpl.colormaps[\"tab10\"],\n    cstart: float = 0,\n    cdist: float = 1,\n    figsize: Tuple[float, float] = (10, 1),\n    title: str = \"\",\n    ylabel: Optional[str] = None,\n    ylim: Optional[Tuple[float, float]] = None,\n    rotation: float = 90,\n    width: float = 0.7,\n    fontsize: int = 6,\n    ax: Optional[Axes] = None,\n    fig: Optional[Figure] = None,\n    showmeans: bool = False,\n    showmedians: bool = True,\n    grid: bool = False,\n    scatter: bool = True,\n    scatter_radius: float = 3,\n    scatter_edge_color: Optional[str] = None,\n    scatter_edge_width: float = 0.5,\n    violin_alpha: float = 0.5,\n    violin_marker_lw: float = 0.5,\n    violin_marker_color: str = \"k\",\n    color_by: Literal[\"groups\", \"experiments\"] = \"groups\",\n    zorder_mean_median: int = 5,\n    zorder_min_max: int = 5,\n    mean_median_linewidth: float = 0.5,\n    mean_median_color: str = \"k\",\n    mean_median_bar_length: Optional[float] = None,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes, ViolinData]:\n    \"\"\"\n    Create violin plots or bar plots for grouped data.\n\n    Args:\n        values: Array of shape (n_random_variables, n_groups, n_samples).\n        xticklabels: Labels for the x-axis ticks (random variables).\n        pvalues: Array of p-values for statistical significance.\n        display_pvalues_kwargs: Keyword arguments for displaying p-values.\n        legend: If True or a list, display a legend with group labels.\n        legend_kwargs: Keyword arguments for the legend.\n        as_bars: If True, create bar plots instead of violin plots.\n        colors: List of colors for the violins or bars.\n        cmap: Colormap to use when colors are not provided.\n        cstart: Starting point in the colormap.\n        cdist: Distance between colors in the colormap.\n        figsize: Size of the figure (width, height).\n        title: Title of the plot.\n        ylabel: Label for the y-axis.\n        ylim: Limits for the y-axis (min, max).\n        rotation: Rotation angle for x-axis labels.\n        width: Width of the violins or bars.\n        fontsize: Font size for labels and ticks.\n        ax: Existing Axes object to plot on.\n        fig: Existing Figure object to use.\n        showmeans: If True, show mean lines on violins.\n        showmedians: If True, show median lines on violins.\n        grid: If True, display a grid.\n        scatter: If True, scatter individual data points.\n        scatter_radius: Size of scattered points.\n        scatter_edge_color: Color of scattered point edges.\n        scatter_edge_width: Width of scattered point edges.\n        violin_alpha: Alpha (transparency) of violin plots.\n        violin_marker_lw: Line width of violin markers.\n        violin_marker_color: Color of violin markers.\n        color_by: Whether to color by \"groups\" or \"experiments\".\n        zorder_mean_median: Z-order for mean and median lines.\n        zorder_min_max: Z-order for min and max lines.\n        mean_median_linewidth: Line width for mean and median lines.\n        mean_median_color: Color for mean and median lines.\n        mean_median_bar_length: Length of mean and median bars.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing:\n        - Figure: The matplotlib Figure object.\n        - Axes: The matplotlib Axes object.\n        - ViolinData: A custom object containing plot data.\n\n    Raises:\n        ValueError: If color specifications are invalid.\n\n    Note:\n        This function creates either violin plots or bar plots for grouped data,\n        with options for customizing colors, scatter plots, and statistical annotations.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(figsize, title, fontsize, ax, fig)\n    if grid:\n        ax.yaxis.grid(zorder=-100)\n\n    def plot_bar(X: float, values: np.ndarray, color: str) -&gt; mpl.patches.Rectangle:\n        handle = ax.bar(x=X, width=width, height=np.mean(values), color=color, zorder=1)\n        return handle\n\n    def plot_violin(\n        X: float, values: np.ndarray, color: str\n    ) -&gt; mpl.collections.PolyCollection:\n        if isinstance(values, np.ma.core.MaskedArray):\n            values = values[~values.mask]\n\n        parts = ax.violinplot(\n            values,\n            positions=[X],\n            widths=width,\n            showmedians=showmedians,\n            showmeans=showmeans,\n        )\n        # Color the bodies.\n        for pc in parts[\"bodies\"]:\n            pc.set_facecolor(color)\n            pc.set_alpha(violin_alpha)\n            pc.set_zorder(0)\n        # Color the lines.\n        parts[\"cbars\"].set_color(violin_marker_color)\n        parts[\"cbars\"].set_linewidth(violin_marker_lw)\n        parts[\"cbars\"].set_zorder(zorder_min_max)\n        parts[\"cmaxes\"].set_color(violin_marker_color)\n        parts[\"cmaxes\"].set_linewidth(violin_marker_lw)\n        parts[\"cmaxes\"].set_zorder(zorder_min_max)\n        parts[\"cmins\"].set_color(violin_marker_color)\n        parts[\"cmins\"].set_linewidth(violin_marker_lw)\n        parts[\"cmins\"].set_zorder(zorder_min_max)\n        if \"cmeans\" in parts:\n            parts[\"cmeans\"].set_color(mean_median_color)\n            parts[\"cmeans\"].set_linewidth(mean_median_linewidth)\n            parts[\"cmeans\"].set_zorder(zorder_mean_median)\n            if mean_median_bar_length is not None:\n                (_, y0), (_, y1) = parts[\"cmeans\"].get_segments()[0]\n                (x0_vert, _), _ = parts[\"cbars\"].get_segments()[0]\n                parts[\"cmeans\"].set_segments([\n                    [\n                        [x0_vert - mean_median_bar_length * width / 2, y0],\n                        [x0_vert + mean_median_bar_length * width / 2, y1],\n                    ]\n                ])\n        if \"cmedians\" in parts:\n            parts[\"cmedians\"].set_color(mean_median_color)\n            parts[\"cmedians\"].set_linewidth(mean_median_linewidth)\n            parts[\"cmedians\"].set_zorder(zorder_mean_median)\n            if mean_median_bar_length is not None:\n                (_, y0), (_, y1) = parts[\"cmedians\"].get_segments()[0]\n                (x0_vert, _), _ = parts[\"cbars\"].get_segments()[0]\n                parts[\"cmedians\"].set_segments([\n                    [\n                        [x0_vert - mean_median_bar_length * width / 2, y0],\n                        [x0_vert + mean_median_bar_length * width / 2, y1],\n                    ]\n                ])\n        return parts[\"bodies\"][0]\n\n    shape = np.array(values).shape\n    n_random_variables, n_groups = shape[0], shape[1]\n\n    violin_locations, first_violins_location = get_violin_x_locations(\n        n_groups, n_random_variables, violin_width=width\n    )\n    X = violin_locations.T\n\n    if colors is None:\n        if color_by == \"groups\":\n            C = np.asarray([cmap(cstart + i * cdist) for i in range(n_groups)]).reshape(\n                n_groups, 4\n            )\n        elif color_by == \"experiments\":\n            C = np.asarray([\n                cmap(cstart + i * cdist) for i in range(n_random_variables)\n            ]).reshape(n_random_variables, 4)\n        else:\n            raise ValueError(\"Invalid color_by option\")\n    elif isinstance(colors, Iterable):\n        if (\n            color_by == \"groups\"\n            and len(colors) == n_groups\n            or color_by == \"experiments\"\n            and len(colors) == n_random_variables\n        ):\n            C = colors\n        else:\n            raise ValueError(\"Invalid colors length\")\n    else:\n        raise ValueError(\"Invalid colors specification\")\n\n    handles = []\n\n    for i in range(n_random_variables):\n        for j in range(n_groups):\n            _color = C[i] if color_by == \"experiments\" else C[j]\n\n            h = (\n                plot_bar(X[i, j], values[i, j], _color)\n                if as_bars\n                else plot_violin(X[i, j], values[i, j], _color)\n            )\n            handles.append(h)\n\n            if scatter:\n                lims = plt_utils.get_lims(\n                    (-width / (2 * n_groups), width / (2 * n_groups)), -0.05\n                )\n                xticks = np.ones_like(values[i][j]) * X[i, j]\n                ax.scatter(\n                    xticks + np.random.uniform(*lims, size=len(xticks)),\n                    values[i][j],\n                    facecolor=\"none\",\n                    edgecolor=scatter_edge_color or _color,\n                    s=scatter_radius,\n                    linewidth=scatter_edge_width,\n                    zorder=2,\n                )\n\n    if legend:\n        ax.legend(handles, legend, **legend_kwargs)\n\n    if ylim is not None:\n        ax.set_ylim(*ylim)\n\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n\n    if xticklabels is not None:\n        ax.set_xticks(first_violins_location + (n_groups - 1) / 2 * width)\n        ax.set_xticklabels(xticklabels, rotation=rotation)\n\n    with suppress(ValueError):\n        ax.set_xlim(np.min(X - width), np.max(X + width))\n\n    ax.set_ylabel(ylabel or \"\", fontsize=fontsize)\n    ax.set_title(title, fontsize=fontsize)\n\n    if pvalues is not None:\n        plt_utils.display_pvalues(\n            ax, pvalues, xticklabels, values, **display_pvalues_kwargs\n        )\n\n    return fig, ax, ViolinData(values, X, colors)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.plot_complex","title":"flyvis.analysis.visualization.plots.plot_complex","text":"<pre><code>plot_complex(z, marker='s', fig=None, ax=None, figsize=(1, 1), fontsize=5)\n</code></pre> <p>Plot a complex number on a polar plot.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>complex</code> <p>Complex number to plot.</p> required <code>marker</code> <code>str</code> <p>Marker style for the point.</p> <code>'s'</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing axes to plot on.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(1, 1)</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>5</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def plot_complex(\n    z: complex,\n    marker: str = \"s\",\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    figsize: Tuple[float, float] = (1, 1),\n    fontsize: int = 5,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"\n    Plot a complex number on a polar plot.\n\n    Args:\n        z: Complex number to plot.\n        marker: Marker style for the point.\n        fig: Existing figure to plot on.\n        ax: Existing axes to plot on.\n        figsize: Size of the figure.\n        fontsize: Font size for text elements.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(\n        figsize=figsize, projection=\"polar\", fontsize=fontsize, fig=fig, ax=ax\n    )\n\n    theta = np.angle(z)\n    r = np.abs(z)\n\n    ax.plot([0, theta], [0, r], marker=marker)\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.plot_complex_vector","title":"flyvis.analysis.visualization.plots.plot_complex_vector","text":"<pre><code>plot_complex_vector(z0, z1, marker='s', fig=None, ax=None, figsize=(1, 1), fontsize=5)\n</code></pre> <p>Plot a vector between two complex numbers on a polar plot.</p> <p>Parameters:</p> Name Type Description Default <code>z0</code> <code>complex</code> <p>Starting complex number.</p> required <code>z1</code> <code>complex</code> <p>Ending complex number.</p> required <code>marker</code> <code>str</code> <p>Marker style for the points.</p> <code>'s'</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing axes to plot on.</p> <code>None</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(1, 1)</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>5</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def plot_complex_vector(\n    z0: complex,\n    z1: complex,\n    marker: str = \"s\",\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    figsize: Tuple[float, float] = (1, 1),\n    fontsize: int = 5,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"\n    Plot a vector between two complex numbers on a polar plot.\n\n    Args:\n        z0: Starting complex number.\n        z1: Ending complex number.\n        marker: Marker style for the points.\n        fig: Existing figure to plot on.\n        ax: Existing axes to plot on.\n        figsize: Size of the figure.\n        fontsize: Font size for text elements.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(\n        figsize=figsize, projection=\"polar\", fontsize=fontsize, fig=fig, ax=ax\n    )\n\n    theta0 = np.angle(z0)\n    r0 = np.abs(z0)\n\n    theta = np.angle(z1)\n    r = np.abs(z1)\n\n    ax.plot([theta0, theta], [r0, r], marker=marker)\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.polar","title":"flyvis.analysis.visualization.plots.polar","text":"<pre><code>polar(theta, r, ax=None, fig=None, color='b', linestyle='-', marker='', markersize=None, label=None, title='', figsize=(5, 5), fontsize=10, xlabel='', fontweight='normal', anglepad=-2, xlabelpad=-3, linewidth=2, ymin=None, ymax=None, stroke_kwargs={}, yticks_off=True, zorder=100, **kwargs)\n</code></pre> <p>Create a polar tuning plot.</p> <p>Parameters:</p> Name Type Description Default <code>theta</code> <code>NDArray</code> <p>Array of angles in degrees.</p> required <code>r</code> <code>NDArray</code> <p>Array of radii.</p> required <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib Axes object.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Matplotlib Figure object.</p> <code>None</code> <code>color</code> <code>Union[str, List[str]]</code> <p>Color(s) for the plot.</p> <code>'b'</code> <code>linestyle</code> <code>str</code> <p>Line style for the plot.</p> <code>'-'</code> <code>marker</code> <code>str</code> <p>Marker style for data points.</p> <code>''</code> <code>markersize</code> <code>Optional[float]</code> <p>Size of markers.</p> <code>None</code> <code>label</code> <code>Optional[str]</code> <p>Label for the plot.</p> <code>None</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure.</p> <code>(5, 5)</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements.</p> <code>10</code> <code>xlabel</code> <code>str</code> <p>X-axis label.</p> <code>''</code> <code>fontweight</code> <code>Literal['normal', 'bold', 'light', 'ultralight', 'heavy', 'black', 'semibold']</code> <p>Font weight for labels.</p> <code>'normal'</code> <code>anglepad</code> <code>int</code> <p>Padding for angle labels.</p> <code>-2</code> <code>xlabelpad</code> <code>int</code> <p>Padding for x-axis label.</p> <code>-3</code> <code>linewidth</code> <code>float</code> <p>Width of the plot lines.</p> <code>2</code> <code>ymin</code> <code>Optional[float]</code> <p>Minimum y-axis value.</p> <code>None</code> <code>ymax</code> <code>Optional[float]</code> <p>Maximum y-axis value.</p> <code>None</code> <code>stroke_kwargs</code> <code>dict</code> <p>Keyword arguments for stroke effects.</p> <code>{}</code> <code>yticks_off</code> <code>bool</code> <p>Whether to turn off y-axis ticks.</p> <code>True</code> <code>zorder</code> <code>Union[int, List[int]]</code> <p>Z-order for plot elements.</p> <code>100</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Note <p>This function creates a polar plot with various customization options. It supports multiple traces and custom styling.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def polar(\n    theta: NDArray,\n    r: NDArray,\n    ax: Optional[Axes] = None,\n    fig: Optional[Figure] = None,\n    color: Union[str, List[str]] = \"b\",\n    linestyle: str = \"-\",\n    marker: str = \"\",\n    markersize: Optional[float] = None,\n    label: Optional[str] = None,\n    title: str = \"\",\n    figsize: Tuple[float, float] = (5, 5),\n    fontsize: int = 10,\n    xlabel: str = \"\",\n    fontweight: Literal[\n        \"normal\", \"bold\", \"light\", \"ultralight\", \"heavy\", \"black\", \"semibold\"\n    ] = \"normal\",\n    anglepad: int = -2,\n    xlabelpad: int = -3,\n    linewidth: float = 2,\n    ymin: Optional[float] = None,\n    ymax: Optional[float] = None,\n    stroke_kwargs: dict = {},\n    yticks_off: bool = True,\n    zorder: Union[int, List[int]] = 100,\n    **kwargs,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"\n    Create a polar tuning plot.\n\n    Args:\n        theta: Array of angles in degrees.\n        r: Array of radii.\n        ax: Matplotlib Axes object.\n        fig: Matplotlib Figure object.\n        color: Color(s) for the plot.\n        linestyle: Line style for the plot.\n        marker: Marker style for data points.\n        markersize: Size of markers.\n        label: Label for the plot.\n        title: Title of the plot.\n        figsize: Size of the figure.\n        fontsize: Font size for text elements.\n        xlabel: X-axis label.\n        fontweight: Font weight for labels.\n        anglepad: Padding for angle labels.\n        xlabelpad: Padding for x-axis label.\n        linewidth: Width of the plot lines.\n        ymin: Minimum y-axis value.\n        ymax: Maximum y-axis value.\n        stroke_kwargs: Keyword arguments for stroke effects.\n        yticks_off: Whether to turn off y-axis ticks.\n        zorder: Z-order for plot elements.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n\n    Note:\n        This function creates a polar plot with various customization options.\n        It supports multiple traces and custom styling.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(\n        figsize=figsize,\n        title=title,\n        fontsize=fontsize,\n        ax=ax,\n        fig=fig,\n        projection=\"polar\",\n    )\n\n    if sum(theta) &lt; 100:\n        logging.warning(\"Using radians instead of degrees?\")\n\n    closed = theta[-1] % 360 == theta[0]\n    theta = theta * np.pi / 180\n    if not closed:\n        theta = np.append(theta, theta[0])\n\n    r = np.asarray(r)\n    if not closed:\n        r = np.append(r, np.expand_dims(r[0], 0), axis=0)\n\n    line_effects = None\n    if stroke_kwargs:\n        line_effects = [\n            path_effects.Stroke(**stroke_kwargs),\n            path_effects.Normal(),\n        ]\n\n    zorder = plt_utils.extend_arg(zorder, int, r, default=0, dim=-1)\n\n    if r.ndim == 2:\n        for i, _r in enumerate(r.T):\n            if isinstance(color, Iterable):\n                if isinstance(color, str) and color.startswith(\"#\"):\n                    _color = color\n                elif len(color) == r.shape[1]:\n                    _color = color[i]\n                else:\n                    _color = color\n            else:\n                _color = color\n\n            ax.plot(\n                theta,\n                _r,\n                linewidth=linewidth,\n                color=_color,\n                linestyle=linestyle,\n                marker=marker,\n                label=label,\n                path_effects=line_effects,\n                zorder=zorder[i],\n                markersize=markersize,\n            )\n    elif r.ndim == 1:\n        ax.plot(\n            theta,\n            r,\n            linewidth=linewidth,\n            color=color,\n            linestyle=linestyle,\n            marker=marker,\n            label=label,\n            path_effects=line_effects,\n            zorder=zorder,\n            markersize=markersize,\n        )\n\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize, pad=anglepad)\n    if yticks_off:\n        ax.set_yticks([])\n        ax.set_yticklabels([])\n    ax.set_xticks([\n        0,\n        np.pi / 4,\n        np.pi / 2,\n        3 / 4 * np.pi,\n        np.pi,\n        5 / 4 * np.pi,\n        3 / 2 * np.pi,\n        7 / 4 * np.pi,\n    ])\n    ax.set_xticklabels([\"0\u00b0\", \"45\u00b0\", \"90\u00b0\", \"\", \"\", \"\", \"\", \"\"])\n\n    ax.set_xlabel(xlabel, fontsize=fontsize, labelpad=xlabelpad, fontweight=fontweight)\n    if all((val is not None for val in (ymin, ymax))):\n        ax.set_ylim((ymin, ymax))\n    plt.setp(ax.spines.values(), color=\"grey\", linewidth=1)\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.multi_polar","title":"flyvis.analysis.visualization.plots.multi_polar","text":"<pre><code>multi_polar(theta, r, ax=None, fig=None, mean_color='b', norm=False, std=False, color='b', mean=False, linestyle='-', marker='', label='', legend=False, title='', figsize=(0.98, 2.38), fontsize=5, xlabel='', fontweight='bold', alpha=1, anglepad=-6, xlabelpad=-3, linewidth=0.75, ymin=None, ymax=None, zorder=None, legend_kwargs=dict(fontsize=5), rm_yticks=True, **kwargs)\n</code></pre> <p>Create a polar tuning plot.</p> <p>Parameters:</p> Name Type Description Default <code>theta</code> <code>ndarray</code> <p>Angles in degrees.</p> required <code>r</code> <code>ndarray</code> <p>Radius values. Shape (n_samples, n_values).</p> required <code>ax</code> <code>Optional[Axes]</code> <p>Existing Axes object to plot on. Defaults to None.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing Figure object to use. Defaults to None.</p> <code>None</code> <code>mean_color</code> <code>str</code> <p>Color for the mean line. Defaults to \u201cb\u201d.</p> <code>'b'</code> <code>norm</code> <code>bool</code> <p>Whether to normalize the radius values. Defaults to False.</p> <code>False</code> <code>std</code> <code>bool</code> <p>Whether to plot standard deviation. Defaults to False.</p> <code>False</code> <code>color</code> <code>Union[str, List[str], ndarray]</code> <p>Color(s) for the lines. Defaults to \u201cb\u201d.</p> <code>'b'</code> <code>mean</code> <code>bool</code> <p>Whether to plot the mean. Defaults to False.</p> <code>False</code> <code>linestyle</code> <code>str</code> <p>Style of the lines. Defaults to \u201c-\u201c.</p> <code>'-'</code> <code>marker</code> <code>str</code> <p>Marker style for data points. Defaults to \u201c\u201d.</p> <code>''</code> <code>label</code> <code>Union[str, List[str]]</code> <p>Label(s) for the lines. Defaults to \u201c\u201d.</p> <code>''</code> <code>legend</code> <code>bool</code> <p>Whether to show a legend. Defaults to False.</p> <code>False</code> <code>title</code> <code>str</code> <p>Title of the plot. Defaults to \u201c\u201d.</p> <code>''</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure. Defaults to (0.98, 2.38).</p> <code>(0.98, 2.38)</code> <code>fontsize</code> <code>int</code> <p>Font size for text elements. Defaults to 5.</p> <code>5</code> <code>xlabel</code> <code>str</code> <p>Label for the x-axis. Defaults to \u201c\u201d.</p> <code>''</code> <code>fontweight</code> <code>str</code> <p>Font weight for labels. Defaults to \u201cbold\u201d.</p> <code>'bold'</code> <code>alpha</code> <code>float</code> <p>Alpha value for line transparency. Defaults to 1.</p> <code>1</code> <code>anglepad</code> <code>int</code> <p>Padding for angle labels. Defaults to -6.</p> <code>-6</code> <code>xlabelpad</code> <code>int</code> <p>Padding for x-axis label. Defaults to -3.</p> <code>-3</code> <code>linewidth</code> <code>float</code> <p>Width of the lines. Defaults to 0.75.</p> <code>0.75</code> <code>ymin</code> <code>Optional[float]</code> <p>Minimum y-axis value. Defaults to None.</p> <code>None</code> <code>ymax</code> <code>Optional[float]</code> <p>Maximum y-axis value. Defaults to None.</p> <code>None</code> <code>zorder</code> <code>Optional[Union[int, List[int], ndarray]]</code> <p>Z-order for drawing. Defaults to None.</p> <code>None</code> <code>legend_kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments for legend. Defaults to dict(fontsize=5).</p> <code>dict(fontsize=5)</code> <code>rm_yticks</code> <code>bool</code> <p>Whether to remove y-axis ticks. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Note <p>This function creates a polar plot with multiple traces, optionally showing mean and standard deviation.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def multi_polar(\n    theta: np.ndarray,\n    r: np.ndarray,\n    ax: Optional[Axes] = None,\n    fig: Optional[Figure] = None,\n    mean_color: str = \"b\",\n    norm: bool = False,\n    std: bool = False,\n    color: Union[str, List[str], np.ndarray] = \"b\",\n    mean: bool = False,\n    linestyle: str = \"-\",\n    marker: str = \"\",\n    label: Union[str, List[str]] = \"\",\n    legend: bool = False,\n    title: str = \"\",\n    figsize: Tuple[float, float] = (0.98, 2.38),\n    fontsize: int = 5,\n    xlabel: str = \"\",\n    fontweight: str = \"bold\",\n    alpha: float = 1,\n    anglepad: int = -6,\n    xlabelpad: int = -3,\n    linewidth: float = 0.75,\n    ymin: Optional[float] = None,\n    ymax: Optional[float] = None,\n    zorder: Optional[Union[int, List[int], np.ndarray]] = None,\n    legend_kwargs: Dict[str, Any] = dict(fontsize=5),\n    rm_yticks: bool = True,\n    **kwargs: Any,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"\n    Create a polar tuning plot.\n\n    Args:\n        theta: Angles in degrees.\n        r: Radius values. Shape (n_samples, n_values).\n        ax: Existing Axes object to plot on. Defaults to None.\n        fig: Existing Figure object to use. Defaults to None.\n        mean_color: Color for the mean line. Defaults to \"b\".\n        norm: Whether to normalize the radius values. Defaults to False.\n        std: Whether to plot standard deviation. Defaults to False.\n        color: Color(s) for the lines. Defaults to \"b\".\n        mean: Whether to plot the mean. Defaults to False.\n        linestyle: Style of the lines. Defaults to \"-\".\n        marker: Marker style for data points. Defaults to \"\".\n        label: Label(s) for the lines. Defaults to \"\".\n        legend: Whether to show a legend. Defaults to False.\n        title: Title of the plot. Defaults to \"\".\n        figsize: Size of the figure. Defaults to (0.98, 2.38).\n        fontsize: Font size for text elements. Defaults to 5.\n        xlabel: Label for the x-axis. Defaults to \"\".\n        fontweight: Font weight for labels. Defaults to \"bold\".\n        alpha: Alpha value for line transparency. Defaults to 1.\n        anglepad: Padding for angle labels. Defaults to -6.\n        xlabelpad: Padding for x-axis label. Defaults to -3.\n        linewidth: Width of the lines. Defaults to 0.75.\n        ymin: Minimum y-axis value. Defaults to None.\n        ymax: Maximum y-axis value. Defaults to None.\n        zorder: Z-order for drawing. Defaults to None.\n        legend_kwargs: Additional keyword arguments for legend.\n            Defaults to dict(fontsize=5).\n        rm_yticks: Whether to remove y-axis ticks. Defaults to True.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n\n    Note:\n        This function creates a polar plot with multiple traces, optionally showing\n        mean and standard deviation.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(\n        figsize=figsize,\n        title=title,\n        fontsize=fontsize,\n        ax=ax,\n        fig=fig,\n        projection=\"polar\",\n    )\n    r = np.atleast_2d(r)\n    n_traces = r.shape[0]\n\n    if norm:\n        r = r / (r.max(axis=1, keepdims=True) + 1e-15)\n\n    closed = theta[-1] % 360 == theta[0]\n    theta = theta * np.pi / 180\n    if not closed:\n        theta = np.append(theta, theta[0])\n        r = np.append(r, np.expand_dims(r[:, 0], 1), axis=1)\n\n    color = [color] * n_traces if not isinstance(color, (list, np.ndarray)) else color\n    label = [label] * n_traces if not isinstance(label, (list, np.ndarray)) else label\n    zorder = [100] * n_traces if not isinstance(zorder, (list, np.ndarray)) else zorder\n\n    for i, _r in enumerate(r):\n        ax.plot(\n            theta,\n            _r,\n            linewidth=linewidth,\n            color=color[i],\n            linestyle=linestyle,\n            marker=marker,\n            label=label[i],\n            zorder=zorder[i],\n            alpha=alpha,\n        )\n\n    if mean:\n        ax.plot(\n            theta,\n            r.mean(0),\n            linewidth=linewidth,\n            color=mean_color,\n            linestyle=linestyle,\n            marker=marker,\n            label=\"average\",\n            alpha=alpha,\n        )\n\n    if std:\n        ax.fill_between(\n            theta,\n            r.mean(0) - r.std(0),\n            r.mean(0) + r.std(0),\n            color=\"0.8\",\n            alpha=0.5,\n            zorder=-1,\n        )\n\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize, pad=anglepad)\n    if rm_yticks:\n        ax.set_yticks([])\n        ax.set_yticklabels([])\n    ax.set_xticks([\n        0,\n        np.pi / 4,\n        np.pi / 2,\n        3 / 4 * np.pi,\n        np.pi,\n        5 / 4 * np.pi,\n        3 / 2 * np.pi,\n        7 / 4 * np.pi,\n    ])\n    ax.set_xticklabels([\"0\u00b0\", \"45\u00b0\", \"90\u00b0\", \"\", \"\", \"\", \"\", \"\"])\n\n    ax.set_xlabel(xlabel, fontsize=fontsize, labelpad=xlabelpad, fontweight=fontweight)\n    if all((val is not None for val in (ymin, ymax))):\n        ax.set_ylim((ymin, ymax))\n    plt.setp(ax.spines.values(), color=\"grey\", linewidth=0.5)\n\n    if legend:\n        ax.legend(**legend_kwargs)\n\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.loss_curves","title":"flyvis.analysis.visualization.plots.loss_curves","text":"<pre><code>loss_curves(losses, smooth=0.05, subsample=1, mean=False, grid=True, colors=None, cbar=False, cmap=None, norm=None, fig=None, ax=None, xlabel=None, ylabel=None)\n</code></pre> <p>Plot loss traces.</p> <p>Parameters:</p> Name Type Description Default <code>losses</code> <code>List[ndarray]</code> <p>List of loss arrays, each of shape (n_iters,).</p> required <code>smooth</code> <code>float</code> <p>Smoothing factor for the loss curves.</p> <code>0.05</code> <code>subsample</code> <code>int</code> <p>Subsample factor for the loss curves.</p> <code>1</code> <code>mean</code> <code>bool</code> <p>Whether to plot the mean loss curve.</p> <code>False</code> <code>grid</code> <code>bool</code> <p>Whether to show grid lines.</p> <code>True</code> <code>colors</code> <code>Optional[List[str]]</code> <p>List of colors for the loss curves.</p> <code>None</code> <code>cbar</code> <code>bool</code> <p>Whether to add a colorbar.</p> <code>False</code> <code>cmap</code> <code>Optional[Colormap]</code> <p>Colormap for the loss curves.</p> <code>None</code> <code>norm</code> <code>Optional[Normalize]</code> <p>Normalization for the colormap.</p> <code>None</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing axes to plot on.</p> <code>None</code> <code>xlabel</code> <code>Optional[str]</code> <p>Label for the x-axis.</p> <code>None</code> <code>ylabel</code> <code>Optional[str]</code> <p>Label for the y-axis.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Note <p>This function plots loss curves for multiple models, with options for smoothing, subsampling, and various visual customizations.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def loss_curves(\n    losses: List[np.ndarray],\n    smooth: float = 0.05,\n    subsample: int = 1,\n    mean: bool = False,\n    grid: bool = True,\n    colors: Optional[List[str]] = None,\n    cbar: bool = False,\n    cmap: Optional[mpl.colors.Colormap] = None,\n    norm: Optional[mpl.colors.Normalize] = None,\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    xlabel: Optional[str] = None,\n    ylabel: Optional[str] = None,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"Plot loss traces.\n\n    Args:\n        losses: List of loss arrays, each of shape (n_iters,).\n        smooth: Smoothing factor for the loss curves.\n        subsample: Subsample factor for the loss curves.\n        mean: Whether to plot the mean loss curve.\n        grid: Whether to show grid lines.\n        colors: List of colors for the loss curves.\n        cbar: Whether to add a colorbar.\n        cmap: Colormap for the loss curves.\n        norm: Normalization for the colormap.\n        fig: Existing figure to plot on.\n        ax: Existing axes to plot on.\n        xlabel: Label for the x-axis.\n        ylabel: Label for the y-axis.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n\n    Note:\n        This function plots loss curves for multiple models, with options for\n        smoothing, subsampling, and various visual customizations.\n    \"\"\"\n    losses = np.array([loss[::subsample] for loss in losses])\n\n    max_n_iters = max(len(loss) for loss in losses)\n\n    _losses = np.full((len(losses), max_n_iters), np.nan)\n    for i, loss in enumerate(losses):\n        n_iters = len(loss)\n        _losses[i, :n_iters] = loss\n\n    fig, ax, _, _ = traces(\n        _losses[::-1],\n        x=np.arange(max_n_iters) * subsample,\n        fontsize=5,\n        figsize=[1.2, 1],\n        smooth=smooth,\n        fig=fig,\n        ax=ax,\n        color=colors[::-1] if colors is not None else None,\n        linewidth=0.5,\n        highlight_mean=mean,\n    )\n\n    ax.set_ylabel(ylabel, fontsize=5)\n    ax.set_xlabel(xlabel, fontsize=5)\n\n    if cbar and cmap is not None and norm is not None:\n        plt_utils.add_colorbar_to_fig(\n            fig,\n            cmap=cmap,\n            norm=norm,\n            label=\"min task error\",\n            fontsize=5,\n            tick_length=1,\n            tick_width=0.5,\n            x_offset=2,\n            y_offset=0.25,\n        )\n\n    if grid:\n        ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n        ax.grid(True, linewidth=0.5)\n\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.histogram","title":"flyvis.analysis.visualization.plots.histogram","text":"<pre><code>histogram(array, bins=None, fill=False, histtype='step', figsize=(1, 1), fontsize=5, fig=None, ax=None, xlabel=None, ylabel=None)\n</code></pre> <p>Create a histogram plot.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Input data to plot.</p> required <code>bins</code> <code>Optional[Union[int, Sequence, str]]</code> <p>Number of bins or bin edges. Defaults to len(array).</p> <code>None</code> <code>fill</code> <code>bool</code> <p>Whether to fill the bars. Defaults to False.</p> <code>False</code> <code>histtype</code> <code>Literal['bar', 'barstacked', 'step', 'stepfilled']</code> <p>Type of histogram to plot. Defaults to \u201cstep\u201d.</p> <code>'step'</code> <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure. Defaults to (1, 1).</p> <code>(1, 1)</code> <code>fontsize</code> <code>int</code> <p>Font size for labels. Defaults to 5.</p> <code>5</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on. Defaults to None.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing axes to plot on. Defaults to None.</p> <code>None</code> <code>xlabel</code> <code>Optional[str]</code> <p>Label for x-axis. Defaults to None.</p> <code>None</code> <code>ylabel</code> <code>Optional[str]</code> <p>Label for y-axis. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>A tuple containing the Figure and Axes objects.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def histogram(\n    array: np.ndarray,\n    bins: Optional[Union[int, Sequence, str]] = None,\n    fill: bool = False,\n    histtype: Literal[\"bar\", \"barstacked\", \"step\", \"stepfilled\"] = \"step\",\n    figsize: Tuple[float, float] = (1, 1),\n    fontsize: int = 5,\n    fig: Optional[Figure] = None,\n    ax: Optional[Axes] = None,\n    xlabel: Optional[str] = None,\n    ylabel: Optional[str] = None,\n) -&gt; Tuple[Figure, Axes]:\n    \"\"\"\n    Create a histogram plot.\n\n    Args:\n        array: Input data to plot.\n        bins: Number of bins or bin edges. Defaults to len(array).\n        fill: Whether to fill the bars. Defaults to False.\n        histtype: Type of histogram to plot. Defaults to \"step\".\n        figsize: Size of the figure. Defaults to (1, 1).\n        fontsize: Font size for labels. Defaults to 5.\n        fig: Existing figure to plot on. Defaults to None.\n        ax: Existing axes to plot on. Defaults to None.\n        xlabel: Label for x-axis. Defaults to None.\n        ylabel: Label for y-axis. Defaults to None.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n    \"\"\"\n    fig, ax = plt_utils.init_plot(figsize=figsize, fontsize=fontsize, fig=fig, ax=ax)\n    ax.hist(\n        array,\n        bins=bins if bins is not None else len(array),\n        linewidth=0.5,\n        fill=fill,\n        histtype=histtype,\n    )\n    ax.set_xlabel(xlabel, fontsize=fontsize)\n    ax.set_ylabel(ylabel, fontsize=fontsize)\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.violins","title":"flyvis.analysis.visualization.plots.violins","text":"<pre><code>violins(variable_names, variable_values, ylabel=None, title=None, max_per_ax=20, colors=None, cmap=plt.cm.viridis_r, fontsize=5, violin_width=0.7, legend=None, scatter_extent=[-0.35, 0.35], figwidth=10, fig=None, axes=None, ylabel_offset=0.2, **kwargs)\n</code></pre> <p>Create violin plots for multiple variables across groups.</p> <p>Parameters:</p> Name Type Description Default <code>variable_names</code> <code>List[str]</code> <p>Names of the variables to plot.</p> required <code>variable_values</code> <code>ndarray</code> <p>Array of values for each variable and group.</p> required <code>ylabel</code> <code>Optional[str]</code> <p>Label for the y-axis.</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>Title of the plot.</p> <code>None</code> <code>max_per_ax</code> <code>Optional[int]</code> <p>Maximum number of variables per axis.</p> <code>20</code> <code>colors</code> <code>Optional[Union[str, List[str]]]</code> <p>Colors for the violin plots.</p> <code>None</code> <code>cmap</code> <code>cm</code> <p>Colormap to use if colors are not specified.</p> <code>viridis_r</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and ticks.</p> <code>5</code> <code>violin_width</code> <code>float</code> <p>Width of each violin plot.</p> <code>0.7</code> <code>legend</code> <code>Optional[Union[str, List[str]]]</code> <p>Legend labels for groups.</p> <code>None</code> <code>scatter_extent</code> <code>List[float]</code> <p>Extent of scatter points on violins.</p> <code>[-0.35, 0.35]</code> <code>figwidth</code> <code>float</code> <p>Width of the figure.</p> <code>10</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>axes</code> <code>Optional[List[Axes]]</code> <p>Existing axes to plot on.</p> <code>None</code> <code>ylabel_offset</code> <code>float</code> <p>Offset for y-axis label.</p> <code>0.2</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for violin_groups function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Figure, List[Axes]]</code> <p>A tuple containing the Figure and list of Axes objects.</p> Note <p>This function creates violin plots for multiple variables, potentially across multiple groups, with optional scatter points on each violin.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def violins(\n    variable_names: List[str],\n    variable_values: np.ndarray,\n    ylabel: Optional[str] = None,\n    title: Optional[str] = None,\n    max_per_ax: Optional[int] = 20,\n    colors: Optional[Union[str, List[str]]] = None,\n    cmap: plt.cm = plt.cm.viridis_r,\n    fontsize: int = 5,\n    violin_width: float = 0.7,\n    legend: Optional[Union[str, List[str]]] = None,\n    scatter_extent: List[float] = [-0.35, 0.35],\n    figwidth: float = 10,\n    fig: Optional[Figure] = None,\n    axes: Optional[List[Axes]] = None,\n    ylabel_offset: float = 0.2,\n    **kwargs: Any,\n) -&gt; Tuple[Figure, List[Axes]]:\n    \"\"\"\n    Create violin plots for multiple variables across groups.\n\n    Args:\n        variable_names: Names of the variables to plot.\n        variable_values: Array of values for each variable and group.\n        ylabel: Label for the y-axis.\n        title: Title of the plot.\n        max_per_ax: Maximum number of variables per axis.\n        colors: Colors for the violin plots.\n        cmap: Colormap to use if colors are not specified.\n        fontsize: Font size for labels and ticks.\n        violin_width: Width of each violin plot.\n        legend: Legend labels for groups.\n        scatter_extent: Extent of scatter points on violins.\n        figwidth: Width of the figure.\n        fig: Existing figure to plot on.\n        axes: Existing axes to plot on.\n        ylabel_offset: Offset for y-axis label.\n        **kwargs: Additional keyword arguments for violin_groups function.\n\n    Returns:\n        A tuple containing the Figure and list of Axes objects.\n\n    Note:\n        This function creates violin plots for multiple variables, potentially\n        across multiple groups, with optional scatter points on each violin.\n    \"\"\"\n    variable_values = variable_values.T\n    if len(variable_values.shape) == 2:\n        variable_values = variable_values[:, None]\n\n    n_variables, n_groups, n_samples = variable_values.shape\n    if max_per_ax is None:\n        max_per_ax = n_variables\n    max_per_ax = min(max_per_ax, n_variables)\n    n_axes = int(n_variables / max_per_ax)\n    max_per_ax += int(np.ceil((n_variables % max_per_ax) / n_axes))\n\n    fig, axes, _ = plt_utils.get_axis_grid(\n        gridheight=n_axes,\n        gridwidth=1,\n        figsize=[figwidth, n_axes * 1.2],\n        hspace=1,\n        alpha=0,\n        fig=fig,\n        axes=axes,\n    )\n\n    for i in range(n_axes):\n        ax_values = variable_values[i * max_per_ax : (i + 1) * max_per_ax]\n        ax_names = variable_names[i * max_per_ax : (i + 1) * max_per_ax]\n\n        fig, ax, C = violin_groups(\n            ax_values,\n            ax_names,\n            rotation=90,\n            scatter=False,\n            fontsize=fontsize,\n            width=violin_width,\n            scatter_edge_color=\"white\",\n            scatter_radius=5,\n            scatter_edge_width=0.25,\n            cdist=100,\n            colors=colors,\n            cmap=cmap,\n            showmedians=True,\n            showmeans=False,\n            violin_marker_lw=0.25,\n            legend=(legend if legend else None if i == 0 else None),\n            legend_kwargs=dict(\n                fontsize=5,\n                markerscale=10,\n                loc=\"lower left\",\n                bbox_to_anchor=(0.75, 0.75),\n            ),\n            fig=fig,\n            ax=axes[i],\n            **kwargs,\n        )\n\n        violin_locations, _ = get_violin_x_locations(\n            n_groups, len(ax_names), violin_width\n        )\n\n        for group in range(n_groups):\n            plt_utils.scatter_on_violins_or_bars(\n                ax_values[:, group].T,\n                ax,\n                xticks=violin_locations[group],\n                facecolor=\"none\",\n                edgecolor=\"k\",\n                zorder=100,\n                alpha=0.35,\n                uniform=scatter_extent,\n                marker=\"o\",\n                linewidth=0.5,\n            )\n\n        ax.grid(False)\n\n        plt_utils.trim_axis(ax, yaxis=False)\n        plt_utils.set_spine_tick_params(\n            ax,\n            tickwidth=0.5,\n            ticklength=3,\n            ticklabelpad=2,\n            spinewidth=0.5,\n        )\n\n    lefts, bottoms, rights, tops = np.array([ax.get_position().extents for ax in axes]).T\n    fig.text(\n        lefts.min() - ylabel_offset * lefts.min(),\n        (tops.max() - bottoms.min()) / 2,\n        ylabel,\n        rotation=90,\n        fontsize=fontsize,\n        ha=\"right\",\n        va=\"center\",\n    )\n\n    axes[0].set_title(title, y=0.91, fontsize=fontsize)\n\n    return fig, axes\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.plot_strf","title":"flyvis.analysis.visualization.plots.plot_strf","text":"<pre><code>plot_strf(time, rf, hlines=True, vlines=True, time_axis=True, fontsize=6, fig=None, axes=None, figsize=[5, 1], wspace=0, y_offset_time_axis=0)\n</code></pre> <p>Plot a Spatio-Temporal Receptive Field (STRF).</p> <p>Parameters:</p> Name Type Description Default <code>time</code> <code>ndarray</code> <p>Array of time points.</p> required <code>rf</code> <code>ndarray</code> <p>Receptive field array.</p> required <code>hlines</code> <code>bool</code> <p>Whether to draw horizontal lines. Defaults to True.</p> <code>True</code> <code>vlines</code> <code>bool</code> <p>Whether to draw vertical lines. Defaults to True.</p> <code>True</code> <code>time_axis</code> <code>bool</code> <p>Whether to add a time axis. Defaults to True.</p> <code>True</code> <code>fontsize</code> <code>int</code> <p>Font size for labels and ticks.</p> <code>6</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to plot on.</p> <code>None</code> <code>axes</code> <code>Optional[ndarray]</code> <p>Existing axes to plot on.</p> <code>None</code> <code>figsize</code> <code>List[float]</code> <p>Size of the figure as [width, height].</p> <code>[5, 1]</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0</code> <code>y_offset_time_axis</code> <code>float</code> <p>Vertical offset for the time axis.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tuple[Figure, ndarray]</code> <p>A tuple containing the Figure and Axes objects.</p> Note <p>This function creates a series of hexagonal plots representing the STRF at different time points.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>def plot_strf(\n    time: np.ndarray,\n    rf: np.ndarray,\n    hlines: bool = True,\n    vlines: bool = True,\n    time_axis: bool = True,\n    fontsize: int = 6,\n    fig: Optional[Figure] = None,\n    axes: Optional[np.ndarray] = None,\n    figsize: List[float] = [5, 1],\n    wspace: float = 0,\n    y_offset_time_axis: float = 0,\n) -&gt; Tuple[Figure, np.ndarray]:\n    \"\"\"\n    Plot a Spatio-Temporal Receptive Field (STRF).\n\n    Args:\n        time: Array of time points.\n        rf: Receptive field array.\n        hlines: Whether to draw horizontal lines. Defaults to True.\n        vlines: Whether to draw vertical lines. Defaults to True.\n        time_axis: Whether to add a time axis. Defaults to True.\n        fontsize: Font size for labels and ticks.\n        fig: Existing figure to plot on.\n        axes: Existing axes to plot on.\n        figsize: Size of the figure as [width, height].\n        wspace: Width space between subplots.\n        y_offset_time_axis: Vertical offset for the time axis.\n\n    Returns:\n        A tuple containing the Figure and Axes objects.\n\n    Note:\n        This function creates a series of hexagonal plots representing the STRF\n        at different time points.\n    \"\"\"\n    max_extent = hex_utils.get_hextent(rf.shape[-1])\n    t_steps = np.arange(0.0, 0.2, 0.01)[::2]\n\n    u, v = hex_utils.get_hex_coords(max_extent)\n    x, y = hex_utils.hex_to_pixel(u, v)\n    xmin, xmax = x.min(), x.max()\n    ymin, ymax = y.min(), y.max()\n    elev = 0\n    azim = 0\n\n    if fig is None or axes is None:\n        fig, axes = plt_utils.divide_figure_to_grid(\n            np.arange(10).reshape(1, 10),\n            wspace=wspace,\n            as_matrix=True,\n            figsize=figsize,\n        )\n\n    crange = np.abs(rf).max()\n\n    for i, t in enumerate(t_steps):\n        mask = np.where(np.abs(time - t) &lt;= 1e-15, True, False)\n        _rf = rf[mask]\n        quick_hex_scatter(\n            _rf,\n            cmap=plt.cm.coolwarm,\n            edgecolor=None,\n            vmin=-crange,\n            vmax=crange,\n            midpoint=0,\n            cbar=False,\n            max_extent=max_extent,\n            fig=fig,\n            ax=axes[0, i],\n            fill=True,\n            fontsize=fontsize,\n        )\n\n        if hlines:\n            axes[0, i].hlines(elev, xmin, xmax, color=\"grey\", linewidth=0.25)\n        if vlines:\n            axes[0, i].vlines(azim, ymin, ymax, color=\"grey\", linewidth=0.25)\n\n    if time_axis:\n        left = fig.transFigure.inverted().transform(\n            axes[0, 0].transData.transform((0, 0))\n        )[0]\n        right = fig.transFigure.inverted().transform(\n            axes[0, -1].transData.transform((0, 0))\n        )[0]\n\n        lefts, bottoms, rights, tops = np.array([\n            ax.get_position().extents for ax in axes.flatten()\n        ]).T\n        time_axis = fig.add_axes((\n            left,\n            bottoms.min() + y_offset_time_axis * bottoms.min(),\n            right - left,\n            0.01,\n        ))\n        plt_utils.rm_spines(\n            time_axis,\n            (\"left\", \"top\", \"right\"),\n            rm_yticks=True,\n            rm_xticks=False,\n        )\n\n        data_centers_in_points = np.array([\n            ax.transData.transform((0, 0)) for ax in axes.flatten()\n        ])\n        time_axis.tick_params(axis=\"both\", labelsize=fontsize)\n        ticks = time_axis.transData.inverted().transform(data_centers_in_points)[:, 0]\n        time_axis.set_xticks(ticks)\n        time_axis.set_xticklabels(np.arange(0, 200, 20))\n        time_axis.set_xlabel(\"time (ms)\", fontsize=fontsize, labelpad=2)\n        plt_utils.set_spine_tick_params(\n            time_axis,\n            spinewidth=0.25,\n            tickwidth=0.25,\n            ticklength=3,\n            ticklabelpad=2,\n            spines=(\"top\", \"right\", \"bottom\", \"left\"),\n        )\n\n    return fig, axes\n</code></pre>"},{"location":"reference/visualization/#classes_2","title":"Classes","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.plots.ViolinData","title":"flyvis.analysis.visualization.plots.ViolinData  <code>dataclass</code>","text":"<p>Container for violin plot data.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>np.ndarray The data used for creating violin plots.</p> <code>locations</code> <code>ndarray</code> <p>np.ndarray The x-axis locations of the violin plots.</p> <code>colors</code> <code>ndarray</code> <p>np.ndarray The colors used for the violin plots.</p> Source code in <code>flyvis/analysis/visualization/plots.py</code> <pre><code>@dataclass\nclass ViolinData:\n    \"\"\"\n    Container for violin plot data.\n\n    Attributes:\n        data: np.ndarray\n            The data used for creating violin plots.\n        locations: np.ndarray\n            The x-axis locations of the violin plots.\n        colors: np.ndarray\n            The colors used for the violin plots.\n    \"\"\"\n\n    data: np.ndarray\n    locations: np.ndarray\n    colors: np.ndarray\n</code></pre>"},{"location":"reference/visualization/#flyvisanalysisvisualizationplt_utils","title":"flyvis.analysis.visualization.plt_utils","text":""},{"location":"reference/visualization/#functions_3","title":"Functions","text":""},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.check_markers","title":"flyvis.analysis.visualization.plt_utils.check_markers","text":"<pre><code>check_markers(N)\n</code></pre> <p>Check if the number of clusters is larger than the number of markers.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Number of clusters.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of markers.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def check_markers(N: int) -&gt; List[str]:\n    \"\"\"\n    Check if the number of clusters is larger than the number of markers.\n\n    Args:\n        N: Number of clusters.\n\n    Returns:\n        List of markers.\n    \"\"\"\n    if len(MARKERS) &lt; N:\n        return [f\"${i}$\" for i in range(N)]\n    return MARKERS\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_marker","title":"flyvis.analysis.visualization.plt_utils.get_marker","text":"<pre><code>get_marker(n)\n</code></pre> <p>Get marker for n.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Index of the marker.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Marker string.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_marker(n: int) -&gt; str:\n    \"\"\"\n    Get marker for n.\n\n    Args:\n        n: Index of the marker.\n\n    Returns:\n        Marker string.\n    \"\"\"\n    return check_markers(n)[n]\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.init_plot","title":"flyvis.analysis.visualization.plt_utils.init_plot","text":"<pre><code>init_plot(figsize=[1, 1], title='', fontsize=5, ax=None, fig=None, projection=None, set_axis_off=False, transparent=False, face_alpha=0, position=None, title_pos='center', title_y=None, **kwargs)\n</code></pre> <p>Creates fig and axis object with certain default settings.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>List[float]</code> <p>Figure size.</p> <code>[1, 1]</code> <code>title</code> <code>str</code> <p>Title of the plot.</p> <code>''</code> <code>fontsize</code> <code>int</code> <p>Font size for title and labels.</p> <code>5</code> <code>ax</code> <code>Axes</code> <p>Existing axis object.</p> <code>None</code> <code>fig</code> <code>Figure</code> <p>Existing figure object.</p> <code>None</code> <code>projection</code> <code>str</code> <p>Projection type (e.g., \u2018polar\u2019).</p> <code>None</code> <code>set_axis_off</code> <code>bool</code> <p>Whether to turn off axis.</p> <code>False</code> <code>transparent</code> <code>bool</code> <p>Whether to make the axis transparent.</p> <code>False</code> <code>face_alpha</code> <code>float</code> <p>Alpha value for the face color.</p> <code>0</code> <code>position</code> <code>List[float]</code> <p>Position for newly created axis.</p> <code>None</code> <code>title_pos</code> <code>Literal['center', 'left', 'right']</code> <p>Position of the title.</p> <code>'center'</code> <code>title_y</code> <code>float</code> <p>Y-coordinate of the title.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>Tuple containing the figure and axis objects.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def init_plot(\n    figsize: List[float] = [1, 1],\n    title: str = \"\",\n    fontsize: int = 5,\n    ax: Axes = None,\n    fig: plt.Figure = None,\n    projection: str = None,\n    set_axis_off: bool = False,\n    transparent: bool = False,\n    face_alpha: float = 0,\n    position: List[float] = None,\n    title_pos: Literal[\"center\", \"left\", \"right\"] = \"center\",\n    title_y: float = None,\n    **kwargs,\n) -&gt; Tuple[plt.Figure, Axes]:\n    \"\"\"\n    Creates fig and axis object with certain default settings.\n\n    Args:\n        figsize: Figure size.\n        title: Title of the plot.\n        fontsize: Font size for title and labels.\n        ax: Existing axis object.\n        fig: Existing figure object.\n        projection: Projection type (e.g., 'polar').\n        set_axis_off: Whether to turn off axis.\n        transparent: Whether to make the axis transparent.\n        face_alpha: Alpha value for the face color.\n        position: Position for newly created axis.\n        title_pos: Position of the title.\n        title_y: Y-coordinate of the title.\n\n    Returns:\n        Tuple containing the figure and axis objects.\n    \"\"\"\n    if fig is None:\n        fig = plt.figure(figsize=figsize, layout=\"constrained\")\n    if ax is not None:\n        ax.set_title(title, fontsize=fontsize, loc=title_pos, y=title_y)\n    else:\n        ax = fig.add_subplot(projection=projection)\n        if position is not None:\n            ax.set_position(position)\n        ax.patch.set_alpha(face_alpha)\n        ax.set_title(title, fontsize=fontsize, loc=title_pos, y=title_y)\n\n        if set_axis_off:\n            ax.set_axis_off()\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n    if transparent:\n        ax.patch.set_alpha(0)\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.truncate_colormap","title":"flyvis.analysis.visualization.plt_utils.truncate_colormap","text":"<pre><code>truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100)\n</code></pre> <p>Truncate colormap.</p> <p>Parameters:</p> Name Type Description Default <code>cmap</code> <code>Colormap</code> <p>Original colormap.</p> required <code>minval</code> <code>float</code> <p>Minimum value for truncation.</p> <code>0.0</code> <code>maxval</code> <code>float</code> <p>Maximum value for truncation.</p> <code>1.0</code> <code>n</code> <code>int</code> <p>Number of colors in the new colormap.</p> <code>100</code> <p>Returns:</p> Type Description <code>LinearSegmentedColormap</code> <p>Truncated colormap.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def truncate_colormap(\n    cmap: colors.Colormap, minval: float = 0.0, maxval: float = 1.0, n: int = 100\n) -&gt; colors.LinearSegmentedColormap:\n    \"\"\"\n    Truncate colormap.\n\n    Args:\n        cmap: Original colormap.\n        minval: Minimum value for truncation.\n        maxval: Maximum value for truncation.\n        n: Number of colors in the new colormap.\n\n    Returns:\n        Truncated colormap.\n    \"\"\"\n    new_cmap = colors.LinearSegmentedColormap.from_list(\n        f\"trunc({cmap.name},{minval:.2f},{maxval:.2f})\",\n        cmap(np.linspace(minval, maxval, n)),\n    )\n    return new_cmap\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.rm_spines","title":"flyvis.analysis.visualization.plt_utils.rm_spines","text":"<pre><code>rm_spines(ax, spines=('top', 'right', 'bottom', 'left'), visible=False, rm_xticks=True, rm_yticks=True)\n</code></pre> <p>Removes spines and ticks from axis.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Matplotlib axis object.</p> required <code>spines</code> <code>Tuple[str, ...]</code> <p>Tuple of spines to remove.</p> <code>('top', 'right', 'bottom', 'left')</code> <code>visible</code> <code>bool</code> <p>Whether to make spines visible.</p> <code>False</code> <code>rm_xticks</code> <code>bool</code> <p>Whether to remove x-ticks.</p> <code>True</code> <code>rm_yticks</code> <code>bool</code> <p>Whether to remove y-ticks.</p> <code>True</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Modified axis object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def rm_spines(\n    ax: Axes,\n    spines: Tuple[str, ...] = (\"top\", \"right\", \"bottom\", \"left\"),\n    visible: bool = False,\n    rm_xticks: bool = True,\n    rm_yticks: bool = True,\n) -&gt; Axes:\n    \"\"\"\n    Removes spines and ticks from axis.\n\n    Args:\n        ax: Matplotlib axis object.\n        spines: Tuple of spines to remove.\n        visible: Whether to make spines visible.\n        rm_xticks: Whether to remove x-ticks.\n        rm_yticks: Whether to remove y-ticks.\n\n    Returns:\n        Modified axis object.\n    \"\"\"\n    for spine in spines:\n        ax.spines[spine].set_visible(visible)\n    if (\"top\" in spines or \"bottom\" in spines) and rm_xticks:\n        ax.xaxis.set_ticklabels([])\n        ax.xaxis.set_ticks_position(\"none\")\n    if (\"left\" in spines or \"right\" in spines) and rm_yticks:\n        ax.yaxis.set_ticklabels([])\n        ax.yaxis.set_ticks_position(\"none\")\n    return ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_ax_positions","title":"flyvis.analysis.visualization.plt_utils.get_ax_positions","text":"<pre><code>get_ax_positions(axes)\n</code></pre> <p>Returns the positions of the axes in the figure.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>Iterable[Axes]</code> <p>Single ax or iterable of axes.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple containing arrays of left, bottom, right, and top positions,</p> <code>ndarray</code> <p>and arrays of centers, widths, and heights.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_ax_positions(axes: Iterable[Axes]) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Returns the positions of the axes in the figure.\n\n    Args:\n        axes: Single ax or iterable of axes.\n\n    Returns:\n        Tuple containing arrays of left, bottom, right, and top positions,\n        and arrays of centers, widths, and heights.\n    \"\"\"\n    axes = np.atleast_1d(axes)\n    lefts, bottoms, rights, tops = np.atleast_2d(\n        np.array([ax.get_position().extents for ax in axes])\n    ).T\n    widths = rights - lefts\n    heights = tops - bottoms\n    centers = np.array([lefts + widths / 2, bottoms + heights / 2])\n    return (lefts, bottoms, rights, tops), (centers, widths, heights)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.is_hex","title":"flyvis.analysis.visualization.plt_utils.is_hex","text":"<pre><code>is_hex(color)\n</code></pre> <p>Checks if color is hex.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>str</code> <p>Color string.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if color is hex, False otherwise.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def is_hex(color: str) -&gt; bool:\n    \"\"\"\n    Checks if color is hex.\n\n    Args:\n        color: Color string.\n\n    Returns:\n        True if color is hex, False otherwise.\n    \"\"\"\n    return \"#\" in color\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.is_integer_rgb","title":"flyvis.analysis.visualization.plt_utils.is_integer_rgb","text":"<pre><code>is_integer_rgb(color)\n</code></pre> <p>Checks if color is integer RGB.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>Iterable[int]</code> <p>Color tuple or list.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if color is integer RGB, False otherwise.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def is_integer_rgb(color: Iterable[int]) -&gt; bool:\n    \"\"\"\n    Checks if color is integer RGB.\n\n    Args:\n        color: Color tuple or list.\n\n    Returns:\n        True if color is integer RGB, False otherwise.\n    \"\"\"\n    try:\n        return any([c &gt; 1 for c in color])\n    except TypeError:\n        return False\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_alpha_colormap","title":"flyvis.analysis.visualization.plt_utils.get_alpha_colormap","text":"<pre><code>get_alpha_colormap(saturated_color, number_of_shades)\n</code></pre> <p>Create a colormap from a color and a number of shades.</p> <p>Parameters:</p> Name Type Description Default <code>saturated_color</code> <code>str</code> <p>Saturated color string.</p> required <code>number_of_shades</code> <code>int</code> <p>Number of shades in the colormap.</p> required <p>Returns:</p> Type Description <code>ListedColormap</code> <p>ListedColormap object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_alpha_colormap(saturated_color: str, number_of_shades: int) -&gt; ListedColormap:\n    \"\"\"\n    Create a colormap from a color and a number of shades.\n\n    Args:\n        saturated_color: Saturated color string.\n        number_of_shades: Number of shades in the colormap.\n\n    Returns:\n        ListedColormap object.\n    \"\"\"\n    if is_hex(saturated_color):\n        rgba = [*hex2color(saturated_color)[:3], 0]\n    elif is_integer_rgb(saturated_color):\n        rgba = [*list(np.array(saturated_color) / 255.0), 0]\n\n    N = number_of_shades\n    colors = []\n    alphas = np.linspace(1 / N, 1, N)[::-1]\n    for alpha in alphas:\n        rgba[-1] = alpha\n        colors.append(rgba.copy())\n\n    return ListedColormap(colors)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.polar_to_cmap","title":"flyvis.analysis.visualization.plt_utils.polar_to_cmap","text":"<pre><code>polar_to_cmap(r, theta, invert=True, cmap=plt.cm.twilight_shifted, norm=None, sm=None)\n</code></pre> <p>Maps angle to rgb and amplitude to alpha and returns the resulting array.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>ndarray</code> <p>Amplitude array.</p> required <code>theta</code> <code>ndarray</code> <p>Angle array.</p> required <code>invert</code> <code>bool</code> <p>Whether to invert the colormap.</p> <code>True</code> <code>cmap</code> <code>Colormap</code> <p>Colormap.</p> <code>twilight_shifted</code> <code>norm</code> <code>Normalize</code> <p>Normalization object.</p> <code>None</code> <code>sm</code> <code>ScalarMappable</code> <p>ScalarMappable object.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>RGBA array.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def polar_to_cmap(\n    r: np.ndarray,\n    theta: np.ndarray,\n    invert: bool = True,\n    cmap: colors.Colormap = plt.cm.twilight_shifted,\n    norm: Normalize = None,\n    sm: ScalarMappable = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Maps angle to rgb and amplitude to alpha and returns the resulting array.\n\n    Args:\n        r: Amplitude array.\n        theta: Angle array.\n        invert: Whether to invert the colormap.\n        cmap: Colormap.\n        norm: Normalization object.\n        sm: ScalarMappable object.\n\n    Returns:\n        RGBA array.\n    \"\"\"\n    sm = sm if sm else plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n    r = r / r.max()\n    A = np.zeros([theta.shape[0], theta.shape[1], 4])\n    RGBA = sm.to_rgba(theta)\n    A[:, :, 0] = RGBA[:, :, 0]\n    A[:, :, 1] = RGBA[:, :, 1]\n    A[:, :, 2] = RGBA[:, :, 2]\n    if invert:\n        A = 1 - A\n        A[:, :, -1] = r  # amplitude\n        return A\n    else:\n        A[:, :, -1] = r  # amplitude\n        return A\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.add_colorwheel_2d","title":"flyvis.analysis.visualization.plt_utils.add_colorwheel_2d","text":"<pre><code>add_colorwheel_2d(fig, axes=None, pos='southeast', radius=0.25, x_offset=0, y_offset=0, sm=None, cmap='cm_uniform_2d', norm=None, fontsize=6, N=512, labelpad=0, invert=False, mode='2d', ticks=[0, 60, 120])\n</code></pre> <p>Adds a colorwheel to a figure.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Matplotlib figure object.</p> required <code>axes</code> <code>Iterable[Axes]</code> <p>Iterable of axes to which the colorwheel will be added.</p> <code>None</code> <code>pos</code> <code>Literal['southeast', 'east', 'northeast', 'north', 'northwest', 'west', 'southwest', 'south', 'origin']</code> <p>Position of the colorwheel.</p> <code>'southeast'</code> <code>radius</code> <code>float</code> <p>Radius of the colorwheel in percentage of the ax radius.</p> <code>0.25</code> <code>x_offset</code> <code>float</code> <p>X-offset of the colorwheel in percentage of the cbar diameter.</p> <code>0</code> <code>y_offset</code> <code>float</code> <p>Y-offset of the colorwheel in percentage of the cbar diameter.</p> <code>0</code> <code>sm</code> <code>ScalarMappable</code> <p>ScalarMappable object.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap name.</p> <code>'cm_uniform_2d'</code> <code>norm</code> <code>Normalize</code> <p>Normalization object.</p> <code>None</code> <code>fontsize</code> <code>int</code> <p>Font size for tick labels.</p> <code>6</code> <code>N</code> <code>int</code> <p>Number of samples for the colorwheel.</p> <code>512</code> <code>labelpad</code> <code>float</code> <p>Padding for tick labels.</p> <code>0</code> <code>invert</code> <code>bool</code> <p>Whether to invert the colormap.</p> <code>False</code> <code>mode</code> <code>Literal['1d', '2d']</code> <p>Mode of the colorwheel (\u201c1d\u201d or \u201c2d\u201d).</p> <code>'2d'</code> <code>ticks</code> <code>List[int]</code> <p>Tick positions in degrees.</p> <code>[0, 60, 120]</code> <p>Returns:</p> Type Description <code>Tuple[Axes, Axes]</code> <p>Tuple containing the colorwheel axis and the annotation axis.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def add_colorwheel_2d(\n    fig: plt.Figure,\n    axes: Iterable[Axes] = None,\n    pos: Literal[\n        \"southeast\",\n        \"east\",\n        \"northeast\",\n        \"north\",\n        \"northwest\",\n        \"west\",\n        \"southwest\",\n        \"south\",\n        \"origin\",\n    ] = \"southeast\",\n    radius: float = 0.25,\n    x_offset: float = 0,\n    y_offset: float = 0,\n    sm: ScalarMappable = None,\n    cmap: str = \"cm_uniform_2d\",\n    norm: Normalize = None,\n    fontsize: int = 6,\n    N: int = 512,\n    labelpad: float = 0,\n    invert: bool = False,\n    mode: Literal[\"1d\", \"2d\"] = \"2d\",\n    ticks: List[int] = [0, 60, 120],\n) -&gt; Tuple[Axes, Axes]:\n    \"\"\"\n    Adds a colorwheel to a figure.\n\n    Args:\n        fig: Matplotlib figure object.\n        axes: Iterable of axes to which the colorwheel will be added.\n        pos: Position of the colorwheel.\n        radius: Radius of the colorwheel in percentage of the ax radius.\n        x_offset: X-offset of the colorwheel in percentage of the cbar diameter.\n        y_offset: Y-offset of the colorwheel in percentage of the cbar diameter.\n        sm: ScalarMappable object.\n        cmap: Colormap name.\n        norm: Normalization object.\n        fontsize: Font size for tick labels.\n        N: Number of samples for the colorwheel.\n        labelpad: Padding for tick labels.\n        invert: Whether to invert the colormap.\n        mode: Mode of the colorwheel (\"1d\" or \"2d\").\n        ticks: Tick positions in degrees.\n\n    Returns:\n        Tuple containing the colorwheel axis and the annotation axis.\n    \"\"\"\n    cmap = plt.get_cmap(cmap)\n\n    pos = derive_position_for_supplementary_ax_hex(\n        fig,\n        axes=axes,\n        pos=pos,\n        radius=radius,\n        x_offset=x_offset,\n        y_offset=y_offset,\n    )\n    cb = fig.add_axes(pos, alpha=0)\n    cb.patch.set_alpha(0)\n\n    x = np.linspace(-1, 1, N)\n    y = np.linspace(-1, 1, N)\n    X, Y = np.meshgrid(x, y)\n    R = np.sqrt(X * X + Y * Y)\n    circular_mask = R &lt; 1\n    R[~circular_mask] = 0\n    if mode == \"1d\":\n        R[circular_mask] = 1\n\n    PHI = np.arctan2(Y, X)  # + np.pi\n    cb.imshow(\n        polar_to_cmap(R, PHI, invert=invert, cmap=cmap, norm=norm, sm=sm),\n        origin=\"lower\",\n    )\n    cb.set_axis_off()\n\n    cs = fig.add_axes(pos, polar=True, label=\"annotation\", alpha=0)\n    cs.set_facecolor(\"none\")\n    cs.set_yticks([])\n    cs.set_yticklabels([])  # turn off radial tick labels (yticks)\n\n    # cosmetic changes to tick labels\n    cs.tick_params(pad=labelpad, labelsize=fontsize)\n    cs.set_xticks(np.radians(ticks))\n    cs.set_xticklabels([x + \"\u00b0\" for x in np.array(ticks).astype(int).astype(str)])\n\n    plt.setp(cs.spines.values(), color=\"white\", linewidth=2)\n\n    return cb, cs\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.add_cluster_marker","title":"flyvis.analysis.visualization.plt_utils.add_cluster_marker","text":"<pre><code>add_cluster_marker(fig, ax, marker='o', marker_size=15, color='#4F73AE', x_offset=0, y_offset=0)\n</code></pre> <p>Adds a cluster marker to a figure.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Matplotlib figure object.</p> required <code>ax</code> <code>Axes</code> <p>Matplotlib axis object.</p> required <code>marker</code> <code>str</code> <p>Marker style.</p> <code>'o'</code> <code>marker_size</code> <code>int</code> <p>Marker size.</p> <code>15</code> <code>color</code> <code>str</code> <p>Marker color.</p> <code>'#4F73AE'</code> <code>x_offset</code> <code>float</code> <p>X-offset of the marker in percentage of the ax width.</p> <code>0</code> <code>y_offset</code> <code>float</code> <p>Y-offset of the marker in percentage of the ax height.</p> <code>0</code> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def add_cluster_marker(\n    fig: plt.Figure,\n    ax: Axes,\n    marker: str = \"o\",\n    marker_size: int = 15,\n    color: str = \"#4F73AE\",\n    x_offset: float = 0,\n    y_offset: float = 0,\n) -&gt; None:\n    \"\"\"\n    Adds a cluster marker to a figure.\n\n    Args:\n        fig: Matplotlib figure object.\n        ax: Matplotlib axis object.\n        marker: Marker style.\n        marker_size: Marker size.\n        color: Marker color.\n        x_offset: X-offset of the marker in percentage of the ax width.\n        y_offset: Y-offset of the marker in percentage of the ax height.\n    \"\"\"\n    # make all axes transparent to see the marker regardless where on the figure\n    # plane it is\n    for _ax in fig.axes:\n        _ax.patch.set_alpha(0)\n\n    # create an invisible ax that spans the entire figure to scatter the marker on it\n    overlay_ax = [ax for ax in fig.axes if ax.get_label() == \"overlay\"]\n    overlay_ax = (\n        overlay_ax[0]\n        if overlay_ax\n        else fig.add_axes([0, 0, 1, 1], label=\"overlay\", alpha=0)\n    )\n\n    overlay_ax.set_ylim(0, 1)\n    overlay_ax.set_xlim(0, 1)\n    overlay_ax.patch.set_alpha(0)\n    rm_spines(overlay_ax, visible=False, rm_xticks=True, rm_yticks=True)\n\n    # get where the axis is actually positioned, that will be annotated with the\n    # marker\n    left, bottom, width, height = ax.get_position().bounds\n\n    # scatter the marker relative to that position of the ax\n    overlay_ax.scatter(\n        left + x_offset * width,\n        bottom + y_offset * height,\n        marker=marker,\n        s=marker_size,\n        color=color,\n    )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.derive_position_for_supplementary_ax","title":"flyvis.analysis.visualization.plt_utils.derive_position_for_supplementary_ax","text":"<pre><code>derive_position_for_supplementary_ax(fig, pos='right', width=0.04, height=0.5, x_offset=0, y_offset=0, axes=None)\n</code></pre> <p>Returns a position for a supplementary ax.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Matplotlib figure object.</p> required <code>pos</code> <code>Literal['right', 'left', 'top', 'bottom']</code> <p>Position of the supplementary ax relative to the main axes.</p> <code>'right'</code> <code>width</code> <code>float</code> <p>Width of the supplementary ax in percentage of the main ax width.</p> <code>0.04</code> <code>height</code> <code>float</code> <p>Height of the supplementary ax in percentage of the main ax height.</p> <code>0.5</code> <code>x_offset</code> <code>float</code> <p>X-offset of the supplementary ax in percentage of the main ax width.</p> <code>0</code> <code>y_offset</code> <code>float</code> <p>Y-offset of the supplementary ax in percentage of the main ax height.</p> <code>0</code> <code>axes</code> <code>Iterable[Axes]</code> <p>Iterable of axes to which the supplementary ax will be added.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing the left, bottom, width, and height of the supplementary ax.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def derive_position_for_supplementary_ax(\n    fig: plt.Figure,\n    pos: Literal[\"right\", \"left\", \"top\", \"bottom\"] = \"right\",\n    width: float = 0.04,\n    height: float = 0.5,\n    x_offset: float = 0,\n    y_offset: float = 0,\n    axes: Iterable[Axes] = None,\n) -&gt; List[float]:\n    \"\"\"\n    Returns a position for a supplementary ax.\n\n    Args:\n        fig: Matplotlib figure object.\n        pos: Position of the supplementary ax relative to the main axes.\n        width: Width of the supplementary ax in percentage of the main ax width.\n        height: Height of the supplementary ax in percentage of the main ax height.\n        x_offset: X-offset of the supplementary ax in percentage of the main ax width.\n        y_offset: Y-offset of the supplementary ax in percentage of the main ax height.\n        axes: Iterable of axes to which the supplementary ax will be added.\n\n    Returns:\n        List containing the left, bottom, width, and height of the supplementary ax.\n    \"\"\"\n    axes = axes if axes is not None else fig.get_axes()\n    x0, y0, x1, y1 = np.array([ax.get_position().extents for ax in axes]).T\n    x0, y0, x1, y1 = x0.min(), y0.min(), x1.max(), y1.max()\n    ax_width = x1 - x0\n    ax_height = y1 - y0\n    positions = {\n        \"right\": [\n            x1 + ax_width * width / 2 + ax_width * width * x_offset,  # left\n            y0 + (1 - height) * ax_height / 2 + ax_height * height * y_offset,  # bottom\n            ax_width * width,  # width\n            ax_height * height,  # height\n        ],\n        \"left\": [\n            x0 - 3 / 2 * ax_width * width + ax_width * width * x_offset,  # left\n            y0 + (1 - height) * ax_height / 2 + y_offset,  # bottom\n            ax_width * width,  # width\n            ax_height * height,  # height\n        ],\n        \"top\": [\n            x1\n            - ax_width * width\n            + ax_width * width * x_offset,  # x0 + (1 - width) * ax_width/2\n            y1 + ax_height * height / 2 + ax_height * height * y_offset,\n            ax_width * width,\n            ax_height * height,\n        ],\n        \"bottom\": [\n            x0 + (1 - width) * ax_width / +ax_width * width * x_offset,\n            y0 - 3 / 2 * ax_height * height + ax_height * height * y_offset,\n            ax_width * width,\n            ax_height * height,\n        ],\n    }\n    return positions[pos]\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.derive_position_for_supplementary_ax_hex","title":"flyvis.analysis.visualization.plt_utils.derive_position_for_supplementary_ax_hex","text":"<pre><code>derive_position_for_supplementary_ax_hex(fig, axes=None, pos='southwest', radius=0.25, x_offset=0, y_offset=0)\n</code></pre> <p>Returns a position for a supplementary ax.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Matplotlib figure object.</p> required <code>axes</code> <code>Iterable[Axes]</code> <p>Iterable of axes to which the supplementary ax will be added.</p> <code>None</code> <code>pos</code> <code>Literal['southeast', 'east', 'northeast', 'north', 'northwest', 'west', 'southwest', 'south', 'origin']</code> <p>Position of the supplementary ax relative to the main axes.</p> <code>'southwest'</code> <code>radius</code> <code>float</code> <p>Radius of the supplementary ax in percentage of the main ax radius.</p> <code>0.25</code> <code>x_offset</code> <code>float</code> <p>X-offset of the supplementary ax in percentage of the main ax width.</p> <code>0</code> <code>y_offset</code> <code>float</code> <p>Y-offset of the supplementary ax in percentage of the main ax height.</p> <code>0</code> <p>Returns:</p> Type Description <code>List[float]</code> <p>List containing the left, bottom, width, and height of the supplementary ax.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def derive_position_for_supplementary_ax_hex(\n    fig: plt.Figure,\n    axes: Iterable[Axes] = None,\n    pos: Literal[\n        \"southeast\",\n        \"east\",\n        \"northeast\",\n        \"north\",\n        \"northwest\",\n        \"west\",\n        \"southwest\",\n        \"south\",\n        \"origin\",\n    ] = \"southwest\",\n    radius: float = 0.25,\n    x_offset: float = 0,\n    y_offset: float = 0,\n) -&gt; List[float]:\n    \"\"\"\n    Returns a position for a supplementary ax.\n\n    Args:\n        fig: Matplotlib figure object.\n        axes: Iterable of axes to which the supplementary ax will be added.\n        pos: Position of the supplementary ax relative to the main axes.\n        radius: Radius of the supplementary ax in percentage of the main ax radius.\n        x_offset: X-offset of the supplementary ax in percentage of the main ax width.\n        y_offset: Y-offset of the supplementary ax in percentage of the main ax height.\n\n    Returns:\n        List containing the left, bottom, width, and height of the supplementary ax.\n    \"\"\"\n    axes = axes if axes is not None else fig.get_axes()\n    x0, y0, x1, y1 = np.array([ax.get_position().extents for ax in axes]).T\n    x0, y0, x1, y1 = x0.min(), y0.min(), x1.max(), y1.max()\n    axes_width = x1 - x0\n    axes_height = y1 - y0\n    axes_radius = (axes_width + axes_height) / 4\n    new_ax_radius = axes_radius * radius\n    position = {\n        \"southeast\": [\n            x1 + x_offset * 2 * new_ax_radius,\n            y1\n            - axes_height\n            - 2 * new_ax_radius\n            + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"east\": [\n            x1 + x_offset * 2 * new_ax_radius,\n            y1\n            - axes_height / 2\n            - new_ax_radius\n            + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"northeast\": [\n            x1 + x_offset * 2 * new_ax_radius,\n            y1 + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"north\": [\n            x1 - axes_width / 2 - new_ax_radius + x_offset * 2 * new_ax_radius,\n            y1 + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"northwest\": [\n            x1 - axes_width - 2 * new_ax_radius + x_offset * 2 * new_ax_radius,\n            y1 + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"west\": [\n            x1 - axes_width - 2 * new_ax_radius + x_offset * 2 * new_ax_radius,\n            y1\n            - axes_height / 2\n            - new_ax_radius\n            + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"southwest\": [\n            x1 - axes_width - 2 * new_ax_radius + x_offset * 2 * new_ax_radius,\n            y1\n            - axes_height\n            - 2 * new_ax_radius\n            + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"south\": [\n            x1 - axes_width / 2 - new_ax_radius + x_offset * 2 * new_ax_radius,\n            y1\n            - axes_height\n            - 2 * new_ax_radius\n            + y_offset * 2 * new_ax_radius,  # + radius ** 2 * axes_height,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n        \"origin\": [\n            x0 + x_offset,\n            y0 + y_offset,\n            2 * new_ax_radius,\n            2 * new_ax_radius,\n        ],\n    }\n    return position[pos]\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.add_colorbar_to_fig","title":"flyvis.analysis.visualization.plt_utils.add_colorbar_to_fig","text":"<pre><code>add_colorbar_to_fig(fig, axes=None, pos='right', width=0.04, height=0.5, x_offset=0, y_offset=0, cmap=cm.get_cmap('binary'), fontsize=10, tick_length=1.5, tick_width=0.75, rm_outline=True, ticks=None, norm=None, label='', plain=False, use_math_text=False, scilimits=None, style='', alpha=1, n_ticks=9, discrete=False, n_discrete=None, discrete_labels=None, n_decimals=2)\n</code></pre> <p>Adds a colorbar to a figure.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>Matplotlib figure object.</p> required <code>axes</code> <code>Iterable[Axes]</code> <p>Iterable of axes to which the colorbar will be added.</p> <code>None</code> <code>pos</code> <code>Literal['right', 'left', 'top', 'bottom']</code> <p>Position of the colorbar.</p> <code>'right'</code> <code>width</code> <code>float</code> <p>Width of the colorbar in percentage of the ax width.</p> <code>0.04</code> <code>height</code> <code>float</code> <p>Height of the colorbar in percentage of the ax height.</p> <code>0.5</code> <code>x_offset</code> <code>float</code> <p>X-offset of the colorbar in percentage of the ax width.</p> <code>0</code> <code>y_offset</code> <code>float</code> <p>Y-offset of the colorbar in percentage of the ax height.</p> <code>0</code> <code>cmap</code> <code>Colormap</code> <p>Colormap.</p> <code>get_cmap('binary')</code> <code>fontsize</code> <code>int</code> <p>Font size for tick labels.</p> <code>10</code> <code>tick_length</code> <code>float</code> <p>Length of the tick marks.</p> <code>1.5</code> <code>tick_width</code> <code>float</code> <p>Width of the tick marks.</p> <code>0.75</code> <code>rm_outline</code> <code>bool</code> <p>Whether to remove the outline of the colorbar.</p> <code>True</code> <code>ticks</code> <code>Iterable[float]</code> <p>Tick positions.</p> <code>None</code> <code>norm</code> <code>Normalize</code> <p>Normalization object.</p> <code>None</code> <code>label</code> <code>str</code> <p>Colorbar label.</p> <code>''</code> <code>plain</code> <code>bool</code> <p>Whether to remove tick labels.</p> <code>False</code> <code>use_math_text</code> <code>bool</code> <p>Whether to use math text for tick labels.</p> <code>False</code> <code>scilimits</code> <code>Tuple[float, float]</code> <p>Limits for scientific notation.</p> <code>None</code> <code>style</code> <code>str</code> <p>Style for scientific notation.</p> <code>''</code> <code>alpha</code> <code>float</code> <p>Alpha value for the colorbar.</p> <code>1</code> <code>n_ticks</code> <code>int</code> <p>Number of ticks for TwoSlopeNorm.</p> <code>9</code> <code>discrete</code> <code>bool</code> <p>Whether to use discrete colors.</p> <code>False</code> <code>n_discrete</code> <code>int</code> <p>Number of discrete colors.</p> <code>None</code> <code>discrete_labels</code> <code>Iterable[str]</code> <p>Labels for discrete colors.</p> <code>None</code> <code>n_decimals</code> <code>int</code> <p>Number of decimal places for tick labels.</p> <code>2</code> <p>Returns:</p> Type Description <code>Colorbar</code> <p>Matplotlib colorbar object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def add_colorbar_to_fig(\n    fig: plt.Figure,\n    axes: Iterable[Axes] = None,\n    pos: Literal[\"right\", \"left\", \"top\", \"bottom\"] = \"right\",\n    width: float = 0.04,\n    height: float = 0.5,\n    x_offset: float = 0,\n    y_offset: float = 0,\n    cmap: colors.Colormap = cm.get_cmap(\"binary\"),\n    fontsize: int = 10,\n    tick_length: float = 1.5,\n    tick_width: float = 0.75,\n    rm_outline: bool = True,\n    ticks: Iterable[float] = None,\n    norm: Normalize = None,\n    label: str = \"\",\n    plain: bool = False,\n    use_math_text: bool = False,\n    scilimits: Tuple[float, float] = None,\n    style: str = \"\",\n    alpha: float = 1,\n    n_ticks: int = 9,  # only effective if norm is TwoSlopeNorm\n    discrete: bool = False,\n    n_discrete: int = None,\n    discrete_labels: Iterable[str] = None,\n    n_decimals: int = 2,\n) -&gt; mpl.colorbar.Colorbar:\n    \"\"\"\n    Adds a colorbar to a figure.\n\n    Args:\n        fig: Matplotlib figure object.\n        axes: Iterable of axes to which the colorbar will be added.\n        pos: Position of the colorbar.\n        width: Width of the colorbar in percentage of the ax width.\n        height: Height of the colorbar in percentage of the ax height.\n        x_offset: X-offset of the colorbar in percentage of the ax width.\n        y_offset: Y-offset of the colorbar in percentage of the ax height.\n        cmap: Colormap.\n        fontsize: Font size for tick labels.\n        tick_length: Length of the tick marks.\n        tick_width: Width of the tick marks.\n        rm_outline: Whether to remove the outline of the colorbar.\n        ticks: Tick positions.\n        norm: Normalization object.\n        label: Colorbar label.\n        plain: Whether to remove tick labels.\n        use_math_text: Whether to use math text for tick labels.\n        scilimits: Limits for scientific notation.\n        style: Style for scientific notation.\n        alpha: Alpha value for the colorbar.\n        n_ticks: Number of ticks for TwoSlopeNorm.\n        discrete: Whether to use discrete colors.\n        n_discrete: Number of discrete colors.\n        discrete_labels: Labels for discrete colors.\n        n_decimals: Number of decimal places for tick labels.\n\n    Returns:\n        Matplotlib colorbar object.\n    \"\"\"\n    _orientation = \"vertical\" if pos in (\"left\", \"right\") else \"horizontal\"\n\n    position = derive_position_for_supplementary_ax(\n        fig=fig,\n        pos=pos,\n        width=width,\n        height=height,\n        x_offset=x_offset,\n        y_offset=y_offset,\n        axes=axes,\n    )\n    cbax = fig.add_axes(position, label=\"cbar\")\n\n    cbar = mpl.colorbar.ColorbarBase(\n        cbax,\n        cmap=cmap,\n        norm=norm,\n        orientation=_orientation,\n        ticks=ticks,\n        alpha=alpha,\n    )\n    cbar.set_label(fontsize=fontsize, label=label)\n    cbar.ax.tick_params(labelsize=fontsize, length=tick_length, width=tick_width)\n    if pos in (\"left\", \"right\"):\n        scalarformatter = isinstance(\n            cbar.ax.yaxis.get_major_formatter(), mpl.ticker.ScalarFormatter\n        )\n        cbar.ax.yaxis.set_ticks_position(pos)\n        cbar.ax.yaxis.set_label_position(pos)\n        cbar.ax.yaxis.get_offset_text().set_fontsize(fontsize)\n        cbar.ax.yaxis.get_offset_text().set_horizontalalignment(\"left\")\n        cbar.ax.yaxis.get_offset_text().set_verticalalignment(\"bottom\")\n    else:\n        scalarformatter = isinstance(\n            cbar.ax.xaxis.get_major_formatter(), mpl.ticker.ScalarFormatter\n        )\n        cbar.ax.xaxis.set_ticks_position(pos)\n        cbar.ax.xaxis.set_label_position(pos)\n        cbar.ax.xaxis.get_offset_text().set_fontsize(fontsize)\n        cbar.ax.xaxis.get_offset_text().set_verticalalignment(\"top\")\n        cbar.ax.xaxis.get_offset_text().set_horizontalalignment(\"left\")\n\n    if scalarformatter:\n        cbar.ax.ticklabel_format(\n            style=style, useMathText=use_math_text, scilimits=scilimits\n        )\n\n    if rm_outline:\n        cbar.outline.set_visible(False)\n\n    if isinstance(norm, TwoSlopeNorm):\n        vmin = norm.vmin\n        vmax = norm.vmax\n        vcenter = norm.vcenter\n        left_ticks = np.linspace(vmin, vcenter, n_ticks // 2)\n        right_ticks = np.linspace(vcenter, vmax, n_ticks // 2)\n        ticks = ticks or [*left_ticks, *right_ticks[1:]]\n        cbar.set_ticks(\n            ticks,\n            labels=[f\"{t:.{n_decimals}f}\" for t in ticks],\n            fontsize=fontsize,\n        )\n\n    if plain:\n        cbar.set_ticks([])\n\n    if discrete:\n        # to put ticklabels for discrete colors in the middle\n        if not n_discrete:\n            raise ValueError(f\"n_discrete {n_discrete}\")\n        lim = cbar.ax.get_ylim() if pos in [\"left\", \"right\"] else cbar.ax.get_xlim()\n        color_width = (lim[1] - lim[0]) / n_discrete\n        label_offset_to_center = color_width / 2\n        labels = np.arange(n_discrete)\n        loc = np.linspace(*lim, n_discrete, endpoint=False) + label_offset_to_center\n        cbar.set_ticks(loc)\n        cbar.set_ticklabels(discrete_labels or labels)\n\n    return cbar\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_norm","title":"flyvis.analysis.visualization.plt_utils.get_norm","text":"<pre><code>get_norm(norm=None, vmin=None, vmax=None, midpoint=None, log=None, symlog=None)\n</code></pre> <p>Returns a normalization object for color normalization.</p> <p>Parameters:</p> Name Type Description Default <code>norm</code> <code>Normalize</code> <p>A class which, when called, can normalize data into an interval [vmin, vmax].</p> <code>None</code> <code>vmin</code> <code>float</code> <p>Minimum value for normalization.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value for normalization.</p> <code>None</code> <code>midpoint</code> <code>float</code> <p>Midpoint value so that data is normalized around it.</p> <code>None</code> <code>log</code> <code>bool</code> <p>Whether to normalize on a log-scale.</p> <code>None</code> <code>symlog</code> <code>float</code> <p>Normalizes to symlog with linear range around the range (-symlog, symlog).</p> <code>None</code> <p>Returns:</p> Type Description <code>Normalize</code> <p>Normalization object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_norm(\n    norm: Normalize = None,\n    vmin: float = None,\n    vmax: float = None,\n    midpoint: float = None,\n    log: bool = None,\n    symlog: float = None,\n) -&gt; Normalize:\n    \"\"\"\n    Returns a normalization object for color normalization.\n\n    Args:\n        norm: A class which, when called, can normalize data into an interval\n            [vmin, vmax].\n        vmin: Minimum value for normalization.\n        vmax: Maximum value for normalization.\n        midpoint: Midpoint value so that data is normalized around it.\n        log: Whether to normalize on a log-scale.\n        symlog: Normalizes to symlog with linear range around the range (-symlog, symlog).\n\n    Returns:\n        Normalization object.\n    \"\"\"\n    if norm:\n        return norm\n\n    if all(val is not None for val in (vmin, vmax)):\n        vmin -= 1e-15\n        vmax += 1e-15\n\n    if all(val is not None for val in (vmin, vmax, midpoint)):\n        if vmin &gt; midpoint or np.isclose(vmin, midpoint, atol=1e-9):\n            vmin = midpoint - vmax\n        if vmax &lt; midpoint or np.isclose(vmax, midpoint, atol=1e-9):\n            vmax = midpoint - vmin\n        return TwoSlopeNorm(vcenter=midpoint, vmin=vmin, vmax=vmax)\n    elif all(val is not None for val in (vmin, vmax, log)):\n        return mpl.colors.LogNorm(vmin=vmin, vmax=vmax)\n    elif all(val is not None for val in (vmin, vmax, symlog)):\n        v = max(np.abs(vmin), np.abs(vmax))\n        return mpl.colors.SymLogNorm(symlog, vmin=-v, vmax=v)\n    elif all(val is not None for val in (vmin, vmax)):\n        return mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n    else:\n        return None\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_scalarmapper","title":"flyvis.analysis.visualization.plt_utils.get_scalarmapper","text":"<pre><code>get_scalarmapper(scalarmapper=None, cmap=None, norm=None, vmin=None, vmax=None, midpoint=None, log=None, symlog=None)\n</code></pre> <p>Returns scalarmappable with norm from <code>get_norm</code> and cmap.</p> <p>Parameters:</p> Name Type Description Default <code>scalarmapper</code> <code>ScalarMappable</code> <p>Scalarmappable for data to RGBA mapping.</p> <code>None</code> <code>cmap</code> <code>Colormap</code> <p>Colormap.</p> <code>None</code> <code>norm</code> <code>Normalize</code> <p>Normalization object.</p> <code>None</code> <code>vmin</code> <code>float</code> <p>Minimum value for normalization.</p> <code>None</code> <code>vmax</code> <code>float</code> <p>Maximum value for normalization.</p> <code>None</code> <code>midpoint</code> <code>float</code> <p>Midpoint value for normalization.</p> <code>None</code> <code>log</code> <code>bool</code> <p>Whether to normalize on a log-scale.</p> <code>None</code> <code>symlog</code> <code>float</code> <p>Normalizes to symlog with linear range around the range (-symlog, symlog).</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ScalarMappable, Normalize]</code> <p>Tuple containing the scalarmappable and the normalization object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_scalarmapper(\n    scalarmapper: ScalarMappable = None,\n    cmap: colors.Colormap = None,\n    norm: Normalize = None,\n    vmin: float = None,\n    vmax: float = None,\n    midpoint: float = None,\n    log: bool = None,\n    symlog: float = None,\n) -&gt; Tuple[ScalarMappable, Normalize]:\n    \"\"\"\n    Returns scalarmappable with norm from `get_norm` and cmap.\n\n    Args:\n        scalarmapper: Scalarmappable for data to RGBA mapping.\n        cmap: Colormap.\n        norm: Normalization object.\n        vmin: Minimum value for normalization.\n        vmax: Maximum value for normalization.\n        midpoint: Midpoint value for normalization.\n        log: Whether to normalize on a log-scale.\n        symlog: Normalizes to symlog with linear range around the range (-symlog, symlog).\n\n    Returns:\n        Tuple containing the scalarmappable and the normalization object.\n    \"\"\"\n    if scalarmapper:\n        return scalarmapper, norm\n\n    norm = get_norm(\n        norm=norm,\n        vmin=vmin,\n        vmax=vmax,\n        midpoint=midpoint,\n        log=log,\n        symlog=symlog,\n    )\n    return plt.cm.ScalarMappable(norm=norm, cmap=cmap), norm\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_lims","title":"flyvis.analysis.visualization.plt_utils.get_lims","text":"<pre><code>get_lims(z, offset, min=None, max=None)\n</code></pre> <p>Get scalar bounds of Ndim-array-like structure with relative offset.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>Union[ndarray, Iterable[ndarray]]</code> <p>Ndim-array-like structure.</p> required <code>offset</code> <code>float</code> <p>Relative offset for the bounds.</p> required <code>min</code> <code>float</code> <p>Minimum value for the bounds.</p> <code>None</code> <code>max</code> <code>float</code> <p>Maximum value for the bounds.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Tuple containing the minimum and maximum values.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_lims(\n    z: Union[np.ndarray, Iterable[np.ndarray]],\n    offset: float,\n    min: float = None,\n    max: float = None,\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Get scalar bounds of Ndim-array-like structure with relative offset.\n\n    Args:\n        z: Ndim-array-like structure.\n        offset: Relative offset for the bounds.\n        min: Minimum value for the bounds.\n        max: Maximum value for the bounds.\n\n    Returns:\n        Tuple containing the minimum and maximum values.\n    \"\"\"\n\n    def sub_nan(val: float, sub: float) -&gt; float:\n        if np.isnan(val):\n            return sub\n        else:\n            return val\n\n    if isinstance(z, (tuple, list)):\n        z = list(map(lambda x: get_lims(x, offset), z))\n    if isinstance(z, torch.Tensor):\n        z = z.detach().cpu().numpy()\n    z = np.array(z)[~np.isinf(z)]\n    if not z.any():\n        return -1, 1\n    _min, _max = np.nanmin(z), np.nanmax(z)\n    _range = np.abs(_max - _min)\n    _min -= _range * offset\n    _max += _range * offset\n    _min, _max = sub_nan(_min, 0), sub_nan(_max, 1)\n    if min is not None:\n        _min = np.min((min, _min))\n    if max is not None:\n        _max = np.max((max, _max))\n    return _min, _max\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.avg_pool","title":"flyvis.analysis.visualization.plt_utils.avg_pool","text":"<pre><code>avg_pool(trace, N)\n</code></pre> <p>Smoothes (multiple) traces over the second dimension using the GPU.</p> <p>Parameters:</p> Name Type Description Default <code>trace</code> <code>ndarray</code> <p>Array of shape (N, t).</p> required <code>N</code> <code>int</code> <p>Window size for averaging.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Smoothed trace array.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def avg_pool(trace: np.ndarray, N: int) -&gt; np.ndarray:\n    \"\"\"\n    Smoothes (multiple) traces over the second dimension using the GPU.\n\n    Args:\n        trace: Array of shape (N, t).\n        N: Window size for averaging.\n\n    Returns:\n        Smoothed trace array.\n    \"\"\"\n    shape = trace.shape\n    trace = trace.reshape(np.prod(shape[:-1]), 1, shape[-1])\n    with torch.no_grad():\n        trace_smooth = (\n            F.avg_pool1d(torch.tensor(trace, dtype=torch.float32), N, N).cpu().numpy()\n        )\n    return trace_smooth.reshape(shape[0], -1)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.width_n_height","title":"flyvis.analysis.visualization.plt_utils.width_n_height","text":"<pre><code>width_n_height(N, aspect_ratio, max_width=None, max_height=None)\n</code></pre> <p>Integer width and height for a grid of N plots with aspect ratio.</p> <p>Parameters:</p> Name Type Description Default <code>N</code> <code>int</code> <p>Number of plots.</p> required <code>aspect_ratio</code> <code>float</code> <p>Aspect ratio of the grid.</p> required <code>max_width</code> <code>int</code> <p>Maximum width of the grid.</p> <code>None</code> <code>max_height</code> <code>int</code> <p>Maximum height of the grid.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple containing the width and height of the grid.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def width_n_height(\n    N: int, aspect_ratio: float, max_width: int = None, max_height: int = None\n) -&gt; Tuple[int, int]:\n    \"\"\"\n    Integer width and height for a grid of N plots with aspect ratio.\n\n    Args:\n        N: Number of plots.\n        aspect_ratio: Aspect ratio of the grid.\n        max_width: Maximum width of the grid.\n        max_height: Maximum height of the grid.\n\n    Returns:\n        Tuple containing the width and height of the grid.\n    \"\"\"\n    if max_width is not None and max_height is not None:\n        raise ValueError\n\n    _sqrt = int(np.ceil(np.sqrt(N)))\n\n    gridwidth = np.ceil(_sqrt * aspect_ratio).astype(int)\n    gridheight = np.ceil(_sqrt / aspect_ratio).astype(int)\n\n    gridwidth = max(1, min(N, gridwidth, np.ceil(N / gridheight)))\n    gridheight = max(1, min(N, gridheight, np.ceil(N / gridwidth)))\n\n    if max_width is not None and gridwidth &gt; max_width:\n        gridwidth = max_width\n        gridheight = np.ceil(N / gridwidth)\n\n    if max_height is not None and gridheight &gt; max_height:\n        gridheight = max_height\n        gridwidth = np.ceil(N / gridheight)\n\n    assert gridwidth * gridheight &gt;= N\n\n    return int(gridwidth), int(gridheight)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.get_axis_grid","title":"flyvis.analysis.visualization.plt_utils.get_axis_grid","text":"<pre><code>get_axis_grid(alist=None, gridwidth=None, gridheight=None, max_width=None, max_height=None, fig=None, ax=None, axes=None, aspect_ratio=1, figsize=None, scale=3, projection=None, as_matrix=False, fontsize=5, wspace=0.1, hspace=0.3, alpha=1, sharex=None, sharey=None, unmask_n=None)\n</code></pre> <p>Create axis grid for a list of elements or integer width and height.</p> <p>Parameters:</p> Name Type Description Default <code>alist</code> <code>Iterable</code> <p>List of elements to create grid for.</p> <code>None</code> <code>gridwidth</code> <code>int</code> <p>Width of grid.</p> <code>None</code> <code>gridheight</code> <code>int</code> <p>Height of grid.</p> <code>None</code> <code>max_width</code> <code>int</code> <p>Maximum width of grid.</p> <code>None</code> <code>max_height</code> <code>int</code> <p>Maximum height of grid.</p> <code>None</code> <code>fig</code> <code>Figure</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Axes</code> <p>Existing axis to use. This ax will be divided into a grid of axes with the same size as the grid.</p> <code>None</code> <code>axes</code> <code>Iterable[Axes]</code> <p>Existing axes to use.</p> <code>None</code> <code>aspect_ratio</code> <code>float</code> <p>Aspect ratio of grid.</p> <code>1</code> <code>figsize</code> <code>List[float]</code> <p>Figure size.</p> <code>None</code> <code>scale</code> <code>Union[int, Iterable[int]]</code> <p>Scales figure size by this factor(s) times the grid width and height.</p> <code>3</code> <code>projection</code> <code>Union[str, Iterable[str]]</code> <p>Projection of axes.</p> <code>None</code> <code>as_matrix</code> <code>bool</code> <p>Return axes as matrix.</p> <code>False</code> <code>fontsize</code> <code>int</code> <p>Fontsize of axes.</p> <code>5</code> <code>wspace</code> <code>float</code> <p>Width space between axes.</p> <code>0.1</code> <code>hspace</code> <code>float</code> <p>Height space between axes.</p> <code>0.3</code> <code>alpha</code> <code>float</code> <p>Alpha of axes.</p> <code>1</code> <code>sharex</code> <code>Axes</code> <p>Share x axis. Only effective if a new grid of axes is created.</p> <code>None</code> <code>sharey</code> <code>Axes</code> <p>Share y axis. Only effective if a new grid of axes is created.</p> <code>None</code> <code>unmask_n</code> <code>int</code> <p>Number of elements to unmask. If None, all elements are unmasked. If provided elements at indices &gt;= unmask_n are padded with nans.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Union[List[Axes], ndarray], Tuple[int, int]]</code> <p>Tuple containing the figure, axes, and the grid width and height.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def get_axis_grid(\n    alist: Iterable = None,\n    gridwidth: int = None,\n    gridheight: int = None,\n    max_width: int = None,\n    max_height: int = None,\n    fig: plt.Figure = None,\n    ax: Axes = None,\n    axes: Iterable[Axes] = None,\n    aspect_ratio: float = 1,\n    figsize: List[float] = None,\n    scale: Union[int, Iterable[int]] = 3,\n    projection: Union[str, Iterable[str]] = None,\n    as_matrix: bool = False,\n    fontsize: int = 5,\n    wspace: float = 0.1,\n    hspace: float = 0.3,\n    alpha: float = 1,\n    sharex: Axes = None,\n    sharey: Axes = None,\n    unmask_n: int = None,\n) -&gt; Tuple[plt.Figure, Union[List[Axes], np.ndarray], Tuple[int, int]]:\n    \"\"\"\n    Create axis grid for a list of elements or integer width and height.\n\n    Args:\n        alist: List of elements to create grid for.\n        gridwidth: Width of grid.\n        gridheight: Height of grid.\n        max_width: Maximum width of grid.\n        max_height: Maximum height of grid.\n        fig: Existing figure to use.\n        ax: Existing axis to use. This ax will be divided into a grid of axes with the\n            same size as the grid.\n        axes: Existing axes to use.\n        aspect_ratio: Aspect ratio of grid.\n        figsize: Figure size.\n        scale: Scales figure size by this factor(s) times the grid width and height.\n        projection: Projection of axes.\n        as_matrix: Return axes as matrix.\n        fontsize: Fontsize of axes.\n        wspace: Width space between axes.\n        hspace: Height space between axes.\n        alpha: Alpha of axes.\n        sharex: Share x axis. Only effective if a new grid of axes is created.\n        sharey: Share y axis. Only effective if a new grid of axes is created.\n        unmask_n: Number of elements to unmask. If None, all elements are unmasked.\n            If provided elements at indices &gt;= unmask_n are padded with nans.\n\n    Returns:\n        Tuple containing the figure, axes, and the grid width and height.\n    \"\"\"\n    if alist is not None and (\n        gridwidth is None or gridheight is None or gridwidth * gridheight != len(alist)\n    ):\n        gridwidth, gridheight = width_n_height(\n            len(alist), aspect_ratio, max_width=max_width, max_height=max_height\n        )\n    elif gridwidth and gridheight:\n        alist = range(gridwidth * gridheight)\n    else:\n        raise ValueError(\"Either specify alist or gridwidth and gridheight manually.\")\n    unmask_n = unmask_n or len(alist)\n    if figsize is not None:\n        pass\n    elif isinstance(scale, Number):\n        figsize = [scale * gridwidth, scale * gridheight]\n    elif isinstance(scale, Iterable) and len(scale) == 2:\n        figsize = [scale[0] * gridwidth, scale[1] * gridheight]\n\n    if fig is None:\n        fig = figure(figsize=figsize, hspace=hspace, wspace=wspace)\n\n    if not isinstance(projection, Iterable) or isinstance(projection, str):\n        projection = (projection,) * len(alist)\n\n    if isinstance(ax, Iterable):\n        assert len(ax) == len(alist)\n        if isinstance(ax, dict):\n            ax = list(ax.values())\n        return fig, ax, (gridwidth, gridheight)\n\n    if ax:\n        # divide an existing ax in a figure\n        matrix = np.ones(gridwidth * gridheight) * np.nan\n        for i in range(len(alist)):\n            matrix[i] = i\n        axes = divide_axis_to_grid(\n            ax,\n            matrix=matrix.reshape(gridwidth, gridheight),\n            wspace=wspace,\n            hspace=hspace,\n        )\n        axes = list(axes.values())\n    elif axes is None:\n        # fill a figure with axes\n        axes = []\n        _sharex, _sharey = None, None\n\n        for i, _ in enumerate(alist):\n            if i &lt; unmask_n:\n                ax = subplot(\n                    \"\",\n                    grid=(gridheight, gridwidth),\n                    location=(int(i // gridwidth), int(i % gridwidth)),\n                    rowspan=1,\n                    colspan=1,\n                    sharex=_sharex,\n                    sharey=_sharey,\n                    projection=projection[i],\n                )\n\n                if sharex is not None:\n                    sharex = ax\n                if sharey is not None:\n                    sharey = ax\n\n                axes.append(ax)\n            else:\n                axes.append(np.nan)\n\n    for ax in axes:\n        if isinstance(ax, Axes):\n            ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n            ax.patch.set_alpha(alpha)\n\n    if as_matrix:\n        axes = np.array(axes).reshape(gridheight, gridwidth)\n\n    return fig, axes, (gridwidth, gridheight)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.figure","title":"flyvis.analysis.visualization.plt_utils.figure","text":"<pre><code>figure(figsize, hspace=0.3, wspace=0.1, left=0.125, right=0.9, top=0.9, bottom=0.1, frameon=None)\n</code></pre> <p>Create a figure with the given size and spacing.</p> <p>Parameters:</p> Name Type Description Default <code>figsize</code> <code>List[float]</code> <p>Figure size.</p> required <code>hspace</code> <code>float</code> <p>Height space between subplots.</p> <code>0.3</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0.1</code> <code>left</code> <code>float</code> <p>Left margin.</p> <code>0.125</code> <code>right</code> <code>float</code> <p>Right margin.</p> <code>0.9</code> <code>top</code> <code>float</code> <p>Top margin.</p> <code>0.9</code> <code>bottom</code> <code>float</code> <p>Bottom margin.</p> <code>0.1</code> <code>frameon</code> <code>bool</code> <p>Whether to draw the figure frame.</p> <code>None</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib figure object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def figure(\n    figsize: List[float],\n    hspace: float = 0.3,\n    wspace: float = 0.1,\n    left: float = 0.125,\n    right: float = 0.9,\n    top: float = 0.9,\n    bottom: float = 0.1,\n    frameon: bool = None,\n) -&gt; plt.Figure:\n    \"\"\"\n    Create a figure with the given size and spacing.\n\n    Args:\n        figsize: Figure size.\n        hspace: Height space between subplots.\n        wspace: Width space between subplots.\n        left: Left margin.\n        right: Right margin.\n        top: Top margin.\n        bottom: Bottom margin.\n        frameon: Whether to draw the figure frame.\n\n    Returns:\n        Matplotlib figure object.\n    \"\"\"\n    fig = plt.figure(figsize=figsize, frameon=frameon)\n    plt.subplots_adjust(\n        hspace=hspace,\n        wspace=wspace,\n        left=left,\n        top=top,\n        right=right,\n        bottom=bottom,\n    )\n    return fig\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.subplot","title":"flyvis.analysis.visualization.plt_utils.subplot","text":"<pre><code>subplot(title='', grid=(1, 1), location=(0, 0), colspan=1, rowspan=1, projection=None, sharex=None, sharey=None, xlabel='', ylabel='', face_alpha=1.0, fontisze=5, title_pos='center', position=None, **kwargs)\n</code></pre> <p>Create a subplot using subplot2grid with some extra options.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Title of the subplot.</p> <code>''</code> <code>grid</code> <code>Tuple[int, int]</code> <p>Grid shape.</p> <code>(1, 1)</code> <code>location</code> <code>Tuple[int, int]</code> <p>Location of the subplot in the grid.</p> <code>(0, 0)</code> <code>colspan</code> <code>int</code> <p>Number of columns the subplot spans.</p> <code>1</code> <code>rowspan</code> <code>int</code> <p>Number of rows the subplot spans.</p> <code>1</code> <code>projection</code> <code>str</code> <p>Projection type (e.g., \u2018polar\u2019).</p> <code>None</code> <code>sharex</code> <code>Axes</code> <p>Axis to share x-axis with.</p> <code>None</code> <code>sharey</code> <code>Axes</code> <p>Axis to share y-axis with.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>X-axis label.</p> <code>''</code> <code>ylabel</code> <code>str</code> <p>Y-axis label.</p> <code>''</code> <code>face_alpha</code> <code>float</code> <p>Alpha value for the face color.</p> <code>1.0</code> <code>fontisze</code> <code>int</code> <p>Font size for title and labels.</p> <code>5</code> <code>title_pos</code> <code>Literal['center', 'left', 'right']</code> <p>Position of the title.</p> <code>'center'</code> <code>position</code> <code>List[float]</code> <p>Position for the subplot.</p> <code>None</code> <p>Returns:</p> Type Description <code>Axes</code> <p>Matplotlib axis object.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def subplot(\n    title: str = \"\",\n    grid: Tuple[int, int] = (1, 1),\n    location: Tuple[int, int] = (0, 0),\n    colspan: int = 1,\n    rowspan: int = 1,\n    projection: str = None,\n    sharex: Axes = None,\n    sharey: Axes = None,\n    xlabel: str = \"\",\n    ylabel: str = \"\",\n    face_alpha: float = 1.0,\n    fontisze: int = 5,\n    title_pos: Literal[\"center\", \"left\", \"right\"] = \"center\",\n    position: List[float] = None,\n    **kwargs,\n) -&gt; Axes:\n    \"\"\"\n    Create a subplot using subplot2grid with some extra options.\n\n    Args:\n        title: Title of the subplot.\n        grid: Grid shape.\n        location: Location of the subplot in the grid.\n        colspan: Number of columns the subplot spans.\n        rowspan: Number of rows the subplot spans.\n        projection: Projection type (e.g., 'polar').\n        sharex: Axis to share x-axis with.\n        sharey: Axis to share y-axis with.\n        xlabel: X-axis label.\n        ylabel: Y-axis label.\n        face_alpha: Alpha value for the face color.\n        fontisze: Font size for title and labels.\n        title_pos: Position of the title.\n        position: Position for the subplot.\n\n    Returns:\n        Matplotlib axis object.\n    \"\"\"\n    ax = plt.subplot2grid(\n        grid,\n        location,\n        colspan,\n        rowspan,\n        sharex=sharex,\n        sharey=sharey,\n        projection=projection,\n    )\n    if position:\n        ax.set_position(position)\n    ax.patch.set_alpha(face_alpha)\n\n    ax.set_title(title, fontsize=fontisze, loc=title_pos)\n\n    plt.xlabel(xlabel, fontsize=fontisze)\n    plt.ylabel(ylabel, fontsize=fontisze)\n\n    return ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.divide_axis_to_grid","title":"flyvis.analysis.visualization.plt_utils.divide_axis_to_grid","text":"<pre><code>divide_axis_to_grid(ax, matrix=((0, 1, 2), (3, 3, 3)), wspace=0.1, hspace=0.1, projection=None)\n</code></pre> <p>Divides an existing axis inside a figure to a grid specified by unique elements in a matrix.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Existing Axes object.</p> required <code>matrix</code> <code>ndarray</code> <p>Grid matrix, where each unique element specifies a new axis.</p> <code>((0, 1, 2), (3, 3, 3))</code> <code>wspace</code> <code>float</code> <p>Horizontal space between new axes.</p> <code>0.1</code> <code>hspace</code> <code>float</code> <p>Vertical space between new axes.</p> <code>0.1</code> <code>projection</code> <code>str</code> <p>Projection of new axes.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[Any, Axes]</code> <p>Dictionary of new axes, where keys are unique elements in the matrix.</p> Example <pre><code>fig = plt.figure()\nax = plt.subplot()\nplt.tight_layout()\ndivide_axis_to_grid(ax, matrix=[[0, 1, 1, 1, 2, 2, 2],\n                                    [3, 4, 5, 6, 2, 2, 2],\n                                    [3, 7, 7, 7, 2, 2, 2],\n                                    [3, 8, 8, 12, 2, 2, 2],\n                                    [3, 10, 11, 12, 2, 2, 2]],\n                        wspace=0.1, hspace=0.1)\n</code></pre> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def divide_axis_to_grid(\n    ax: Axes,\n    matrix: np.ndarray = ((0, 1, 2), (3, 3, 3)),\n    wspace: float = 0.1,\n    hspace: float = 0.1,\n    projection: str = None,\n) -&gt; Dict[Any, Axes]:\n    \"\"\"\n    Divides an existing axis inside a figure to a grid specified by unique elements\n    in a matrix.\n\n    Args:\n        ax: Existing Axes object.\n        matrix: Grid matrix, where each unique element specifies a new axis.\n        wspace: Horizontal space between new axes.\n        hspace: Vertical space between new axes.\n        projection: Projection of new axes.\n\n    Returns:\n        Dictionary of new axes, where keys are unique elements in the matrix.\n\n    Example:\n        ```python\n        fig = plt.figure()\n        ax = plt.subplot()\n        plt.tight_layout()\n        divide_axis_to_grid(ax, matrix=[[0, 1, 1, 1, 2, 2, 2],\n                                            [3, 4, 5, 6, 2, 2, 2],\n                                            [3, 7, 7, 7, 2, 2, 2],\n                                            [3, 8, 8, 12, 2, 2, 2],\n                                            [3, 10, 11, 12, 2, 2, 2]],\n                                wspace=0.1, hspace=0.1)\n        ```\n    \"\"\"\n\n    # get position of original axis, and dispose it\n    x0, y0, x1, y1 = ax.get_position().extents\n    ax.set_axis_off()\n    ax.patch.set_alpha(0)\n    fig = ax.figure\n\n    # get grid shape\n    n_row, n_col = np.array(matrix).shape\n\n    # get geometry params\n    width = x1 - x0\n    height = y1 - y0\n    height_per_row = height / n_row\n    width_per_col = width / n_col\n\n    _ax_pos = {}\n\n    for i, row in enumerate(matrix):\n        for j, _ax in enumerate(row):\n            # get occurence of unique element per row and column\n            _ax_per_row = sum([1 for _ in np.array(matrix).T[j] if _ == _ax])\n            _ax_per_col = sum([1 for _ in row if _ == _ax])\n\n            # compute positioning of _ax\n            left = x0 + j * width_per_col + wspace / 2\n            bottom = y0 + height - (i + _ax_per_row) * height_per_row + hspace / 2\n            _width = width_per_col * _ax_per_col - min(\n                wspace / 2, width_per_col * _ax_per_col\n            )\n            _height = height_per_row * _ax_per_row - min(\n                hspace / 2, height_per_row * _ax_per_row\n            )\n\n            # store positioning\n            if _ax not in _ax_pos and not np.isnan(_ax):\n                _ax_pos[_ax] = [left, bottom, _width, _height]\n\n    # add axis to existing figure and store in dict\n    axes = {k: None for k in _ax_pos}\n    for _ax, pos in _ax_pos.items():\n        axes[_ax] = fig.add_axes(pos, projection=projection)\n\n    return axes\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.divide_figure_to_grid","title":"flyvis.analysis.visualization.plt_utils.divide_figure_to_grid","text":"<pre><code>divide_figure_to_grid(matrix=[[0, 1, 1, 1, 2, 2, 2], [3, 4, 5, 6, 2, 2, 2], [3, 7, 7, 7, 2, 2, 2], [3, 8, 8, 12, 2, 2, 2], [3, 10, 11, 12, 2, 2, 2]], as_matrix=False, alpha=0, constrained_layout=False, fig=None, figsize=[10, 10], projection=None, wspace=0.1, hspace=0.3, no_spines=False, keep_nan_axes=False, fontsize=5, reshape_order='F')\n</code></pre> <p>Creates a figure grid specified by the arrangement of unique elements in a matrix.</p> Info <p><code>matplotlib</code> now also has <code>matplotlib.pyplot.subplot_mosaic</code> which does the same thing and should be used instead.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>List[List[int]]</code> <p>Grid layout specification.</p> <code>[[0, 1, 1, 1, 2, 2, 2], [3, 4, 5, 6, 2, 2, 2], [3, 7, 7, 7, 2, 2, 2], [3, 8, 8, 12, 2, 2, 2], [3, 10, 11, 12, 2, 2, 2]]</code> <code>as_matrix</code> <code>bool</code> <p>If True, return axes as a numpy array.</p> <code>False</code> <code>alpha</code> <code>float</code> <p>Alpha value for axis patches.</p> <code>0</code> <code>constrained_layout</code> <code>bool</code> <p>Use constrained layout for the figure.</p> <code>False</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to use. If None, a new figure is created.</p> <code>None</code> <code>figsize</code> <code>List[float]</code> <p>Figure size in inches.</p> <code>[10, 10]</code> <code>projection</code> <code>Optional[Union[str, List[str]]]</code> <p>Projection type for the axes.</p> <code>None</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0.1</code> <code>hspace</code> <code>float</code> <p>Height space between subplots.</p> <code>0.3</code> <code>no_spines</code> <code>bool</code> <p>If True, remove spines from all axes.</p> <code>False</code> <code>keep_nan_axes</code> <code>bool</code> <p>If True, keep axes for NaN values in the matrix.</p> <code>False</code> <code>fontsize</code> <code>int</code> <p>Font size for tick labels.</p> <code>5</code> <code>reshape_order</code> <code>Literal['C', 'F', 'A', 'K']</code> <p>Order to use when reshaping the axes array.</p> <code>'F'</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Union[Dict[int, Axes], ndarray]]</code> <p>A tuple containing the figure and a dictionary or numpy array of axes.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def divide_figure_to_grid(\n    matrix: List[List[int]] = [\n        [0, 1, 1, 1, 2, 2, 2],\n        [3, 4, 5, 6, 2, 2, 2],\n        [3, 7, 7, 7, 2, 2, 2],\n        [3, 8, 8, 12, 2, 2, 2],\n        [3, 10, 11, 12, 2, 2, 2],\n    ],\n    as_matrix: bool = False,\n    alpha: float = 0,\n    constrained_layout: bool = False,\n    fig: Optional[plt.Figure] = None,\n    figsize: List[float] = [10, 10],\n    projection: Optional[Union[str, List[str]]] = None,\n    wspace: float = 0.1,\n    hspace: float = 0.3,\n    no_spines: bool = False,\n    keep_nan_axes: bool = False,\n    fontsize: int = 5,\n    reshape_order: Literal[\"C\", \"F\", \"A\", \"K\"] = \"F\",\n) -&gt; Tuple[plt.Figure, Union[Dict[int, plt.Axes], np.ndarray]]:\n    \"\"\"\n    Creates a figure grid specified by the arrangement of unique elements in a matrix.\n\n    Info:\n        `matplotlib` now also has `matplotlib.pyplot.subplot_mosaic` which does the\n        same thing and should be used instead.\n\n    Args:\n        matrix: Grid layout specification.\n        as_matrix: If True, return axes as a numpy array.\n        alpha: Alpha value for axis patches.\n        constrained_layout: Use constrained layout for the figure.\n        fig: Existing figure to use. If None, a new figure is created.\n        figsize: Figure size in inches.\n        projection: Projection type for the axes.\n        wspace: Width space between subplots.\n        hspace: Height space between subplots.\n        no_spines: If True, remove spines from all axes.\n        keep_nan_axes: If True, keep axes for NaN values in the matrix.\n        fontsize: Font size for tick labels.\n        reshape_order: Order to use when reshaping the axes array.\n\n    Returns:\n        A tuple containing the figure and a dictionary or numpy array of axes.\n    \"\"\"\n\n    def _array_to_slice(array):\n        step = 1\n        start = array.min()\n        stop = array.max() + 1\n        return slice(start, stop, step)\n\n    fig = plt.figure(figsize=figsize) if fig is None else fig\n    fig.set_constrained_layout(constrained_layout)\n    matrix = np.ma.masked_invalid(matrix)\n    rows, columns = matrix.shape\n\n    gs = GridSpec(rows, columns, figure=fig, hspace=hspace, wspace=wspace)\n\n    axes = {}\n    for val in np.unique(matrix[~matrix.mask]):\n        _row_ind, _col_ind = np.where(matrix == val)\n        _row_slc, _col_slc = _array_to_slice(_row_ind), _array_to_slice(_col_ind)\n\n        _projection = projection[val] if isinstance(projection, dict) else projection\n        ax = fig.add_subplot(gs[_row_slc, _col_slc], projection=_projection)\n        ax.patch.set_alpha(alpha)\n        ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n        if projection is None:\n            ax.spines[\"top\"].set_visible(False)\n            ax.spines[\"right\"].set_visible(False)\n        axes[val] = ax\n\n    if keep_nan_axes:\n        for _row_ind, _col_ind in np.array(np.where(np.isnan(matrix))).T:\n            _row_slc, _col_slc = _array_to_slice(_row_ind), _array_to_slice(_col_ind)\n            ax = fig.add_subplot(gs[_row_slc, _col_slc])\n            ax.patch.set_alpha(alpha)\n            rm_spines(ax, (\"left\", \"right\", \"top\", \"bottom\"))\n\n    if no_spines:\n        for ax in axes.values():\n            rm_spines(ax, rm_xticks=True, rm_yticks=True)\n\n    if as_matrix:\n        if reshape_order == \"special\":\n            # reshape based on elements in matrix\n            ax_matrix = np.ones(matrix.shape, dtype=object) * np.nan\n            for key, value in axes.items():\n                _row_ind, _col_ind = np.where(matrix == key)\n                ax_matrix[_row_ind, _col_ind] = value\n            axes = ax_matrix\n        else:\n            # reshape without considering specific locations\n            _axes = np.ones(matrix.shape, dtype=object).flatten() * np.nan\n            _axes[: len(axes)] = np.array(list(axes.values()), dtype=object)\n            axes = _axes.reshape(matrix.shape, order=reshape_order)\n\n    return fig, axes\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.scale","title":"flyvis.analysis.visualization.plt_utils.scale","text":"<pre><code>scale(x, y, wpad=0.1, hpad=0.1, wspace=0, hspace=0)\n</code></pre> <p>Scale x and y coordinates to fit within a specified padding and spacing.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Array of x-coordinates.</p> required <code>y</code> <code>ndarray</code> <p>Array of y-coordinates.</p> required <code>wpad</code> <code>float</code> <p>Width padding.</p> <code>0.1</code> <code>hpad</code> <code>float</code> <p>Height padding.</p> <code>0.1</code> <code>wspace</code> <code>float</code> <p>Width space between elements.</p> <code>0</code> <code>hspace</code> <code>float</code> <p>Height space between elements.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, float, float]</code> <p>A tuple containing scaled x, y coordinates, width, and height.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def scale(\n    x: np.ndarray,\n    y: np.ndarray,\n    wpad: float = 0.1,\n    hpad: float = 0.1,\n    wspace: float = 0,\n    hspace: float = 0,\n) -&gt; Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    Scale x and y coordinates to fit within a specified padding and spacing.\n\n    Args:\n        x: Array of x-coordinates.\n        y: Array of y-coordinates.\n        wpad: Width padding.\n        hpad: Height padding.\n        wspace: Width space between elements.\n        hspace: Height space between elements.\n\n    Returns:\n        A tuple containing scaled x, y coordinates, width, and height.\n    \"\"\"\n    x, y = np.array(x), np.array(y)\n    assert len(x) == len(y)\n\n    # Min-Max Scale x-Positions.\n    width = (1 - 2 * wpad) / (2 * np.ceil(np.median(np.unique(x))))\n    width = width - wspace * width\n    x = (x - np.min(x)) / (np.max(x) + np.min(x)) * (1 - width) * (1 - wpad * 2) + wpad\n\n    # Min-Max Scale y-Positions.\n    height = (1 - 2 * hpad) / (2 * np.ceil(np.median(np.unique(y))))\n    height = height - hspace * height\n    y = (y - np.min(y)) / (np.max(y) + np.min(y)) * (1 - height) * (1 - hpad * 2) + hpad\n    return x, y, width, height\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.ax_scatter","title":"flyvis.analysis.visualization.plt_utils.ax_scatter","text":"<pre><code>ax_scatter(x, y, fig=None, figsize=[7, 7], hspace=0, wspace=0, hpad=0.1, wpad=0.1, alpha=0, zorder=10, projection=None, labels=None)\n</code></pre> <p>Creates scattered axes in a given or new figure.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Array of x-coordinates.</p> required <code>y</code> <code>ndarray</code> <p>Array of y-coordinates.</p> required <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to use. If None, a new figure is created.</p> <code>None</code> <code>figsize</code> <code>List[float]</code> <p>Figure size in inches.</p> <code>[7, 7]</code> <code>hspace</code> <code>float</code> <p>Height space between subplots.</p> <code>0</code> <code>wspace</code> <code>float</code> <p>Width space between subplots.</p> <code>0</code> <code>hpad</code> <code>float</code> <p>Height padding.</p> <code>0.1</code> <code>wpad</code> <code>float</code> <p>Width padding.</p> <code>0.1</code> <code>alpha</code> <code>float</code> <p>Alpha value for axis patches.</p> <code>0</code> <code>zorder</code> <code>int</code> <p>Z-order for axis patches.</p> <code>10</code> <code>projection</code> <code>Optional[str]</code> <p>Projection type for the axes.</p> <code>None</code> <code>labels</code> <code>Optional[List[str]]</code> <p>List of labels for each axis.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, List[Axes], List[List[float]]]</code> <p>A tuple containing the figure, a list of axes, and a list of center coordinates.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def ax_scatter(\n    x: np.ndarray,\n    y: np.ndarray,\n    fig: Optional[plt.Figure] = None,\n    figsize: List[float] = [7, 7],\n    hspace: float = 0,\n    wspace: float = 0,\n    hpad: float = 0.1,\n    wpad: float = 0.1,\n    alpha: float = 0,\n    zorder: int = 10,\n    projection: Optional[str] = None,\n    labels: Optional[List[str]] = None,\n) -&gt; Tuple[plt.Figure, List[plt.Axes], List[List[float]]]:\n    \"\"\"\n    Creates scattered axes in a given or new figure.\n\n    Args:\n        x: Array of x-coordinates.\n        y: Array of y-coordinates.\n        fig: Existing figure to use. If None, a new figure is created.\n        figsize: Figure size in inches.\n        hspace: Height space between subplots.\n        wspace: Width space between subplots.\n        hpad: Height padding.\n        wpad: Width padding.\n        alpha: Alpha value for axis patches.\n        zorder: Z-order for axis patches.\n        projection: Projection type for the axes.\n        labels: List of labels for each axis.\n\n    Returns:\n        A tuple containing the figure, a list of axes, and a list of center coordinates.\n    \"\"\"\n    x, y, width, height = scale(x, y, wpad, hpad, wspace, hspace)\n\n    # Create axes in figure.\n    fig = fig or plt.figure(figsize=figsize)\n    axes = []\n    for i, (_x, _y) in enumerate(zip(x, y)):\n        ax = fig.add_axes(\n            [_x, _y, width, height],\n            projection=projection,\n            label=labels[i] if labels is not None else None,\n        )\n        ax.set_zorder(zorder)\n        ax.patch.set_alpha(alpha)\n        axes.append(ax)\n\n    center = []\n    for ax in axes:\n        _, (_center, _, _) = get_ax_positions(ax)\n        center.append(_center.flatten().tolist())\n    return fig, axes, center\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.color_labels","title":"flyvis.analysis.visualization.plt_utils.color_labels","text":"<pre><code>color_labels(labels, color, ax)\n</code></pre> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def color_labels(labels: List[str], color, ax):\n    for label in labels:\n        color_label(label, color, ax)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.color_label","title":"flyvis.analysis.visualization.plt_utils.color_label","text":"<pre><code>color_label(label, color, ax)\n</code></pre> <p>Color a specific label in the given axes.</p> <p>Parameters:</p> Name Type Description Default <code>label</code> <code>str</code> <p>The label text to color.</p> required <code>color</code> <code>Union[str, Tuple[float, float, float]]</code> <p>The color to apply to the label.</p> required <code>ax</code> <code>Axes</code> <p>The matplotlib axes object.</p> required Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def color_label(\n    label: str, color: Union[str, Tuple[float, float, float]], ax: plt.Axes\n) -&gt; None:\n    \"\"\"\n    Color a specific label in the given axes.\n\n    Args:\n        label: The label text to color.\n        color: The color to apply to the label.\n        ax: The matplotlib axes object.\n    \"\"\"\n    for t in ax.texts:\n        if t.get_text() == label:\n            t.set_color(color)\n\n    for tick in ax.xaxis.get_major_ticks():\n        if tick.label1.get_text() == label:\n            tick.label1.set_color(color)\n\n    for tick in ax.yaxis.get_major_ticks():\n        if tick.label1.get_text() == label:\n            tick.label1.set_color(color)\n\n    if ax.xaxis.get_label().get_text() == label:\n        ax.xaxis.get_label().set_color(color)\n\n    if ax.yaxis.get_label().get_text() == label:\n        ax.yaxis.get_label().set_color(color)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.boldify_labels","title":"flyvis.analysis.visualization.plt_utils.boldify_labels","text":"<pre><code>boldify_labels(labels, ax)\n</code></pre> <p>Make specific labels bold in the given axes.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>List[str]</code> <p>List of label texts to make bold.</p> required <code>ax</code> <code>Axes</code> <p>The matplotlib axes object.</p> required Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def boldify_labels(labels: List[str], ax: plt.Axes) -&gt; None:\n    \"\"\"\n    Make specific labels bold in the given axes.\n\n    Args:\n        labels: List of label texts to make bold.\n        ax: The matplotlib axes object.\n    \"\"\"\n    for t in ax.texts:\n        if t.get_text() in labels:\n            t.set_weight(\"bold\")\n\n    for tick in ax.xaxis.get_major_ticks():\n        if tick.label1.get_text() in labels:\n            tick.label1.set_weight(\"bold\")\n\n    for tick in ax.yaxis.get_major_ticks():\n        if tick.label1.get_text() in labels:\n            tick.label1.set_weight(\"bold\")\n\n    if ax.xaxis.get_label().get_text() in labels:\n        ax.xaxis.get_label().set_weight(\"bold\")\n\n    if ax.yaxis.get_label().get_text() in labels:\n        ax.yaxis.get_label().set_weight(\"bold\")\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.scatter_on_violins_or_bars","title":"flyvis.analysis.visualization.plt_utils.scatter_on_violins_or_bars","text":"<pre><code>scatter_on_violins_or_bars(data, ax, xticks=None, indices=None, s=5, zorder=100, facecolor='none', edgecolor='k', linewidth=0.5, alpha=0.35, uniform=[-0.35, 0.35], seed=42, marker='o', **kwargs)\n</code></pre> <p>Scatter data points on violin or bar plots.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n_samples, n_random_variables).</p> required <code>ax</code> <code>Axes</code> <p>Matplotlib axes object to plot on.</p> required <code>xticks</code> <code>Optional[ndarray]</code> <p>X-axis tick positions.</p> <code>None</code> <code>indices</code> <code>Optional[ndarray]</code> <p>Selection along sample dimension.</p> <code>None</code> <code>s</code> <code>float</code> <p>Marker size.</p> <code>5</code> <code>zorder</code> <code>int</code> <p>Z-order for plotting.</p> <code>100</code> <code>facecolor</code> <code>Union[str, Tuple[float, float, float], List[Union[str, Tuple[float, float, float]]]]</code> <p>Color(s) for marker face.</p> <code>'none'</code> <code>edgecolor</code> <code>Union[str, Tuple[float, float, float], List[Union[str, Tuple[float, float, float]]]]</code> <p>Color(s) for marker edge.</p> <code>'k'</code> <code>linewidth</code> <code>float</code> <p>Width of marker edge.</p> <code>0.5</code> <code>alpha</code> <code>float</code> <p>Transparency of markers.</p> <code>0.35</code> <code>uniform</code> <code>List[float]</code> <p>Range for uniform distribution of x-positions.</p> <code>[-0.35, 0.35]</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>marker</code> <code>str</code> <p>Marker style.</p> <code>'o'</code> <code>**kwargs</code> <p>Additional keyword arguments for plt.scatter.</p> <code>{}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def scatter_on_violins_or_bars(\n    data: np.ndarray,\n    ax: Axes,\n    xticks: Optional[np.ndarray] = None,\n    indices: Optional[np.ndarray] = None,\n    s: float = 5,\n    zorder: int = 100,\n    facecolor: Union[\n        str, Tuple[float, float, float], List[Union[str, Tuple[float, float, float]]]\n    ] = \"none\",\n    edgecolor: Union[\n        str, Tuple[float, float, float], List[Union[str, Tuple[float, float, float]]]\n    ] = \"k\",\n    linewidth: float = 0.5,\n    alpha: float = 0.35,\n    uniform: List[float] = [-0.35, 0.35],\n    seed: int = 42,\n    marker: str = \"o\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Scatter data points on violin or bar plots.\n\n    Args:\n        data: Array of shape (n_samples, n_random_variables).\n        ax: Matplotlib axes object to plot on.\n        xticks: X-axis tick positions.\n        indices: Selection along sample dimension.\n        s: Marker size.\n        zorder: Z-order for plotting.\n        facecolor: Color(s) for marker face.\n        edgecolor: Color(s) for marker edge.\n        linewidth: Width of marker edge.\n        alpha: Transparency of markers.\n        uniform: Range for uniform distribution of x-positions.\n        seed: Random seed for reproducibility.\n        marker: Marker style.\n        **kwargs: Additional keyword arguments for plt.scatter.\n\n    Returns:\n        None\n    \"\"\"\n    random = np.random.RandomState(seed)\n\n    if xticks is None:\n        xticks = ax.get_xticks()\n    data = np.atleast_2d(data)\n    indices = indices if indices is not None else range(data.shape[0])\n\n    if (\n        not isinstance(facecolor, Iterable)\n        or len(facecolor) != len(data)\n        or isinstance(facecolor, str)\n    ):\n        facecolor = (facecolor,) * len(indices)\n\n    if (\n        not isinstance(edgecolor, Iterable)\n        or len(edgecolor) != len(data)\n        or isinstance(edgecolor, str)\n    ):\n        edgecolor = (edgecolor,) * len(indices)\n\n    for i, model_index in enumerate(indices):\n        ax.scatter(\n            xticks + random.uniform(*uniform, size=len(xticks)),\n            data[model_index],\n            s=s,\n            zorder=zorder,\n            facecolor=facecolor[i],\n            edgecolor=edgecolor[i],\n            linewidth=linewidth,\n            alpha=alpha,\n            marker=marker,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.set_spine_tick_params","title":"flyvis.analysis.visualization.plt_utils.set_spine_tick_params","text":"<pre><code>set_spine_tick_params(ax, spinewidth=0.25, tickwidth=0.25, ticklength=3, ticklabelpad=2, spines=('top', 'right', 'bottom', 'left'))\n</code></pre> <p>Set spine and tick widths and lengths.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Matplotlib axes object.</p> required <code>spinewidth</code> <code>float</code> <p>Width of spines.</p> <code>0.25</code> <code>tickwidth</code> <code>float</code> <p>Width of ticks.</p> <code>0.25</code> <code>ticklength</code> <code>float</code> <p>Length of ticks.</p> <code>3</code> <code>ticklabelpad</code> <code>float</code> <p>Padding between ticks and labels.</p> <code>2</code> <code>spines</code> <code>Tuple[str, ...]</code> <p>Tuple of spine names to adjust.</p> <code>('top', 'right', 'bottom', 'left')</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def set_spine_tick_params(\n    ax: Axes,\n    spinewidth: float = 0.25,\n    tickwidth: float = 0.25,\n    ticklength: float = 3,\n    ticklabelpad: float = 2,\n    spines: Tuple[str, ...] = (\"top\", \"right\", \"bottom\", \"left\"),\n) -&gt; None:\n    \"\"\"\n    Set spine and tick widths and lengths.\n\n    Args:\n        ax: Matplotlib axes object.\n        spinewidth: Width of spines.\n        tickwidth: Width of ticks.\n        ticklength: Length of ticks.\n        ticklabelpad: Padding between ticks and labels.\n        spines: Tuple of spine names to adjust.\n\n    Returns:\n        None\n    \"\"\"\n    for s in spines:\n        ax.spines[s].set_linewidth(spinewidth)\n    ax.tick_params(axis=\"both\", width=tickwidth, length=ticklength, pad=ticklabelpad)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.scatter_on_violins_with_best","title":"flyvis.analysis.visualization.plt_utils.scatter_on_violins_with_best","text":"<pre><code>scatter_on_violins_with_best(data, ax, scatter_best, scatter_all, xticks=None, facecolor='none', edgecolor='k', best_scatter_alpha=1.0, all_scatter_alpha=0.35, best_index=None, best_color=None, all_marker='o', best_marker='o', linewidth=0.5, best_linewidth=0.75, uniform=[-0.35, 0.35], **kwargs)\n</code></pre> <p>Scatter data points on violin plots, optionally highlighting the best point.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Array of shape (n_samples, n_variables).</p> required <code>ax</code> <code>Axes</code> <p>Matplotlib axes object to plot on.</p> required <code>scatter_best</code> <code>bool</code> <p>Whether to scatter the best point.</p> required <code>scatter_all</code> <code>bool</code> <p>Whether to scatter all points.</p> required <code>xticks</code> <code>Optional[ndarray]</code> <p>X-axis tick positions.</p> <code>None</code> <code>facecolor</code> <code>Union[str, Tuple[float, float, float]]</code> <p>Color for marker face.</p> <code>'none'</code> <code>edgecolor</code> <code>Union[str, Tuple[float, float, float]]</code> <p>Color for marker edge.</p> <code>'k'</code> <code>best_scatter_alpha</code> <code>float</code> <p>Alpha for best point.</p> <code>1.0</code> <code>all_scatter_alpha</code> <code>float</code> <p>Alpha for all other points.</p> <code>0.35</code> <code>best_index</code> <code>Optional[int]</code> <p>Index of the best point.</p> <code>None</code> <code>best_color</code> <code>Optional[Union[str, Tuple[float, float, float]]]</code> <p>Color for the best point.</p> <code>None</code> <code>all_marker</code> <code>str</code> <p>Marker style for all points.</p> <code>'o'</code> <code>best_marker</code> <code>str</code> <p>Marker style for the best point.</p> <code>'o'</code> <code>linewidth</code> <code>float</code> <p>Width of marker edge for all points.</p> <code>0.5</code> <code>best_linewidth</code> <code>float</code> <p>Width of marker edge for the best point.</p> <code>0.75</code> <code>uniform</code> <code>List[float]</code> <p>Range for uniform distribution of x-positions.</p> <code>[-0.35, 0.35]</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def scatter_on_violins_with_best(\n    data: np.ndarray,\n    ax: Axes,\n    scatter_best: bool,\n    scatter_all: bool,\n    xticks: Optional[np.ndarray] = None,\n    facecolor: Union[str, Tuple[float, float, float]] = \"none\",\n    edgecolor: Union[str, Tuple[float, float, float]] = \"k\",\n    best_scatter_alpha: float = 1.0,\n    all_scatter_alpha: float = 0.35,\n    best_index: Optional[int] = None,\n    best_color: Optional[Union[str, Tuple[float, float, float]]] = None,\n    all_marker: str = \"o\",\n    best_marker: str = \"o\",\n    linewidth: float = 0.5,\n    best_linewidth: float = 0.75,\n    uniform: List[float] = [-0.35, 0.35],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Scatter data points on violin plots, optionally highlighting the best point.\n\n    Args:\n        data: Array of shape (n_samples, n_variables).\n        ax: Matplotlib axes object to plot on.\n        scatter_best: Whether to scatter the best point.\n        scatter_all: Whether to scatter all points.\n        xticks: X-axis tick positions.\n        facecolor: Color for marker face.\n        edgecolor: Color for marker edge.\n        best_scatter_alpha: Alpha for best point.\n        all_scatter_alpha: Alpha for all other points.\n        best_index: Index of the best point.\n        best_color: Color for the best point.\n        all_marker: Marker style for all points.\n        best_marker: Marker style for the best point.\n        linewidth: Width of marker edge for all points.\n        best_linewidth: Width of marker edge for the best point.\n        uniform: Range for uniform distribution of x-positions.\n\n    Returns:\n        None\n    \"\"\"\n    if scatter_all and not scatter_best:\n        scatter_on_violins_or_bars(\n            data,\n            ax,\n            xticks=xticks,\n            zorder=100,\n            facecolor=facecolor,\n            edgecolor=edgecolor,\n            alpha=all_scatter_alpha,\n            uniform=uniform,\n            marker=all_marker,\n            linewidth=linewidth,\n        )\n    elif scatter_all:\n        assert (\n            best_index is not None\n        ), \"`best_index` must be provided if `scatter_best=True`\"\n        indices = list(range(data.shape[0]))\n        indices.remove(best_index)\n        scatter_on_violins_or_bars(\n            data,\n            ax,\n            xticks=xticks,\n            indices=indices,\n            zorder=10,\n            facecolor=facecolor,\n            edgecolor=edgecolor,\n            alpha=all_scatter_alpha,\n            uniform=uniform,\n            marker=all_marker,\n            linewidth=linewidth,\n        )\n    if scatter_best:\n        assert (\n            best_index is not None\n        ), \"`best_index` must be provided if `scatter_best=True`\"\n        assert (\n            best_color is not None\n        ), \"`best_color` must be provided if `scatter_all=True`\"\n        scatter_on_violins_or_bars(\n            data,\n            ax,\n            xticks=xticks,\n            indices=[best_index],\n            alpha=best_scatter_alpha,\n            linewidth=best_linewidth,\n            edgecolor=best_color,\n            facecolor=best_color,\n            uniform=[0, 0],\n            s=7.5,\n            zorder=11,\n            marker=best_marker,\n        )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.trim_axis","title":"flyvis.analysis.visualization.plt_utils.trim_axis","text":"<pre><code>trim_axis(ax, xaxis=True, yaxis=True)\n</code></pre> <p>Trim axis to show only the range of data.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Matplotlib axes object.</p> required <code>xaxis</code> <code>bool</code> <p>Whether to trim x-axis.</p> <code>True</code> <code>yaxis</code> <code>bool</code> <p>Whether to trim y-axis.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def trim_axis(ax: Axes, xaxis: bool = True, yaxis: bool = True) -&gt; None:\n    \"\"\"\n    Trim axis to show only the range of data.\n\n    Args:\n        ax: Matplotlib axes object.\n        xaxis: Whether to trim x-axis.\n        yaxis: Whether to trim y-axis.\n\n    Returns:\n        None\n    \"\"\"\n    if xaxis:\n        xticks = np.array(ax.get_xticks())\n        minor_xticks = np.array(ax.get_xticks(minor=True))\n        all_ticks = np.sort(np.concatenate((minor_xticks, xticks)))\n        if hasattr(xticks, \"size\"):\n            firsttick = np.compress(all_ticks &gt;= min(ax.get_xlim()), all_ticks)[0]\n            lasttick = np.compress(all_ticks &lt;= max(ax.get_xlim()), all_ticks)[-1]\n            ax.spines[\"top\"].set_bounds(firsttick, lasttick)\n            ax.spines[\"bottom\"].set_bounds(firsttick, lasttick)\n            new_minor_ticks = minor_xticks.compress(minor_xticks &lt;= lasttick)\n            new_minor_ticks = new_minor_ticks.compress(new_minor_ticks &gt;= firsttick)\n            newticks = xticks.compress(xticks &lt;= lasttick)\n            newticks = newticks.compress(newticks &gt;= firsttick)\n            ax.set_xticks(newticks)\n            ax.set_xticks(new_minor_ticks, minor=True)\n\n    if yaxis:\n        yticks = np.array(ax.get_yticks())\n        minor_yticks = np.array(ax.get_yticks(minor=True))\n        all_ticks = np.sort(np.concatenate((minor_yticks, yticks)))\n        if hasattr(yticks, \"size\"):\n            firsttick = np.compress(all_ticks &gt;= min(ax.get_ylim()), all_ticks)[0]\n            lasttick = np.compress(all_ticks &lt;= max(ax.get_ylim()), all_ticks)[-1]\n            ax.spines[\"left\"].set_bounds(firsttick, lasttick)\n            ax.spines[\"right\"].set_bounds(firsttick, lasttick)\n            new_minor_ticks = minor_yticks.compress(minor_yticks &lt;= lasttick)\n            new_minor_ticks = new_minor_ticks.compress(new_minor_ticks &gt;= firsttick)\n            newticks = yticks.compress(yticks &lt;= lasttick)\n            newticks = newticks.compress(newticks &gt;= firsttick)\n            ax.set_yticks(newticks)\n            ax.set_yticks(new_minor_ticks, minor=True)\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.display_significance_value","title":"flyvis.analysis.visualization.plt_utils.display_significance_value","text":"<pre><code>display_significance_value(ax, pvalue, y, x0=None, x1=None, ticklabel=None, bar_width=0.7, pthresholds={0.01: '***', 0.05: '**', 0.1: '*'}, fontsize=8, annotate_insignificant='', append_tick=False, show_bar=False, other_ax=None, bar_height_ylim_ratio=0.01, linewidth=0.5, annotate_pthresholds=True, loc_pthresh_annotation=(0.1, 0.1), location='above', asterisk_offset=None)\n</code></pre> <p>Display a significance value annotation along x at height y.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Matplotlib axes object.</p> required <code>pvalue</code> <code>float</code> <p>P-value to display.</p> required <code>y</code> <code>float</code> <p>Height to put text.</p> required <code>x0</code> <code>Optional[float]</code> <p>Left edge of bar if show_bar is True.</p> <code>None</code> <code>x1</code> <code>Optional[float]</code> <p>Right edge of bar if show_bar is True.</p> <code>None</code> <code>ticklabel</code> <code>Optional[str]</code> <p>Tick label to annotate.</p> <code>None</code> <code>bar_width</code> <code>float</code> <p>Width of the bar.</p> <code>0.7</code> <code>pthresholds</code> <code>Dict[float, str]</code> <p>Dictionary of p-value thresholds and corresponding annotations.</p> <code>{0.01: '***', 0.05: '**', 0.1: '*'}</code> <code>fontsize</code> <code>int</code> <p>Font size for annotations.</p> <code>8</code> <code>annotate_insignificant</code> <code>str</code> <p>Annotation for insignificant p-values.</p> <code>''</code> <code>append_tick</code> <code>bool</code> <p>Whether to append annotation to tick label.</p> <code>False</code> <code>show_bar</code> <code>bool</code> <p>Whether to show a bar above the annotation.</p> <code>False</code> <code>other_ax</code> <code>Optional[Axes]</code> <p>Another axes object to get tick labels from.</p> <code>None</code> <code>bar_height_ylim_ratio</code> <code>float</code> <p>Ratio of bar height to y-axis limits.</p> <code>0.01</code> <code>linewidth</code> <code>float</code> <p>Line width for the bar.</p> <code>0.5</code> <code>annotate_pthresholds</code> <code>bool</code> <p>Whether to annotate p-value thresholds.</p> <code>True</code> <code>loc_pthresh_annotation</code> <code>Tuple[float, float]</code> <p>Location of p-value threshold annotation.</p> <code>(0.1, 0.1)</code> <code>location</code> <code>Literal['above', 'below']</code> <p>Location of annotation (\u201cabove\u201d or \u201cbelow\u201d).</p> <code>'above'</code> <code>asterisk_offset</code> <code>Optional[float]</code> <p>Offset for asterisk annotation.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def display_significance_value(\n    ax: Axes,\n    pvalue: float,\n    y: float,\n    x0: Optional[float] = None,\n    x1: Optional[float] = None,\n    ticklabel: Optional[str] = None,\n    bar_width: float = 0.7,\n    pthresholds: Dict[float, str] = {0.01: \"***\", 0.05: \"**\", 0.1: \"*\"},\n    fontsize: int = 8,\n    annotate_insignificant: str = \"\",\n    append_tick: bool = False,\n    show_bar: bool = False,\n    other_ax: Optional[Axes] = None,\n    bar_height_ylim_ratio: float = 0.01,\n    linewidth: float = 0.5,\n    annotate_pthresholds: bool = True,\n    loc_pthresh_annotation: Tuple[float, float] = (0.1, 0.1),\n    location: Literal[\"above\", \"below\"] = \"above\",\n    asterisk_offset: Optional[float] = None,\n) -&gt; None:\n    \"\"\"\n    Display a significance value annotation along x at height y.\n\n    Args:\n        ax: Matplotlib axes object.\n        pvalue: P-value to display.\n        y: Height to put text.\n        x0: Left edge of bar if show_bar is True.\n        x1: Right edge of bar if show_bar is True.\n        ticklabel: Tick label to annotate.\n        bar_width: Width of the bar.\n        pthresholds: Dictionary of p-value thresholds and corresponding annotations.\n        fontsize: Font size for annotations.\n        annotate_insignificant: Annotation for insignificant p-values.\n        append_tick: Whether to append annotation to tick label.\n        show_bar: Whether to show a bar above the annotation.\n        other_ax: Another axes object to get tick labels from.\n        bar_height_ylim_ratio: Ratio of bar height to y-axis limits.\n        linewidth: Line width for the bar.\n        annotate_pthresholds: Whether to annotate p-value thresholds.\n        loc_pthresh_annotation: Location of p-value threshold annotation.\n        location: Location of annotation (\"above\" or \"below\").\n        asterisk_offset: Offset for asterisk annotation.\n\n    Returns:\n        None\n    \"\"\"\n    if x0 is None and x1 is None and ticklabel is None and bar_width is None:\n        raise ValueError(\"specify (x0, x1) or (ticklabel, bar_width)\")\n\n    if show_bar and ((x0 is None or x1 is None) and bar_width is None):\n        raise ValueError(\"need to specify width of bar or specify x0 and x1\")\n\n    if location == \"above\":\n        va = \"bottom\"\n        asterisk_offset = asterisk_offset or -0.1\n    elif location == \"below\":\n        va = \"top\"\n        asterisk_offset = asterisk_offset or -0.05\n    else:\n        raise ValueError(f\"location {location}\")\n\n    if x0 is None and x1 is None and ticklabel is not None:\n        ticklabels = ax.get_xticklabels()\n        if not ticklabels:\n            ticklabels = other_ax.get_xticklabels()\n        if not ticklabels:\n            raise AssertionError(\"no ticklables found\")\n        tick = [tick for tick in ticklabels if tick.get_text() == ticklabel][0]\n        x, _ = tick.get_position()\n        x0 = x - bar_width / 2\n        x1 = x + bar_width / 2\n\n    text = \"\"\n    any_thresh = False\n    less = []\n    for thresh in pthresholds:\n        if pvalue &lt; thresh:\n            less.append(thresh)\n            any_thresh = True\n\n    if (any_thresh or annotate_insignificant) and show_bar:\n        bar_height = (ax.get_ylim()[1] - ax.get_ylim()[0]) * bar_height_ylim_ratio\n        bar_x = [x0, x0, x1, x1]\n        if location == \"above\":\n            bar_y = [y, y + bar_height, y + bar_height, y]\n            y = y + bar_height\n            mid = ((x0 + x1) / 2, y)\n        elif location == \"below\":\n            bar_y = [y, y - bar_height, y - bar_height, y]\n            y = y - bar_height\n            mid = ((x0 + x1) / 2, y)\n        ax.plot(bar_x, bar_y, c=\"k\", lw=linewidth)\n        x = mid[0]\n\n    if any_thresh:\n        text = pthresholds[min(less)]\n        if ticklabel is not None and append_tick:\n            tick.set_text(f\"{tick.get_text()}$^{{{text}}}$\")\n            ax.xaxis.set_ticklabels(ax.xaxis.get_ticklabels())\n        else:\n            ax.annotate(\n                text,\n                (x, y + asterisk_offset),\n                fontsize=fontsize,\n                ha=\"center\",\n                va=va,\n            )\n\n    elif annotate_insignificant:\n        if ticklabel is not None and append_tick:\n            tick.set_text(f\"{tick.get_text()}$^{{{annotate_insignificant}}}$\")\n            ax.xaxis.set_ticklabels(ax.xaxis.get_ticklabels())\n        else:\n            ax.annotate(\n                annotate_insignificant,\n                (x, y),\n                fontsize=fontsize,\n                ha=\"center\",\n                va=va,\n            )\n\n    if annotate_pthresholds:\n        pthreshold_annotation = \"\"\n        for i, (thresh, symbol) in enumerate(pthresholds.items()):\n            pthreshold_annotation += f\"{symbol}p&lt;{thresh:.2f}\"\n            if i != len(pthresholds) - 1:\n                pthreshold_annotation += \"\\n\"\n\n        ax.annotate(\n            pthreshold_annotation,\n            loc_pthresh_annotation,\n            xycoords=\"axes fraction\",\n            fontsize=fontsize,\n            va=\"bottom\",\n            ha=\"left\",\n        )\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.display_pvalues","title":"flyvis.analysis.visualization.plt_utils.display_pvalues","text":"<pre><code>display_pvalues(ax, pvalues, ticklabels, data, location='above', bar_width=0.7, show_bar=True, bar_height_ylim_ratio=0.01, fontsize=6, annotate_insignificant='ns', loc_pthresh_annotation=(0.01, 0.01), append_tick=False, data_relative_offset=0.05, asterisk_offset=0, pthresholds={0.01: '***', 0.05: '**', 0.1: '*'})\n</code></pre> <p>Annotate all p-values from a dictionary of x-tick labels to p-values.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>Matplotlib axes object.</p> required <code>pvalues</code> <code>Dict[str, float]</code> <p>Dictionary mapping x-tick labels to p-values.</p> required <code>ticklabels</code> <code>List[str]</code> <p>List of x-tick labels.</p> required <code>data</code> <code>ndarray</code> <p>Array of shape (random variables, \u2026).</p> required <code>location</code> <code>Literal['above', 'below']</code> <p>Location of annotation (\u201cabove\u201d or \u201cbelow\u201d).</p> <code>'above'</code> <code>bar_width</code> <code>float</code> <p>Width of the bar.</p> <code>0.7</code> <code>show_bar</code> <code>bool</code> <p>Whether to show a bar above the annotation.</p> <code>True</code> <code>bar_height_ylim_ratio</code> <code>float</code> <p>Ratio of bar height to y-axis limits.</p> <code>0.01</code> <code>fontsize</code> <code>int</code> <p>Font size for annotations.</p> <code>6</code> <code>annotate_insignificant</code> <code>str</code> <p>Annotation for insignificant p-values.</p> <code>'ns'</code> <code>loc_pthresh_annotation</code> <code>Tuple[float, float]</code> <p>Location of p-value threshold annotation.</p> <code>(0.01, 0.01)</code> <code>append_tick</code> <code>bool</code> <p>Whether to append annotation to tick label.</p> <code>False</code> <code>data_relative_offset</code> <code>float</code> <p>Relative offset for annotation placement.</p> <code>0.05</code> <code>asterisk_offset</code> <code>float</code> <p>Offset for asterisk annotation.</p> <code>0</code> <code>pthresholds</code> <code>Dict[float, str]</code> <p>Dictionary of p-value thresholds and corresponding annotations.</p> <code>{0.01: '***', 0.05: '**', 0.1: '*'}</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def display_pvalues(\n    ax: Axes,\n    pvalues: Dict[str, float],\n    ticklabels: List[str],\n    data: np.ndarray,\n    location: Literal[\"above\", \"below\"] = \"above\",\n    bar_width: float = 0.7,\n    show_bar: bool = True,\n    bar_height_ylim_ratio: float = 0.01,\n    fontsize: int = 6,\n    annotate_insignificant: str = \"ns\",\n    loc_pthresh_annotation: Tuple[float, float] = (0.01, 0.01),\n    append_tick: bool = False,\n    data_relative_offset: float = 0.05,\n    asterisk_offset: float = 0,\n    pthresholds: Dict[float, str] = {0.01: \"***\", 0.05: \"**\", 0.1: \"*\"},\n) -&gt; None:\n    \"\"\"\n    Annotate all p-values from a dictionary of x-tick labels to p-values.\n\n    Args:\n        ax: Matplotlib axes object.\n        pvalues: Dictionary mapping x-tick labels to p-values.\n        ticklabels: List of x-tick labels.\n        data: Array of shape (random variables, ...).\n        location: Location of annotation (\"above\" or \"below\").\n        bar_width: Width of the bar.\n        show_bar: Whether to show a bar above the annotation.\n        bar_height_ylim_ratio: Ratio of bar height to y-axis limits.\n        fontsize: Font size for annotations.\n        annotate_insignificant: Annotation for insignificant p-values.\n        loc_pthresh_annotation: Location of p-value threshold annotation.\n        append_tick: Whether to append annotation to tick label.\n        data_relative_offset: Relative offset for annotation placement.\n        asterisk_offset: Offset for asterisk annotation.\n        pthresholds: Dictionary of p-value thresholds and corresponding annotations.\n\n    Returns:\n        None\n    \"\"\"\n    for key in pvalues:\n        if key not in ticklabels:\n            raise ValueError(f\"pvalue key {key} is not a ticklabel\")\n\n    offset = data_relative_offset * np.abs(data.max() - data.min())\n\n    ylim = ax.get_ylim()\n    bars = []\n    for ticklabel, pvalue in pvalues.items():\n        index = [i for i, _ticklabel in enumerate(ticklabels) if _ticklabel == ticklabel][\n            0\n        ]\n        _values = data[index]\n\n        if location == \"above\":\n            _max = _values.max()\n            y = min(_max + offset, ylim[1])\n        elif location == \"below\":\n            _min = _values.min()\n            y = max(_min - offset, ylim[0])\n\n        display_significance_value(\n            ax,\n            pvalue,\n            y=y,\n            ticklabel=str(ticklabel),\n            bar_width=bar_width,\n            show_bar=show_bar,\n            bar_height_ylim_ratio=bar_height_ylim_ratio,\n            fontsize=fontsize,\n            annotate_insignificant=annotate_insignificant,\n            loc_pthresh_annotation=loc_pthresh_annotation,\n            append_tick=append_tick,\n            location=location,\n            asterisk_offset=asterisk_offset,\n            pthresholds=pthresholds,\n        )\n        bars.append(y)\n\n    ax.set_ylim(*get_lims([bars, ylim], 0.01))\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.closest_divisors","title":"flyvis.analysis.visualization.plt_utils.closest_divisors","text":"<pre><code>closest_divisors(n)\n</code></pre> <p>Find the closest divisors of a number.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number to find divisors for.</p> required <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple of closest divisors.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def closest_divisors(n: int) -&gt; Tuple[int, int]:\n    \"\"\"\n    Find the closest divisors of a number.\n\n    Args:\n        n: Number to find divisors for.\n\n    Returns:\n        Tuple of closest divisors.\n    \"\"\"\n    closest_diff = float(\"inf\")\n    closest_divisors = (1, 1)\n\n    for divisor in range(1, int(n**0.5) + 1):\n        if n % divisor == 0:\n            other_divisor = n // divisor\n            diff = abs(divisor - other_divisor)\n\n            if diff &lt; closest_diff:\n                closest_diff = diff\n                closest_divisors = (divisor, other_divisor)\n\n    return closest_divisors\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.standalone_legend","title":"flyvis.analysis.visualization.plt_utils.standalone_legend","text":"<pre><code>standalone_legend(labels, colors, legend_elements=None, alpha=1, fontsize=6, fig=None, ax=None, lw=4, labelspacing=0.5, handlelength=2.0, n_cols=None, columnspacing=0.8, figsize=None, linestyles=None)\n</code></pre> <p>Create a standalone legend.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>List[str]</code> <p>List of labels for legend entries.</p> required <code>colors</code> <code>List[Union[str, Tuple[float, float, float]]]</code> <p>List of colors for legend entries.</p> required <code>legend_elements</code> <code>Optional[List]</code> <p>List of custom legend elements.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Alpha value for legend entries.</p> <code>1</code> <code>fontsize</code> <code>int</code> <p>Font size for legend text.</p> <code>6</code> <code>fig</code> <code>Optional[Figure]</code> <p>Existing figure to use.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Existing axes to use.</p> <code>None</code> <code>lw</code> <code>float</code> <p>Line width for legend entries.</p> <code>4</code> <code>labelspacing</code> <code>float</code> <p>Vertical space between legend entries.</p> <code>0.5</code> <code>handlelength</code> <code>float</code> <p>Length of the legend handles.</p> <code>2.0</code> <code>n_cols</code> <code>Optional[int]</code> <p>Number of columns in the legend.</p> <code>None</code> <code>columnspacing</code> <code>float</code> <p>Spacing between legend columns.</p> <code>0.8</code> <code>figsize</code> <code>Optional[Tuple[float, float]]</code> <p>Figure size (width, height) in inches.</p> <code>None</code> <code>linestyles</code> <code>Optional[List[str]]</code> <p>List of line styles for legend entries.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Figure, Axes]</code> <p>Tuple containing the figure and axes objects.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def standalone_legend(\n    labels: List[str],\n    colors: List[Union[str, Tuple[float, float, float]]],\n    legend_elements: Optional[List] = None,\n    alpha: float = 1,\n    fontsize: int = 6,\n    fig: Optional[plt.Figure] = None,\n    ax: Optional[Axes] = None,\n    lw: float = 4,\n    labelspacing: float = 0.5,\n    handlelength: float = 2.0,\n    n_cols: Optional[int] = None,\n    columnspacing: float = 0.8,\n    figsize: Optional[Tuple[float, float]] = None,\n    linestyles: Optional[List[str]] = None,\n) -&gt; Tuple[plt.Figure, Axes]:\n    \"\"\"\n    Create a standalone legend.\n\n    Args:\n        labels: List of labels for legend entries.\n        colors: List of colors for legend entries.\n        legend_elements: List of custom legend elements.\n        alpha: Alpha value for legend entries.\n        fontsize: Font size for legend text.\n        fig: Existing figure to use.\n        ax: Existing axes to use.\n        lw: Line width for legend entries.\n        labelspacing: Vertical space between legend entries.\n        handlelength: Length of the legend handles.\n        n_cols: Number of columns in the legend.\n        columnspacing: Spacing between legend columns.\n        figsize: Figure size (width, height) in inches.\n        linestyles: List of line styles for legend entries.\n\n    Returns:\n        Tuple containing the figure and axes objects.\n    \"\"\"\n    if legend_elements is None:\n        from matplotlib.lines import Line2D\n\n        legend_elements = []\n        for i, label in enumerate(labels):\n            legend_elements.append(\n                Line2D(\n                    [0],\n                    [0],\n                    color=colors[i],\n                    lw=lw,\n                    label=label,\n                    alpha=alpha,\n                    solid_capstyle=\"round\",\n                    linestyle=linestyles[i] if linestyles is not None else \"solid\",\n                )\n            )\n    if n_cols is None:\n        n_rows, n_cols = closest_divisors(\n            len(legend_elements) - (len(legend_elements) % 2)\n        )\n    else:\n        n_rows = int(np.ceil(len(labels) / n_cols))\n    if fig is None or ax is None:\n        figsize = figsize or [0.1 * n_cols, 0.1 * n_rows]\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.legend(\n        handles=legend_elements,\n        loc=\"center\",\n        edgecolor=\"white\",\n        framealpha=1,\n        fontsize=fontsize,\n        labelspacing=labelspacing,\n        handlelength=handlelength,\n        columnspacing=columnspacing,\n        ncol=n_cols,\n    )\n    rm_spines(ax, rm_yticks=True, rm_xticks=True)\n    return fig, ax\n</code></pre>"},{"location":"reference/visualization/#flyvis.analysis.visualization.plt_utils.extend_arg","title":"flyvis.analysis.visualization.plt_utils.extend_arg","text":"<pre><code>extend_arg(arg, argtype, r, default, dim=-1)\n</code></pre> <p>Extend an argument to the correct length for a given dimension.</p> <p>Parameters:</p> Name Type Description Default <code>arg</code> <code>Union[Number, List[Number]]</code> <p>Argument to extend.</p> required <code>argtype</code> <code>type</code> <p>Type of the argument.</p> required <code>r</code> <code>ndarray</code> <p>Reference array for shape.</p> required <code>default</code> <code>Any</code> <p>Default value if arg is not provided.</p> required <code>dim</code> <code>int</code> <p>Dimension to extend along.</p> <code>-1</code> <p>Returns:</p> Type Description <code>Union[List[Number], Number]</code> <p>Extended argument.</p> Source code in <code>flyvis/analysis/visualization/plt_utils.py</code> <pre><code>def extend_arg(\n    arg: Union[Number, List[Number]],\n    argtype: type,\n    r: np.ndarray,\n    default: Any,\n    dim: int = -1,\n) -&gt; Union[List[Number], Number]:\n    \"\"\"\n    Extend an argument to the correct length for a given dimension.\n\n    Args:\n        arg: Argument to extend.\n        argtype: Type of the argument.\n        r: Reference array for shape.\n        default: Default value if arg is not provided.\n        dim: Dimension to extend along.\n\n    Returns:\n        Extended argument.\n    \"\"\"\n    r = np.asarray(r)\n\n    if isinstance(arg, argtype) and r.ndim &gt; 1:\n        return [arg] * r.shape[dim]\n    elif (\n        isinstance(arg, Iterable)\n        and len(arg) == r.shape[dim]\n        or r.ndim == 1\n        and np.asarray(arg).size == 1\n    ):\n        return arg\n    elif r.ndim == 1:\n        return default\n    else:\n        raise ValueError(\n            f\"arg must be either an integer or a list of length {r.shape[-1]}.\"\n        )\n</code></pre>"},{"location":"reference/flyvis_cli/download_pretrained_models/","title":"Download Pretrained Models","text":"<pre><code>usage:\nflyvis download-pretrained [-h] [--skip_large_files]\n       or\ndownload_pretrained_models.py [-h] [--skip_large_files]\n\nDownload pretrained models and UMAP clustering results. This script downloads two ZIP files from Google Drive:\n1. results_pretrained_models.zip: Contains pretrained neural networks.\n2. results_umap_and_clustering.zip: Contains UMAP embeddings and clustering.\nThe files are downloaded and unpacked to the 'data' directory in the project root.\n\noptions:\n  -h, --help          show this help message and exit\n  --skip_large_files  Skip downloading large files. If set, only 'results_pretrained_models.zip' will be downloaded, and 'results_umap_and_clustering.zip' will be skipped.\n</code></pre>"},{"location":"reference/flyvis_cli/download_pretrained_models/#flyvis_cli.download_pretrained_models","title":"flyvis_cli.download_pretrained_models","text":""},{"location":"reference/flyvis_cli/download_pretrained_models/#flyvis_cli.download_pretrained_models.calculate_sha256","title":"calculate_sha256","text":"<pre><code>calculate_sha256(file_path)\n</code></pre> <p>Calculate the SHA256 checksum of a file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the file.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The SHA256 checksum as a hexadecimal string.</p> Source code in <code>flyvis_cli/download_pretrained_models.py</code> <pre><code>def calculate_sha256(file_path: str) -&gt; str:\n    \"\"\"\n    Calculate the SHA256 checksum of a file.\n\n    Args:\n        file_path: Path to the file.\n\n    Returns:\n        The SHA256 checksum as a hexadecimal string.\n    \"\"\"\n    sha256_hash = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for byte_block in iter(lambda: f.read(4096), b\"\"):\n            sha256_hash.update(byte_block)\n    return sha256_hash.hexdigest()\n</code></pre>"},{"location":"reference/flyvis_cli/download_pretrained_models/#flyvis_cli.download_pretrained_models.download_and_unpack_files","title":"download_and_unpack_files","text":"<pre><code>download_and_unpack_files(folder_id, destination_dir, api_key, skip_large_files=False)\n</code></pre> <p>Download and unpack files from a Google Drive folder.</p> <p>Parameters:</p> Name Type Description Default <code>folder_id</code> <code>str</code> <p>The ID of the Google Drive folder.</p> required <code>destination_dir</code> <code>str</code> <p>The local directory to save and unpack the files.</p> required <code>api_key</code> <code>str</code> <p>The Google Drive API key.</p> required <code>skip_large_files</code> <code>bool</code> <p>Whether to skip downloading large files.</p> <code>False</code> Note <p>This function creates the destination directory if it doesn\u2019t exist, downloads ZIP files from the specified Google Drive folder, checks their checksums, and unpacks them.</p> Source code in <code>flyvis_cli/download_pretrained_models.py</code> <pre><code>def download_and_unpack_files(\n    folder_id: str, destination_dir: str, api_key: str, skip_large_files: bool = False\n) -&gt; None:\n    \"\"\"\n    Download and unpack files from a Google Drive folder.\n\n    Args:\n        folder_id: The ID of the Google Drive folder.\n        destination_dir: The local directory to save and unpack the files.\n        api_key: The Google Drive API key.\n        skip_large_files: Whether to skip downloading large files.\n\n    Note:\n        This function creates the destination directory if it doesn't exist,\n        downloads ZIP files from the specified Google Drive folder, checks their\n        checksums, and unpacks them.\n    \"\"\"\n    if not os.path.exists(destination_dir):\n        os.makedirs(destination_dir)\n\n    service = build(\"drive\", \"v3\", developerKey=api_key)\n\n    query = f\"'{folder_id}' in parents and mimeType='application/zip'\"\n    results = service.files().list(q=query, fields=\"files(id, name)\").execute()\n    items = results.get(\"files\", [])\n\n    if not items:\n        print(\"No files found.\")\n        return\n\n    for item in items:\n        file_id = item[\"id\"]\n        file_name = item[\"name\"]\n\n        if skip_large_files and large_files.get(file_name, False):\n            print(f\"Skipping {file_name}.\")\n            continue\n\n        request = service.files().get_media(fileId=file_id)\n        file_path = os.path.join(destination_dir, file_name)\n        print(f\"Downloading {file_name} to {file_path}.\")\n\n        with io.FileIO(file_path, \"wb\") as fh:\n            downloader = MediaIoBaseDownload(fh, request)\n            done = False\n            while not done:\n                status, done = downloader.next_chunk()\n                print(f\"Progress {file_name}: {int(status.progress() * 100)}%\", end=\"\\r\")\n            print()\n\n        checksum = calculate_sha256(file_path)\n        if checksum != checksums[file_name]:\n            print(\n                f\"Checksum mismatch for {file_name}. Expected {checksums[file_name]}, \"\n                f\"got {checksum}.\"\n            )\n            return\n        print(f\"Checksum OK for {file_name}.\")\n\n        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n            zip_ref.extractall(destination_dir)\n        print(f\"Unpacked {file_name}.\")\n</code></pre>"},{"location":"reference/flyvis_cli/download_pretrained_models/#flyvis_cli.download_pretrained_models.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main function to handle command line arguments and initiate the download process.</p> Source code in <code>flyvis_cli/download_pretrained_models.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"\n    Main function to handle command line arguments and initiate the download process.\n    \"\"\"\n    arg_parser = argparse.ArgumentParser(\n        description=\"Download pretrained models and UMAP clustering results. \"\n        \"This script downloads two ZIP files from Google Drive:\\n\"\n        \"1. results_pretrained_models.zip: Contains pretrained neural networks.\\n\"\n        \"2. results_umap_and_clustering.zip: Contains UMAP embeddings and \"\n        \"clustering.\\n\"\n        \"The files are downloaded and unpacked to the 'data' directory in the \"\n        \"project root.\",\n        formatter_class=argparse.RawTextHelpFormatter,\n        usage=(\n            \"\\nflyvis download-pretrained [-h] [--skip_large_files]\\n\"\n            \"       or\\n\"\n            \"%(prog)s [-h] [--skip_large_files]\\n\"\n        ),\n    )\n    arg_parser.add_argument(\n        \"--skip_large_files\",\n        action=\"store_true\",\n        help=\"Skip downloading large files. If set, only 'results_pretrained_models.zip' \"\n        \"will be downloaded, and 'results_umap_and_clustering.zip' will be skipped.\",\n    )\n    args, _ = arg_parser.parse_known_intermixed_args()\n\n    folder_id = \"15_8gPaVVJV6wGAspwkrdN8r-2NxMY4Kj\"\n    api_key = \"AIzaSyDOy2_N7B5UjxKy5Xxeyd9WZfnDWzQ4-54\"\n\n    download_and_unpack_files(folder_id, str(root_dir), api_key, args.skip_large_files)\n</code></pre>"},{"location":"reference/flyvis_cli/flyvis_cli/","title":"Command Line Interface Entry Point","text":""},{"location":"reference/flyvis_cli/flyvis_cli/#flyvis_cli.flyvis_cli","title":"flyvis_cli.flyvis_cli","text":"<p>CLI entry point and pipeline manager for ensemble operations.</p> Example usage <pre><code># Run a pipeline of operations\nflyvis         --ensemble_id 0001         --task_name flow         train         validate         record         analysis         notebook_per_model         notebook_per_ensemble\n</code></pre>"},{"location":"reference/flyvis_cli/flyvis_cli/#flyvis_cli.flyvis_cli.run_script","title":"run_script","text":"<pre><code>run_script(script_path, args)\n</code></pre> <p>Run a Python script with the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>script_path</code> <code>Path</code> <p>Path to the script to run.</p> required <code>args</code> <code>List[str]</code> <p>List of command-line arguments to pass to the script.</p> required Source code in <code>flyvis_cli/flyvis_cli.py</code> <pre><code>def run_script(script_path: Path, args: List[str]) -&gt; None:\n    \"\"\"\n    Run a Python script with the given arguments.\n\n    Args:\n        script_path: Path to the script to run.\n        args: List of command-line arguments to pass to the script.\n    \"\"\"\n    cmd = [sys.executable, str(script_path)] + args\n    try:\n        subprocess.run(cmd, check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"Error running {script_path}: {e}\", file=sys.stderr)\n        sys.exit(1)\n</code></pre>"},{"location":"reference/flyvis_cli/flyvis_cli/#flyvis_cli.flyvis_cli.filter_args","title":"filter_args","text":"<pre><code>filter_args(argv, allowed_commands)\n</code></pre> <p>Filter out commands from command line arguments.</p> <p>Parameters:</p> Name Type Description Default <code>argv</code> <code>List[str]</code> <p>List of command line arguments (typically sys.argv[1:])</p> required <code>commands</code> <p>List of commands to filter out</p> required <p>Returns:</p> Type Description <code>Tuple[List[str], List[str]]</code> <p>List of arguments with commands removed</p> Source code in <code>flyvis_cli/flyvis_cli.py</code> <pre><code>def filter_args(\n    argv: List[str], allowed_commands: List[str]\n) -&gt; Tuple[List[str], List[str]]:\n    \"\"\"\n    Filter out commands from command line arguments.\n\n    Args:\n        argv: List of command line arguments (typically sys.argv[1:])\n        commands: List of commands to filter out\n\n    Returns:\n        List of arguments with commands removed\n    \"\"\"\n    selected_commands = []\n    other_args = []\n    for arg in argv:\n        if arg in allowed_commands:\n            selected_commands.append(arg)\n        else:\n            other_args.append(arg)\n\n    return selected_commands, other_args\n</code></pre>"},{"location":"reference/flyvis_cli/flyvis_cli/#flyvis_cli.flyvis_cli.handle_help_request","title":"handle_help_request","text":"<pre><code>handle_help_request(argv)\n</code></pre> <p>Check if help is requested for a specific command and handle it.</p> <p>Parameters:</p> Name Type Description Default <code>argv</code> <code>List[str]</code> <p>Command line arguments (typically sys.argv)</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if help was handled, False otherwise</p> Source code in <code>flyvis_cli/flyvis_cli.py</code> <pre><code>def handle_help_request(argv: List[str]) -&gt; bool:\n    \"\"\"\n    Check if help is requested for a specific command and handle it.\n\n    Args:\n        argv: Command line arguments (typically sys.argv)\n\n    Returns:\n        True if help was handled, False otherwise\n    \"\"\"\n    if len(argv) &gt; 1 and argv[1] in SCRIPT_COMMANDS:\n        help_flags = {\"-h\", \"--help\"}\n        if any(flag in argv[2:] for flag in help_flags):\n            command = argv[1]\n            run_script(SCRIPT_COMMANDS[command], argv[2:])\n            return True\n    return False\n</code></pre>"},{"location":"reference/flyvis_cli/init_config/","title":"Initialize Configuration","text":"<pre><code>usage: init_config.py [-h] [--output-dir OUTPUT_DIR]\n                      [--config-groups [CONFIG_GROUPS ...]]\n\nInitialize a local config directory with defaults from the package\n\noptions:\n  -h, --help            show this help message and exit\n  --output-dir OUTPUT_DIR\n                        Directory where config should be initialized\n  --config-groups [CONFIG_GROUPS ...]\n                        Specific config groups to initialize (e.g.,\n                        network/edge_config/syn_strength). If none specified,\n                        copies all.\n</code></pre>"},{"location":"reference/flyvis_cli/init_config/#flyvis_cli.init_config","title":"flyvis_cli.init_config","text":""},{"location":"reference/flyvis_cli/init_config/#flyvis_cli.init_config.get_valid_config_groups","title":"get_valid_config_groups","text":"<pre><code>get_valid_config_groups(pkg_config_dir)\n</code></pre> <p>Get list of valid config groups from package config directory.</p> Source code in <code>flyvis_cli/init_config.py</code> <pre><code>def get_valid_config_groups(pkg_config_dir):\n    \"\"\"Get list of valid config groups from package config directory.\"\"\"\n    config_path = Path(pkg_config_dir)\n    valid_groups = []\n\n    for path in config_path.rglob('*.yaml'):\n        relative_path = path.relative_to(config_path)\n        group = str(relative_path.parent / relative_path.stem)\n        valid_groups.append(group)\n\n    return sorted(valid_groups)\n</code></pre>"},{"location":"reference/flyvis_cli/init_config/#flyvis_cli.init_config.init_config","title":"init_config","text":"<pre><code>init_config(args)\n</code></pre> <p>Initialize a local config directory with defaults from the package.</p> Source code in <code>flyvis_cli/init_config.py</code> <pre><code>def init_config(args):\n    \"\"\"Initialize a local config directory with defaults from the package.\"\"\"\n    pkg_config_dir = str(files('flyvis') / 'config')\n    output_path = Path(args.output_dir).resolve()\n    success = False\n\n    valid_groups = get_valid_config_groups(pkg_config_dir)\n\n    if not args.config_groups:\n        # Copy entire config structure contents to flyvis_config\n        config_path = output_path / 'flyvis_config'\n        config_path.mkdir(parents=True, exist_ok=True)\n\n        # Copy contents of pkg_config_dir to flyvis_config\n        for item in Path(pkg_config_dir).iterdir():\n            dst = config_path / item.name\n            if item.is_file():\n                shutil.copy2(item, dst)\n            else:\n                shutil.copytree(item, dst, dirs_exist_ok=True)\n\n        print(f\"Copied full config structure to {config_path.absolute()}\")\n        print(\n            \"Remember: When creating custom configs, use different names than the \"\n            \"defaults.\"\n        )\n        success = True\n    else:\n        # Copy only specified config groups\n        for group in args.config_groups:\n            # Strip leading 'config/' if present\n            group = group[7:] if group.startswith('config/') else group\n            src_path = Path(pkg_config_dir) / group\n            if not src_path.exists():\n                print(f\"Warning: Config group '{group}' not found in package\")\n                print(\"\\nValid config groups:\")\n                for valid_group in valid_groups:\n                    print(f\"  - {valid_group}\")\n                continue\n\n            dst_path = output_path / group\n            dst_path.parent.mkdir(parents=True, exist_ok=True)\n            if src_path.is_file():\n                shutil.copy2(src_path, dst_path)\n            else:\n                shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n\n            print(f\"Copied {group} to {dst_path.absolute()}.\")\n            print(\n                \"Remember: When creating custom configs, use different names than the \"\n                \"defaults\"\n            )\n            success = True\n\n    if not success:\n        print(\"\\nNo valid config groups were copied. Available config groups:\")\n        for group in valid_groups:\n            print(f\"  - {group}\")\n        raise ValueError(\"No valid config groups were found to copy\")\n\n    # Update README content with correct path and location\n    config_dir = '$(pwd)/flyvis_config' if not args.config_groups else '$(pwd)'\n    readme_path = (\n        output_path / ('flyvis_config' if not args.config_groups else '') / 'README.md'\n    )\n    readme_content = f\"\"\"# Custom FlyVis Configuration\n\nThis directory contains custom configurations for FlyVis. To use these configs:\n\nImportant: When creating custom configs, use different names than the defaults to\nensure proper override behavior.\nFor example:\n- Default: syn_strength.yaml\n- Custom: custom_syn_strength.yaml\n\nOverride specific configs:\n```bash\nflyvis train-single network/edge_config/syn_strength=custom_syn_strength --config-dir \\\n{config_dir}\n```\n\nThe directory structure mirrors the package config structure, allowing you to override\nspecific parts while keeping others at their defaults.\nNote that Hydra will look in the package's default config directory first, so your\ncustom configs must have different names.\n\"\"\"\n\n    readme_path.parent.mkdir(parents=True, exist_ok=True)\n    with open(readme_path, 'w') as f:\n        f.write(readme_content)\n\n    print(\n        f\"\\nConfig initialization complete! See {readme_path.absolute()} for usage \"\n        \"instructions.\"\n    )\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/analysis/","title":"Launch Ensemble Analysis on Compute Cloud","text":"<pre><code>usage:\nflyvis analysis [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [ensemble_analysis_script_options...]\n       or\nanalysis.py [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [ensemble_analysis_script_options...]\n\nFor a full list of options and default arguments, run: flyvis ensemble-analysis --help\n\nRun ensemble analysis on the compute cloud. Launches a single job to analyze all models in the ensemble.\n\noptions:\n  -h, --help            show this help message and exit\n  --nP NP               Number of processors to use (default: 4).\n  --gpu GPU             GPU configuration (default: 'num=1').\n  --q Q                 Queue to submit the job to.\n  --ensemble_id ENSEMBLE_ID\n                        ID of the ensemble, e.g., 0045.\n  --task_name TASK_NAME\n                        Name given to the task, e.g., 'flow', 'depth', 'lum'.\n  --ensemble_analysis_script ENSEMBLE_ANALYSIS_SCRIPT\n                        Script to run for ensemble analysis. Default: /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvis_cli/analysis/ensemble_analysis.py\n  --dry                 Perform a dry run without actually launching jobs.\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/analysis/#flyvis_cli.analysis.analysis","title":"flyvis_cli.analysis.analysis","text":"<p>Script to run ensemble analysis.</p>"},{"location":"reference/flyvis_cli/analysis/analysis/#flyvis_cli.analysis.analysis.run_ensemble_analysis","title":"run_ensemble_analysis","text":"<pre><code>run_ensemble_analysis(args, kwargs)\n</code></pre> <p>Launch ensemble analysis job.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Command-line arguments.</p> required <code>kwargs</code> <code>List[str]</code> <p>Additional keyword arguments as a list of strings.</p> required Source code in <code>flyvis_cli/analysis/analysis.py</code> <pre><code>def run_ensemble_analysis(args: argparse.Namespace, kwargs: List[str]) -&gt; None:\n    \"\"\"\n    Launch ensemble analysis job.\n\n    Args:\n        args: Command-line arguments.\n        kwargs: Additional keyword arguments as a list of strings.\n    \"\"\"\n    launch_single(\n        args.ensemble_id,\n        args.task_name,\n        args.nP,\n        args.gpu,\n        args.q,\n        args.ensemble_analysis_script,\n        args.dry,\n        kwargs,\n    )\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/ensemble_analysis/","title":"Run Ensemble Analysis","text":"<pre><code>usage:\nflyvis ensemble-analysis [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [ensemble_analysis_script_options...]\n       or\nensemble_analysis.py [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [hydra_options...]\n\nExample:\n    Compute UMAP and clustering for the ensemble 0000:\n    flyvis ensemble-analysis\n        task_name=flow\n        ensemble_and_network_id=0000/000\n        --functions umap_and_clustering_main\n\nAnalysis for ensemble.\n\noptions:\n  -h, --help            show this help message and exit\n  --validation_subdir VALIDATION_SUBDIR\n  --loss_file_name LOSS_FILE_NAME\n  --functions {umap_and_clustering_main} [{umap_and_clustering_main} ...]\n                        List of functions to run.\n  --delete_umap_and_clustering\n\nHybrid Arguments:\n  --task_name TASK_NAME\n                        task_name=value:  (Required)\n  --ensemble_id ENSEMBLE_ID\n                        ensemble_id=value:  (Required)\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/ensemble_analysis/#flyvis_cli.analysis.ensemble_analysis","title":"flyvis_cli.analysis.ensemble_analysis","text":"<p>Store analysis results of an ensemble.</p>"},{"location":"reference/flyvis_cli/analysis/notebook/","title":"Run Notebook","text":"<pre><code>usage:\nflyvis notebook [-h] --notebook_path PATH [options] [hybrid_args...]\n       or\nnotebook.py [-h] --notebook_path PATH [options] [hybrid_args...]\n\nThere are three modes of operation:\n1. Basic: Only requires --notebook_path\n2. Per-model: Requires --notebook_per_model_path, --notebook_per_model=true, --ensemble_and_network_id\n3. Per-ensemble: Requires --notebook_path, --per_ensemble=true, --task_name, --ensemble_id\n\nRun a Jupyter notebook using papermill. Required arguments depend on the specific notebook. Pass any additional arguments as key:type=value triplets.\n\noptions:\n  -h, --help            show this help message and exit\n  --notebook_path NOTEBOOK_PATH\n                        Path of the notebook to execute, e.g.\n                        /path/to/__main__.ipynb.\n  --notebook_per_model_path NOTEBOOK_PER_MODEL_PATH\n                        Path of the notebook to execute for each model, e.g.\n                        /path/to/__main_per_model__.ipynb.\n  --output_path OUTPUT_PATH\n                        Path for the output notebook. If not provided, a\n                        temporary file will be used and deleted after\n                        execution.\n  --dry                 Perform a dry run without actually executing the\n                        notebook.\n\nHybrid Arguments:\n  --notebook_per_model NOTEBOOK_PER_MODEL\n                        notebook_per_model=value: Flag to set the output path\n                        to the per-model notebook path. Requires\n                        ensemble_and_network_id. (type: bool)\n  --ensemble_and_network_id ENSEMBLE_AND_NETWORK_ID\n                        ensemble_and_network_id=value: Id in form of\n                        task_name/ensemble_id/network_id, e.g., flow/0000/000.\n                        Required if notebook_per_model is True. (type: str)\n  --per_ensemble PER_ENSEMBLE\n                        per_ensemble=value: Flag to set the output path to the\n                        per-ensemble notebook path. Requires ensemble_id and\n                        task_name. (type: bool)\n  --task_name TASK_NAME\n                        task_name=value: Name of the task, e.g. flow. Required\n                        if per_ensemble is True. (type: str)\n  --ensemble_id ENSEMBLE_ID\n                        ensemble_id=value: Id of the ensemble, e.g. 0045.\n                        Required if per_ensemble is True. (type: int)\n\n        Examples:\n            # Basic usage\n            flyvis notebook --notebook_path notebooks/analysis.ipynb\n            # Per-model analysis\n            flyvis notebook --notebook_per_model_path notebooks/per_model.ipynb \\\n                            notebook_per_model=true \\\n                            ensemble_and_network_id=flow/0045/000\n            # Per-ensemble analysis\n            flyvis notebook --notebook_path notebooks/ensemble.ipynb \\\n                            per_ensemble=true \\\n                            task_name=flow \\\n                            ensemble_id=45\n            # With additional parameters passed to the notebook\n            flyvis notebook --notebook_path notebooks/analysis.ipynb \\\n                            param1:str=value1 \\\n                            param2:int=42\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/notebook/#flyvis_cli.analysis.notebook","title":"flyvis_cli.analysis.notebook","text":"<p>Script to run a jupyter notebook for a particular model.</p>"},{"location":"reference/flyvis_cli/analysis/notebook_per_ensemble/","title":"Launch Notebook Per Ensemble on Compute Cloud","text":"<pre><code>usage:\nflyvis notebook-per-ensemble [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME --notebook_path PATH\n       or\nnotebook_per_ensemble.py [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME --notebook_path PATH\n\nRun ensemble notebook on the compute cloud.\n\noptions:\n  -h, --help            show this help message and exit\n  --nP NP               Number of processors.\n  --gpu GPU             Number of GPUs.\n  --q Q                 Queue.\n  --ensemble_id ENSEMBLE_ID\n                        Id of the ensemble, e.g. 0045.\n  --task_name TASK_NAME\n                        Name given to the task, e.g., flow.\n  --notebook_path NOTEBOOK_PATH\n                        Path of the notebook to execute. Default: /groups/tura\n                        ga/home/lappalainenj/FlyVis/private/flyvision/flyvis/a\n                        nalysis/__main__.ipynb\n  --dry                 Perform a dry run without actually launching jobs.\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/notebook_per_ensemble/#flyvis_cli.analysis.notebook_per_ensemble","title":"flyvis_cli.analysis.notebook_per_ensemble","text":"<p>Script to run a jupyter notebook for an ensemble.</p>"},{"location":"reference/flyvis_cli/analysis/notebook_per_ensemble/#flyvis_cli.analysis.notebook_per_ensemble.run_ensemble_notebook","title":"run_ensemble_notebook","text":"<pre><code>run_ensemble_notebook(args, kwargs)\n</code></pre> <p>Launch ensemble notebook job.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Command-line arguments.</p> required <code>kwargs</code> <code>List[str]</code> <p>Additional keyword arguments as a list of strings.</p> required Source code in <code>flyvis_cli/analysis/notebook_per_ensemble.py</code> <pre><code>def run_ensemble_notebook(args: argparse.Namespace, kwargs: List[str]) -&gt; None:\n    \"\"\"\n    Launch ensemble notebook job.\n\n    Args:\n        args: Command-line arguments.\n        kwargs: Additional keyword arguments as a list of strings.\n    \"\"\"\n    launch_single(\n        args.ensemble_id,\n        args.task_name,\n        args.nP,\n        args.gpu,\n        args.q,\n        str(NOTEBOOK_SCRIPT_DIR),\n        args.dry,\n        [\"--notebook_path\", args.notebook_path] + [\"per_ensemble:bool=true\"] + kwargs,\n    )\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/notebook_per_model/","title":"Launch Notebook Per Model on Compute Cloud","text":"<pre><code>usage:\nflyvis notebook-per-model [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME --notebook_per_model_path PATH\n       or\nnotebook_per_model.py [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME --notebook_per_model_path PATH\n\nRun a notebook for each model of an ensemble on the compute cloud.\n\noptions:\n  -h, --help            show this help message and exit\n  --start START         Start id of ensemble.\n  --end END             End id of ensemble.\n  --nP NP               Number of processors.\n  --gpu GPU             Number of GPUs.\n  --q Q                 Queue.\n  --ensemble_id ENSEMBLE_ID\n                        Id of the ensemble, e.g. 0045.\n  --task_name TASK_NAME\n                        Name given to the task, e.g., flow.\n  --notebook_per_model_path NOTEBOOK_PER_MODEL_PATH\n                        Path of the notebook to execute. Default: /groups/tura\n                        ga/home/lappalainenj/FlyVis/private/flyvision/flyvis/a\n                        nalysis/__main_per_model__.ipynb\n  --dry                 Perform a dry run without actually launching jobs.\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/notebook_per_model/#flyvis_cli.analysis.notebook_per_model","title":"flyvis_cli.analysis.notebook_per_model","text":"<p>Script to run a notebook for each model of an ensemble.</p>"},{"location":"reference/flyvis_cli/analysis/notebook_per_model/#flyvis_cli.analysis.notebook_per_model.run_notebook_ensemble","title":"run_notebook_ensemble","text":"<pre><code>run_notebook_ensemble(args, kwargs)\n</code></pre> <p>Launch notebook jobs for an ensemble of models.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Command-line arguments.</p> required <code>kwargs</code> <code>List[str]</code> <p>Additional keyword arguments as a list of strings.</p> required Source code in <code>flyvis_cli/analysis/notebook_per_model.py</code> <pre><code>def run_notebook_ensemble(args: argparse.Namespace, kwargs: List[str]) -&gt; None:\n    \"\"\"\n    Launch notebook jobs for an ensemble of models.\n\n    Args:\n        args: Command-line arguments.\n        kwargs: Additional keyword arguments as a list of strings.\n    \"\"\"\n    # remove conflicting argument\n    launch_range(\n        args.start,\n        args.end,\n        args.ensemble_id,\n        args.task_name,\n        args.nP,\n        args.gpu,\n        args.q,\n        str(NOTEBOOK_SCRIPT_DIR),\n        args.dry,\n        # add hybrid argument\n        [\"--notebook_per_model_path\", args.notebook_per_model_path]\n        + [\"notebook_per_model:bool=true\"]\n        + kwargs,\n    )\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/record/","title":"Launch Synthetic Recordings on Compute Cloud","text":"<pre><code>usage:\nflyvis record [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [options] [synthetic_recordings_script_args...]\n       or\nrecord.py [-h] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [options] [synthetic_recordings_script_args...]\n\nFor a full list of options and default arguments, run: flyvis synthetic-recordings-single --help\n\nRun synthetic recordings for each model of an ensemble on the compute cloud.\n\noptions:\n  -h, --help            show this help message and exit\n  --start START         Start id of ensemble.\n  --end END             End id of ensemble.\n  --nP NP               Number of processors.\n  --gpu GPU             Number of GPUs.\n  --q Q                 Queue.\n  --ensemble_id ENSEMBLE_ID\n                        Id of the ensemble, e.g. 0045.\n  --task_name TASK_NAME\n                        Name given to the task, e.g., flow.\n  --synthetic_recordings_script SYNTHETIC_RECORDINGS_SCRIPT\n                        Script to run for synthetic recordings. Default: /grou\n                        ps/turaga/home/lappalainenj/FlyVis/private/flyvision/f\n                        lyvis_cli/analysis/synthetic_recordings_single.py\n  --dry                 Perform a dry run without actually launching jobs.\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/record/#flyvis_cli.analysis.record","title":"flyvis_cli.analysis.record","text":"<p>Script to run synthetic recordings for each model of an ensemble.</p>"},{"location":"reference/flyvis_cli/analysis/record/#flyvis_cli.analysis.record.run_synthetic_recordings","title":"run_synthetic_recordings","text":"<pre><code>run_synthetic_recordings(args, kwargs)\n</code></pre> <p>Launch synthetic recording job for each model of an ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Command-line arguments.</p> required <code>kwargs</code> <code>List[str]</code> <p>Additional keyword arguments as a list of strings.</p> required Source code in <code>flyvis_cli/analysis/record.py</code> <pre><code>def run_synthetic_recordings(args: argparse.Namespace, kwargs: List[str]) -&gt; None:\n    \"\"\"\n    Launch synthetic recording job for each model of an ensemble.\n\n    Args:\n        args: Command-line arguments.\n        kwargs: Additional keyword arguments as a list of strings.\n    \"\"\"\n    launch_range(\n        args.start,\n        args.end,\n        args.ensemble_id,\n        args.task_name,\n        args.nP,\n        args.gpu,\n        args.q,\n        args.synthetic_recordings_script,\n        args.dry,\n        kwargs,\n    )\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/synthetic_recordings_single/","title":"Run Synthetic Recordings","text":"<pre><code>usage:\nflyvis synthetic-recordings [-h] task_name=TASK ensemble_and_network_id=XXXX/YYY [options]\n       or\nsynthetic_recordings_single.py [-h] task_name=TASK ensemble_and_network_id=XXXX/YYY [options]\n\nThis script generates and stores various types of synthetic responses for a given network, such as flash responses, moving edge responses, and impulse responses. The responses are automatically cached for later use in analysis.\n\noptions:\n  -h, --help            show this help message and exit\n  --validation_subdir VALIDATION_SUBDIR\n  --loss_file_name LOSS_FILE_NAME\n  --batch_size BATCH_SIZE\n  --delete_recordings\n  --functions FUNCTIONS [FUNCTIONS ...]\n                        List of functions to run.\n\nHybrid Arguments:\n  --task_name TASK_NAME\n                        task_name=value: Name of the task (e.g., 'flow',\n                        'depth') (Required)\n  --ensemble_and_network_id ENSEMBLE_AND_NETWORK_ID\n                        ensemble_and_network_id=value: ID in the format\n                        XXXX/YYY (ensemble/network) (Required)\n\nExamples:\n--------\n1. Generate all default synthetic recordings:\n   flyvis synthetic-recordings task_name=flow ensemble_and_network_id=0000/000\n\n2. Generate only specific response types:\n   flyvis synthetic-recordings task_name=flow ensemble_and_network_id=0000/000 \\\n       --functions spatial_impulses_responses central_impulses_responses\n\n3. Generate with custom batch size and clear existing recordings:\n   flyvis synthetic-recordings task_name=flow ensemble_and_network_id=0000/000 \\\n       --batch_size 16 --delete_recordings\n</code></pre>"},{"location":"reference/flyvis_cli/analysis/synthetic_recordings_single/#flyvis_cli.analysis.synthetic_recordings_single","title":"flyvis_cli.analysis.synthetic_recordings_single","text":"<p>Script for precomputing synthetic recordings for a single network.</p>"},{"location":"reference/flyvis_cli/training/train/","title":"Launch Ensemble Training on Compute Cloud","text":"<pre><code>usage:\nflyvis train [-h] [--start START] [--end END] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [hydra_options...]\n       or\ntrain.py [-h] [--start START] [--end END] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [hydra_options...]\n\nFor a full list of hydra options and default arguments, run: flyvis train-single --help\n\nTrain an ensemble of models. Launches a job for each model on the compute cloud.\n\noptions:\n  -h, --help            show this help message and exit\n  --start START         Start id of ensemble.\n  --end END             End id of ensemble.\n  --nP NP               Number of processors.\n  --gpu GPU             Number of GPUs.\n  --q Q                 Queue.\n  --ensemble_id ENSEMBLE_ID\n                        Id of the ensemble, e.g. 0045.\n  --task_name TASK_NAME\n                        Name given to the task, e.g., flow.\n  --train_script TRAIN_SCRIPT\n                        Script to run for training. Default: /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvis_cli/training/train_single.py\n  --dry                 Perform a dry run without actually launching jobs.\n</code></pre>"},{"location":"reference/flyvis_cli/training/train/#flyvis_cli.training.train","title":"flyvis_cli.training.train","text":"<p>Script to train an ensemble of models.</p>"},{"location":"reference/flyvis_cli/training/train/#flyvis_cli.training.train.train_models","title":"train_models","text":"<pre><code>train_models(args, kwargs)\n</code></pre> <p>Launch training jobs for an ensemble of models.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Command-line arguments.</p> required <code>kwargs</code> <code>List[str]</code> <p>Additional keyword arguments as a list of strings.</p> required Source code in <code>flyvis_cli/training/train.py</code> <pre><code>def train_models(args: argparse.Namespace, kwargs: List[str]) -&gt; None:\n    \"\"\"\n    Launch training jobs for an ensemble of models.\n\n    Args:\n        args: Command-line arguments.\n        kwargs: Additional keyword arguments as a list of strings.\n    \"\"\"\n    launch_range(\n        args.start,\n        args.end,\n        args.ensemble_id,\n        args.task_name,\n        args.nP,\n        args.gpu,\n        args.q,\n        args.train_script,\n        args.dry,\n        kwargs,\n    )\n</code></pre>"},{"location":"reference/flyvis_cli/training/train_single/","title":"Run Training for Single Model","text":"<pre><code>== train single flyvis network ==\n\nTrain the visual system model using the specified configuration.\n\n  This script initializes and runs the training process for the model.\n  It uses the configuration provided through Hydra to set up the solver, manage the\n  training process, and handle checkpoints.\n\n  Example:\n      Train a network for 1000 iterations (and add description 'test'):\n\n      flyvis train-single \\\n          ensemble_and_network_id=0045/000 \\\n          task_name=flow \\\n          train=true \\\n          resume=false \\\n          task.n_iters=1000\n          description='test'\n\n      or\n\n      python train_single.py \\\n          ensemble_and_network_id=0045/000 \\\n          task_name=flow \\\n          train=true \\\n          resume=false \\\n          task.n_iters=1000 \\\n          description='test'\n\n\n  High-level options:\n\n    - train (bool): Whether to run the training process\n    - resume (bool): Whether to resume training from the last checkpoint\n    - overfit (bool): Whether to use overfitting mode in training\n    - checkpoint_only (bool): Whether to create a checkpoint without training\n    - save_environment (bool): Whether to save the source code and environment details\n\n== Configuration groups ==\nCompose your configuration from those groups (group=option)\n\nnetwork: network\nnetwork/connectome: connectome\nnetwork/dynamics: dynamics\nnetwork/edge_config: edge_config\nnetwork/edge_config/sign: sign\nnetwork/edge_config/syn_count: syn_count\nnetwork/edge_config/syn_strength: syn_strength\nnetwork/node_config: node_config\nnetwork/node_config/bias: bias\nnetwork/node_config/time_const: time_const\nnetwork/stimulus_config: stimulus_config\noptim: optim\npenalizer: penalizer\nscheduler: scheduler\ntask: task\n\n\n== Config ==\nOverride anything in the config (foo.bar=value)\n\nensemble_and_network_id: ???\ntask_name: ???\ntrain: true\nresume: false\ncheckpoint_only: false\nnetwork_name: ${task_name}/${ensemble_and_network_id}\ndescription: ???\noverfit: false\ndelete_if_exists: false\nsave_environment: false\nnetwork:\n  connectome:\n    type: ConnectomeFromAvgFilters\n    file: fib25-fib19_v2.2.json\n    extent: 15\n    n_syn_fill: 1\n  dynamics:\n    type: PPNeuronIGRSynapses\n    activation:\n      type: relu\n  edge_config:\n    sign:\n      type: SynapseSign\n      form: value\n      requires_grad: false\n      initial_dist: Value\n      groupby:\n      - source_type\n      - target_type\n    syn_count:\n      type: SynapseCount\n      initial_dist: Lognormal\n      mode: mean\n      requires_grad: false\n      std: 1.0\n      groupby:\n      - source_type\n      - target_type\n      - dv\n      - du\n      penalize:\n        function: weight_decay\n        kwargs:\n          lambda: 0\n    syn_strength:\n      type: SynapseCountScaling\n      initial_dist: Value\n      requires_grad: true\n      scale: 0.01\n      clamp: non_negative\n      groupby:\n      - source_type\n      - target_type\n      penalize:\n        function: weight_decay\n        kwargs:\n          lambda: 0\n  node_config:\n    bias:\n      type: RestingPotential\n      groupby:\n      - type\n      initial_dist: Normal\n      mode: sample\n      requires_grad: true\n      seed: 0\n      mean: 0.5\n      std: 0.05\n      symmetric: []\n      penalize:\n        activity: true\n    time_const:\n      type: TimeConstant\n      groupby:\n      - type\n      initial_dist: Value\n      value: 0.05\n      requires_grad: true\n  stimulus_config:\n    type: Stimulus\n    init_buffer: false\ntask:\n  dataset:\n    type: MultiTaskSintel\n    tasks:\n    - flow\n    boxfilter:\n      extent: 15\n      kernel_size: 13\n    vertical_splits: 3\n    n_frames: 19\n    center_crop_fraction: 0.7\n    dt: 0.02\n    augment: true\n    random_temporal_crop: true\n    all_frames: false\n    resampling: true\n    interpolate: true\n    p_flip: 0.5\n    p_rot: 0.5\n    contrast_std: 0.2\n    brightness_std: 0.1\n    gaussian_white_noise: 0.08\n    gamma_std: null\n    _init_cache: true\n    unittest: false\n    flip_axes:\n    - 0\n    - 1\n    - 2\n    - 3\n  decoder:\n    flow:\n      type: DecoderGAVP\n      shape:\n      - 8\n      - 2\n      kernel_size: 5\n      const_weight: 0.001\n      n_out_features: null\n      p_dropout: 0.5\n  loss:\n    flow: l2norm\n  task_weights: null\n  batch_size: 4\n  n_iters: 250000\n  n_folds: 4\n  fold: 1\n  seed: 0\n  original_split: true\noptim:\n  type: Adam\n  optim_dec:\n    lr: ${scheduler.lr_dec.start}\n  optim_net:\n    lr: ${scheduler.lr_net.start}\npenalizer:\n  activity_penalty:\n    activity_baseline: 5.0\n    activity_penalty: 0.1\n    stop_iter: 150000\n    below_baseline_penalty_weight: 1.0\n    above_baseline_penalty_weight: 0.1\n  optim: SGD\nscheduler:\n  lr_net:\n    function: stepwise\n    start: 5.0e-05\n    stop: 5.0e-06\n    steps: 10\n  lr_dec:\n    function: stepwise\n    start: 5.0e-05\n    stop: 5.0e-06\n    steps: 10\n  lr_pen:\n    function: stepwise\n    start: ${scheduler.lr_net.start}\n    stop: ${scheduler.lr_net.stop}\n    steps: 10\n  dt:\n    function: stepwise\n    start: 0.02\n    stop: 0.02\n    steps: 10\n  chkpt_every_epoch: 300\n\n\nPowered by Hydra (https://hydra.cc)\nUse --hydra-help to view Hydra specific help\n</code></pre>"},{"location":"reference/flyvis_cli/training/train_single/#flyvis_cli.training.train_single","title":"flyvis_cli.training.train_single","text":"<p>Train the visual system model using the specified configuration.</p> <p>This script initializes and runs the training process for the model. It uses the configuration provided through Hydra to set up the solver, manage the training process, and handle checkpoints.</p> <p>Key option defaults:</p> <ul> <li><code>train=true</code>: Whether to run the training process</li> <li><code>resume=false</code>: Whether to resume training from the last checkpoint</li> <li><code>overfit=false</code>: Whether to use overfitting mode in training</li> <li><code>checkpoint_only=false</code>: Whether to create a checkpoint without training</li> <li><code>save_environment=false</code>: Whether to save the source code and environment details</li> </ul> Example <p>Train a network for 1000 iterations and describe it as \u2018test\u2019: <pre><code>$ python train.py         ensemble_and_network_id=0045/000         task_name=flow         train=true         resume=false         task.n_iters=1000\n    description='test'\n</code></pre></p>"},{"location":"reference/flyvis_cli/validation/val_single/","title":"Run Validation for Single Model","text":"<pre><code>usage:\nflyvis val-single [-h] task_name=TASK ensemble_and_network_id=XXXX/YYY\n       or\nval_single.py [-h] task_name=TASK ensemble_and_network_id=XXXX/YYY\n\nValidate a single network across all its checkpoints. Computes and stores validation metrics in the network's validation directory.\n\noptions:\n  -h, --help            show this help message and exit\n\nHybrid Arguments:\n  --ensemble_and_network_id ENSEMBLE_AND_NETWORK_ID\n                        ensemble_and_network_id=value: ID of the ensemble and\n                        network to use, e.g. 0045/000 (Required)\n  --task_name TASK_NAME\n                        task_name=value: Name of the task. Resulting network\n                        name will be task_name/ensemble_and_network_id.\n                        (Required)\n\nExamples:\n--------\n1. Validate a specific network:\n    flyvis val-single task_name=flow ensemble_and_network_id=0045/000\n\n2. Validate a network from a different task:\n    flyvis val-single task_name=depth ensemble_and_network_id=0023/012\n</code></pre>"},{"location":"reference/flyvis_cli/validation/val_single/#flyvis_cli.validation.val_single","title":"flyvis_cli.validation.val_single","text":"<p>Script to validate a single network across all its checkpoints.</p>"},{"location":"reference/flyvis_cli/validation/validate/","title":"Launch Ensemble Validation on Compute Cloud","text":"<pre><code>usage:\nflyvis validate [-h] [--start START] [--end END] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [additional_options...]\n       or\nvalidate.py [-h] [--start START] [--end END] [...] --ensemble_id ENSEMBLE_ID --task_name TASK_NAME [additional_options...]\n\nFor a full list of validation options and default arguments, run: flyvis val_single --help\n\nValidate each model of an ensemble on the compute cloud.\n\noptions:\n  -h, --help            show this help message and exit\n  --start START         Start id of ensemble.\n  --end END             End id of ensemble.\n  --nP NP               Number of processors.\n  --gpu GPU             Number of GPUs.\n  --q Q                 Queue.\n  --ensemble_id ENSEMBLE_ID\n                        Id of the ensemble, e.g. 0045.\n  --task_name TASK_NAME\n                        Name given to the task, e.g., flow.\n  --val_script VAL_SCRIPT\n                        Script to run for validation. Default: /groups/turaga/home/lappalainenj/FlyVis/private/flyvision/flyvis_cli/validation/val_single.py\n  --dry                 Perform a dry run without actually launching jobs.\n</code></pre>"},{"location":"reference/flyvis_cli/validation/validate/#flyvis_cli.validation.validate","title":"flyvis_cli.validation.validate","text":"<p>Script to validate an each model of an ensemble on the compute cloud.</p>"},{"location":"reference/flyvis_cli/validation/validate/#flyvis_cli.validation.validate.validate_models","title":"validate_models","text":"<pre><code>validate_models(args, kwargs)\n</code></pre> <p>Launch validation jobs for an ensemble of models.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Command-line arguments.</p> required <code>kwargs</code> <code>List[str]</code> <p>Additional keyword arguments as a list of strings.</p> required Source code in <code>flyvis_cli/validation/validate.py</code> <pre><code>def validate_models(args: argparse.Namespace, kwargs: List[str]) -&gt; None:\n    \"\"\"\n    Launch validation jobs for an ensemble of models.\n\n    Args:\n        args: Command-line arguments.\n        kwargs: Additional keyword arguments as a list of strings.\n    \"\"\"\n    launch_range(\n        args.start,\n        args.end,\n        args.ensemble_id,\n        args.task_name,\n        args.nP,\n        args.gpu,\n        args.q,\n        args.val_script,\n        args.dry,\n        kwargs,\n    )\n</code></pre>"}]}